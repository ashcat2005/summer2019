Using TensorFlow backend.
WARNING:tensorflow:From /n/home00/nchou/.conda/envs/envi/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.
Instructions for updating:
Colocations handled automatically by placer.
WARNING:tensorflow:From /n/home00/nchou/.conda/envs/envi/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.cast instead.
2019-08-06 14:57:32.861511: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-08-06 14:57:32.885022: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2095255000 Hz
2019-08-06 14:57:32.885454: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x55738e35af30 executing computations on platform Host. Devices:
2019-08-06 14:57:32.885502: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (0): <undefined>, <undefined>
0
286
57
1
16
3
2
76
15
3
18
3
4
9
3
Train on 1000 samples, validate on 1000 samples
Epoch 1/35

1000/1000 [==============================] - 355s 355ms/step - loss: 1.6103 - acc: 0.2240 - val_loss: 1.5479 - val_acc: 0.2880
Epoch 2/35

1000/1000 [==============================] - 324s 324ms/step - loss: 1.4886 - acc: 0.5120 - val_loss: 1.4791 - val_acc: 0.2980
Epoch 3/35

1000/1000 [==============================] - 321s 321ms/step - loss: 1.3320 - acc: 0.5680 - val_loss: 1.4349 - val_acc: 0.4260
Epoch 4/35

1000/1000 [==============================] - 324s 324ms/step - loss: 1.2005 - acc: 0.7450 - val_loss: 1.4297 - val_acc: 0.3870
Epoch 5/35

1000/1000 [==============================] - 325s 325ms/step - loss: 1.0997 - acc: 0.5980 - val_loss: 1.4205 - val_acc: 0.4250
Epoch 6/35

1000/1000 [==============================] - 329s 329ms/step - loss: 1.0164 - acc: 0.7660 - val_loss: 1.4224 - val_acc: 0.4000
Epoch 7/35

1000/1000 [==============================] - 317s 317ms/step - loss: 0.9280 - acc: 0.6970 - val_loss: 1.4327 - val_acc: 0.4070
Epoch 8/35

1000/1000 [==============================] - 327s 327ms/step - loss: 0.8556 - acc: 0.7080 - val_loss: 1.4335 - val_acc: 0.4420
Epoch 9/35

1000/1000 [==============================] - 326s 326ms/step - loss: 0.8084 - acc: 0.8080 - val_loss: 1.5037 - val_acc: 0.4010
Epoch 10/35

1000/1000 [==============================] - 324s 324ms/step - loss: 0.7562 - acc: 0.7160 - val_loss: 1.4497 - val_acc: 0.4340
Epoch 11/35

1000/1000 [==============================] - 323s 323ms/step - loss: 0.6906 - acc: 0.7910 - val_loss: 1.4811 - val_acc: 0.4390
Epoch 12/35

1000/1000 [==============================] - 332s 332ms/step - loss: 0.6439 - acc: 0.7940 - val_loss: 1.5455 - val_acc: 0.4340
Epoch 13/35

1000/1000 [==============================] - 331s 331ms/step - loss: 0.6087 - acc: 0.7620 - val_loss: 1.5082 - val_acc: 0.4670
Epoch 14/35

1000/1000 [==============================] - 323s 323ms/step - loss: 0.5668 - acc: 0.8310 - val_loss: 1.5280 - val_acc: 0.4770
Epoch 15/35

1000/1000 [==============================] - 323s 323ms/step - loss: 0.5285 - acc: 0.8370 - val_loss: 1.5858 - val_acc: 0.4690
Epoch 16/35

1000/1000 [==============================] - 325s 325ms/step - loss: 0.5043 - acc: 0.8150 - val_loss: 1.5611 - val_acc: 0.4950
Epoch 17/35

1000/1000 [==============================] - 326s 326ms/step - loss: 0.4710 - acc: 0.8620 - val_loss: 1.5769 - val_acc: 0.4900
Epoch 18/35

1000/1000 [==============================] - 320s 320ms/step - loss: 0.4456 - acc: 0.8630 - val_loss: 1.6333 - val_acc: 0.4890
Epoch 19/35

1000/1000 [==============================] - 328s 328ms/step - loss: 0.4253 - acc: 0.8520 - val_loss: 1.6022 - val_acc: 0.5130
Epoch 20/35

1000/1000 [==============================] - 331s 331ms/step - loss: 0.3987 - acc: 0.8700 - val_loss: 1.6227 - val_acc: 0.5140
Epoch 21/35

1000/1000 [==============================] - 323s 323ms/step - loss: 0.3757 - acc: 0.8780 - val_loss: 1.6749 - val_acc: 0.4980
Epoch 22/35

1000/1000 [==============================] - 322s 322ms/step - loss: 0.3590 - acc: 0.8840 - val_loss: 1.6408 - val_acc: 0.5100
Epoch 23/35

1000/1000 [==============================] - 325s 325ms/step - loss: 0.3388 - acc: 0.8910 - val_loss: 1.6658 - val_acc: 0.5150
Epoch 24/35

1000/1000 [==============================] - 326s 326ms/step - loss: 0.3177 - acc: 0.8980 - val_loss: 1.6950 - val_acc: 0.5260
Epoch 25/35

1000/1000 [==============================] - 322s 322ms/step - loss: 0.3030 - acc: 0.9020 - val_loss: 1.6721 - val_acc: 0.5250
Epoch 26/35

1000/1000 [==============================] - 328s 328ms/step - loss: 0.2874 - acc: 0.9230 - val_loss: 1.7090 - val_acc: 0.5260
Epoch 27/35

1000/1000 [==============================] - 331s 331ms/step - loss: 0.2710 - acc: 0.9150 - val_loss: 1.7076 - val_acc: 0.5230
Epoch 28/35

1000/1000 [==============================] - 325s 325ms/step - loss: 0.2567 - acc: 0.9260 - val_loss: 1.7014 - val_acc: 0.5310
Epoch 29/35

1000/1000 [==============================] - 321s 321ms/step - loss: 0.2436 - acc: 0.9460 - val_loss: 1.7518 - val_acc: 0.5300
Epoch 30/35

1000/1000 [==============================] - 328s 328ms/step - loss: 0.2324 - acc: 0.9300 - val_loss: 1.7232 - val_acc: 0.5410
Epoch 31/35

1000/1000 [==============================] - 332s 332ms/step - loss: 0.2190 - acc: 0.9590 - val_loss: 1.7446 - val_acc: 0.5280
Epoch 32/35

1000/1000 [==============================] - 331s 331ms/step - loss: 0.2070 - acc: 0.9480 - val_loss: 1.7591 - val_acc: 0.5280
Epoch 33/35

1000/1000 [==============================] - 333s 333ms/step - loss: 0.1966 - acc: 0.9510 - val_loss: 1.7440 - val_acc: 0.5600
Epoch 34/35

1000/1000 [==============================] - 335s 335ms/step - loss: 0.1872 - acc: 0.9780 - val_loss: 1.7961 - val_acc: 0.5350
Epoch 35/35

1000/1000 [==============================] - 327s 327ms/step - loss: 0.1780 - acc: 0.9560 - val_loss: 1.7658 - val_acc: 0.5680
[[1.3158336e-01 4.5504946e-02 1.3722032e-01 3.3872381e-01 3.4696755e-01]
 [6.4875591e-01 5.6586810e-04 2.4734922e-02 3.0348262e-01 2.2460636e-02]
 [3.3061292e-02 4.2299934e-02 6.2083300e-02 4.9217042e-01 3.7038496e-01]
 ...
 [3.6570355e-02 2.5071062e-02 4.1122608e-02 2.4844755e-01 6.4878845e-01]
 [1.1363320e-06 4.3573626e-05 9.9995518e-01 1.5177723e-10 6.9617599e-08]
 [4.2759322e-02 1.6245776e-01 7.9478198e-01 3.5700538e-07 5.2290505e-07]]
[4 0 3 4 1 3 4 3 4 4 4 4 3 3 4 2 0 3 4 3 2 1 4 3 0 3 2 3 3 3 4 4 4 4 3 2 2
 4 0 4 4 2 2 4 3 4 0 3 4 3 4 0 1 4 4 0 3 4 0 3 3 2 4 4 0 4 0 4 2 0 4 2 4 2
 4 2 4 4 3 2 4 4 0 1 4 4 4 4 3 2 2 2 0 4 3 3 1 2 3 2 0 2 3 4 0 1 3 3 1 2 4
 3 2 3 3 3 3 2 0 3 2 1 2 4 3 3 1 3 4 0 2 2 1 3 0 0 3 4 1 0 1 4 3 4 0 4 2 4
 4 1 4 3 1 3 4 2 1 0 4 0 4 4 3 3 4 3 0 3 0 0 3 4 1 4 0 3 3 3 3 3 2 4 3 3 4
 3 3 3 3 0 3 3 1 3 2 4 2 2 1 3 2 3 3 4 4 2 3 0 3 3 4 3 4 3 2 0 1 3 3 3 3 3
 3 4 1 0 3 3 4 0 2 2 1 3 3 2 4 0 0 4 0 4 0 0 0 2 3 0 4 4 4 4 3 1 3 1 3 0 3
 1 3 4 1 2 2 4 0 1 3 3 4 0 3 4 2 2 4 4 0 3 3 4 2 3 2 3 4 2 4 2 3 4 3 3 4 2
 3 3 2 4 0 1 4 4 0 2 2 4 4 3 1 3 3 1 4 0 2 0 4 3 3 0 4 4 2 4 3 2 4 3 4 3 3
 4 3 4 4 3 4 4 4 3 3 4 4 3 0 4 2 2 4 4 3 1 0 3 2 4 4 4 3 3 4 0 3 4 2 0 4 2
 1 2 4 0 0 3 3 3 4 3 1 4 4 3 3 1 2 2 0 0 3 0 2 4 1 0 0 4 3 3 4 4 3 3 4 4 3
 4 3 2 4 4 1 2 3 4 2 0 4 2 2 3 4 3 1 4 1 2 0 3 0 1 2 2 0 0 3 4 3 4 3 3 0 2
 2 3 3 2 4 2 2 4 4 3 1 1 4 3 4 3 4 2 4 2 3 0 1 0 1 0 4 3 3 1 4 3 0 2 2 1 1
 3 1 0 2 4 3 3 0 2 4 3 3 0 1 3 0 4 0 3 2 2 1 1 4 3 4 0 0 2 0 3 2 1 2 4 4 2
 4 3 2 0 1 3 4 1 4 4 0 2 3 4 4 3 1 2 4 0 3 4 3 3 1 2 3 1 3 4 3 3 4 4 3 0 4
 0 4 4 3 4 4 3 4 3 3 3 3 3 4 1 0 1 4 0 4 3 4 2 2 4 2 2 4 1 2 4 4 2 0 3 3 4
 0 3 3 4 4 4 2 4 0 3 4 1 4 0 0 4 4 1 4 3 2 4 4 3 3 2 1 2 2 4 4 4 0 4 4 4 4
 4 0 3 4 2 4 3 4 4 4 3 0 3 3 3 1 4 0 2 3 4 1 3 1 3 3 3 4 0 3 0 1 4 1 0 0 0
 2 3 3 3 4 3 3 3 4 2 0 3 2 0 4 3 4 3 2 2 4 4 4 3 0 0 3 3 0 3 3 4 3 4 4 2 3
 2 4 4 3 3 3 0 0 0 4 0 4 2 3 4 4 3 4 0 1 0 0 4 3 3 0 1 0 3 1 3 3 2 3 4 3 4
 3 4 2 1 3 4 3 4 3 4 3 4 2 3 3 2 4 3 0 4 2 4 3 4 0 2 3 3 3 1 2 4 0 4 4 4 3
 2 3 0 3 4 2 1 3 3 4 3 3 4 3 0 4 1 4 0 4 3 2 4 0 4 3 3 2 3 0 0 2 3 3 4 3 3
 3 1 4 4 2 3 3 4 4 0 1 4 4 1 2 2 0 3 4 2 4 3 4 1 3 4 4 3 4 3 3 0 2 4 1 0 4
 0 3 2 4 4 3 1 4 3 3 3 2 4 4 1 2 3 1 4 3 4 3 1 3 4 4 2 3 4 4 2 3 2 3 3 2 4
 2 3 4 1 2 4 1 2 4 4 3 0 0 2 3 0 3 1 2 4 4 2 3 3 2 4 4 4 1 3 4 0 2 0 4 3 3
 2 2 3 4 4 4 0 0 0 3 4 4 3 2 2 4 3 3 1 3 3 4 4 0 0 0 4 3 2 4 1 1 0 3 4 4 0
 3 3 0 3 2 3 4 4 1 3 3 2 4 3 3 1 3 3 4 3 0 4 1 0 2 3 1 0 4 1 4 2 4 1 4 4 2
 2]

  32/1000 [..............................] - ETA: 1:18
  64/1000 [>.............................] - ETA: 1:15
  96/1000 [=>............................] - ETA: 1:13
 128/1000 [==>...........................] - ETA: 1:10
 160/1000 [===>..........................] - ETA: 1:08
 192/1000 [====>.........................] - ETA: 1:05
 224/1000 [=====>........................] - ETA: 1:03
 256/1000 [======>.......................] - ETA: 1:01
 288/1000 [=======>......................] - ETA: 59s 
 320/1000 [========>.....................] - ETA: 57s
 352/1000 [=========>....................] - ETA: 55s
 384/1000 [==========>...................] - ETA: 52s
 416/1000 [===========>..................] - ETA: 49s
 448/1000 [============>.................] - ETA: 47s
 480/1000 [=============>................] - ETA: 44s
 512/1000 [==============>...............] - ETA: 41s
 544/1000 [===============>..............] - ETA: 39s
 576/1000 [================>.............] - ETA: 36s
 608/1000 [=================>............] - ETA: 33s
 640/1000 [==================>...........] - ETA: 30s
 672/1000 [===================>..........] - ETA: 27s
 704/1000 [====================>.........] - ETA: 25s
 736/1000 [=====================>........] - ETA: 22s
 768/1000 [======================>.......] - ETA: 19s
 800/1000 [=======================>......] - ETA: 16s
 832/1000 [=======================>......] - ETA: 14s
 864/1000 [========================>.....] - ETA: 11s
 896/1000 [=========================>....] - ETA: 8s 
 928/1000 [==========================>...] - ETA: 6s
 960/1000 [===========================>..] - ETA: 3s
 992/1000 [============================>.] - ETA: 0s
1000/1000 [==============================] - 84s 84ms/step
Test loss: 2.093983564376831
Test accuracy: 0.546
[[ 77  19  48  38  18]
 [ 20  61   2 103  14]
 [ 37  15  97  50   1]
 [  9   0   9 111  71]
 [  0   0   0   0 200]]
