Using TensorFlow backend.
WARNING:tensorflow:From /n/home00/nchou/.conda/envs/envi/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.
Instructions for updating:
Colocations handled automatically by placer.
cnn_aardvark_aug_concat.py:326: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor("in..., outputs=Tensor("de...)`
  model = Model(input=ins, output=dense2)
WARNING:tensorflow:From /n/home00/nchou/.conda/envs/envi/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.cast instead.
2019-11-01 06:41:46.651233: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
2019-11-01 06:41:46.810306: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2900000000 Hz
2019-11-01 06:41:46.810573: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x55644d30cd30 executing computations on platform Host. Devices:
2019-11-01 06:41:46.810624: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (0): <undefined>, <undefined>
Train on 1000 samples, validate on 1000 samples
Epoch 1/35

1000/1000 [==============================] - 108s 108ms/step - loss: 1.6141 - acc: 0.1900 - val_loss: 1.6048 - val_acc: 0.2380
Epoch 2/35

1000/1000 [==============================] - 103s 103ms/step - loss: 1.5951 - acc: 0.3300 - val_loss: 1.5969 - val_acc: 0.2430
Epoch 3/35

1000/1000 [==============================] - 102s 102ms/step - loss: 1.5741 - acc: 0.4020 - val_loss: 1.5890 - val_acc: 0.1910
Epoch 4/35

1000/1000 [==============================] - 102s 102ms/step - loss: 1.5526 - acc: 0.3860 - val_loss: 1.5815 - val_acc: 0.1870
Epoch 5/35

1000/1000 [==============================] - 102s 102ms/step - loss: 1.5313 - acc: 0.3760 - val_loss: 1.5742 - val_acc: 0.1810
Epoch 6/35

1000/1000 [==============================] - 101s 101ms/step - loss: 1.5100 - acc: 0.3740 - val_loss: 1.5673 - val_acc: 0.1900
Epoch 7/35

1000/1000 [==============================] - 101s 101ms/step - loss: 1.4888 - acc: 0.3840 - val_loss: 1.5608 - val_acc: 0.1970
Epoch 8/35

1000/1000 [==============================] - 101s 101ms/step - loss: 1.4677 - acc: 0.3920 - val_loss: 1.5548 - val_acc: 0.2080
Epoch 9/35

1000/1000 [==============================] - 101s 101ms/step - loss: 1.4466 - acc: 0.4870 - val_loss: 1.5491 - val_acc: 0.3220
Epoch 10/35

1000/1000 [==============================] - 101s 101ms/step - loss: 1.4255 - acc: 0.5770 - val_loss: 1.5441 - val_acc: 0.3360
Epoch 11/35

1000/1000 [==============================] - 101s 101ms/step - loss: 1.4045 - acc: 0.5700 - val_loss: 1.5397 - val_acc: 0.3550
Epoch 12/35

1000/1000 [==============================] - 103s 103ms/step - loss: 1.3834 - acc: 0.5930 - val_loss: 1.5362 - val_acc: 0.3620
Epoch 13/35

1000/1000 [==============================] - 101s 101ms/step - loss: 1.3626 - acc: 0.5990 - val_loss: 1.5335 - val_acc: 0.3610
Epoch 14/35

1000/1000 [==============================] - 102s 102ms/step - loss: 1.3419 - acc: 0.6010 - val_loss: 1.5317 - val_acc: 0.3630
Epoch 15/35

1000/1000 [==============================] - 101s 101ms/step - loss: 1.3213 - acc: 0.5930 - val_loss: 1.5308 - val_acc: 0.3660
Epoch 16/35

1000/1000 [==============================] - 102s 102ms/step - loss: 1.3009 - acc: 0.5830 - val_loss: 1.5308 - val_acc: 0.3660
Epoch 17/35

1000/1000 [==============================] - 102s 102ms/step - loss: 1.2806 - acc: 0.5810 - val_loss: 1.5315 - val_acc: 0.3620
Epoch 18/35

1000/1000 [==============================] - 104s 104ms/step - loss: 1.2607 - acc: 0.5800 - val_loss: 1.5330 - val_acc: 0.3520
Epoch 19/35

1000/1000 [==============================] - 102s 102ms/step - loss: 1.2410 - acc: 0.5760 - val_loss: 1.5352 - val_acc: 0.3430
Epoch 20/35

1000/1000 [==============================] - 102s 102ms/step - loss: 1.2216 - acc: 0.5730 - val_loss: 1.5379 - val_acc: 0.3420
Epoch 21/35

1000/1000 [==============================] - 102s 102ms/step - loss: 1.2026 - acc: 0.5710 - val_loss: 1.5413 - val_acc: 0.3380
Epoch 22/35

1000/1000 [==============================] - 103s 103ms/step - loss: 1.1838 - acc: 0.5740 - val_loss: 1.5449 - val_acc: 0.3380
Epoch 23/35

1000/1000 [==============================] - 103s 103ms/step - loss: 1.1652 - acc: 0.5760 - val_loss: 1.5486 - val_acc: 0.3400
Epoch 24/35

1000/1000 [==============================] - 105s 105ms/step - loss: 1.1468 - acc: 0.5810 - val_loss: 1.5526 - val_acc: 0.3420
Epoch 25/35

1000/1000 [==============================] - 103s 103ms/step - loss: 1.1286 - acc: 0.5830 - val_loss: 1.5564 - val_acc: 0.3460
Epoch 26/35

1000/1000 [==============================] - 103s 103ms/step - loss: 1.1106 - acc: 0.5850 - val_loss: 1.5603 - val_acc: 0.3490
Epoch 27/35

1000/1000 [==============================] - 103s 103ms/step - loss: 1.0928 - acc: 0.5890 - val_loss: 1.5639 - val_acc: 0.3550
Epoch 28/35

1000/1000 [==============================] - 103s 103ms/step - loss: 1.0751 - acc: 0.6010 - val_loss: 1.5679 - val_acc: 0.3610
Epoch 29/35

1000/1000 [==============================] - 104s 104ms/step - loss: 1.0577 - acc: 0.6110 - val_loss: 1.5722 - val_acc: 0.3630
Epoch 30/35

1000/1000 [==============================] - 103s 103ms/step - loss: 1.0406 - acc: 0.6160 - val_loss: 1.5763 - val_acc: 0.3680
Epoch 31/35

1000/1000 [==============================] - 104s 104ms/step - loss: 1.0237 - acc: 0.6240 - val_loss: 1.5810 - val_acc: 0.3680
Epoch 32/35

1000/1000 [==============================] - 103s 103ms/step - loss: 1.0070 - acc: 0.6260 - val_loss: 1.5848 - val_acc: 0.3670
Epoch 33/35

1000/1000 [==============================] - 105s 105ms/step - loss: 0.9908 - acc: 0.6300 - val_loss: 1.5865 - val_acc: 0.3780
Epoch 34/35

1000/1000 [==============================] - 104s 104ms/step - loss: 0.9748 - acc: 0.6480 - val_loss: 1.5915 - val_acc: 0.3780
Epoch 35/35

1000/1000 [==============================] - 104s 104ms/step - loss: 0.9590 - acc: 0.6450 - val_loss: 1.5950 - val_acc: 0.3840
Saved trained model at /n/holylfs03/LABS/berger_lab/nchou/saved_models/aardvark_aug11.h5 
[[2.08741389e-04 1.48259616e-07 5.47122036e-05 9.99736249e-01
  9.31469515e-08]
 [1.24690898e-01 1.06999800e-01 1.62565202e-01 1.79255933e-01
  4.26488191e-01]
 [1.53727472e-01 1.21725969e-01 1.68866664e-01 1.56776637e-01
  3.98903251e-01]
 ...
 [1.11417376e-01 1.06374793e-01 1.68760940e-01 2.13813201e-01
  3.99633676e-01]
 [1.16722092e-01 1.12913720e-01 1.64678574e-01 1.98517337e-01
  4.07168269e-01]
 [2.95291864e-03 9.94874299e-01 2.15159613e-03 1.52370276e-05
  6.02072851e-06]]
[3 4 4 0 3 4 1 0 1 0 4 4 4 4 4 1 4 4 4 0 0 4 4 1 1 4 4 0 3 4 4 4 4 2 3 4 4
 0 1 2 4 4 4 1 0 1 4 4 4 4 0 4 4 1 4 4 4 3 1 4 4 1 1 4 4 4 2 4 4 4 1 4 4 4
 4 1 4 4 4 4 2 1 1 4 4 1 0 3 1 4 4 2 4 1 3 0 3 3 1 4 4 4 4 2 3 4 4 3 4 1 4
 4 0 2 4 4 4 4 3 4 1 2 4 2 4 1 4 1 3 2 4 3 4 0 1 2 1 3 4 4 4 4 4 4 3 4 4 1
 1 2 4 0 4 4 3 4 4 3 0 4 4 4 2 2 4 3 1 4 4 4 4 4 1 3 4 3 4 4 0 3 1 4 1 4 4
 1 4 4 1 1 3 4 0 4 4 4 4 1 0 4 0 4 2 4 4 4 4 3 0 3 4 2 4 4 4 4 4 4 4 4 3 4
 3 4 4 0 4 0 1 0 4 4 1 4 4 4 4 4 4 1 4 4 2 1 4 0 3 4 4 4 4 1 1 4 4 0 4 1 0
 4 3 4 0 1 4 4 4 4 1 4 4 1 1 4 1 1 3 4 4 4 1 1 4 1 0 4 2 4 4 0 2 4 1 3 4 3
 3 4 0 1 4 4 4 4 1 2 3 1 1 4 4 4 1 3 4 4 3 4 4 0 2 1 4 3 3 4 3 3 2 4 4 4 4
 4 4 3 0 2 3 4 4 4 2 4 2 4 1 4 0 4 4 4 4 4 0 4 4 4 4 4 4 1 4 4 3 0 1 4 2 2
 4 3 4 4 4 4 4 4 1 0 1 3 0 1 1 3 2 1 2 0 4 3 4 1 4 4 2 0 1 1 4 4 4 4 4 4 4
 1 4 4 4 2 3 4 4 3 4 2 1 1 4 4 1 4 0 4 4 3 4 4 3 2 4 4 4 4 4 1 4 4 0 1 1 4
 1 4 4 4 4 1 4 3 4 3 3 4 4 3 4 1 4 3 0 2 3 4 4 1 4 3 1 4 4 4 4 4 0 2 3 2 4
 2 0 2 4 4 4 4 4 3 1 4 1 3 2 0 4 4 4 4 0 4 4 4 4 4 0 4 4 4 1 4 0 4 1 2 4 3
 4 4 4 1 1 2 1 4 3 1 4 4 4 4 4 4 4 4 1 1 4 4 0 3 4 4 4 1 1 3 4 0 2 4 4 4 1
 1 4 3 1 2 1 4 1 2 3 4 3 4 2 4 4 4 1 4 4 1 4 1 4 3 4 3 4 4 4 4 3 4 0 4 1 4
 4 4 4 1 4 4 4 4 2 4 4 2 3 4 3 3 3 4 4 4 0 1 4 1 4 3 4 0 4 4 2 3 4 4 4 1 1
 1 1 0 4 3 4 4 1 4 1 1 4 4 4 4 1 4 0 3 1 4 1 4 4 3 2 4 4 4 4 2 4 4 1 4 1 0
 4 3 4 0 3 4 4 4 4 4 4 4 4 3 3 1 0 4 4 1 4 4 2 4 4 0 4 4 0 1 0 3 1 4 3 4 3
 4 4 2 4 4 4 4 1 3 4 4 3 4 4 4 0 4 4 2 3 0 1 0 4 4 4 3 4 4 4 1 4 1 4 4 1 4
 1 4 4 3 4 1 4 4 1 3 4 1 4 2 2 2 1 4 1 0 1 4 4 3 4 1 4 1 4 3 4 3 4 1 4 4 3
 4 4 3 4 4 4 1 4 4 1 4 1 3 1 0 2 0 3 3 0 4 4 0 3 1 3 0 4 2 4 1 4 1 4 3 3 3
 4 4 0 3 1 2 4 2 3 4 4 4 3 0 4 4 1 4 4 4 4 4 2 0 4 2 4 4 4 4 1 4 3 4 4 3 0
 0 4 4 4 4 4 0 4 3 4 4 0 1 4 2 1 4 1 4 3 4 0 4 4 1 0 4 4 1 1 3 1 3 1 3 3 4
 4 1 4 1 3 4 0 3 1 4 4 4 4 4 3 4 4 4 4 1 4 4 2 1 0 4 1 0 4 1 2 4 3 2 1 0 3
 2 1 4 0 4 1 4 3 4 4 3 1 1 1 1 4 4 3 1 4 1 4 1 4 4 4 2 0 0 4 1 4 4 4 4 4 4
 3 1 4 4 4 3 2 4 4 4 4 1 4 4 4 4 4 0 3 4 4 1 4 3 4 4 4 0 3 4 4 2 4 4 2 4 4
 1]

  32/1000 [..............................] - ETA: 28s
  64/1000 [>.............................] - ETA: 27s
  96/1000 [=>............................] - ETA: 26s
 128/1000 [==>...........................] - ETA: 25s
 160/1000 [===>..........................] - ETA: 24s
 192/1000 [====>.........................] - ETA: 23s
 224/1000 [=====>........................] - ETA: 22s
 256/1000 [======>.......................] - ETA: 21s
 288/1000 [=======>......................] - ETA: 21s
 320/1000 [========>.....................] - ETA: 20s
 352/1000 [=========>....................] - ETA: 19s
 384/1000 [==========>...................] - ETA: 18s
 416/1000 [===========>..................] - ETA: 17s
 448/1000 [============>.................] - ETA: 16s
 480/1000 [=============>................] - ETA: 15s
 512/1000 [==============>...............] - ETA: 14s
 544/1000 [===============>..............] - ETA: 13s
 576/1000 [================>.............] - ETA: 12s
 608/1000 [=================>............] - ETA: 11s
 640/1000 [==================>...........] - ETA: 10s
 672/1000 [===================>..........] - ETA: 9s 
 704/1000 [====================>.........] - ETA: 8s
 736/1000 [=====================>........] - ETA: 7s
 768/1000 [======================>.......] - ETA: 6s
 800/1000 [=======================>......] - ETA: 5s
 832/1000 [=======================>......] - ETA: 4s
 864/1000 [========================>.....] - ETA: 4s
 896/1000 [=========================>....] - ETA: 3s
 928/1000 [==========================>...] - ETA: 2s
 960/1000 [===========================>..] - ETA: 1s
 992/1000 [============================>.] - ETA: 0s
1000/1000 [==============================] - 29s 29ms/step
Test loss: 1.6091054458618164
Test accuracy: 0.349
[[ 51  51  18  42  38]
 [  4  25  31   0 140]
 [ 22 101  20  35  22]
 [ 11   0   2  53 134]
 [  0   0   0   0 200]]
