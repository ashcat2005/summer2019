Using TensorFlow backend.
WARNING:tensorflow:From /n/home00/nchou/.conda/envs/envi/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.
Instructions for updating:
Colocations handled automatically by placer.
WARNING:tensorflow:From /n/home00/nchou/.conda/envs/envi/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.cast instead.
2019-08-04 17:46:42.696101: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-08-04 17:46:42.713482: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2095315000 Hz
2019-08-04 17:46:42.713633: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x5584e1aa1790 executing computations on platform Host. Devices:
2019-08-04 17:46:42.713671: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (0): <undefined>, <undefined>
0
286
95
augmenting
95
returning
<class 'list'>
200
augmenting
95
returning
augmenting
96
returning
1
16
5
augmenting
5
returning
<class 'list'>
200
augmenting
5
returning
augmenting
6
returning
2
76
25
augmenting
25
returning
<class 'list'>
200
augmenting
25
returning
augmenting
26
returning
3
18
6
augmenting
6
returning
<class 'list'>
200
augmenting
6
returning
augmenting
6
returning
4
9
3
augmenting
3
returning
<class 'list'>
200
augmenting
3
returning
augmenting
3
returning
Train on 1000 samples, validate on 1000 samples
Epoch 1/25

1000/1000 [==============================] - 198s 198ms/step - loss: 1.6102 - acc: 0.1020 - val_loss: 1.5865 - val_acc: 0.2350
Epoch 2/25

1000/1000 [==============================] - 186s 186ms/step - loss: 1.5469 - acc: 0.3370 - val_loss: 1.5539 - val_acc: 0.2740
Epoch 3/25

1000/1000 [==============================] - 188s 188ms/step - loss: 1.4437 - acc: 0.6310 - val_loss: 1.5377 - val_acc: 0.2130
Epoch 4/25

1000/1000 [==============================] - 189s 189ms/step - loss: 1.3312 - acc: 0.6560 - val_loss: 1.5332 - val_acc: 0.3570
Epoch 5/25

1000/1000 [==============================] - 189s 189ms/step - loss: 1.2545 - acc: 0.5480 - val_loss: 1.6174 - val_acc: 0.2380
Epoch 6/25

1000/1000 [==============================] - 188s 188ms/step - loss: 1.1511 - acc: 0.7450 - val_loss: 1.6079 - val_acc: 0.3230
Epoch 7/25

1000/1000 [==============================] - 188s 188ms/step - loss: 1.0544 - acc: 0.8700 - val_loss: 1.6017 - val_acc: 0.3510
Epoch 8/25

1000/1000 [==============================] - 188s 188ms/step - loss: 0.9845 - acc: 0.6480 - val_loss: 1.6676 - val_acc: 0.3740
Epoch 9/25

1000/1000 [==============================] - 190s 190ms/step - loss: 0.8947 - acc: 0.7620 - val_loss: 1.8065 - val_acc: 0.3310
Epoch 10/25

1000/1000 [==============================] - 188s 188ms/step - loss: 0.8407 - acc: 0.8910 - val_loss: 1.7658 - val_acc: 0.4030
Epoch 11/25

1000/1000 [==============================] - 187s 187ms/step - loss: 0.7585 - acc: 0.8420 - val_loss: 1.7919 - val_acc: 0.3790
Epoch 12/25

1000/1000 [==============================] - 188s 188ms/step - loss: 0.7119 - acc: 0.8070 - val_loss: 1.9379 - val_acc: 0.4380
Epoch 13/25

1000/1000 [==============================] - 189s 189ms/step - loss: 0.6420 - acc: 0.8660 - val_loss: 2.0565 - val_acc: 0.3900
Epoch 14/25

1000/1000 [==============================] - 188s 188ms/step - loss: 0.5978 - acc: 0.8960 - val_loss: 2.0105 - val_acc: 0.4200
Epoch 15/25

1000/1000 [==============================] - 189s 189ms/step - loss: 0.5481 - acc: 0.8630 - val_loss: 2.0728 - val_acc: 0.4300
Epoch 16/25

1000/1000 [==============================] - 188s 188ms/step - loss: 0.4999 - acc: 0.8850 - val_loss: 2.2485 - val_acc: 0.3380
Epoch 17/25

1000/1000 [==============================] - 188s 188ms/step - loss: 0.4682 - acc: 0.9140 - val_loss: 2.2518 - val_acc: 0.4110
Restoring model weights from the end of the best epoch
Epoch 00017: early stopping
[[1.3465943e-03 9.9281561e-01 4.0284893e-03 7.4175821e-04 1.0675289e-03]
 [1.7945893e-01 1.5593524e-01 1.5407068e-01 2.2035080e-01 2.9018429e-01]
 [6.3889816e-02 6.7640826e-02 5.4712170e-01 3.2126701e-01 8.0685473e-05]
 ...
 [1.7872954e-02 4.0679271e-05 9.5334059e-01 2.8728150e-02 1.7635968e-05]
 [2.0207039e-01 1.3642110e-01 1.5124649e-01 1.8877620e-01 3.2148582e-01]
 [2.6795447e-01 2.3497327e-01 3.3120272e-01 7.1742088e-02 9.4127513e-02]]
[1 4 2 2 3 2 3 1 0 2 0 2 2 2 2 4 4 4 4 4 0 3 4 2 2 4 0 0 4 2 4 2 4 3 2 2 4
 2 4 4 2 0 2 4 0 4 4 4 1 4 4 4 4 4 3 1 4 4 0 4 4 2 2 4 3 4 4 4 4 2 2 4 4 1
 4 4 2 0 0 4 0 0 4 0 0 4 0 0 0 2 2 2 2 4 4 4 0 4 2 2 0 2 4 2 4 2 2 0 4 4 4
 4 4 4 4 2 4 2 2 4 2 0 0 4 4 4 4 4 2 0 2 4 4 2 4 0 2 1 4 2 4 0 4 4 4 2 1 4
 2 4 0 4 4 2 0 4 4 4 0 4 0 4 0 4 4 4 2 3 4 4 0 4 2 4 4 0 3 4 4 4 0 4 0 2 4
 2 0 4 0 4 4 2 1 4 4 4 1 2 4 4 0 2 4 4 2 4 2 1 4 0 2 2 4 4 4 4 2 4 0 4 0 4
 0 1 0 0 0 3 0 4 4 2 2 2 3 2 2 2 2 4 4 2 4 4 3 0 2 2 3 4 0 2 3 0 0 2 2 0 2
 1 0 4 2 4 4 0 2 1 3 4 4 4 2 1 4 4 4 2 1 4 2 4 3 1 4 4 4 4 3 0 4 4 4 4 0 2
 0 4 2 0 2 4 4 1 4 2 0 2 1 4 4 4 2 2 0 4 2 4 0 0 4 2 4 2 2 2 4 4 2 4 2 2 1
 4 0 0 0 2 2 4 3 2 4 1 4 4 4 4 4 0 2 0 4 2 4 4 0 2 4 4 0 2 0 4 2 0 4 0 2 2
 4 3 4 2 0 4 2 4 2 0 4 4 4 4 3 4 4 0 2 4 2 4 4 1 2 4 0 4 4 4 4 0 2 2 4 0 2
 4 2 1 4 2 2 4 3 0 4 2 4 4 4 2 1 4 0 2 2 0 4 0 4 0 4 4 2 0 2 2 2 2 2 4 4 4
 2 4 4 4 1 2 1 4 2 0 4 2 2 4 1 4 4 2 4 4 4 4 2 4 2 0 0 4 2 0 4 2 0 0 4 1 2
 2 0 4 0 1 1 4 4 4 0 2 0 4 0 2 0 4 4 0 4 1 4 1 4 3 2 2 4 0 4 4 0 0 0 2 0 2
 2 4 4 1 4 3 2 4 2 4 4 2 0 2 4 2 2 4 1 2 2 4 4 0 4 4 4 2 0 2 4 2 0 2 4 4 0
 0 4 0 4 1 4 2 0 2 2 0 2 2 0 2 4 0 2 0 4 2 2 0 2 2 4 2 4 1 4 3 1 0 4 2 2 1
 4 4 1 0 2 4 4 4 2 4 4 4 4 4 4 2 0 4 2 4 2 1 1 4 4 0 4 4 4 4 0 4 2 3 0 2 2
 4 4 4 4 1 1 2 3 2 4 4 4 0 2 4 4 4 4 3 4 4 4 4 4 2 4 0 2 4 4 2 2 2 4 2 4 4
 2 3 0 4 4 4 0 2 0 2 2 4 0 0 4 0 0 0 4 2 4 2 4 4 0 0 4 2 1 2 1 4 4 0 4 2 4
 4 2 2 1 4 2 1 0 4 4 2 0 4 4 4 0 4 0 4 4 0 4 0 4 4 4 0 0 2 4 4 0 4 2 0 4 4
 4 4 1 4 4 2 4 4 2 2 4 4 4 0 4 4 2 4 4 4 4 0 4 0 4 2 4 0 2 4 2 4 4 2 0 2 0
 0 0 2 2 2 4 4 4 2 0 0 2 3 2 4 2 2 0 4 2 4 4 3 0 0 2 4 2 4 2 4 0 0 4 0 0 0
 4 4 0 4 0 0 4 4 2 4 4 4 0 2 1 4 4 4 1 4 4 4 2 4 4 4 2 2 4 4 1 2 2 2 4 0 4
 0 2 4 4 4 4 2 4 4 0 4 4 4 0 0 4 4 4 0 1 4 4 2 0 4 4 4 2 4 4 0 2 3 2 1 4 2
 4 3 4 4 4 0 2 2 2 4 0 2 3 4 1 0 4 4 2 4 2 2 4 4 2 2 2 2 2 4 4 4 4 4 0 3 2
 0 4 2 2 0 1 3 4 4 4 4 4 4 0 2 4 4 4 3 4 2 3 4 4 2 4 4 4 2 0 4 4 4 4 2 0 1
 2 3 0 2 4 4 1 2 2 4 2 2 0 4 2 0 4 0 2 3 0 2 2 0 4 2 2 4 4 0 0 4 2 4 4 2 4
 2]

  32/1000 [..............................] - ETA: 49s
  64/1000 [>.............................] - ETA: 47s
  96/1000 [=>............................] - ETA: 46s
 128/1000 [==>...........................] - ETA: 44s
 160/1000 [===>..........................] - ETA: 43s
 192/1000 [====>.........................] - ETA: 41s
 224/1000 [=====>........................] - ETA: 39s
 256/1000 [======>.......................] - ETA: 38s
 288/1000 [=======>......................] - ETA: 36s
 320/1000 [========>.....................] - ETA: 34s
 352/1000 [=========>....................] - ETA: 33s
 384/1000 [==========>...................] - ETA: 31s
 416/1000 [===========>..................] - ETA: 29s
 448/1000 [============>.................] - ETA: 28s
 480/1000 [=============>................] - ETA: 26s
 512/1000 [==============>...............] - ETA: 25s
 544/1000 [===============>..............] - ETA: 23s
 576/1000 [================>.............] - ETA: 21s
 608/1000 [=================>............] - ETA: 20s
 640/1000 [==================>...........] - ETA: 18s
 672/1000 [===================>..........] - ETA: 16s
 704/1000 [====================>.........] - ETA: 15s
 736/1000 [=====================>........] - ETA: 13s
 768/1000 [======================>.......] - ETA: 11s
 800/1000 [=======================>......] - ETA: 10s
 832/1000 [=======================>......] - ETA: 8s 
 864/1000 [========================>.....] - ETA: 6s
 896/1000 [=========================>....] - ETA: 5s
 928/1000 [==========================>...] - ETA: 3s
 960/1000 [===========================>..] - ETA: 2s
 992/1000 [============================>.] - ETA: 0s
1000/1000 [==============================] - 51s 51ms/step
Test loss: 1.7126311702728272
Test accuracy: 0.366
[[ 77  21  56  11  35]
 [ 26   0 120   0  54]
 [ 63  35  77  15  10]
 [ 23   0  17  12 148]
 [  0   0   0   0 200]]
