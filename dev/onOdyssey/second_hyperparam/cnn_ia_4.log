using 5type input matrix, cut to 100 each ia/not, but iwth normal lr

Using TensorFlow backend.
WARNING:tensorflow:From /n/home00/nchou/.conda/envs/envi/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.
Instructions for updating:
Colocations handled automatically by placer.
cnn_aardvark_aug_concat.py:319: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor("in..., outputs=Tensor("de...)`
  model = Model(input=ins, output=dense2)
WARNING:tensorflow:From /n/home00/nchou/.conda/envs/envi/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.cast instead.
2019-10-31 22:57:40.661657: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
2019-10-31 22:57:40.812520: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2900000000 Hz
2019-10-31 22:57:40.812780: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x555f9796a400 executing computations on platform Host. Devices:
2019-10-31 22:57:40.812834: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (0): <undefined>, <undefined>
Train on 200 samples, validate on 1000 samples
Epoch 1/10

 50/200 [======>.......................] - ETA: 1:10 - loss: 0.6927 - acc: 0.5000
100/200 [==============>...............] - ETA: 33s - loss: 0.6939 - acc: 0.4900 
150/200 [=====================>........] - ETA: 14s - loss: 0.7003 - acc: 0.4400
200/200 [==============================] - 96s 482ms/step - loss: 0.6911 - acc: 0.4750 - val_loss: 0.6881 - val_acc: 0.3250
Epoch 2/10

 50/200 [======>.......................] - ETA: 29s - loss: 0.5914 - acc: 0.7400
100/200 [==============>...............] - ETA: 19s - loss: 0.5921 - acc: 0.7000
150/200 [=====================>........] - ETA: 9s - loss: 0.5769 - acc: 0.7000 
200/200 [==============================] - 81s 406ms/step - loss: 0.5562 - acc: 0.7050 - val_loss: 0.7293 - val_acc: 0.3230
Epoch 3/10

 50/200 [======>.......................] - ETA: 29s - loss: 0.5161 - acc: 0.8000
100/200 [==============>...............] - ETA: 19s - loss: 0.4566 - acc: 0.8300
150/200 [=====================>........] - ETA: 9s - loss: 0.4674 - acc: 0.7867 
200/200 [==============================] - 81s 406ms/step - loss: 0.4520 - acc: 0.8200 - val_loss: 0.7019 - val_acc: 0.6680
Epoch 4/10

 50/200 [======>.......................] - ETA: 29s - loss: 0.3548 - acc: 0.9400
100/200 [==============>...............] - ETA: 19s - loss: 0.3700 - acc: 0.9200
150/200 [=====================>........] - ETA: 9s - loss: 0.3594 - acc: 0.9333 
200/200 [==============================] - 81s 406ms/step - loss: 0.3305 - acc: 0.9400 - val_loss: 0.5866 - val_acc: 0.8080
Epoch 5/10

 50/200 [======>.......................] - ETA: 29s - loss: 0.2686 - acc: 0.8400
100/200 [==============>...............] - ETA: 19s - loss: 0.2565 - acc: 0.8900
150/200 [=====================>........] - ETA: 9s - loss: 0.3142 - acc: 0.8267 
200/200 [==============================] - 81s 407ms/step - loss: 0.2990 - acc: 0.8500 - val_loss: 0.6589 - val_acc: 0.8030
Epoch 6/10

 50/200 [======>.......................] - ETA: 29s - loss: 0.2207 - acc: 0.8800
100/200 [==============>...............] - ETA: 19s - loss: 0.2185 - acc: 0.8900
150/200 [=====================>........] - ETA: 9s - loss: 0.2165 - acc: 0.8867 
200/200 [==============================] - 82s 408ms/step - loss: 0.2234 - acc: 0.8900 - val_loss: 1.1576 - val_acc: 0.3640
Epoch 7/10

 50/200 [======>.......................] - ETA: 29s - loss: 0.2663 - acc: 0.9000
100/200 [==============>...............] - ETA: 19s - loss: 0.2160 - acc: 0.9400
150/200 [=====================>........] - ETA: 9s - loss: 0.2024 - acc: 0.9467 
200/200 [==============================] - 82s 409ms/step - loss: 0.1859 - acc: 0.9500 - val_loss: 0.8003 - val_acc: 0.8000
Epoch 8/10

 50/200 [======>.......................] - ETA: 29s - loss: 0.2037 - acc: 0.8800
100/200 [==============>...............] - ETA: 19s - loss: 0.1535 - acc: 0.9200
150/200 [=====================>........] - ETA: 9s - loss: 0.1457 - acc: 0.9333 
200/200 [==============================] - 82s 409ms/step - loss: 0.1511 - acc: 0.9300 - val_loss: 1.0124 - val_acc: 0.6890
Epoch 9/10

 50/200 [======>.......................] - ETA: 29s - loss: 0.1479 - acc: 0.9600
100/200 [==============>...............] - ETA: 19s - loss: 0.1117 - acc: 0.9700
150/200 [=====================>........] - ETA: 9s - loss: 0.1298 - acc: 0.9600 
200/200 [==============================] - 82s 409ms/step - loss: 0.1143 - acc: 0.9650 - val_loss: 0.8963 - val_acc: 0.7990
Epoch 10/10

 50/200 [======>.......................] - ETA: 29s - loss: 0.0783 - acc: 0.9800
100/200 [==============>...............] - ETA: 19s - loss: 0.1175 - acc: 0.9500
150/200 [=====================>........] - ETA: 9s - loss: 0.0994 - acc: 0.9667 
200/200 [==============================] - 82s 409ms/step - loss: 0.0947 - acc: 0.9700 - val_loss: 1.0204 - val_acc: 0.7290
Saved trained model at /n/holylfs03/LABS/berger_lab/nchou/saved_models/aardvark_aug11.h5 
[[2.5118193e-06 9.9999750e-01]
 [4.3933299e-01 5.6066692e-01]
 [2.6673439e-01 7.3326558e-01]
 ...
 [1.7264616e-01 8.2735378e-01]
 [2.2541970e-01 7.7458030e-01]
 [9.9989665e-01 1.0332553e-04]]
[1 1 1 1 0 1 0 0 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 1 1 0 0 0 1 1 1 1 0 1 1
 0 0 1 0 1 1 0 0 0 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 0 0 1 1 1 1 1 1 0 0 1 0 1
 1 1 1 0 0 1 1 1 0 1 1 1 1 1 1 1 1 0 1 0 1 0 0 1 1 1 1 1 1 0 1 1 1 0 1 0 1
 1 0 0 1 1 1 1 1 1 1 1 1 1 1 0 1 1 0 1 1 1 1 0 0 1 1 1 1 1 1 1 1 1 0 1 1 1
 1 0 1 0 0 1 1 1 1 1 0 1 1 1 0 1 1 1 1 1 1 1 1 1 1 0 1 0 1 0 0 0 1 1 1 1 0
 0 1 1 1 1 0 0 0 1 1 1 1 0 0 1 0 1 1 1 0 1 1 1 0 0 1 1 1 1 1 0 1 1 1 1 0 1
 1 1 0 1 1 0 1 0 1 1 0 0 1 1 1 1 1 1 1 0 0 1 1 0 1 1 1 1 1 1 0 1 1 0 1 1 0
 1 0 1 1 0 1 0 1 1 1 0 1 0 1 1 1 1 0 1 1 1 0 0 1 0 0 1 1 1 1 0 1 1 1 1 1 0
 0 1 0 1 1 1 1 1 0 1 0 0 1 1 1 1 0 1 1 1 1 1 1 0 0 1 1 0 1 1 1 1 1 0 1 1 1
 1 1 1 0 1 1 1 0 1 1 1 1 1 1 1 0 0 1 0 1 1 0 1 1 1 1 1 0 0 1 1 1 0 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 0 1 0 1 1 1 1 0 1 1 1 1 1 1 1 1 0 1
 1 1 1 1 0 0 0 1 0 1 0 1 0 0 1 0 1 0 1 1 0 1 1 1 0 1 1 0 1 1 0 1 1 0 0 1 0
 0 1 1 1 1 1 1 0 1 0 1 1 1 1 1 1 1 0 0 1 0 1 1 0 1 0 1 1 1 1 0 1 0 0 0 1 1
 1 0 1 0 1 1 1 1 0 1 1 1 0 1 0 0 1 0 1 0 1 1 1 1 1 1 1 1 1 1 1 0 1 1 0 1 0
 1 1 1 0 0 1 0 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 0 1 0 1 1 1 0 0
 1 1 1 1 1 1 1 1 1 0 0 1 1 0 1 1 1 0 1 1 0 1 1 1 0 1 1 1 1 1 0 0 1 1 1 0 1
 1 1 1 1 1 1 1 1 0 1 0 1 0 1 1 0 1 1 1 1 0 1 1 0 0 0 1 0 1 1 1 1 1 1 1 1 1
 0 0 0 1 1 1 1 0 1 1 1 1 1 1 1 0 1 0 0 0 1 0 1 1 1 0 1 1 1 1 1 1 1 0 0 0 1
 1 0 1 1 0 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 0 1 1 1 1 0 1 1 1 0 0 0 0 1 0 1 1
 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 1 1 1 0 1 0 1 1 1 1
 0 0 1 0 1 0 1 1 1 0 1 1 1 1 1 1 1 1 0 0 1 1 1 0 1 1 1 1 1 0 0 0 1 0 1 1 0
 0 1 0 0 0 0 0 1 1 1 1 0 1 1 0 1 0 0 0 1 0 1 0 1 1 0 0 1 1 1 0 1 0 1 0 0 0
 1 1 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 0 1 0 1 1 1 1
 0 1 1 1 1 1 0 1 0 1 1 0 1 1 1 1 1 1 1 0 1 0 1 1 0 0 1 1 1 1 0 0 1 0 0 1 1
 1 1 1 0 0 1 0 1 0 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 0 1 1 0 1 0 1 0 0 1 0
 1 1 1 1 1 0 1 1 1 1 1 0 1 0 1 1 1 1 1 1 1 1 0 1 1 1 0 0 0 1 1 1 1 1 1 1 1
 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 0 1 0 1 1 1 1 1 1 1 1 0 1 1 1 1
 0]

  32/1000 [..............................] - ETA: 42s
  64/1000 [>.............................] - ETA: 42s
  96/1000 [=>............................] - ETA: 40s
 128/1000 [==>...........................] - ETA: 39s
 160/1000 [===>..........................] - ETA: 37s
 192/1000 [====>.........................] - ETA: 36s
 224/1000 [=====>........................] - ETA: 34s
 256/1000 [======>.......................] - ETA: 33s
 288/1000 [=======>......................] - ETA: 31s
 320/1000 [========>.....................] - ETA: 30s
 352/1000 [=========>....................] - ETA: 29s
 384/1000 [==========>...................] - ETA: 27s
 416/1000 [===========>..................] - ETA: 26s
 448/1000 [============>.................] - ETA: 24s
 480/1000 [=============>................] - ETA: 23s
 512/1000 [==============>...............] - ETA: 22s
 544/1000 [===============>..............] - ETA: 20s
 576/1000 [================>.............] - ETA: 19s
 608/1000 [=================>............] - ETA: 17s
 640/1000 [==================>...........] - ETA: 16s
 672/1000 [===================>..........] - ETA: 14s
 704/1000 [====================>.........] - ETA: 13s
 736/1000 [=====================>........] - ETA: 11s
 768/1000 [======================>.......] - ETA: 10s
 800/1000 [=======================>......] - ETA: 9s 
 832/1000 [=======================>......] - ETA: 7s
 864/1000 [========================>.....] - ETA: 6s
 896/1000 [=========================>....] - ETA: 4s
 928/1000 [==========================>...] - ETA: 3s
 960/1000 [===========================>..] - ETA: 1s
 992/1000 [============================>.] - ETA: 0s
1000/1000 [==============================] - 45s 45ms/step
Test loss: 1.6274863872528076
Test accuracy: 0.74
[[110  90]
 [170 630]]
