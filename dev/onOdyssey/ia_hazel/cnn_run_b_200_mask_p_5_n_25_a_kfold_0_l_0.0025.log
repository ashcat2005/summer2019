Using TensorFlow backend.
WARNING:tensorflow:From /n/home00/nchou/.conda/envs/envi/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.
Instructions for updating:
Colocations handled automatically by placer.
cnn_aardvark_aug_concat.py:672: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor("in..., outputs=Tensor("de...)`
  model = Model(input=ins, output=dense2)
WARNING:tensorflow:From /n/home00/nchou/.conda/envs/envi/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.cast instead.
2019-12-10 18:19:36.237215: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
2019-12-10 18:19:36.319768: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2900000000 Hz
2019-12-10 18:19:36.319947: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x558efb4436a0 executing computations on platform Host. Devices:
2019-12-10 18:19:36.319966: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (0): <undefined>, <undefined>
['cnn_aardvark_aug_concat.py', '-b', '200', '--mask', '-p', '5', '-n', '25', '-a', '--kfold', '0', '-l', '0.0025']
1
2
Train on 673 samples, validate on 122 samples
Epoch 1/25

200/673 [=======>......................] - ETA: 18s - loss: 0.6928 - acc: 0.4750
400/673 [================>.............] - ETA: 9s - loss: 0.6945 - acc: 0.5150 
600/673 [=========================>....] - ETA: 2s - loss: 0.6985 - acc: 0.5100
673/673 [==============================] - 24s 36ms/step - loss: 0.6928 - acc: 0.5186 - val_loss: 0.6443 - val_acc: 0.6803
Epoch 2/25

200/673 [=======>......................] - ETA: 14s - loss: 0.6413 - acc: 0.6000
400/673 [================>.............] - ETA: 8s - loss: 0.6180 - acc: 0.6425 
600/673 [=========================>....] - ETA: 2s - loss: 0.6065 - acc: 0.6550
673/673 [==============================] - 22s 33ms/step - loss: 0.6148 - acc: 0.6389 - val_loss: 0.8676 - val_acc: 0.3770
Epoch 3/25

200/673 [=======>......................] - ETA: 14s - loss: 0.5990 - acc: 0.6200
400/673 [================>.............] - ETA: 8s - loss: 0.5903 - acc: 0.6525 
600/673 [=========================>....] - ETA: 2s - loss: 0.5721 - acc: 0.6667
673/673 [==============================] - 22s 33ms/step - loss: 0.5647 - acc: 0.6716 - val_loss: 0.8099 - val_acc: 0.6066
Epoch 4/25

200/673 [=======>......................] - ETA: 14s - loss: 0.5401 - acc: 0.7000
400/673 [================>.............] - ETA: 8s - loss: 0.5612 - acc: 0.6800 
600/673 [=========================>....] - ETA: 2s - loss: 0.5391 - acc: 0.6817
673/673 [==============================] - 22s 32ms/step - loss: 0.5359 - acc: 0.6805 - val_loss: 0.9460 - val_acc: 0.5410
Epoch 5/25

200/673 [=======>......................] - ETA: 14s - loss: 0.5346 - acc: 0.7100
400/673 [================>.............] - ETA: 8s - loss: 0.5150 - acc: 0.7250 
600/673 [=========================>....] - ETA: 2s - loss: 0.5026 - acc: 0.7117
673/673 [==============================] - 22s 32ms/step - loss: 0.5031 - acc: 0.7132 - val_loss: 0.9937 - val_acc: 0.5738
Epoch 6/25

200/673 [=======>......................] - ETA: 14s - loss: 0.4635 - acc: 0.7550
400/673 [================>.............] - ETA: 8s - loss: 0.4712 - acc: 0.7425 
600/673 [=========================>....] - ETA: 2s - loss: 0.4721 - acc: 0.7467
673/673 [==============================] - 22s 32ms/step - loss: 0.4694 - acc: 0.7459 - val_loss: 1.0511 - val_acc: 0.6066
Epoch 7/25

200/673 [=======>......................] - ETA: 14s - loss: 0.4703 - acc: 0.7300
400/673 [================>.............] - ETA: 8s - loss: 0.4640 - acc: 0.7425 
600/673 [=========================>....] - ETA: 2s - loss: 0.4526 - acc: 0.7533
673/673 [==============================] - 21s 32ms/step - loss: 0.4399 - acc: 0.7623 - val_loss: 1.2268 - val_acc: 0.5492
Epoch 8/25

200/673 [=======>......................] - ETA: 14s - loss: 0.4566 - acc: 0.7800
400/673 [================>.............] - ETA: 8s - loss: 0.4150 - acc: 0.8075 
600/673 [=========================>....] - ETA: 2s - loss: 0.4045 - acc: 0.8017
673/673 [==============================] - 22s 32ms/step - loss: 0.4030 - acc: 0.8009 - val_loss: 1.3514 - val_acc: 0.5410
Epoch 9/25

200/673 [=======>......................] - ETA: 14s - loss: 0.3682 - acc: 0.8200
400/673 [================>.............] - ETA: 8s - loss: 0.3743 - acc: 0.8175 
600/673 [=========================>....] - ETA: 2s - loss: 0.3774 - acc: 0.8067
673/673 [==============================] - 22s 32ms/step - loss: 0.3749 - acc: 0.8024 - val_loss: 1.3824 - val_acc: 0.5492
Epoch 10/25

200/673 [=======>......................] - ETA: 14s - loss: 0.3253 - acc: 0.8350
400/673 [================>.............] - ETA: 8s - loss: 0.3386 - acc: 0.8225 
600/673 [=========================>....] - ETA: 2s - loss: 0.3423 - acc: 0.8217
673/673 [==============================] - 22s 32ms/step - loss: 0.3438 - acc: 0.8172 - val_loss: 1.3837 - val_acc: 0.5410
Epoch 11/25

200/673 [=======>......................] - ETA: 14s - loss: 0.3298 - acc: 0.8150
400/673 [================>.............] - ETA: 8s - loss: 0.3078 - acc: 0.8375 
600/673 [=========================>....] - ETA: 2s - loss: 0.3142 - acc: 0.8400
673/673 [==============================] - 22s 32ms/step - loss: 0.3196 - acc: 0.8440 - val_loss: 1.4879 - val_acc: 0.5246
Epoch 12/25

200/673 [=======>......................] - ETA: 14s - loss: 0.3127 - acc: 0.8400
400/673 [================>.............] - ETA: 8s - loss: 0.3018 - acc: 0.8425 
600/673 [=========================>....] - ETA: 2s - loss: 0.2994 - acc: 0.8667
673/673 [==============================] - 22s 32ms/step - loss: 0.2998 - acc: 0.8678 - val_loss: 1.6408 - val_acc: 0.5328
Epoch 13/25

200/673 [=======>......................] - ETA: 14s - loss: 0.2803 - acc: 0.8800
400/673 [================>.............] - ETA: 8s - loss: 0.2775 - acc: 0.8575 
600/673 [=========================>....] - ETA: 2s - loss: 0.2795 - acc: 0.8633
673/673 [==============================] - 22s 32ms/step - loss: 0.2776 - acc: 0.8663 - val_loss: 1.7983 - val_acc: 0.5164
Epoch 14/25

200/673 [=======>......................] - ETA: 14s - loss: 0.2468 - acc: 0.9200
400/673 [================>.............] - ETA: 8s - loss: 0.2406 - acc: 0.9050 
600/673 [=========================>....] - ETA: 2s - loss: 0.2429 - acc: 0.8983
673/673 [==============================] - 22s 32ms/step - loss: 0.2535 - acc: 0.8871 - val_loss: 1.7166 - val_acc: 0.5246
Epoch 15/25

200/673 [=======>......................] - ETA: 14s - loss: 0.2264 - acc: 0.9000
400/673 [================>.............] - ETA: 8s - loss: 0.2272 - acc: 0.9000 
600/673 [=========================>....] - ETA: 2s - loss: 0.2316 - acc: 0.8983
673/673 [==============================] - 22s 32ms/step - loss: 0.2499 - acc: 0.8900 - val_loss: 1.7579 - val_acc: 0.5492
Epoch 16/25

200/673 [=======>......................] - ETA: 14s - loss: 0.2022 - acc: 0.9200
400/673 [================>.............] - ETA: 8s - loss: 0.2012 - acc: 0.9275 
600/673 [=========================>....] - ETA: 2s - loss: 0.2221 - acc: 0.9083
673/673 [==============================] - 22s 32ms/step - loss: 0.2288 - acc: 0.9049 - val_loss: 1.6606 - val_acc: 0.5820
Epoch 17/25

200/673 [=======>......................] - ETA: 14s - loss: 0.2284 - acc: 0.9100
400/673 [================>.............] - ETA: 8s - loss: 0.2386 - acc: 0.8900 
600/673 [=========================>....] - ETA: 2s - loss: 0.2158 - acc: 0.9050
673/673 [==============================] - 22s 32ms/step - loss: 0.2158 - acc: 0.9094 - val_loss: 1.8999 - val_acc: 0.5492
Epoch 18/25

200/673 [=======>......................] - ETA: 14s - loss: 0.2248 - acc: 0.9200
400/673 [================>.............] - ETA: 8s - loss: 0.2088 - acc: 0.9200 
600/673 [=========================>....] - ETA: 2s - loss: 0.2009 - acc: 0.9217
673/673 [==============================] - 22s 32ms/step - loss: 0.1983 - acc: 0.9227 - val_loss: 1.8170 - val_acc: 0.5656
Epoch 19/25

200/673 [=======>......................] - ETA: 14s - loss: 0.1603 - acc: 0.9400
400/673 [================>.............] - ETA: 8s - loss: 0.1731 - acc: 0.9275 
600/673 [=========================>....] - ETA: 2s - loss: 0.1705 - acc: 0.9300
673/673 [==============================] - 22s 32ms/step - loss: 0.1758 - acc: 0.9257 - val_loss: 1.8378 - val_acc: 0.5902
Epoch 20/25

200/673 [=======>......................] - ETA: 14s - loss: 0.1848 - acc: 0.9350
400/673 [================>.............] - ETA: 8s - loss: 0.1642 - acc: 0.9425 
600/673 [=========================>....] - ETA: 2s - loss: 0.1636 - acc: 0.9433
673/673 [==============================] - 22s 32ms/step - loss: 0.1625 - acc: 0.9421 - val_loss: 1.9330 - val_acc: 0.5984
Epoch 21/25

200/673 [=======>......................] - ETA: 14s - loss: 0.1284 - acc: 0.9600
400/673 [================>.............] - ETA: 8s - loss: 0.1414 - acc: 0.9550 
600/673 [=========================>....] - ETA: 2s - loss: 0.1418 - acc: 0.9500
673/673 [==============================] - 22s 32ms/step - loss: 0.1464 - acc: 0.9495 - val_loss: 1.7655 - val_acc: 0.6066
Epoch 22/25

200/673 [=======>......................] - ETA: 14s - loss: 0.1320 - acc: 0.9600
400/673 [================>.............] - ETA: 8s - loss: 0.1415 - acc: 0.9500 
600/673 [=========================>....] - ETA: 2s - loss: 0.1326 - acc: 0.9583
673/673 [==============================] - 22s 32ms/step - loss: 0.1313 - acc: 0.9614 - val_loss: 1.6740 - val_acc: 0.6311
Epoch 23/25

200/673 [=======>......................] - ETA: 14s - loss: 0.1291 - acc: 0.9700
400/673 [================>.............] - ETA: 8s - loss: 0.1258 - acc: 0.9625 
600/673 [=========================>....] - ETA: 2s - loss: 0.1243 - acc: 0.9600
673/673 [==============================] - 22s 32ms/step - loss: 0.1207 - acc: 0.9614 - val_loss: 1.6713 - val_acc: 0.6639
Epoch 24/25

200/673 [=======>......................] - ETA: 14s - loss: 0.1113 - acc: 0.9550
400/673 [================>.............] - ETA: 8s - loss: 0.1126 - acc: 0.9575 
600/673 [=========================>....] - ETA: 2s - loss: 0.1207 - acc: 0.9567
673/673 [==============================] - 22s 32ms/step - loss: 0.1196 - acc: 0.9554 - val_loss: 1.7518 - val_acc: 0.6639
Epoch 25/25

200/673 [=======>......................] - ETA: 14s - loss: 0.1151 - acc: 0.9700
400/673 [================>.............] - ETA: 8s - loss: 0.1184 - acc: 0.9700 
600/673 [=========================>....] - ETA: 2s - loss: 0.1175 - acc: 0.9667
673/673 [==============================] - 22s 32ms/step - loss: 0.1101 - acc: 0.9703 - val_loss: 1.7254 - val_acc: 0.6393
[[1.00000000e+00 2.52193309e-23]
 [2.85011351e-01 7.14988589e-01]
 [7.95006633e-01 2.04993382e-01]
 [0.00000000e+00 1.00000000e+00]
 [9.99958634e-01 4.13709313e-05]
 [8.45896602e-01 1.54103383e-01]
 [9.99611795e-01 3.88257991e-04]
 [0.00000000e+00 1.00000000e+00]
 [7.47848894e-09 1.00000000e+00]
 [4.72084939e-01 5.27915061e-01]
 [4.90622735e-03 9.95093822e-01]
 [6.46946669e-01 3.53053331e-01]
 [1.46676367e-02 9.85332310e-01]
 [1.00000000e+00 3.70290443e-09]
 [3.01247954e-01 6.98752046e-01]
 [6.43916905e-01 3.56083065e-01]
 [9.93409932e-01 6.59002410e-03]
 [8.89539540e-01 1.10460475e-01]
 [7.16601193e-01 2.83398807e-01]
 [1.98518485e-01 8.01481545e-01]
 [1.00000000e+00 8.57863885e-18]
 [9.99874592e-01 1.25347549e-04]
 [8.43904316e-01 1.56095713e-01]
 [9.47352588e-01 5.26474044e-02]
 [9.77915674e-02 9.02208447e-01]
 [9.99999762e-01 2.22322910e-07]
 [7.86642253e-01 2.13357732e-01]
 [7.26055086e-01 2.73944974e-01]
 [9.99338567e-01 6.61380007e-04]
 [9.26202953e-01 7.37970769e-02]
 [1.00000000e+00 3.34186401e-28]
 [6.78027749e-01 3.21972221e-01]
 [9.99940276e-01 5.97041435e-05]
 [9.09664184e-02 9.09033537e-01]
 [7.93397970e-09 1.00000000e+00]
 [7.69298375e-01 2.30701596e-01]
 [9.91411328e-01 8.58869683e-03]
 [9.79179919e-01 2.08200328e-02]
 [1.87581056e-04 9.99812424e-01]
 [5.17642319e-01 4.82357681e-01]
 [2.49638811e-01 7.50361204e-01]
 [4.78399359e-03 9.95216012e-01]
 [9.99350727e-01 6.49259309e-04]
 [9.95437205e-01 4.56281612e-03]
 [4.03891802e-01 5.96108139e-01]
 [2.58878176e-03 9.97411191e-01]
 [9.97598112e-01 2.40185554e-03]
 [2.16136128e-03 9.97838676e-01]
 [6.86403573e-01 3.13596427e-01]
 [1.00000000e+00 0.00000000e+00]
 [7.56402850e-01 2.43597195e-01]
 [3.16973299e-01 6.83026731e-01]
 [1.00000000e+00 2.52497103e-11]
 [0.00000000e+00 1.00000000e+00]
 [8.53699982e-01 1.46300018e-01]
 [3.20776224e-01 6.79223776e-01]
 [7.85968527e-02 9.21403110e-01]
 [7.82644987e-01 2.17355072e-01]
 [2.95679551e-02 9.70432103e-01]
 [1.00000000e+00 1.97843093e-08]
 [9.99999523e-01 4.33386617e-07]
 [9.76637840e-01 2.33621132e-02]
 [9.91384983e-01 8.61505140e-03]
 [7.51597155e-03 9.92484033e-01]
 [6.52932376e-02 9.34706748e-01]
 [1.50940090e-01 8.49059880e-01]
 [9.82824087e-01 1.71759035e-02]
 [5.46882927e-01 4.53117102e-01]
 [9.99954104e-01 4.58874456e-05]
 [1.46608268e-17 1.00000000e+00]
 [1.16692714e-01 8.83307219e-01]
 [9.95833635e-01 4.16629901e-03]
 [9.99976516e-01 2.34587606e-05]
 [9.92806911e-01 7.19308620e-03]
 [8.73097301e-01 1.26902729e-01]
 [9.94734287e-01 5.26572065e-03]
 [9.97621953e-01 2.37798784e-03]
 [4.35003251e-01 5.64996719e-01]
 [8.90126452e-03 9.91098702e-01]
 [5.24546564e-01 4.75453436e-01]
 [1.00000000e+00 4.31069641e-19]
 [9.99975204e-01 2.48142242e-05]
 [6.44451737e-01 3.55548233e-01]
 [1.00000000e+00 1.89943107e-14]
 [6.13505602e-01 3.86494398e-01]
 [4.76716261e-04 9.99523282e-01]
 [1.37629723e-02 9.86237049e-01]
 [1.14360014e-02 9.88564014e-01]
 [5.66211939e-01 4.33788031e-01]
 [8.60018365e-04 9.99139905e-01]
 [4.27156478e-01 5.72843492e-01]
 [4.52818036e-01 5.47181964e-01]
 [4.23773348e-01 5.76226652e-01]
 [9.09924030e-01 9.00759473e-02]
 [3.14738870e-01 6.85261130e-01]
 [3.14061910e-01 6.85938060e-01]
 [8.48079175e-02 9.15192127e-01]
 [6.38425887e-01 3.61574084e-01]
 [8.89438272e-01 1.10561714e-01]
 [7.58630931e-01 2.41369024e-01]
 [1.88221224e-04 9.99811828e-01]
 [5.96871972e-01 4.03128058e-01]
 [1.54631868e-01 8.45368087e-01]
 [4.22598794e-02 9.57740068e-01]
 [5.34468156e-04 9.99465525e-01]
 [9.76012886e-01 2.39871070e-02]
 [5.54749310e-01 4.45250660e-01]
 [4.22982067e-01 5.77017903e-01]
 [3.68428432e-13 1.00000000e+00]
 [6.77530210e-08 9.99999881e-01]
 [4.48807180e-02 9.55119252e-01]
 [5.64285578e-08 1.00000000e+00]
 [1.88672319e-01 8.11327636e-01]
 [4.64864641e-01 5.35135388e-01]
 [7.08955586e-01 2.91044354e-01]
 [3.60054284e-01 6.39945686e-01]
 [9.99702871e-01 2.97043152e-04]
 [5.30404627e-01 4.69595402e-01]
 [9.56208229e-01 4.37917672e-02]
 [5.32276392e-01 4.67723608e-01]
 [2.76884139e-01 7.23115921e-01]
 [6.78426683e-01 3.21573377e-01]]
saved: y_pred_from__cnn_aardvark_aug_concat.py_b_200_mask_p_5_n_25_a_kfold_0_l_0.0025
[[55 30]
 [14 23]]
