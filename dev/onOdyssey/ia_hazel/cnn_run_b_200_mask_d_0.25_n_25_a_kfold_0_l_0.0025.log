Using TensorFlow backend.
WARNING:tensorflow:From /n/home00/nchou/.conda/envs/envi/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.
Instructions for updating:
Colocations handled automatically by placer.
WARNING:tensorflow:From /n/home00/nchou/.conda/envs/envi/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.
Instructions for updating:
Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.
cnn_aardvark_aug_concat.py:672: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor("in..., outputs=Tensor("de...)`
  model = Model(input=ins, output=dense2)
WARNING:tensorflow:From /n/home00/nchou/.conda/envs/envi/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.cast instead.
2019-12-10 18:19:45.799220: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
2019-12-10 18:19:45.803289: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2900000000 Hz
2019-12-10 18:19:45.803386: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x55845fc11180 executing computations on platform Host. Devices:
2019-12-10 18:19:45.803394: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (0): <undefined>, <undefined>
['cnn_aardvark_aug_concat.py', '-b', '200', '--mask', '-d', '0.25', '-n', '25', '-a', '--kfold', '0', '-l', '0.0025']
1
2
Train on 673 samples, validate on 122 samples
Epoch 1/25

200/673 [=======>......................] - ETA: 53s - loss: 0.6947 - acc: 0.4800
400/673 [================>.............] - ETA: 27s - loss: 0.6933 - acc: 0.5425
600/673 [=========================>....] - ETA: 6s - loss: 0.9280 - acc: 0.5267 
673/673 [==============================] - 67s 99ms/step - loss: 0.9454 - acc: 0.5245 - val_loss: 0.7261 - val_acc: 0.4180
Epoch 2/25

200/673 [=======>......................] - ETA: 39s - loss: 0.5767 - acc: 0.6550
400/673 [================>.............] - ETA: 22s - loss: 0.5850 - acc: 0.6950
600/673 [=========================>....] - ETA: 6s - loss: 0.5926 - acc: 0.7117 
673/673 [==============================] - 59s 88ms/step - loss: 0.5920 - acc: 0.6999 - val_loss: 0.6939 - val_acc: 0.6475
Epoch 3/25

200/673 [=======>......................] - ETA: 39s - loss: 0.5576 - acc: 0.7600
400/673 [================>.............] - ETA: 22s - loss: 0.5585 - acc: 0.7475
600/673 [=========================>....] - ETA: 6s - loss: 0.5635 - acc: 0.7383 
673/673 [==============================] - 60s 88ms/step - loss: 0.5585 - acc: 0.7385 - val_loss: 0.6737 - val_acc: 0.6639
Epoch 4/25

200/673 [=======>......................] - ETA: 39s - loss: 0.5151 - acc: 0.7050
400/673 [================>.............] - ETA: 22s - loss: 0.5125 - acc: 0.7150
600/673 [=========================>....] - ETA: 6s - loss: 0.5039 - acc: 0.7150 
673/673 [==============================] - 60s 89ms/step - loss: 0.5083 - acc: 0.7147 - val_loss: 1.0201 - val_acc: 0.3607
Epoch 5/25

200/673 [=======>......................] - ETA: 39s - loss: 0.6540 - acc: 0.6250
400/673 [================>.............] - ETA: 22s - loss: 0.5694 - acc: 0.6825
600/673 [=========================>....] - ETA: 6s - loss: 0.5351 - acc: 0.7083 
673/673 [==============================] - 60s 89ms/step - loss: 0.5245 - acc: 0.7117 - val_loss: 0.7687 - val_acc: 0.5574
Epoch 6/25

200/673 [=======>......................] - ETA: 39s - loss: 0.4627 - acc: 0.7550
400/673 [================>.............] - ETA: 22s - loss: 0.4447 - acc: 0.7650
600/673 [=========================>....] - ETA: 6s - loss: 0.4513 - acc: 0.7633 
673/673 [==============================] - 60s 89ms/step - loss: 0.4476 - acc: 0.7652 - val_loss: 0.8075 - val_acc: 0.5410
Epoch 7/25

200/673 [=======>......................] - ETA: 39s - loss: 0.4434 - acc: 0.7550
400/673 [================>.............] - ETA: 22s - loss: 0.4257 - acc: 0.7725
600/673 [=========================>....] - ETA: 6s - loss: 0.4255 - acc: 0.7700 
673/673 [==============================] - 60s 89ms/step - loss: 0.4223 - acc: 0.7682 - val_loss: 0.8793 - val_acc: 0.5328
Epoch 8/25

200/673 [=======>......................] - ETA: 39s - loss: 0.3862 - acc: 0.8000
400/673 [================>.............] - ETA: 22s - loss: 0.4033 - acc: 0.7900
600/673 [=========================>....] - ETA: 6s - loss: 0.3893 - acc: 0.7983 
673/673 [==============================] - 60s 89ms/step - loss: 0.3827 - acc: 0.8009 - val_loss: 0.9515 - val_acc: 0.5574
Epoch 9/25

200/673 [=======>......................] - ETA: 39s - loss: 0.3649 - acc: 0.7950
400/673 [================>.............] - ETA: 22s - loss: 0.3645 - acc: 0.7975
600/673 [=========================>....] - ETA: 6s - loss: 0.3454 - acc: 0.8133 
673/673 [==============================] - 60s 88ms/step - loss: 0.3484 - acc: 0.8113 - val_loss: 1.0186 - val_acc: 0.5574
Epoch 10/25

200/673 [=======>......................] - ETA: 39s - loss: 0.3505 - acc: 0.8000
400/673 [================>.............] - ETA: 22s - loss: 0.3166 - acc: 0.8225
600/673 [=========================>....] - ETA: 6s - loss: 0.3268 - acc: 0.8183 
673/673 [==============================] - 59s 88ms/step - loss: 0.3181 - acc: 0.8262 - val_loss: 1.1215 - val_acc: 0.5410
Epoch 11/25

200/673 [=======>......................] - ETA: 39s - loss: 0.2797 - acc: 0.8800
400/673 [================>.............] - ETA: 22s - loss: 0.2728 - acc: 0.8625
600/673 [=========================>....] - ETA: 5s - loss: 0.2785 - acc: 0.8500 
673/673 [==============================] - 59s 88ms/step - loss: 0.2835 - acc: 0.8484 - val_loss: 1.2126 - val_acc: 0.5574
Epoch 12/25

200/673 [=======>......................] - ETA: 38s - loss: 0.2641 - acc: 0.8650
400/673 [================>.............] - ETA: 22s - loss: 0.2690 - acc: 0.8600
600/673 [=========================>....] - ETA: 5s - loss: 0.2631 - acc: 0.8617 
673/673 [==============================] - 59s 88ms/step - loss: 0.2620 - acc: 0.8678 - val_loss: 1.3216 - val_acc: 0.5410
Epoch 13/25

200/673 [=======>......................] - ETA: 38s - loss: 0.2035 - acc: 0.9000
400/673 [================>.............] - ETA: 22s - loss: 0.2293 - acc: 0.8750
600/673 [=========================>....] - ETA: 5s - loss: 0.2200 - acc: 0.8933 
673/673 [==============================] - 59s 88ms/step - loss: 0.2240 - acc: 0.8886 - val_loss: 1.5164 - val_acc: 0.5082
Epoch 14/25

200/673 [=======>......................] - ETA: 38s - loss: 0.2280 - acc: 0.8900
400/673 [================>.............] - ETA: 22s - loss: 0.2226 - acc: 0.8950
600/673 [=========================>....] - ETA: 5s - loss: 0.2026 - acc: 0.9083 
673/673 [==============================] - 59s 87ms/step - loss: 0.2021 - acc: 0.9123 - val_loss: 1.5674 - val_acc: 0.5164
Epoch 15/25

200/673 [=======>......................] - ETA: 38s - loss: 0.1769 - acc: 0.9300
400/673 [================>.............] - ETA: 22s - loss: 0.1913 - acc: 0.9225
600/673 [=========================>....] - ETA: 6s - loss: 0.1851 - acc: 0.9233 
673/673 [==============================] - 59s 88ms/step - loss: 0.1797 - acc: 0.9272 - val_loss: 1.6275 - val_acc: 0.4836
Epoch 16/25

200/673 [=======>......................] - ETA: 38s - loss: 0.1878 - acc: 0.9450
400/673 [================>.............] - ETA: 22s - loss: 0.1988 - acc: 0.9150
600/673 [=========================>....] - ETA: 6s - loss: 0.1753 - acc: 0.9233 
673/673 [==============================] - 59s 88ms/step - loss: 0.1699 - acc: 0.9287 - val_loss: 2.0044 - val_acc: 0.4590
Epoch 17/25

200/673 [=======>......................] - ETA: 38s - loss: 0.1630 - acc: 0.9300
400/673 [================>.............] - ETA: 22s - loss: 0.1760 - acc: 0.9425
600/673 [=========================>....] - ETA: 6s - loss: 0.1706 - acc: 0.9417 
673/673 [==============================] - 59s 88ms/step - loss: 0.1644 - acc: 0.9465 - val_loss: 1.9488 - val_acc: 0.5000
Epoch 18/25

200/673 [=======>......................] - ETA: 38s - loss: 0.1477 - acc: 0.9350
400/673 [================>.............] - ETA: 22s - loss: 0.1300 - acc: 0.9450
600/673 [=========================>....] - ETA: 5s - loss: 0.1214 - acc: 0.9517 
673/673 [==============================] - 59s 88ms/step - loss: 0.1259 - acc: 0.9510 - val_loss: 2.0901 - val_acc: 0.4754
Epoch 19/25

200/673 [=======>......................] - ETA: 38s - loss: 0.1049 - acc: 0.9550
400/673 [================>.............] - ETA: 22s - loss: 0.1074 - acc: 0.9600
600/673 [=========================>....] - ETA: 5s - loss: 0.1130 - acc: 0.9617 
673/673 [==============================] - 59s 88ms/step - loss: 0.1188 - acc: 0.9599 - val_loss: 2.1849 - val_acc: 0.4836
Epoch 20/25

200/673 [=======>......................] - ETA: 38s - loss: 0.1057 - acc: 0.9500
400/673 [================>.............] - ETA: 22s - loss: 0.0963 - acc: 0.9625
600/673 [=========================>....] - ETA: 5s - loss: 0.0889 - acc: 0.9683 
673/673 [==============================] - 59s 88ms/step - loss: 0.0951 - acc: 0.9658 - val_loss: 2.2074 - val_acc: 0.5246
Epoch 21/25

200/673 [=======>......................] - ETA: 38s - loss: 0.0838 - acc: 0.9700
400/673 [================>.............] - ETA: 22s - loss: 0.0807 - acc: 0.9725
600/673 [=========================>....] - ETA: 5s - loss: 0.0974 - acc: 0.9717 
673/673 [==============================] - 59s 88ms/step - loss: 0.1112 - acc: 0.9703 - val_loss: 2.3025 - val_acc: 0.5082
Epoch 22/25

200/673 [=======>......................] - ETA: 38s - loss: 0.0757 - acc: 0.9750
400/673 [================>.............] - ETA: 22s - loss: 0.0854 - acc: 0.9725
600/673 [=========================>....] - ETA: 5s - loss: 0.0838 - acc: 0.9717 
673/673 [==============================] - 59s 88ms/step - loss: 0.0873 - acc: 0.9718 - val_loss: 2.3776 - val_acc: 0.5000
Epoch 23/25

200/673 [=======>......................] - ETA: 38s - loss: 0.0663 - acc: 0.9800
400/673 [================>.............] - ETA: 22s - loss: 0.0805 - acc: 0.9800
600/673 [=========================>....] - ETA: 6s - loss: 0.0835 - acc: 0.9783 
673/673 [==============================] - 59s 88ms/step - loss: 0.0902 - acc: 0.9747 - val_loss: 2.2502 - val_acc: 0.5328
Epoch 24/25

200/673 [=======>......................] - ETA: 38s - loss: 0.1558 - acc: 0.9800
400/673 [================>.............] - ETA: 22s - loss: 0.1197 - acc: 0.9775
600/673 [=========================>....] - ETA: 5s - loss: 0.1035 - acc: 0.9783 
673/673 [==============================] - 59s 88ms/step - loss: 0.1001 - acc: 0.9777 - val_loss: 2.3386 - val_acc: 0.5328
Epoch 25/25

200/673 [=======>......................] - ETA: 38s - loss: 0.0778 - acc: 0.9750
400/673 [================>.............] - ETA: 22s - loss: 0.0689 - acc: 0.9775
600/673 [=========================>....] - ETA: 6s - loss: 0.0644 - acc: 0.9833 
673/673 [==============================] - 59s 88ms/step - loss: 0.0640 - acc: 0.9837 - val_loss: 2.5575 - val_acc: 0.5164
[[1.0000000e+00 4.9381534e-17]
 [1.3537900e-05 9.9998641e-01]
 [4.7596812e-01 5.2403182e-01]
 [4.8397439e-31 1.0000000e+00]
 [1.0000000e+00 4.9930438e-11]
 [1.8128647e-02 9.8187137e-01]
 [9.1942203e-01 8.0577984e-02]
 [3.3564207e-10 1.0000000e+00]
 [3.8094690e-08 1.0000000e+00]
 [8.9755648e-01 1.0244345e-01]
 [8.7688863e-04 9.9912316e-01]
 [4.9510407e-01 5.0489587e-01]
 [5.1939860e-02 9.4806015e-01]
 [1.3742977e-09 1.0000000e+00]
 [1.2158647e-02 9.8784131e-01]
 [5.8965228e-02 9.4103479e-01]
 [9.8960668e-01 1.0393325e-02]
 [8.0961883e-01 1.9038114e-01]
 [3.0790210e-01 6.9209784e-01]
 [2.0885475e-02 9.7911453e-01]
 [1.0000000e+00 7.7214859e-14]
 [8.9643908e-01 1.0356091e-01]
 [6.0654157e-01 3.9345846e-01]
 [5.0245756e-01 4.9754250e-01]
 [2.3969048e-01 7.6030958e-01]
 [9.9538213e-01 4.6178959e-03]
 [7.2687358e-01 2.7312642e-01]
 [2.9427785e-01 7.0572215e-01]
 [8.0080044e-01 1.9919959e-01]
 [7.8719926e-01 2.1280073e-01]
 [7.8069788e-06 9.9999225e-01]
 [4.8382592e-01 5.1617408e-01]
 [3.4966370e-01 6.5033627e-01]
 [7.5320085e-03 9.9246794e-01]
 [8.2260306e-04 9.9917740e-01]
 [6.5048970e-02 9.3495107e-01]
 [7.9861330e-35 1.0000000e+00]
 [2.5542316e-01 7.4457681e-01]
 [7.9231013e-06 9.9999213e-01]
 [4.4033527e-01 5.5966467e-01]
 [4.0869313e-01 5.9130687e-01]
 [5.2323530e-04 9.9947673e-01]
 [9.9827623e-01 1.7237311e-03]
 [9.9792945e-01 2.0705746e-03]
 [6.0378861e-01 3.9621139e-01]
 [1.9799155e-04 9.9980205e-01]
 [8.9202380e-01 1.0797622e-01]
 [2.4161187e-01 7.5838810e-01]
 [8.0254090e-01 1.9745906e-01]
 [1.0000000e+00 4.6520832e-08]
 [5.6685907e-01 4.3314093e-01]
 [2.9071191e-01 7.0928806e-01]
 [2.4893339e-09 1.0000000e+00]
 [5.8826002e-31 1.0000000e+00]
 [7.9270613e-01 2.0729393e-01]
 [5.6073225e-01 4.3926778e-01]
 [7.5600791e-01 2.4399209e-01]
 [7.6725417e-01 2.3274578e-01]
 [3.0519588e-02 9.6948045e-01]
 [9.7419953e-01 2.5800478e-02]
 [9.8116279e-01 1.8837268e-02]
 [9.6436113e-01 3.5638895e-02]
 [8.5454077e-01 1.4545928e-01]
 [7.5925719e-03 9.9240750e-01]
 [3.8655080e-02 9.6134490e-01]
 [2.6697469e-01 7.3302531e-01]
 [7.9680163e-01 2.0319834e-01]
 [4.1136748e-01 5.8863252e-01]
 [9.9998403e-01 1.5936908e-05]
 [3.4453489e-17 1.0000000e+00]
 [4.4251549e-01 5.5748445e-01]
 [5.1985558e-02 9.4801444e-01]
 [6.7403004e-02 9.3259698e-01]
 [1.1752518e-04 9.9988246e-01]
 [7.6994568e-01 2.3005432e-01]
 [8.6786896e-01 1.3213107e-01]
 [6.8515640e-01 3.1484360e-01]
 [6.8795502e-01 3.1204495e-01]
 [1.2365708e-01 8.7634295e-01]
 [9.7513586e-02 9.0248644e-01]
 [1.0000000e+00 3.6141246e-14]
 [9.9995995e-01 4.0062241e-05]
 [2.0284660e-06 9.9999797e-01]
 [1.0000000e+00 6.3064285e-12]
 [7.4971426e-01 2.5028583e-01]
 [1.4301108e-01 8.5698897e-01]
 [2.6226232e-03 9.9737740e-01]
 [2.9662184e-02 9.7033781e-01]
 [7.3052508e-01 2.6947486e-01]
 [7.3494768e-05 9.9992645e-01]
 [4.3316339e-03 9.9566841e-01]
 [5.1025611e-01 4.8974395e-01]
 [6.8873519e-01 3.1126478e-01]
 [7.2104913e-01 2.7895087e-01]
 [5.5116916e-01 4.4883087e-01]
 [3.9854798e-01 6.0145205e-01]
 [4.1652167e-01 5.8347827e-01]
 [1.7479810e-01 8.2520187e-01]
 [2.9385458e-06 9.9999702e-01]
 [6.1698985e-01 3.8301018e-01]
 [4.6270575e-08 1.0000000e+00]
 [3.4248403e-01 6.5751606e-01]
 [2.8502852e-01 7.1497154e-01]
 [1.8777336e-03 9.9812227e-01]
 [2.7540906e-07 9.9999976e-01]
 [9.9792564e-01 2.0743378e-03]
 [8.4932756e-01 1.5067248e-01]
 [3.6589092e-01 6.3410908e-01]
 [5.3386648e-06 9.9999464e-01]
 [3.1533941e-07 9.9999964e-01]
 [5.9744924e-01 4.0255076e-01]
 [3.0445202e-13 1.0000000e+00]
 [3.3651775e-01 6.6348225e-01]
 [5.9109903e-03 9.9408901e-01]
 [6.2733769e-01 3.7266234e-01]
 [4.0994054e-01 5.9005946e-01]
 [5.6431530e-04 9.9943572e-01]
 [6.0275042e-01 3.9724964e-01]
 [9.6364361e-01 3.6356457e-02]
 [4.4888866e-01 5.5111134e-01]
 [2.3656110e-01 7.6343882e-01]
 [5.0424850e-01 4.9575153e-01]]
saved: y_pred_from__cnn_aardvark_aug_concat.py_b_200_mask_d_0.25_n_25_a_kfold_0_l_0.0025
[[39 46]
 [13 24]]
