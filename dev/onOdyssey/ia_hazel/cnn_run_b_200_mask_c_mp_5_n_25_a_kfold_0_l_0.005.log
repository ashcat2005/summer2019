Using TensorFlow backend.
WARNING:tensorflow:From /n/home00/nchou/.conda/envs/envi/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.
Instructions for updating:
Colocations handled automatically by placer.
cnn_aardvark_aug_concat.py:672: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor("in..., outputs=Tensor("de...)`
  model = Model(input=ins, output=dense2)
WARNING:tensorflow:From /n/home00/nchou/.conda/envs/envi/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.cast instead.
2019-12-10 18:19:28.252496: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
2019-12-10 18:19:28.256207: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2900000000 Hz
2019-12-10 18:19:28.256277: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x557a88797bd0 executing computations on platform Host. Devices:
2019-12-10 18:19:28.256285: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (0): <undefined>, <undefined>
['cnn_aardvark_aug_concat.py', '-b', '200', '--mask', '-c', '--mp', '5', '-n', '25', '-a', '--kfold', '0', '-l', '0.005']
1
2
Train on 673 samples, validate on 122 samples
Epoch 1/25

200/673 [=======>......................] - ETA: 26s - loss: 0.6931 - acc: 0.5250
400/673 [================>.............] - ETA: 14s - loss: 0.6951 - acc: 0.4825
600/673 [=========================>....] - ETA: 3s - loss: 0.7031 - acc: 0.4733 
673/673 [==============================] - 37s 55ms/step - loss: 0.7025 - acc: 0.4770 - val_loss: 0.6873 - val_acc: 0.7049
Epoch 2/25

200/673 [=======>......................] - ETA: 23s - loss: 0.6874 - acc: 0.5950
400/673 [================>.............] - ETA: 13s - loss: 0.6860 - acc: 0.5725
600/673 [=========================>....] - ETA: 3s - loss: 1.0971 - acc: 0.5483 
673/673 [==============================] - 35s 53ms/step - loss: 1.0510 - acc: 0.5557 - val_loss: 1.2613 - val_acc: 0.6967
Epoch 3/25

200/673 [=======>......................] - ETA: 23s - loss: 1.9947 - acc: 0.5200
400/673 [================>.............] - ETA: 13s - loss: 1.4549 - acc: 0.4975
600/673 [=========================>....] - ETA: 3s - loss: 1.4764 - acc: 0.4867 
673/673 [==============================] - 35s 53ms/step - loss: 1.4318 - acc: 0.4948 - val_loss: 0.9167 - val_acc: 0.3033
Epoch 4/25

200/673 [=======>......................] - ETA: 23s - loss: 0.7277 - acc: 0.5150
400/673 [================>.............] - ETA: 13s - loss: 0.7079 - acc: 0.5325
600/673 [=========================>....] - ETA: 3s - loss: 0.7308 - acc: 0.5367 
673/673 [==============================] - 35s 53ms/step - loss: 0.7507 - acc: 0.5260 - val_loss: 0.6124 - val_acc: 0.6967
Epoch 5/25

200/673 [=======>......................] - ETA: 23s - loss: 0.7550 - acc: 0.4850
400/673 [================>.............] - ETA: 13s - loss: 0.7163 - acc: 0.5275
600/673 [=========================>....] - ETA: 3s - loss: 0.7041 - acc: 0.5450 
673/673 [==============================] - 35s 53ms/step - loss: 0.7010 - acc: 0.5498 - val_loss: 0.7504 - val_acc: 0.3033
Epoch 6/25

200/673 [=======>......................] - ETA: 23s - loss: 0.6863 - acc: 0.5150
400/673 [================>.............] - ETA: 13s - loss: 0.6935 - acc: 0.4975
600/673 [=========================>....] - ETA: 3s - loss: 0.6887 - acc: 0.5033 
673/673 [==============================] - 35s 53ms/step - loss: 0.6871 - acc: 0.5007 - val_loss: 0.7098 - val_acc: 0.3197
Epoch 7/25

200/673 [=======>......................] - ETA: 23s - loss: 0.6866 - acc: 0.4850
400/673 [================>.............] - ETA: 13s - loss: 0.6812 - acc: 0.5375
600/673 [=========================>....] - ETA: 3s - loss: 0.6783 - acc: 0.5483 
673/673 [==============================] - 35s 53ms/step - loss: 0.6792 - acc: 0.5498 - val_loss: 0.6963 - val_acc: 0.5820
Epoch 8/25

200/673 [=======>......................] - ETA: 23s - loss: 0.6765 - acc: 0.5800
400/673 [================>.............] - ETA: 13s - loss: 0.6738 - acc: 0.5925
600/673 [=========================>....] - ETA: 3s - loss: 0.6703 - acc: 0.6000 
673/673 [==============================] - 35s 53ms/step - loss: 0.6682 - acc: 0.6122 - val_loss: 0.6752 - val_acc: 0.6967
Epoch 9/25

200/673 [=======>......................] - ETA: 23s - loss: 0.6591 - acc: 0.6200
400/673 [================>.............] - ETA: 13s - loss: 0.6581 - acc: 0.6300
600/673 [=========================>....] - ETA: 3s - loss: 0.6612 - acc: 0.6117 
673/673 [==============================] - 35s 53ms/step - loss: 0.6720 - acc: 0.6048 - val_loss: 0.6476 - val_acc: 0.7213
Epoch 10/25

200/673 [=======>......................] - ETA: 23s - loss: 0.6703 - acc: 0.5900
400/673 [================>.............] - ETA: 13s - loss: 0.6747 - acc: 0.5850
600/673 [=========================>....] - ETA: 3s - loss: 0.6745 - acc: 0.6033 
673/673 [==============================] - 35s 53ms/step - loss: 0.6763 - acc: 0.5884 - val_loss: 0.7210 - val_acc: 0.5738
Epoch 11/25

200/673 [=======>......................] - ETA: 23s - loss: 0.6645 - acc: 0.6000
400/673 [================>.............] - ETA: 13s - loss: 0.6649 - acc: 0.5975
600/673 [=========================>....] - ETA: 3s - loss: 0.6604 - acc: 0.6183 
673/673 [==============================] - 35s 53ms/step - loss: 0.6575 - acc: 0.6196 - val_loss: 0.6718 - val_acc: 0.7049
Epoch 12/25

200/673 [=======>......................] - ETA: 23s - loss: 0.6496 - acc: 0.6250
400/673 [================>.............] - ETA: 13s - loss: 0.6543 - acc: 0.6375
600/673 [=========================>....] - ETA: 3s - loss: 0.6519 - acc: 0.6300 
673/673 [==============================] - 36s 53ms/step - loss: 0.6512 - acc: 0.6270 - val_loss: 0.7270 - val_acc: 0.6066
Epoch 13/25

200/673 [=======>......................] - ETA: 23s - loss: 0.6482 - acc: 0.6400
400/673 [================>.............] - ETA: 13s - loss: 0.6532 - acc: 0.6425
600/673 [=========================>....] - ETA: 3s - loss: 0.6383 - acc: 0.6517 
673/673 [==============================] - 35s 53ms/step - loss: 0.6393 - acc: 0.6419 - val_loss: 0.7626 - val_acc: 0.6066
Epoch 14/25

200/673 [=======>......................] - ETA: 23s - loss: 0.6241 - acc: 0.6500
400/673 [================>.............] - ETA: 13s - loss: 0.6280 - acc: 0.6425
600/673 [=========================>....] - ETA: 3s - loss: 0.6330 - acc: 0.6400 
673/673 [==============================] - 35s 53ms/step - loss: 0.6372 - acc: 0.6419 - val_loss: 0.7896 - val_acc: 0.5984
Epoch 15/25

200/673 [=======>......................] - ETA: 23s - loss: 0.6464 - acc: 0.6000
400/673 [================>.............] - ETA: 13s - loss: 0.6334 - acc: 0.6350
600/673 [=========================>....] - ETA: 3s - loss: 0.6346 - acc: 0.6367 
673/673 [==============================] - 35s 53ms/step - loss: 0.6280 - acc: 0.6434 - val_loss: 0.7348 - val_acc: 0.6803
Epoch 16/25

200/673 [=======>......................] - ETA: 23s - loss: 0.6394 - acc: 0.6000
400/673 [================>.............] - ETA: 13s - loss: 0.6074 - acc: 0.6525
600/673 [=========================>....] - ETA: 3s - loss: 0.6081 - acc: 0.6433 
673/673 [==============================] - 35s 52ms/step - loss: 0.6189 - acc: 0.6404 - val_loss: 0.7319 - val_acc: 0.7049
Epoch 17/25

200/673 [=======>......................] - ETA: 23s - loss: 0.6490 - acc: 0.5850
400/673 [================>.............] - ETA: 13s - loss: 0.6391 - acc: 0.6100
600/673 [=========================>....] - ETA: 3s - loss: 0.6228 - acc: 0.6317 
673/673 [==============================] - 35s 52ms/step - loss: 0.6250 - acc: 0.6226 - val_loss: 0.8843 - val_acc: 0.5984
Epoch 18/25

200/673 [=======>......................] - ETA: 23s - loss: 0.6203 - acc: 0.6600
400/673 [================>.............] - ETA: 13s - loss: 0.6180 - acc: 0.6525
600/673 [=========================>....] - ETA: 3s - loss: 0.6134 - acc: 0.6517 
673/673 [==============================] - 35s 52ms/step - loss: 0.6104 - acc: 0.6508 - val_loss: 1.0759 - val_acc: 0.3525
Epoch 19/25

200/673 [=======>......................] - ETA: 23s - loss: 0.5953 - acc: 0.6150
400/673 [================>.............] - ETA: 13s - loss: 0.6220 - acc: 0.5975
600/673 [=========================>....] - ETA: 3s - loss: 0.6098 - acc: 0.6250 
673/673 [==============================] - 35s 52ms/step - loss: 0.6102 - acc: 0.6256 - val_loss: 0.7911 - val_acc: 0.6967
Epoch 20/25

200/673 [=======>......................] - ETA: 23s - loss: 0.6163 - acc: 0.6850
400/673 [================>.............] - ETA: 13s - loss: 0.6045 - acc: 0.6500
600/673 [=========================>....] - ETA: 3s - loss: 0.5891 - acc: 0.6417 
673/673 [==============================] - 35s 52ms/step - loss: 0.6050 - acc: 0.6300 - val_loss: 0.8910 - val_acc: 0.6311
Epoch 21/25

200/673 [=======>......................] - ETA: 23s - loss: 0.6115 - acc: 0.6750
400/673 [================>.............] - ETA: 13s - loss: 0.6933 - acc: 0.6125
600/673 [=========================>....] - ETA: 3s - loss: 0.6871 - acc: 0.6233 
673/673 [==============================] - 35s 52ms/step - loss: 0.6748 - acc: 0.6270 - val_loss: 1.1982 - val_acc: 0.3525
Epoch 22/25

200/673 [=======>......................] - ETA: 23s - loss: 0.6414 - acc: 0.6100
400/673 [================>.............] - ETA: 13s - loss: 0.6233 - acc: 0.6425
600/673 [=========================>....] - ETA: 3s - loss: 0.6284 - acc: 0.6500 
673/673 [==============================] - 35s 52ms/step - loss: 0.6281 - acc: 0.6478 - val_loss: 1.0475 - val_acc: 0.6066
Epoch 23/25

200/673 [=======>......................] - ETA: 23s - loss: 0.5851 - acc: 0.6600
400/673 [================>.............] - ETA: 13s - loss: 0.6024 - acc: 0.6400
600/673 [=========================>....] - ETA: 3s - loss: 0.5974 - acc: 0.6600 
673/673 [==============================] - 35s 53ms/step - loss: 0.6139 - acc: 0.6419 - val_loss: 0.9332 - val_acc: 0.6557
Epoch 24/25

200/673 [=======>......................] - ETA: 23s - loss: 0.5991 - acc: 0.6650
400/673 [================>.............] - ETA: 13s - loss: 0.5881 - acc: 0.6800
600/673 [=========================>....] - ETA: 3s - loss: 0.5953 - acc: 0.6683 
673/673 [==============================] - 35s 52ms/step - loss: 0.5887 - acc: 0.6701 - val_loss: 0.8812 - val_acc: 0.6230
Epoch 25/25

200/673 [=======>......................] - ETA: 23s - loss: 0.5469 - acc: 0.6800
400/673 [================>.............] - ETA: 13s - loss: 0.5810 - acc: 0.6450
600/673 [=========================>....] - ETA: 3s - loss: 0.5927 - acc: 0.6333 
673/673 [==============================] - 35s 52ms/step - loss: 0.5886 - acc: 0.6419 - val_loss: 0.8511 - val_acc: 0.5574
[[6.2380224e-01 3.7619781e-01]
 [4.6346667e-01 5.3653330e-01]
 [5.3877044e-01 4.6122959e-01]
 [1.7598469e-04 9.9982399e-01]
 [5.1360106e-01 4.8639894e-01]
 [5.3016025e-01 4.6983972e-01]
 [6.1442411e-01 3.8557592e-01]
 [6.1106801e-01 3.8893196e-01]
 [4.0130295e-02 9.5986962e-01]
 [4.9604470e-01 5.0395536e-01]
 [3.6738133e-01 6.3261867e-01]
 [5.3768611e-01 4.6231392e-01]
 [5.3865534e-01 4.6134463e-01]
 [3.2088959e-01 6.7911041e-01]
 [5.7323128e-01 4.2676872e-01]
 [4.6981072e-01 5.3018928e-01]
 [4.9225792e-01 5.0774211e-01]
 [5.4341495e-01 4.5658505e-01]
 [4.9325642e-01 5.0674361e-01]
 [2.1187137e-01 7.8812861e-01]
 [5.1706380e-01 4.8293626e-01]
 [5.5269688e-01 4.4730312e-01]
 [4.7125232e-01 5.2874774e-01]
 [4.5905402e-01 5.4094595e-01]
 [5.3507560e-01 4.6492445e-01]
 [4.8386854e-01 5.1613146e-01]
 [4.7031039e-01 5.2968967e-01]
 [5.0760698e-01 4.9239308e-01]
 [5.4401177e-01 4.5598826e-01]
 [5.1069033e-01 4.8930961e-01]
 [3.7053469e-01 6.2946528e-01]
 [5.1154822e-01 4.8845181e-01]
 [4.7797850e-01 5.2202153e-01]
 [5.6193393e-01 4.3806604e-01]
 [5.9718204e-01 4.0281793e-01]
 [4.7039157e-01 5.2960843e-01]
 [1.7534101e-05 9.9998248e-01]
 [5.4049730e-01 4.5950276e-01]
 [2.0547517e-01 7.9452491e-01]
 [5.3914249e-01 4.6085751e-01]
 [5.2458614e-01 4.7541383e-01]
 [5.1589322e-01 4.8410684e-01]
 [3.8397786e-01 6.1602211e-01]
 [3.8021052e-01 6.1978948e-01]
 [5.3327477e-01 4.6672520e-01]
 [2.4951808e-01 7.5048196e-01]
 [5.7212627e-01 4.2787376e-01]
 [1.8403386e-01 8.1596619e-01]
 [5.4968065e-01 4.5031932e-01]
 [9.4575024e-01 5.4249737e-02]
 [5.4558206e-01 4.5441794e-01]
 [5.3759271e-01 4.6240735e-01]
 [9.4677210e-01 5.3227905e-02]
 [2.1640408e-01 7.8359592e-01]
 [5.4925776e-01 4.5074227e-01]
 [4.8216775e-01 5.1783216e-01]
 [5.4637915e-01 4.5362091e-01]
 [5.3628451e-01 4.6371546e-01]
 [3.7085739e-01 6.2914252e-01]
 [4.9058756e-01 5.0941247e-01]
 [5.4423678e-01 4.5576322e-01]
 [4.4763440e-01 5.5236554e-01]
 [5.3247350e-01 4.6752650e-01]
 [4.7707495e-01 5.2292502e-01]
 [5.5724549e-01 4.4275445e-01]
 [5.3744084e-01 4.6255919e-01]
 [5.4478383e-01 4.5521611e-01]
 [5.2014422e-01 4.7985584e-01]
 [4.8445836e-01 5.1554155e-01]
 [5.7980925e-02 9.4201905e-01]
 [5.0660080e-01 4.9339914e-01]
 [5.0012964e-01 4.9987042e-01]
 [6.3959557e-01 3.6040443e-01]
 [4.7671238e-01 5.2328759e-01]
 [5.5138868e-01 4.4861129e-01]
 [5.3017473e-01 4.6982527e-01]
 [5.4211408e-01 4.5788592e-01]
 [4.8822221e-01 5.1177776e-01]
 [3.3815727e-01 6.6184276e-01]
 [5.1081538e-01 4.8918468e-01]
 [9.0918565e-01 9.0814352e-02]
 [4.0476632e-01 5.9523368e-01]
 [4.2661682e-01 5.7338321e-01]
 [9.6121722e-01 3.8782761e-02]
 [4.6640277e-01 5.3359723e-01]
 [3.7279487e-01 6.2720513e-01]
 [2.5153217e-01 7.4846780e-01]
 [2.5939935e-01 7.4060065e-01]
 [4.9000829e-01 5.0999165e-01]
 [2.1268114e-01 7.8731883e-01]
 [4.2192453e-01 5.7807547e-01]
 [5.3013641e-01 4.6986362e-01]
 [5.2387148e-01 4.7612858e-01]
 [5.3666234e-01 4.6333769e-01]
 [3.8761595e-01 6.1238402e-01]
 [5.1691580e-01 4.8308420e-01]
 [3.9187437e-01 6.0812563e-01]
 [4.3138665e-01 5.6861335e-01]
 [3.4327149e-02 9.6567285e-01]
 [5.2498531e-01 4.7501472e-01]
 [7.2165355e-02 9.2783469e-01]
 [4.5088822e-01 5.4911178e-01]
 [4.6109754e-01 5.3890252e-01]
 [3.7275144e-01 6.2724859e-01]
 [2.3994109e-02 9.7600591e-01]
 [5.4228622e-01 4.5771372e-01]
 [5.0603586e-01 4.9396411e-01]
 [4.7392797e-01 5.2607203e-01]
 [2.4096878e-01 7.5903124e-01]
 [3.2422394e-02 9.6757764e-01]
 [3.9125696e-01 6.0874301e-01]
 [4.4801529e-02 9.5519841e-01]
 [5.2622986e-01 4.7377014e-01]
 [5.6646109e-01 4.3353888e-01]
 [5.3207552e-01 4.6792448e-01]
 [5.3127933e-01 4.6872070e-01]
 [5.7569343e-01 4.2430657e-01]
 [5.3297555e-01 4.6702439e-01]
 [5.3851801e-01 4.6148193e-01]
 [5.4454261e-01 4.5545745e-01]
 [5.3196812e-01 4.6803191e-01]
 [5.4419374e-01 4.5580626e-01]]
saved: y_pred_from__cnn_aardvark_aug_concat.py_b_200_mask_c_mp_5_n_25_a_kfold_0_l_0.005
[[48 37]
 [17 20]]
