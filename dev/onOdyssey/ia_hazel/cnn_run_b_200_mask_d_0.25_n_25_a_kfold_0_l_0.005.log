Using TensorFlow backend.
WARNING:tensorflow:From /n/home00/nchou/.conda/envs/envi/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.
Instructions for updating:
Colocations handled automatically by placer.
WARNING:tensorflow:From /n/home00/nchou/.conda/envs/envi/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.
Instructions for updating:
Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.
cnn_aardvark_aug_concat.py:672: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor("in..., outputs=Tensor("de...)`
  model = Model(input=ins, output=dense2)
WARNING:tensorflow:From /n/home00/nchou/.conda/envs/envi/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.cast instead.
2019-12-10 18:19:42.063287: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
2019-12-10 18:19:42.067354: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2900000000 Hz
2019-12-10 18:19:42.067444: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x55d1ee8333b0 executing computations on platform Host. Devices:
2019-12-10 18:19:42.067452: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (0): <undefined>, <undefined>
['cnn_aardvark_aug_concat.py', '-b', '200', '--mask', '-d', '0.25', '-n', '25', '-a', '--kfold', '0', '-l', '0.005']
1
2
Train on 673 samples, validate on 122 samples
Epoch 1/25

200/673 [=======>......................] - ETA: 57s - loss: 0.6923 - acc: 0.5450
400/673 [================>.............] - ETA: 28s - loss: 2.8074 - acc: 0.5150
600/673 [=========================>....] - ETA: 7s - loss: 2.2442 - acc: 0.5183 
673/673 [==============================] - 71s 105ms/step - loss: 2.0878 - acc: 0.5171 - val_loss: 0.6726 - val_acc: 0.6639
Epoch 2/25

200/673 [=======>......................] - ETA: 42s - loss: 0.6543 - acc: 0.6150
400/673 [================>.............] - ETA: 24s - loss: 0.6521 - acc: 0.6200
600/673 [=========================>....] - ETA: 6s - loss: 0.6515 - acc: 0.6300 
673/673 [==============================] - 64s 95ms/step - loss: 0.6488 - acc: 0.6389 - val_loss: 0.7034 - val_acc: 0.3770
Epoch 3/25

200/673 [=======>......................] - ETA: 41s - loss: 0.6182 - acc: 0.6650
400/673 [================>.............] - ETA: 24s - loss: 0.6141 - acc: 0.6575
600/673 [=========================>....] - ETA: 6s - loss: 0.6144 - acc: 0.6417 
673/673 [==============================] - 63s 94ms/step - loss: 0.6040 - acc: 0.6553 - val_loss: 0.7455 - val_acc: 0.3770
Epoch 4/25

200/673 [=======>......................] - ETA: 42s - loss: 0.5448 - acc: 0.7450
400/673 [================>.............] - ETA: 24s - loss: 0.5413 - acc: 0.7275
600/673 [=========================>....] - ETA: 6s - loss: 0.5419 - acc: 0.7233 
673/673 [==============================] - 64s 95ms/step - loss: 0.5582 - acc: 0.7088 - val_loss: 1.4290 - val_acc: 0.3361
Epoch 5/25

200/673 [=======>......................] - ETA: 42s - loss: 0.9249 - acc: 0.6000
400/673 [================>.............] - ETA: 24s - loss: 0.7289 - acc: 0.6100
600/673 [=========================>....] - ETA: 6s - loss: 0.6339 - acc: 0.6650 
673/673 [==============================] - 64s 94ms/step - loss: 0.6233 - acc: 0.6776 - val_loss: 0.9893 - val_acc: 0.4590
Epoch 6/25

200/673 [=======>......................] - ETA: 41s - loss: 0.4581 - acc: 0.7950
400/673 [================>.............] - ETA: 23s - loss: 0.4401 - acc: 0.7900
600/673 [=========================>....] - ETA: 6s - loss: 0.4434 - acc: 0.7767 
673/673 [==============================] - 63s 94ms/step - loss: 0.4391 - acc: 0.7816 - val_loss: 1.1075 - val_acc: 0.5082
Epoch 7/25

200/673 [=======>......................] - ETA: 41s - loss: 0.4123 - acc: 0.7700
400/673 [================>.............] - ETA: 23s - loss: 0.6986 - acc: 0.6925
600/673 [=========================>....] - ETA: 6s - loss: 0.5825 - acc: 0.7367 
673/673 [==============================] - 63s 94ms/step - loss: 0.5668 - acc: 0.7429 - val_loss: 1.0608 - val_acc: 0.5328
Epoch 8/25

200/673 [=======>......................] - ETA: 41s - loss: 0.3397 - acc: 0.8100
400/673 [================>.............] - ETA: 23s - loss: 0.3521 - acc: 0.8175
600/673 [=========================>....] - ETA: 6s - loss: 0.3585 - acc: 0.8133 
673/673 [==============================] - 63s 94ms/step - loss: 0.3611 - acc: 0.8083 - val_loss: 1.1010 - val_acc: 0.5574
Epoch 9/25

200/673 [=======>......................] - ETA: 41s - loss: 0.3198 - acc: 0.8350
400/673 [================>.............] - ETA: 23s - loss: 0.3124 - acc: 0.8450
600/673 [=========================>....] - ETA: 6s - loss: 0.3408 - acc: 0.8250 
673/673 [==============================] - 63s 94ms/step - loss: 0.3368 - acc: 0.8217 - val_loss: 1.1584 - val_acc: 0.5902
Epoch 10/25

200/673 [=======>......................] - ETA: 41s - loss: 0.3019 - acc: 0.8500
400/673 [================>.............] - ETA: 23s - loss: 0.2799 - acc: 0.8750
600/673 [=========================>....] - ETA: 6s - loss: 0.2838 - acc: 0.8617 
673/673 [==============================] - 63s 94ms/step - loss: 0.2845 - acc: 0.8633 - val_loss: 1.3213 - val_acc: 0.5656
Epoch 11/25

200/673 [=======>......................] - ETA: 41s - loss: 0.2457 - acc: 0.8950
400/673 [================>.............] - ETA: 23s - loss: 0.2784 - acc: 0.8625
600/673 [=========================>....] - ETA: 6s - loss: 0.2657 - acc: 0.8717 
673/673 [==============================] - 63s 94ms/step - loss: 0.2606 - acc: 0.8752 - val_loss: 1.3099 - val_acc: 0.5820
Epoch 12/25

200/673 [=======>......................] - ETA: 41s - loss: 0.3020 - acc: 0.8850
400/673 [================>.............] - ETA: 24s - loss: 0.2596 - acc: 0.8975
600/673 [=========================>....] - ETA: 6s - loss: 0.2657 - acc: 0.8883 
673/673 [==============================] - 64s 94ms/step - loss: 0.2498 - acc: 0.8945 - val_loss: 1.5642 - val_acc: 0.5000
Epoch 13/25

200/673 [=======>......................] - ETA: 41s - loss: 0.2489 - acc: 0.8950
400/673 [================>.............] - ETA: 24s - loss: 0.2198 - acc: 0.9000
600/673 [=========================>....] - ETA: 6s - loss: 0.2162 - acc: 0.8933 
673/673 [==============================] - 64s 95ms/step - loss: 0.2102 - acc: 0.8990 - val_loss: 1.6588 - val_acc: 0.4918
Epoch 14/25

200/673 [=======>......................] - ETA: 41s - loss: 0.1597 - acc: 0.9250
400/673 [================>.............] - ETA: 24s - loss: 0.1529 - acc: 0.9325
600/673 [=========================>....] - ETA: 6s - loss: 0.1677 - acc: 0.9350 
673/673 [==============================] - 63s 94ms/step - loss: 0.1657 - acc: 0.9346 - val_loss: 1.6570 - val_acc: 0.5328
Epoch 15/25

200/673 [=======>......................] - ETA: 41s - loss: 0.1622 - acc: 0.9400
400/673 [================>.............] - ETA: 24s - loss: 0.1741 - acc: 0.9250
600/673 [=========================>....] - ETA: 6s - loss: 0.1625 - acc: 0.9333 
673/673 [==============================] - 64s 95ms/step - loss: 0.1583 - acc: 0.9376 - val_loss: 1.8202 - val_acc: 0.5000
Epoch 16/25

200/673 [=======>......................] - ETA: 41s - loss: 0.1328 - acc: 0.9500
400/673 [================>.............] - ETA: 24s - loss: 0.1325 - acc: 0.9550
600/673 [=========================>....] - ETA: 6s - loss: 0.1290 - acc: 0.9600 
673/673 [==============================] - 64s 94ms/step - loss: 0.1262 - acc: 0.9614 - val_loss: 1.8880 - val_acc: 0.5328
Epoch 17/25

200/673 [=======>......................] - ETA: 41s - loss: 0.1077 - acc: 0.9700
400/673 [================>.............] - ETA: 24s - loss: 0.1103 - acc: 0.9725
600/673 [=========================>....] - ETA: 6s - loss: 0.1133 - acc: 0.9667 
673/673 [==============================] - 63s 94ms/step - loss: 0.1114 - acc: 0.9673 - val_loss: 2.0879 - val_acc: 0.5246
Epoch 18/25

200/673 [=======>......................] - ETA: 41s - loss: 0.1281 - acc: 0.9450
400/673 [================>.............] - ETA: 23s - loss: 0.1457 - acc: 0.9525
600/673 [=========================>....] - ETA: 6s - loss: 0.1255 - acc: 0.9617 
673/673 [==============================] - 63s 94ms/step - loss: 0.1187 - acc: 0.9658 - val_loss: 1.9616 - val_acc: 0.5574
Epoch 19/25

200/673 [=======>......................] - ETA: 41s - loss: 0.0907 - acc: 0.9700
400/673 [================>.............] - ETA: 23s - loss: 0.1010 - acc: 0.9775
600/673 [=========================>....] - ETA: 6s - loss: 0.0959 - acc: 0.9750 
673/673 [==============================] - 62s 92ms/step - loss: 0.0916 - acc: 0.9762 - val_loss: 2.2550 - val_acc: 0.5656
Epoch 20/25

200/673 [=======>......................] - ETA: 40s - loss: 0.0675 - acc: 0.9900
400/673 [================>.............] - ETA: 23s - loss: 0.1072 - acc: 0.9750
600/673 [=========================>....] - ETA: 6s - loss: 0.0885 - acc: 0.9800 
673/673 [==============================] - 61s 91ms/step - loss: 0.0855 - acc: 0.9807 - val_loss: 2.5219 - val_acc: 0.5492
Epoch 21/25

200/673 [=======>......................] - ETA: 39s - loss: 0.0594 - acc: 0.9750
400/673 [================>.............] - ETA: 22s - loss: 0.0586 - acc: 0.9750
600/673 [=========================>....] - ETA: 6s - loss: 0.0880 - acc: 0.9767 
673/673 [==============================] - 60s 89ms/step - loss: 0.1050 - acc: 0.9777 - val_loss: 2.5278 - val_acc: 0.5656
Epoch 22/25

200/673 [=======>......................] - ETA: 39s - loss: 0.0421 - acc: 0.9900
400/673 [================>.............] - ETA: 22s - loss: 0.1127 - acc: 0.9825
600/673 [=========================>....] - ETA: 6s - loss: 0.0877 - acc: 0.9850 
673/673 [==============================] - 60s 90ms/step - loss: 0.0817 - acc: 0.9851 - val_loss: 2.4326 - val_acc: 0.5164
Epoch 23/25

200/673 [=======>......................] - ETA: 39s - loss: 0.0469 - acc: 0.9900
400/673 [================>.............] - ETA: 23s - loss: 0.0594 - acc: 0.9800
600/673 [=========================>....] - ETA: 6s - loss: 0.0803 - acc: 0.9833 
673/673 [==============================] - 61s 90ms/step - loss: 0.0836 - acc: 0.9822 - val_loss: 2.2670 - val_acc: 0.5492
Epoch 24/25

200/673 [=======>......................] - ETA: 40s - loss: 0.1455 - acc: 0.9800
400/673 [================>.............] - ETA: 23s - loss: 0.1040 - acc: 0.9800
600/673 [=========================>....] - ETA: 6s - loss: 0.0976 - acc: 0.9783 
673/673 [==============================] - 61s 90ms/step - loss: 0.0980 - acc: 0.9777 - val_loss: 2.2519 - val_acc: 0.5410
Epoch 25/25

200/673 [=======>......................] - ETA: 40s - loss: 0.0622 - acc: 0.9800
400/673 [================>.............] - ETA: 23s - loss: 0.1078 - acc: 0.9825
600/673 [=========================>....] - ETA: 6s - loss: 0.1042 - acc: 0.9800 
673/673 [==============================] - 61s 90ms/step - loss: 0.0986 - acc: 0.9807 - val_loss: 2.6910 - val_acc: 0.5656
[[1.00000000e+00 7.15858339e-21]
 [1.47817109e-03 9.98521864e-01]
 [6.79071069e-01 3.20928901e-01]
 [8.82434096e-21 1.00000000e+00]
 [1.00000000e+00 5.48218381e-23]
 [1.41448513e-01 8.58551502e-01]
 [7.26964176e-01 2.73035914e-01]
 [5.04209907e-19 1.00000000e+00]
 [9.09421591e-21 1.00000000e+00]
 [4.72470298e-02 9.52753007e-01]
 [3.51062808e-05 9.99964833e-01]
 [4.65894401e-01 5.34105659e-01]
 [9.74295065e-02 9.02570426e-01]
 [1.00000000e+00 2.02013095e-09]
 [6.16987236e-03 9.93830144e-01]
 [3.08330983e-01 6.91669047e-01]
 [9.47431624e-01 5.25683463e-02]
 [9.26830232e-01 7.31697679e-02]
 [9.28812474e-02 9.07118738e-01]
 [6.17637408e-09 1.00000000e+00]
 [1.00000000e+00 6.61429522e-10]
 [8.67412448e-01 1.32587492e-01]
 [8.56698275e-01 1.43301696e-01]
 [9.13525045e-01 8.64749774e-02]
 [2.49842301e-01 7.50157714e-01]
 [9.86549795e-01 1.34502696e-02]
 [6.97301030e-01 3.02699029e-01]
 [3.41897041e-01 6.58102930e-01]
 [8.88191938e-01 1.11808069e-01]
 [8.75819623e-01 1.24180421e-01]
 [1.00000000e+00 1.42346487e-19]
 [6.05927765e-01 3.94072235e-01]
 [6.84899628e-01 3.15100431e-01]
 [1.06320970e-01 8.93678963e-01]
 [1.07544845e-04 9.99892473e-01]
 [3.95284221e-03 9.96047199e-01]
 [2.71376183e-32 1.00000000e+00]
 [4.77590024e-01 5.22409976e-01]
 [9.37832354e-08 9.99999881e-01]
 [5.04856944e-01 4.95142996e-01]
 [2.63358831e-01 7.36641169e-01]
 [1.57011470e-08 1.00000000e+00]
 [9.99349177e-01 6.50774629e-04]
 [9.96622205e-01 3.37776472e-03]
 [5.52087784e-01 4.47912186e-01]
 [1.04714318e-05 9.99989510e-01]
 [9.55982625e-01 4.40173559e-02]
 [5.29460142e-10 1.00000000e+00]
 [8.79563689e-01 1.20436341e-01]
 [2.13286730e-05 9.99978662e-01]
 [5.78289807e-01 4.21710193e-01]
 [2.61228979e-01 7.38771081e-01]
 [1.00000000e+00 3.28859358e-08]
 [0.00000000e+00 1.00000000e+00]
 [5.21536529e-01 4.78463471e-01]
 [2.61685520e-01 7.38314450e-01]
 [7.77245462e-01 2.22754538e-01]
 [6.68131590e-01 3.31868410e-01]
 [5.04005281e-03 9.94959950e-01]
 [9.99989986e-01 9.97481493e-06]
 [9.73279774e-01 2.67202184e-02]
 [9.73393619e-01 2.66063791e-02]
 [9.85472977e-01 1.45270163e-02]
 [5.74869057e-03 9.94251370e-01]
 [4.20571342e-02 9.57942843e-01]
 [3.26804757e-01 6.73195243e-01]
 [9.09237683e-01 9.07622725e-02]
 [6.33776844e-01 3.66223216e-01]
 [9.99927044e-01 7.29406747e-05]
 [1.13957284e-07 9.99999881e-01]
 [1.48036793e-01 8.51963222e-01]
 [2.14775987e-02 9.78522360e-01]
 [1.02647310e-02 9.89735246e-01]
 [1.53625999e-02 9.84637320e-01]
 [4.48197901e-01 5.51802099e-01]
 [9.51940715e-01 4.80592661e-02]
 [8.52514863e-01 1.47485182e-01]
 [5.52960753e-01 4.47039187e-01]
 [8.79195184e-02 9.12080407e-01]
 [1.53437927e-01 8.46562088e-01]
 [1.00000000e+00 0.00000000e+00]
 [9.99999642e-01 4.03737801e-07]
 [2.11314330e-07 9.99999762e-01]
 [9.99990940e-01 9.02142619e-06]
 [2.81519890e-01 7.18480110e-01]
 [9.85612810e-01 1.43871829e-02]
 [6.41453371e-04 9.99358594e-01]
 [1.64869812e-03 9.98351336e-01]
 [4.81203973e-01 5.18795967e-01]
 [2.41486705e-05 9.99975801e-01]
 [2.25932745e-04 9.99774039e-01]
 [4.73868430e-01 5.26131570e-01]
 [3.72187972e-01 6.27812028e-01]
 [6.40901744e-01 3.59098226e-01]
 [3.95517908e-02 9.60448146e-01]
 [3.85575652e-01 6.14424288e-01]
 [4.80381493e-03 9.95196164e-01]
 [4.04532373e-01 5.95467627e-01]
 [8.11226666e-01 1.88773304e-01]
 [6.64370954e-01 3.35629016e-01]
 [1.36024594e-10 1.00000000e+00]
 [7.80844510e-01 2.19155505e-01]
 [3.35157514e-01 6.64842546e-01]
 [3.07721639e-05 9.99969244e-01]
 [4.98804309e-16 1.00000000e+00]
 [9.99529839e-01 4.70224768e-04]
 [7.97524452e-01 2.02475503e-01]
 [5.11251748e-01 4.88748342e-01]
 [2.49940194e-12 1.00000000e+00]
 [4.26347337e-16 1.00000000e+00]
 [1.64719835e-01 8.35280120e-01]
 [1.48912394e-18 1.00000000e+00]
 [3.66178483e-01 6.33821487e-01]
 [8.94111954e-03 9.91058886e-01]
 [4.91742343e-01 5.08257627e-01]
 [2.45784119e-01 7.54215896e-01]
 [2.35775439e-03 9.97642219e-01]
 [5.74306011e-01 4.25693989e-01]
 [9.04585063e-01 9.54149216e-02]
 [4.25720662e-01 5.74279368e-01]
 [1.34106651e-01 8.65893364e-01]
 [4.95306015e-01 5.04693925e-01]]
saved: y_pred_from__cnn_aardvark_aug_concat.py_b_200_mask_d_0.25_n_25_a_kfold_0_l_0.005
[[42 43]
 [10 27]]
