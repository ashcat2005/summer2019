Using TensorFlow backend.
WARNING:tensorflow:From /n/home00/nchou/.conda/envs/envi/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.
Instructions for updating:
Colocations handled automatically by placer.
cnn_aardvark_aug_concat.py:672: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor("in..., outputs=Tensor("de...)`
  model = Model(input=ins, output=dense2)
WARNING:tensorflow:From /n/home00/nchou/.conda/envs/envi/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.cast instead.
2019-12-10 18:19:08.426580: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
2019-12-10 18:19:08.430603: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2900000000 Hz
2019-12-10 18:19:08.430697: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x56460de07b30 executing computations on platform Host. Devices:
2019-12-10 18:19:08.430707: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (0): <undefined>, <undefined>
['cnn_aardvark_aug_concat.py', '-b', '200', '--mask', '-c', '-p', '5', '-n', '25', '-a', '--kfold', '0', '-l', '0.0005']
1
2
Train on 673 samples, validate on 122 samples
Epoch 1/25

200/673 [=======>......................] - ETA: 28s - loss: 0.6954 - acc: 0.4900
400/673 [================>.............] - ETA: 15s - loss: 0.6940 - acc: 0.4825
600/673 [=========================>....] - ETA: 4s - loss: 0.6936 - acc: 0.5167 
673/673 [==============================] - 41s 61ms/step - loss: 0.6935 - acc: 0.5111 - val_loss: 0.6934 - val_acc: 0.5738
Epoch 2/25

200/673 [=======>......................] - ETA: 26s - loss: 0.6886 - acc: 0.5900
400/673 [================>.............] - ETA: 15s - loss: 0.6890 - acc: 0.5900
600/673 [=========================>....] - ETA: 4s - loss: 0.6868 - acc: 0.6183 
673/673 [==============================] - 40s 60ms/step - loss: 0.6860 - acc: 0.6152 - val_loss: 0.6924 - val_acc: 0.5820
Epoch 3/25

200/673 [=======>......................] - ETA: 26s - loss: 0.6783 - acc: 0.6450
400/673 [================>.............] - ETA: 15s - loss: 0.6786 - acc: 0.6475
600/673 [=========================>....] - ETA: 4s - loss: 0.6785 - acc: 0.6200 
673/673 [==============================] - 40s 59ms/step - loss: 0.6777 - acc: 0.6196 - val_loss: 0.6941 - val_acc: 0.5902
Epoch 4/25

200/673 [=======>......................] - ETA: 26s - loss: 0.6838 - acc: 0.5500
400/673 [================>.............] - ETA: 15s - loss: 0.6703 - acc: 0.6000
600/673 [=========================>....] - ETA: 4s - loss: 0.6721 - acc: 0.6050 
673/673 [==============================] - 40s 59ms/step - loss: 0.6669 - acc: 0.6137 - val_loss: 0.7033 - val_acc: 0.5820
Epoch 5/25

200/673 [=======>......................] - ETA: 26s - loss: 0.6538 - acc: 0.5950
400/673 [================>.............] - ETA: 15s - loss: 0.6590 - acc: 0.6175
600/673 [=========================>....] - ETA: 4s - loss: 0.6566 - acc: 0.6267 
673/673 [==============================] - 40s 59ms/step - loss: 0.6610 - acc: 0.6181 - val_loss: 0.7339 - val_acc: 0.5000
Epoch 6/25

200/673 [=======>......................] - ETA: 26s - loss: 0.6366 - acc: 0.6400
400/673 [================>.............] - ETA: 15s - loss: 0.6399 - acc: 0.6425
600/673 [=========================>....] - ETA: 4s - loss: 0.6513 - acc: 0.6200 
673/673 [==============================] - 40s 60ms/step - loss: 0.6527 - acc: 0.6181 - val_loss: 0.7492 - val_acc: 0.5082
Epoch 7/25

200/673 [=======>......................] - ETA: 26s - loss: 0.6518 - acc: 0.6500
400/673 [================>.............] - ETA: 15s - loss: 0.6389 - acc: 0.6475
600/673 [=========================>....] - ETA: 4s - loss: 0.6394 - acc: 0.6300 
673/673 [==============================] - 40s 59ms/step - loss: 0.6427 - acc: 0.6226 - val_loss: 0.7686 - val_acc: 0.4918
Epoch 8/25

200/673 [=======>......................] - ETA: 26s - loss: 0.6462 - acc: 0.5900
400/673 [================>.............] - ETA: 15s - loss: 0.6312 - acc: 0.6100
600/673 [=========================>....] - ETA: 4s - loss: 0.6330 - acc: 0.6150 
673/673 [==============================] - 40s 60ms/step - loss: 0.6334 - acc: 0.6241 - val_loss: 0.7842 - val_acc: 0.5246
Epoch 9/25

200/673 [=======>......................] - ETA: 26s - loss: 0.6157 - acc: 0.6100
400/673 [================>.............] - ETA: 15s - loss: 0.6253 - acc: 0.6200
600/673 [=========================>....] - ETA: 4s - loss: 0.6276 - acc: 0.6233 
673/673 [==============================] - 40s 59ms/step - loss: 0.6247 - acc: 0.6345 - val_loss: 0.7893 - val_acc: 0.5246
Epoch 10/25

200/673 [=======>......................] - ETA: 26s - loss: 0.6317 - acc: 0.6550
400/673 [================>.............] - ETA: 15s - loss: 0.6194 - acc: 0.6675
600/673 [=========================>....] - ETA: 4s - loss: 0.6122 - acc: 0.6850 
673/673 [==============================] - 40s 59ms/step - loss: 0.6142 - acc: 0.6672 - val_loss: 0.8041 - val_acc: 0.5082
Epoch 11/25

200/673 [=======>......................] - ETA: 26s - loss: 0.5777 - acc: 0.6950
400/673 [================>.............] - ETA: 15s - loss: 0.5972 - acc: 0.6550
600/673 [=========================>....] - ETA: 4s - loss: 0.6031 - acc: 0.6567 
673/673 [==============================] - 40s 59ms/step - loss: 0.6048 - acc: 0.6612 - val_loss: 0.8027 - val_acc: 0.5246
Epoch 12/25

200/673 [=======>......................] - ETA: 26s - loss: 0.5942 - acc: 0.6450
400/673 [================>.............] - ETA: 15s - loss: 0.5685 - acc: 0.6675
600/673 [=========================>....] - ETA: 4s - loss: 0.5830 - acc: 0.6683 
673/673 [==============================] - 40s 59ms/step - loss: 0.5938 - acc: 0.6464 - val_loss: 0.8034 - val_acc: 0.5656
Epoch 13/25

200/673 [=======>......................] - ETA: 26s - loss: 0.5931 - acc: 0.6150
400/673 [================>.............] - ETA: 15s - loss: 0.5632 - acc: 0.6825
600/673 [=========================>....] - ETA: 4s - loss: 0.5771 - acc: 0.6733 
673/673 [==============================] - 40s 59ms/step - loss: 0.5812 - acc: 0.6716 - val_loss: 0.8517 - val_acc: 0.5246
Epoch 14/25

200/673 [=======>......................] - ETA: 26s - loss: 0.5764 - acc: 0.6550
400/673 [================>.............] - ETA: 15s - loss: 0.5677 - acc: 0.7100
600/673 [=========================>....] - ETA: 4s - loss: 0.5808 - acc: 0.6800 
673/673 [==============================] - 40s 60ms/step - loss: 0.5716 - acc: 0.6880 - val_loss: 0.8566 - val_acc: 0.5492
Epoch 15/25

200/673 [=======>......................] - ETA: 26s - loss: 0.5813 - acc: 0.6900
400/673 [================>.............] - ETA: 15s - loss: 0.5675 - acc: 0.6900
600/673 [=========================>....] - ETA: 4s - loss: 0.5616 - acc: 0.7017 
673/673 [==============================] - 40s 60ms/step - loss: 0.5604 - acc: 0.6984 - val_loss: 0.8856 - val_acc: 0.5082
Epoch 16/25

200/673 [=======>......................] - ETA: 26s - loss: 0.5840 - acc: 0.6300
400/673 [================>.............] - ETA: 15s - loss: 0.5670 - acc: 0.6675
600/673 [=========================>....] - ETA: 4s - loss: 0.5512 - acc: 0.6883 
673/673 [==============================] - 41s 60ms/step - loss: 0.5501 - acc: 0.6880 - val_loss: 0.8871 - val_acc: 0.5328
Epoch 17/25

200/673 [=======>......................] - ETA: 26s - loss: 0.4974 - acc: 0.7150
400/673 [================>.............] - ETA: 15s - loss: 0.5331 - acc: 0.7175
600/673 [=========================>....] - ETA: 4s - loss: 0.5387 - acc: 0.7083 
673/673 [==============================] - 40s 60ms/step - loss: 0.5399 - acc: 0.7043 - val_loss: 0.9241 - val_acc: 0.5410
Epoch 18/25

200/673 [=======>......................] - ETA: 26s - loss: 0.5315 - acc: 0.7250
400/673 [================>.............] - ETA: 15s - loss: 0.5285 - acc: 0.7125
600/673 [=========================>....] - ETA: 4s - loss: 0.5357 - acc: 0.7033 
673/673 [==============================] - 40s 60ms/step - loss: 0.5286 - acc: 0.7088 - val_loss: 0.9345 - val_acc: 0.5492
Epoch 19/25

200/673 [=======>......................] - ETA: 26s - loss: 0.5164 - acc: 0.7150
400/673 [================>.............] - ETA: 15s - loss: 0.5128 - acc: 0.7250
600/673 [=========================>....] - ETA: 4s - loss: 0.5166 - acc: 0.7150 
673/673 [==============================] - 40s 60ms/step - loss: 0.5152 - acc: 0.7147 - val_loss: 0.9432 - val_acc: 0.6230
Epoch 20/25

200/673 [=======>......................] - ETA: 26s - loss: 0.5214 - acc: 0.7300
400/673 [================>.............] - ETA: 15s - loss: 0.5009 - acc: 0.7500
600/673 [=========================>....] - ETA: 4s - loss: 0.5081 - acc: 0.7417 
673/673 [==============================] - 40s 59ms/step - loss: 0.5063 - acc: 0.7415 - val_loss: 0.9235 - val_acc: 0.6230
Epoch 21/25

200/673 [=======>......................] - ETA: 26s - loss: 0.4853 - acc: 0.7450
400/673 [================>.............] - ETA: 15s - loss: 0.4875 - acc: 0.7250
600/673 [=========================>....] - ETA: 4s - loss: 0.4993 - acc: 0.7267 
673/673 [==============================] - 40s 59ms/step - loss: 0.4956 - acc: 0.7281 - val_loss: 0.9509 - val_acc: 0.6066
Epoch 22/25

200/673 [=======>......................] - ETA: 26s - loss: 0.5121 - acc: 0.6950
400/673 [================>.............] - ETA: 15s - loss: 0.5103 - acc: 0.7100
600/673 [=========================>....] - ETA: 4s - loss: 0.4859 - acc: 0.7433 
673/673 [==============================] - 40s 59ms/step - loss: 0.4892 - acc: 0.7415 - val_loss: 0.9972 - val_acc: 0.5984
Epoch 23/25

200/673 [=======>......................] - ETA: 26s - loss: 0.4980 - acc: 0.7450
400/673 [================>.............] - ETA: 15s - loss: 0.4907 - acc: 0.7325
600/673 [=========================>....] - ETA: 4s - loss: 0.4910 - acc: 0.7167 
673/673 [==============================] - 40s 59ms/step - loss: 0.4829 - acc: 0.7281 - val_loss: 0.9288 - val_acc: 0.6230
Epoch 24/25

200/673 [=======>......................] - ETA: 26s - loss: 0.4805 - acc: 0.7350
400/673 [================>.............] - ETA: 15s - loss: 0.4955 - acc: 0.7150
600/673 [=========================>....] - ETA: 4s - loss: 0.4883 - acc: 0.7300 
673/673 [==============================] - 40s 59ms/step - loss: 0.4810 - acc: 0.7340 - val_loss: 1.1914 - val_acc: 0.5738
Epoch 25/25

200/673 [=======>......................] - ETA: 26s - loss: 0.4609 - acc: 0.7100
400/673 [================>.............] - ETA: 15s - loss: 0.4452 - acc: 0.7450
600/673 [=========================>....] - ETA: 4s - loss: 0.4682 - acc: 0.7233 
673/673 [==============================] - 40s 59ms/step - loss: 0.4730 - acc: 0.7296 - val_loss: 0.9679 - val_acc: 0.6311
[[9.94153678e-01 5.84629551e-03]
 [8.35576236e-01 1.64423749e-01]
 [6.45344257e-01 3.54655743e-01]
 [1.38817823e-05 9.99986172e-01]
 [8.49193633e-01 1.50806352e-01]
 [6.29972100e-01 3.70027870e-01]
 [7.46347904e-01 2.53652066e-01]
 [4.73620683e-01 5.26379287e-01]
 [9.24316887e-03 9.90756810e-01]
 [6.04641259e-01 3.95358801e-01]
 [4.97706532e-01 5.02293468e-01]
 [6.22644007e-01 3.77355993e-01]
 [6.46354854e-01 3.53645176e-01]
 [5.90463698e-01 4.09536332e-01]
 [6.36895478e-01 3.63104492e-01]
 [6.63601518e-01 3.36398453e-01]
 [6.56909287e-01 3.43090683e-01]
 [6.58135891e-01 3.41864109e-01]
 [6.73572242e-01 3.26427758e-01]
 [7.56146833e-02 9.24385309e-01]
 [9.58175302e-01 4.18247618e-02]
 [6.57970309e-01 3.42029691e-01]
 [5.78917861e-01 4.21082139e-01]
 [4.39228624e-01 5.60771346e-01]
 [6.41911149e-01 3.58088881e-01]
 [1.49206638e-01 8.50793362e-01]
 [6.54446304e-01 3.45553726e-01]
 [4.53580528e-01 5.46419442e-01]
 [6.47589862e-01 3.52410197e-01]
 [5.76120794e-01 4.23879206e-01]
 [9.98967290e-01 1.03276863e-03]
 [5.73952675e-01 4.26047355e-01]
 [7.29184449e-01 2.70815581e-01]
 [7.30339825e-01 2.69660205e-01]
 [9.29038703e-01 7.09613338e-02]
 [6.91019237e-01 3.08980733e-01]
 [2.07109656e-03 9.97928858e-01]
 [5.97085714e-01 4.02914256e-01]
 [2.74321944e-01 7.25678086e-01]
 [6.45677686e-01 3.54322314e-01]
 [6.80189252e-01 3.19810748e-01]
 [1.64555848e-01 8.35444152e-01]
 [3.85358334e-01 6.14641666e-01]
 [8.27366531e-01 1.72633454e-01]
 [5.85430562e-01 4.14569378e-01]
 [3.32183182e-01 6.67816877e-01]
 [7.98202217e-01 2.01797768e-01]
 [2.35118773e-02 9.76488113e-01]
 [6.84153855e-01 3.15846145e-01]
 [9.99999166e-01 8.67555627e-07]
 [6.44676268e-01 3.55323762e-01]
 [6.29847825e-01 3.70152235e-01]
 [9.69232202e-01 3.07677835e-02]
 [6.11130278e-20 1.00000000e+00]
 [6.46756709e-01 3.53243321e-01]
 [5.03569186e-01 4.96430814e-01]
 [6.92784607e-01 3.07215422e-01]
 [3.92754048e-01 6.07245982e-01]
 [2.96492338e-01 7.03507602e-01]
 [2.31584883e-03 9.97684121e-01]
 [7.33550489e-01 2.66449541e-01]
 [4.64274645e-01 5.35725355e-01]
 [6.47046864e-01 3.52953106e-01]
 [5.95547378e-01 4.04452652e-01]
 [6.00777149e-01 3.99222910e-01]
 [5.78961492e-01 4.21038479e-01]
 [6.31701708e-01 3.68298292e-01]
 [5.67583740e-01 4.32416230e-01]
 [6.19316638e-01 3.80683362e-01]
 [7.30870292e-02 9.26912963e-01]
 [4.63040799e-01 5.36959171e-01]
 [6.72146738e-01 3.27853233e-01]
 [9.22326684e-01 7.76733607e-02]
 [8.37909758e-01 1.62090257e-01]
 [7.50328720e-01 2.49671310e-01]
 [7.07591414e-01 2.92408556e-01]
 [6.53299093e-01 3.46700907e-01]
 [5.91619074e-01 4.08380896e-01]
 [2.81220675e-01 7.18779325e-01]
 [5.19943953e-01 4.80056107e-01]
 [1.00000000e+00 8.57188886e-13]
 [6.47316396e-01 3.52683574e-01]
 [9.31487978e-01 6.85120150e-02]
 [6.20172441e-01 3.79827559e-01]
 [5.48861086e-01 4.51138943e-01]
 [4.36291635e-01 5.63708425e-01]
 [2.02527046e-01 7.97473013e-01]
 [2.20745787e-01 7.79254258e-01]
 [5.75456500e-01 4.24543530e-01]
 [2.27288455e-01 7.72711575e-01]
 [5.68078756e-01 4.31921184e-01]
 [5.85290968e-01 4.14709032e-01]
 [5.68362355e-01 4.31637585e-01]
 [5.67851961e-01 4.32148010e-01]
 [5.75858831e-01 4.24141109e-01]
 [5.88233113e-01 4.11766917e-01]
 [2.28586555e-01 7.71413505e-01]
 [5.20729065e-01 4.79270965e-01]
 [1.87462736e-02 9.81253803e-01]
 [5.86736917e-01 4.13263112e-01]
 [1.85129687e-01 8.14870358e-01]
 [4.90928620e-01 5.09071350e-01]
 [4.97994006e-01 5.02005994e-01]
 [3.26462865e-01 6.73537135e-01]
 [1.76237643e-01 8.23762417e-01]
 [6.80797458e-01 3.19202513e-01]
 [5.98012269e-01 4.01987761e-01]
 [5.06232798e-01 4.93767172e-01]
 [5.42911708e-01 4.57088321e-01]
 [3.18265595e-02 9.68173444e-01]
 [3.97678673e-01 6.02321327e-01]
 [1.64997697e-01 8.35002363e-01]
 [5.83679259e-01 4.16320741e-01]
 [6.10019207e-01 3.89980793e-01]
 [5.81837296e-01 4.18162674e-01]
 [6.02286935e-01 3.97713035e-01]
 [8.88908267e-01 1.11091755e-01]
 [5.81673861e-01 4.18326169e-01]
 [6.31434858e-01 3.68565172e-01]
 [6.40229166e-01 3.59770834e-01]
 [6.39730215e-01 3.60269845e-01]
 [6.42328620e-01 3.57671410e-01]]
saved: y_pred_from__cnn_aardvark_aug_concat.py_b_200_mask_c_p_5_n_25_a_kfold_0_l_0.0005
[[63 22]
 [23 14]]
