Using TensorFlow backend.
WARNING:tensorflow:From /n/home00/nchou/.conda/envs/envi/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.
Instructions for updating:
Colocations handled automatically by placer.
cnn_aardvark_aug_concat.py:672: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor("in..., outputs=Tensor("de...)`
  model = Model(input=ins, output=dense2)
WARNING:tensorflow:From /n/home00/nchou/.conda/envs/envi/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.cast instead.
2019-12-10 18:19:59.565562: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
2019-12-10 18:19:59.617539: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2900000000 Hz
2019-12-10 18:19:59.617794: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x55c7c2114b70 executing computations on platform Host. Devices:
2019-12-10 18:19:59.617819: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (0): <undefined>, <undefined>
['cnn_aardvark_aug_concat.py', '-b', '200', '--mask', '-n', '25', '-a', '--kfold', '0', '-l', '0.005']
1
2
Train on 673 samples, validate on 122 samples
Epoch 1/25

200/673 [=======>......................] - ETA: 50s - loss: 0.6933 - acc: 0.5400
400/673 [================>.............] - ETA: 24s - loss: 0.7568 - acc: 0.5875
600/673 [=========================>....] - ETA: 6s - loss: 3.2937 - acc: 0.5517 
673/673 [==============================] - 59s 87ms/step - loss: 3.7617 - acc: 0.5483 - val_loss: 1.6491 - val_acc: 0.6967
Epoch 2/25

200/673 [=======>......................] - ETA: 30s - loss: 2.6026 - acc: 0.5100
400/673 [================>.............] - ETA: 17s - loss: 1.6349 - acc: 0.5875
600/673 [=========================>....] - ETA: 4s - loss: 1.3070 - acc: 0.6017 
673/673 [==============================] - 46s 68ms/step - loss: 1.2460 - acc: 0.6033 - val_loss: 0.8988 - val_acc: 0.5082
Epoch 3/25

200/673 [=======>......................] - ETA: 28s - loss: 0.5782 - acc: 0.6900
400/673 [================>.............] - ETA: 16s - loss: 0.5809 - acc: 0.6925
600/673 [=========================>....] - ETA: 4s - loss: 0.5819 - acc: 0.6767 
673/673 [==============================] - 45s 67ms/step - loss: 0.5833 - acc: 0.6761 - val_loss: 0.8773 - val_acc: 0.5820
Epoch 4/25

200/673 [=======>......................] - ETA: 30s - loss: 0.5277 - acc: 0.7050
400/673 [================>.............] - ETA: 17s - loss: 0.5281 - acc: 0.7050
600/673 [=========================>....] - ETA: 4s - loss: 0.5218 - acc: 0.7000 
673/673 [==============================] - 46s 68ms/step - loss: 0.5149 - acc: 0.7103 - val_loss: 1.0753 - val_acc: 0.4590
Epoch 5/25

200/673 [=======>......................] - ETA: 28s - loss: 0.4726 - acc: 0.7150
400/673 [================>.............] - ETA: 16s - loss: 0.4671 - acc: 0.7275
600/673 [=========================>....] - ETA: 4s - loss: 0.4599 - acc: 0.7317 
673/673 [==============================] - 45s 66ms/step - loss: 0.4615 - acc: 0.7325 - val_loss: 1.2018 - val_acc: 0.4672
Epoch 6/25

200/673 [=======>......................] - ETA: 26s - loss: 0.4160 - acc: 0.7650
400/673 [================>.............] - ETA: 15s - loss: 0.4124 - acc: 0.7650
600/673 [=========================>....] - ETA: 4s - loss: 0.4151 - acc: 0.7650 
673/673 [==============================] - 42s 62ms/step - loss: 0.4050 - acc: 0.7801 - val_loss: 1.3899 - val_acc: 0.5820
Epoch 7/25

200/673 [=======>......................] - ETA: 26s - loss: 0.4240 - acc: 0.7950
400/673 [================>.............] - ETA: 15s - loss: 0.3792 - acc: 0.7975
600/673 [=========================>....] - ETA: 4s - loss: 0.3625 - acc: 0.8067 
673/673 [==============================] - 42s 62ms/step - loss: 0.3571 - acc: 0.8098 - val_loss: 1.7241 - val_acc: 0.5246
Epoch 8/25

200/673 [=======>......................] - ETA: 26s - loss: 0.2833 - acc: 0.8600
400/673 [================>.............] - ETA: 15s - loss: 0.2805 - acc: 0.8625
600/673 [=========================>....] - ETA: 4s - loss: 0.2906 - acc: 0.8450 
673/673 [==============================] - 42s 62ms/step - loss: 0.3017 - acc: 0.8425 - val_loss: 1.7583 - val_acc: 0.5246
Epoch 9/25

200/673 [=======>......................] - ETA: 26s - loss: 0.2503 - acc: 0.8600
400/673 [================>.............] - ETA: 15s - loss: 0.2740 - acc: 0.8525
600/673 [=========================>....] - ETA: 4s - loss: 0.2579 - acc: 0.8617 
673/673 [==============================] - 42s 62ms/step - loss: 0.2576 - acc: 0.8648 - val_loss: 2.1597 - val_acc: 0.5164
Epoch 10/25

200/673 [=======>......................] - ETA: 26s - loss: 0.2145 - acc: 0.8900
400/673 [================>.............] - ETA: 15s - loss: 0.2372 - acc: 0.8875
600/673 [=========================>....] - ETA: 4s - loss: 0.2199 - acc: 0.8933 
673/673 [==============================] - 42s 62ms/step - loss: 0.2191 - acc: 0.8915 - val_loss: 2.4713 - val_acc: 0.4672
Epoch 11/25

200/673 [=======>......................] - ETA: 26s - loss: 0.2069 - acc: 0.9050
400/673 [================>.............] - ETA: 15s - loss: 0.2082 - acc: 0.8925
600/673 [=========================>....] - ETA: 4s - loss: 0.2100 - acc: 0.8967 
673/673 [==============================] - 42s 62ms/step - loss: 0.2063 - acc: 0.9034 - val_loss: 2.7014 - val_acc: 0.5082
Epoch 12/25

200/673 [=======>......................] - ETA: 26s - loss: 0.1923 - acc: 0.9350
400/673 [================>.............] - ETA: 15s - loss: 0.2304 - acc: 0.9125
600/673 [=========================>....] - ETA: 4s - loss: 0.2186 - acc: 0.9183 
673/673 [==============================] - 42s 62ms/step - loss: 0.2310 - acc: 0.9153 - val_loss: 2.6288 - val_acc: 0.5164
Epoch 13/25

200/673 [=======>......................] - ETA: 26s - loss: 0.1977 - acc: 0.8900
400/673 [================>.............] - ETA: 15s - loss: 0.1977 - acc: 0.9075
600/673 [=========================>....] - ETA: 4s - loss: 0.1891 - acc: 0.9167 
673/673 [==============================] - 42s 62ms/step - loss: 0.1821 - acc: 0.9242 - val_loss: 2.7009 - val_acc: 0.5000
Epoch 14/25

200/673 [=======>......................] - ETA: 26s - loss: 0.1655 - acc: 0.9500
400/673 [================>.............] - ETA: 15s - loss: 0.1856 - acc: 0.9350
600/673 [=========================>....] - ETA: 4s - loss: 0.1872 - acc: 0.9317 
673/673 [==============================] - 42s 62ms/step - loss: 0.1826 - acc: 0.9346 - val_loss: 2.8081 - val_acc: 0.5246
Epoch 15/25

200/673 [=======>......................] - ETA: 26s - loss: 0.1508 - acc: 0.9600
400/673 [================>.............] - ETA: 15s - loss: 0.1488 - acc: 0.9475
600/673 [=========================>....] - ETA: 4s - loss: 0.1756 - acc: 0.9467 
673/673 [==============================] - 42s 62ms/step - loss: 0.1694 - acc: 0.9465 - val_loss: 2.9767 - val_acc: 0.5082
Epoch 16/25

200/673 [=======>......................] - ETA: 26s - loss: 0.1813 - acc: 0.9850
400/673 [================>.............] - ETA: 15s - loss: 0.1568 - acc: 0.9600
600/673 [=========================>....] - ETA: 4s - loss: 0.1460 - acc: 0.9600 
673/673 [==============================] - 42s 62ms/step - loss: 0.1426 - acc: 0.9584 - val_loss: 3.0615 - val_acc: 0.4918
Epoch 17/25

200/673 [=======>......................] - ETA: 26s - loss: 0.1066 - acc: 0.9750
400/673 [================>.............] - ETA: 15s - loss: 0.1395 - acc: 0.9725
600/673 [=========================>....] - ETA: 4s - loss: 0.1186 - acc: 0.9717 
673/673 [==============================] - 42s 62ms/step - loss: 0.1186 - acc: 0.9688 - val_loss: 3.1773 - val_acc: 0.4836
Epoch 18/25

200/673 [=======>......................] - ETA: 26s - loss: 0.0988 - acc: 0.9700
400/673 [================>.............] - ETA: 15s - loss: 0.0975 - acc: 0.9625
600/673 [=========================>....] - ETA: 4s - loss: 0.1106 - acc: 0.9533 
673/673 [==============================] - 42s 62ms/step - loss: 0.1069 - acc: 0.9569 - val_loss: 3.3273 - val_acc: 0.4918
Epoch 19/25

200/673 [=======>......................] - ETA: 26s - loss: 0.0922 - acc: 0.9700
400/673 [================>.............] - ETA: 15s - loss: 0.0866 - acc: 0.9750
600/673 [=========================>....] - ETA: 4s - loss: 0.0811 - acc: 0.9767 
673/673 [==============================] - 42s 62ms/step - loss: 0.0784 - acc: 0.9777 - val_loss: 3.4097 - val_acc: 0.5246
Epoch 20/25

200/673 [=======>......................] - ETA: 26s - loss: 0.0725 - acc: 0.9850
400/673 [================>.............] - ETA: 15s - loss: 0.1067 - acc: 0.9800
600/673 [=========================>....] - ETA: 4s - loss: 0.0956 - acc: 0.9767 
673/673 [==============================] - 42s 62ms/step - loss: 0.0916 - acc: 0.9792 - val_loss: 3.6557 - val_acc: 0.5246
Epoch 21/25

200/673 [=======>......................] - ETA: 26s - loss: 0.0573 - acc: 0.9800
400/673 [================>.............] - ETA: 15s - loss: 0.0806 - acc: 0.9800
600/673 [=========================>....] - ETA: 4s - loss: 0.1077 - acc: 0.9733 
673/673 [==============================] - 42s 62ms/step - loss: 0.1324 - acc: 0.9688 - val_loss: 3.4912 - val_acc: 0.5410
Epoch 22/25

200/673 [=======>......................] - ETA: 26s - loss: 0.1397 - acc: 0.9750
400/673 [================>.............] - ETA: 15s - loss: 0.0980 - acc: 0.9850
600/673 [=========================>....] - ETA: 4s - loss: 0.0944 - acc: 0.9800 
673/673 [==============================] - 42s 62ms/step - loss: 0.0882 - acc: 0.9807 - val_loss: 3.8613 - val_acc: 0.5164
Epoch 23/25

200/673 [=======>......................] - ETA: 26s - loss: 0.0680 - acc: 0.9750
400/673 [================>.............] - ETA: 15s - loss: 0.0691 - acc: 0.9725
600/673 [=========================>....] - ETA: 4s - loss: 0.0890 - acc: 0.9800 
673/673 [==============================] - 42s 62ms/step - loss: 0.0876 - acc: 0.9822 - val_loss: 3.6034 - val_acc: 0.5082
Epoch 24/25

200/673 [=======>......................] - ETA: 26s - loss: 0.0661 - acc: 0.9900
400/673 [================>.............] - ETA: 15s - loss: 0.1004 - acc: 0.9850
600/673 [=========================>....] - ETA: 4s - loss: 0.0868 - acc: 0.9883 
673/673 [==============================] - 42s 62ms/step - loss: 0.0858 - acc: 0.9851 - val_loss: 3.8727 - val_acc: 0.4836
Epoch 25/25

200/673 [=======>......................] - ETA: 26s - loss: 0.1324 - acc: 0.9800
400/673 [================>.............] - ETA: 15s - loss: 0.0946 - acc: 0.9875
600/673 [=========================>....] - ETA: 4s - loss: 0.0798 - acc: 0.9833 
673/673 [==============================] - 42s 62ms/step - loss: 0.0759 - acc: 0.9851 - val_loss: 3.8698 - val_acc: 0.4672
[[1.00000000e+00 9.39413049e-31]
 [3.32518283e-07 9.99999642e-01]
 [7.01066315e-01 2.98933744e-01]
 [0.00000000e+00 1.00000000e+00]
 [9.96826053e-01 3.17397108e-03]
 [8.43253702e-07 9.99999166e-01]
 [7.15666413e-02 9.28433359e-01]
 [0.00000000e+00 1.00000000e+00]
 [1.24801125e-35 1.00000000e+00]
 [7.83699930e-01 2.16300070e-01]
 [6.49197602e-08 9.99999881e-01]
 [5.55177689e-01 4.44822311e-01]
 [8.10869224e-03 9.91891265e-01]
 [0.00000000e+00 1.00000000e+00]
 [1.50372265e-02 9.84962821e-01]
 [9.57763568e-02 9.04223680e-01]
 [9.51235473e-01 4.87644821e-02]
 [9.64413226e-01 3.55867334e-02]
 [2.59710606e-02 9.74028945e-01]
 [4.40069705e-01 5.59930265e-01]
 [1.00000000e+00 8.89753434e-18]
 [9.06936944e-01 9.30630788e-02]
 [6.47686496e-02 9.35231328e-01]
 [6.17918326e-03 9.93820846e-01]
 [1.01392336e-01 8.98607671e-01]
 [1.43503109e-02 9.85649645e-01]
 [6.20791614e-01 3.79208356e-01]
 [4.05052960e-01 5.94947040e-01]
 [9.06382799e-01 9.36171934e-02]
 [9.47604477e-01 5.23955338e-02]
 [1.00000000e+00 0.00000000e+00]
 [8.25807571e-01 1.74192354e-01]
 [4.50709649e-07 9.99999523e-01]
 [1.67825038e-03 9.98321712e-01]
 [3.85448207e-09 1.00000000e+00]
 [4.84169723e-05 9.99951601e-01]
 [0.00000000e+00 1.00000000e+00]
 [4.14014965e-01 5.85985065e-01]
 [8.89573652e-14 1.00000000e+00]
 [4.82154310e-01 5.17845750e-01]
 [6.27736390e-01 3.72263700e-01]
 [1.98449000e-11 1.00000000e+00]
 [9.79944825e-01 2.00552046e-02]
 [9.99998450e-01 1.52579855e-06]
 [7.31251836e-01 2.68748164e-01]
 [4.31788940e-05 9.99956846e-01]
 [7.95980215e-01 2.04019770e-01]
 [2.22884020e-11 1.00000000e+00]
 [9.04666722e-01 9.53332782e-02]
 [1.12557784e-03 9.98874366e-01]
 [5.79937518e-01 4.20062453e-01]
 [2.58570671e-01 7.41429269e-01]
 [5.63389034e-18 1.00000000e+00]
 [0.00000000e+00 1.00000000e+00]
 [4.72945958e-01 5.27054071e-01]
 [7.79463589e-01 2.20536456e-01]
 [4.47282977e-02 9.55271721e-01]
 [6.14712596e-01 3.85287344e-01]
 [1.39213540e-03 9.98607934e-01]
 [9.98970985e-01 1.02904043e-03]
 [9.84527469e-01 1.54725946e-02]
 [2.05868528e-05 9.99979377e-01]
 [9.97930408e-01 2.06955196e-03]
 [2.49390796e-05 9.99975085e-01]
 [8.33610166e-03 9.91663933e-01]
 [4.01202232e-01 5.98797739e-01]
 [8.79176378e-01 1.20823622e-01]
 [8.17226589e-01 1.82773396e-01]
 [9.99992132e-01 7.82621828e-06]
 [9.12860225e-26 1.00000000e+00]
 [1.97805658e-01 8.02194357e-01]
 [1.57193234e-03 9.98428106e-01]
 [9.99998689e-01 1.26948532e-06]
 [9.34003309e-12 1.00000000e+00]
 [9.13266540e-01 8.67334828e-02]
 [9.73518014e-01 2.64820419e-02]
 [8.64054203e-01 1.35945767e-01]
 [1.17805950e-01 8.82193983e-01]
 [1.16214158e-08 1.00000000e+00]
 [6.08010367e-02 9.39198971e-01]
 [1.00000000e+00 0.00000000e+00]
 [1.00000000e+00 9.18166077e-09]
 [0.00000000e+00 1.00000000e+00]
 [1.00000000e+00 1.34845753e-23]
 [2.86948621e-01 7.13051438e-01]
 [9.99999881e-01 1.63346229e-07]
 [6.95068638e-06 9.99993086e-01]
 [1.55887188e-04 9.99844074e-01]
 [6.07856214e-01 3.92143726e-01]
 [6.02533745e-10 1.00000000e+00]
 [8.82358187e-10 1.00000000e+00]
 [5.74629009e-01 4.25371051e-01]
 [2.19667152e-01 7.80332863e-01]
 [8.24568868e-01 1.75431132e-01]
 [8.56343806e-01 1.43656135e-01]
 [5.27784169e-01 4.72215831e-01]
 [6.94521877e-04 9.99305487e-01]
 [9.68803391e-02 9.03119683e-01]
 [1.80141409e-18 1.00000000e+00]
 [7.84831583e-01 2.15168461e-01]
 [1.21713763e-24 1.00000000e+00]
 [3.40184301e-01 6.59815729e-01]
 [1.61942244e-01 8.38057756e-01]
 [9.44193602e-01 5.58063686e-02]
 [2.64680583e-24 1.00000000e+00]
 [9.96750593e-01 3.24947853e-03]
 [7.93818176e-01 2.06181809e-01]
 [5.18572271e-01 4.81427670e-01]
 [1.13958688e-13 1.00000000e+00]
 [1.28781928e-27 1.00000000e+00]
 [1.63114667e-01 8.36885333e-01]
 [0.00000000e+00 1.00000000e+00]
 [4.13008124e-01 5.86991847e-01]
 [7.78214201e-07 9.99999166e-01]
 [6.79576099e-01 3.20423871e-01]
 [6.17945552e-01 3.82054448e-01]
 [3.13628479e-09 1.00000000e+00]
 [6.78926706e-01 3.21073234e-01]
 [9.57071900e-01 4.29281034e-02]
 [3.64128947e-01 6.35871053e-01]
 [1.66191623e-01 8.33808362e-01]
 [5.80057979e-01 4.19942051e-01]]
saved: y_pred_from__cnn_aardvark_aug_concat.py_b_200_mask_n_25_a_kfold_0_l_0.005
[[36 49]
 [16 21]]
