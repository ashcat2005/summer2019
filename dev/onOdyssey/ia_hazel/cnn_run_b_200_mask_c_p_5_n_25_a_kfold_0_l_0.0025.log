Using TensorFlow backend.
WARNING:tensorflow:From /n/home00/nchou/.conda/envs/envi/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.
Instructions for updating:
Colocations handled automatically by placer.
cnn_aardvark_aug_concat.py:672: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor("in..., outputs=Tensor("de...)`
  model = Model(input=ins, output=dense2)
WARNING:tensorflow:From /n/home00/nchou/.conda/envs/envi/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.cast instead.
2019-12-10 18:19:16.383267: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
2019-12-10 18:19:16.387230: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2900000000 Hz
2019-12-10 18:19:16.387324: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x55a45840ee50 executing computations on platform Host. Devices:
2019-12-10 18:19:16.387332: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (0): <undefined>, <undefined>
['cnn_aardvark_aug_concat.py', '-b', '200', '--mask', '-c', '-p', '5', '-n', '25', '-a', '--kfold', '0', '-l', '0.0025']
1
2
Train on 673 samples, validate on 122 samples
Epoch 1/25

200/673 [=======>......................] - ETA: 25s - loss: 0.6935 - acc: 0.4850
400/673 [================>.............] - ETA: 14s - loss: 0.6897 - acc: 0.4950
600/673 [=========================>....] - ETA: 3s - loss: 0.6924 - acc: 0.5233 
673/673 [==============================] - 38s 56ms/step - loss: 0.7027 - acc: 0.5215 - val_loss: 0.7104 - val_acc: 0.5574
Epoch 2/25

200/673 [=======>......................] - ETA: 24s - loss: 0.6689 - acc: 0.6400
400/673 [================>.............] - ETA: 14s - loss: 0.6610 - acc: 0.6225
600/673 [=========================>....] - ETA: 3s - loss: 0.6603 - acc: 0.6000 
673/673 [==============================] - 37s 55ms/step - loss: 0.6620 - acc: 0.5988 - val_loss: 0.7895 - val_acc: 0.3852
Epoch 3/25

200/673 [=======>......................] - ETA: 24s - loss: 0.6607 - acc: 0.5650
400/673 [================>.............] - ETA: 14s - loss: 0.6490 - acc: 0.6000
600/673 [=========================>....] - ETA: 3s - loss: 0.6430 - acc: 0.6183 
673/673 [==============================] - 37s 55ms/step - loss: 0.6463 - acc: 0.6211 - val_loss: 0.8144 - val_acc: 0.5000
Epoch 4/25

200/673 [=======>......................] - ETA: 24s - loss: 0.6337 - acc: 0.6350
400/673 [================>.............] - ETA: 14s - loss: 0.6340 - acc: 0.6325
600/673 [=========================>....] - ETA: 3s - loss: 0.6302 - acc: 0.6367 
673/673 [==============================] - 37s 55ms/step - loss: 0.6310 - acc: 0.6374 - val_loss: 0.7896 - val_acc: 0.5492
Epoch 5/25

200/673 [=======>......................] - ETA: 24s - loss: 0.6038 - acc: 0.6250
400/673 [================>.............] - ETA: 14s - loss: 0.6093 - acc: 0.6400
600/673 [=========================>....] - ETA: 3s - loss: 0.6007 - acc: 0.6417 
673/673 [==============================] - 37s 55ms/step - loss: 0.5961 - acc: 0.6478 - val_loss: 0.8178 - val_acc: 0.5656
Epoch 6/25

200/673 [=======>......................] - ETA: 24s - loss: 0.5598 - acc: 0.7000
400/673 [================>.............] - ETA: 14s - loss: 0.5707 - acc: 0.6950
600/673 [=========================>....] - ETA: 3s - loss: 0.5739 - acc: 0.6883 
673/673 [==============================] - 37s 55ms/step - loss: 0.5780 - acc: 0.6820 - val_loss: 1.0153 - val_acc: 0.5492
Epoch 7/25

200/673 [=======>......................] - ETA: 24s - loss: 0.5975 - acc: 0.6550
400/673 [================>.............] - ETA: 14s - loss: 0.5731 - acc: 0.7050
600/673 [=========================>....] - ETA: 3s - loss: 0.5621 - acc: 0.6917 
673/673 [==============================] - 37s 55ms/step - loss: 0.5537 - acc: 0.7028 - val_loss: 1.1692 - val_acc: 0.5574
Epoch 8/25

200/673 [=======>......................] - ETA: 24s - loss: 0.5265 - acc: 0.6300
400/673 [================>.............] - ETA: 14s - loss: 0.5919 - acc: 0.6650
600/673 [=========================>....] - ETA: 3s - loss: 0.5916 - acc: 0.6767 
673/673 [==============================] - 37s 55ms/step - loss: 0.5962 - acc: 0.6805 - val_loss: 1.1669 - val_acc: 0.6066
Epoch 9/25

200/673 [=======>......................] - ETA: 24s - loss: 0.5145 - acc: 0.7150
400/673 [================>.............] - ETA: 14s - loss: 0.5648 - acc: 0.6900
600/673 [=========================>....] - ETA: 3s - loss: 0.5830 - acc: 0.6783 
673/673 [==============================] - 37s 55ms/step - loss: 0.5995 - acc: 0.6716 - val_loss: 1.1251 - val_acc: 0.6721
Epoch 10/25

200/673 [=======>......................] - ETA: 24s - loss: 0.6971 - acc: 0.6900
400/673 [================>.............] - ETA: 14s - loss: 0.6829 - acc: 0.6950
600/673 [=========================>....] - ETA: 3s - loss: 0.6278 - acc: 0.6867 
673/673 [==============================] - 37s 55ms/step - loss: 0.6136 - acc: 0.6939 - val_loss: 1.3921 - val_acc: 0.5328
Epoch 11/25

200/673 [=======>......................] - ETA: 24s - loss: 0.5509 - acc: 0.7150
400/673 [================>.............] - ETA: 14s - loss: 0.5397 - acc: 0.7000
600/673 [=========================>....] - ETA: 3s - loss: 0.5467 - acc: 0.6917 
673/673 [==============================] - 37s 55ms/step - loss: 0.5612 - acc: 0.6924 - val_loss: 0.9373 - val_acc: 0.6230
Epoch 12/25

200/673 [=======>......................] - ETA: 24s - loss: 0.5428 - acc: 0.6600
400/673 [================>.............] - ETA: 14s - loss: 0.5059 - acc: 0.7075
600/673 [=========================>....] - ETA: 3s - loss: 0.5303 - acc: 0.7100 
673/673 [==============================] - 37s 55ms/step - loss: 0.5221 - acc: 0.7177 - val_loss: 1.4608 - val_acc: 0.5574
Epoch 13/25

200/673 [=======>......................] - ETA: 24s - loss: 0.5099 - acc: 0.7250
400/673 [================>.............] - ETA: 14s - loss: 0.5624 - acc: 0.7400
600/673 [=========================>....] - ETA: 3s - loss: 0.5519 - acc: 0.7267 
673/673 [==============================] - 37s 55ms/step - loss: 0.5375 - acc: 0.7355 - val_loss: 1.1970 - val_acc: 0.6639
Epoch 14/25

200/673 [=======>......................] - ETA: 24s - loss: 0.6591 - acc: 0.7050
400/673 [================>.............] - ETA: 14s - loss: 0.5693 - acc: 0.7250
600/673 [=========================>....] - ETA: 3s - loss: 0.5642 - acc: 0.7283 
673/673 [==============================] - 37s 55ms/step - loss: 0.5712 - acc: 0.7221 - val_loss: 1.3741 - val_acc: 0.5574
Epoch 15/25

200/673 [=======>......................] - ETA: 24s - loss: 0.5215 - acc: 0.6800
400/673 [================>.............] - ETA: 14s - loss: 0.4840 - acc: 0.7275
600/673 [=========================>....] - ETA: 3s - loss: 0.4909 - acc: 0.7350 
673/673 [==============================] - 37s 55ms/step - loss: 0.4901 - acc: 0.7400 - val_loss: 0.9729 - val_acc: 0.6311
Epoch 16/25

200/673 [=======>......................] - ETA: 24s - loss: 0.4190 - acc: 0.7700
400/673 [================>.............] - ETA: 14s - loss: 0.4457 - acc: 0.7575
600/673 [=========================>....] - ETA: 3s - loss: 0.4489 - acc: 0.7583 
673/673 [==============================] - 37s 55ms/step - loss: 0.4609 - acc: 0.7504 - val_loss: 1.3226 - val_acc: 0.5328
Epoch 17/25

200/673 [=======>......................] - ETA: 24s - loss: 0.4139 - acc: 0.7900
400/673 [================>.............] - ETA: 14s - loss: 0.4512 - acc: 0.7575
600/673 [=========================>....] - ETA: 3s - loss: 0.4878 - acc: 0.7467 
673/673 [==============================] - 37s 55ms/step - loss: 0.4899 - acc: 0.7459 - val_loss: 1.1877 - val_acc: 0.6066
Epoch 18/25

200/673 [=======>......................] - ETA: 24s - loss: 0.5017 - acc: 0.7150
400/673 [================>.............] - ETA: 14s - loss: 0.4904 - acc: 0.7475
600/673 [=========================>....] - ETA: 3s - loss: 0.4494 - acc: 0.7650 
673/673 [==============================] - 37s 55ms/step - loss: 0.4512 - acc: 0.7637 - val_loss: 1.3498 - val_acc: 0.5738
Epoch 19/25

200/673 [=======>......................] - ETA: 24s - loss: 0.4459 - acc: 0.7550
400/673 [================>.............] - ETA: 14s - loss: 0.4542 - acc: 0.7425
600/673 [=========================>....] - ETA: 3s - loss: 0.4448 - acc: 0.7617 
673/673 [==============================] - 37s 55ms/step - loss: 0.4714 - acc: 0.7548 - val_loss: 1.3805 - val_acc: 0.5820
Epoch 20/25

200/673 [=======>......................] - ETA: 24s - loss: 0.3741 - acc: 0.8200
400/673 [================>.............] - ETA: 14s - loss: 0.4096 - acc: 0.7950
600/673 [=========================>....] - ETA: 3s - loss: 0.4445 - acc: 0.7750 
673/673 [==============================] - 37s 55ms/step - loss: 0.4460 - acc: 0.7667 - val_loss: 1.4741 - val_acc: 0.5820
Epoch 21/25

200/673 [=======>......................] - ETA: 24s - loss: 0.4046 - acc: 0.7800
400/673 [================>.............] - ETA: 14s - loss: 0.4459 - acc: 0.7925
600/673 [=========================>....] - ETA: 3s - loss: 0.4272 - acc: 0.8067 
673/673 [==============================] - 37s 55ms/step - loss: 0.4643 - acc: 0.7979 - val_loss: 1.2165 - val_acc: 0.6393
Epoch 22/25

200/673 [=======>......................] - ETA: 24s - loss: 0.3885 - acc: 0.7900
400/673 [================>.............] - ETA: 14s - loss: 0.3949 - acc: 0.7875
600/673 [=========================>....] - ETA: 3s - loss: 0.4287 - acc: 0.7683 
673/673 [==============================] - 37s 55ms/step - loss: 0.4146 - acc: 0.7756 - val_loss: 1.4714 - val_acc: 0.5656
Epoch 23/25

200/673 [=======>......................] - ETA: 24s - loss: 0.4947 - acc: 0.7550
400/673 [================>.............] - ETA: 14s - loss: 0.4658 - acc: 0.7400
600/673 [=========================>....] - ETA: 3s - loss: 0.4904 - acc: 0.7533 
673/673 [==============================] - 37s 55ms/step - loss: 0.4890 - acc: 0.7533 - val_loss: 1.4072 - val_acc: 0.5656
Epoch 24/25

200/673 [=======>......................] - ETA: 24s - loss: 0.3785 - acc: 0.7650
400/673 [================>.............] - ETA: 14s - loss: 0.4248 - acc: 0.7800
600/673 [=========================>....] - ETA: 3s - loss: 0.4148 - acc: 0.7850 
673/673 [==============================] - 37s 55ms/step - loss: 0.4182 - acc: 0.7875 - val_loss: 1.6356 - val_acc: 0.5656
Epoch 25/25

200/673 [=======>......................] - ETA: 24s - loss: 0.5016 - acc: 0.7850
400/673 [================>.............] - ETA: 14s - loss: 0.4407 - acc: 0.7900
600/673 [=========================>....] - ETA: 3s - loss: 0.4417 - acc: 0.7867 
673/673 [==============================] - 37s 55ms/step - loss: 0.4459 - acc: 0.7786 - val_loss: 1.5576 - val_acc: 0.5984
[[9.9999940e-01 6.2107944e-07]
 [9.9571675e-01 4.2832168e-03]
 [7.1767730e-01 2.8232265e-01]
 [8.4575032e-18 1.0000000e+00]
 [6.3114810e-01 3.6885187e-01]
 [9.9044168e-01 9.5583890e-03]
 [7.2619557e-01 2.7380443e-01]
 [6.9793286e-12 1.0000000e+00]
 [6.3829502e-04 9.9936169e-01]
 [3.7570712e-01 6.2429291e-01]
 [2.6520532e-01 7.3479462e-01]
 [6.8279392e-01 3.1720605e-01]
 [5.4087633e-01 4.5912367e-01]
 [6.4859980e-01 3.5140017e-01]
 [7.2241390e-01 2.7758607e-01]
 [7.8310192e-01 2.1689810e-01]
 [7.5434637e-01 2.4565361e-01]
 [6.6076517e-01 3.3923489e-01]
 [5.8082467e-01 4.1917533e-01]
 [8.7111659e-04 9.9912888e-01]
 [9.9999285e-01 7.1813633e-06]
 [7.2668540e-01 2.7331454e-01]
 [6.4032400e-01 3.5967600e-01]
 [2.2586611e-01 7.7413392e-01]
 [6.5633905e-01 3.4366092e-01]
 [2.1537287e-02 9.7846270e-01]
 [7.7508181e-01 2.2491816e-01]
 [6.0540813e-01 3.9459190e-01]
 [7.1941203e-01 2.8058800e-01]
 [7.3035794e-01 2.6964206e-01]
 [1.0000000e+00 1.0684984e-10]
 [5.3935426e-01 4.6064577e-01]
 [3.4860450e-01 6.5139550e-01]
 [6.8555546e-01 3.1444454e-01]
 [9.9937063e-01 6.2942080e-04]
 [6.2676728e-01 3.7323269e-01]
 [2.6977886e-21 1.0000000e+00]
 [5.6926119e-01 4.3073875e-01]
 [3.8729630e-02 9.6127039e-01]
 [6.6003513e-01 3.3996487e-01]
 [6.6108096e-01 3.3891907e-01]
 [3.3042291e-03 9.9669576e-01]
 [3.3646825e-01 6.6353178e-01]
 [8.0140144e-01 1.9859855e-01]
 [6.4223534e-01 3.5776460e-01]
 [2.9583544e-01 7.0416462e-01]
 [9.1007668e-01 8.9923374e-02]
 [2.5644383e-01 7.4355614e-01]
 [7.4522746e-01 2.5477254e-01]
 [1.0000000e+00 1.5910257e-14]
 [6.3460070e-01 3.6539930e-01]
 [6.2889999e-01 3.7110004e-01]
 [9.9982882e-01 1.7115014e-04]
 [0.0000000e+00 1.0000000e+00]
 [7.7000934e-01 2.2999066e-01]
 [6.5129864e-01 3.4870136e-01]
 [3.6318180e-01 6.3681823e-01]
 [1.9049868e-01 8.0950135e-01]
 [1.5927257e-01 8.4072745e-01]
 [1.3094575e-05 9.9998689e-01]
 [7.2673839e-01 2.7326161e-01]
 [4.0188891e-01 5.9811103e-01]
 [5.5479699e-01 4.4520301e-01]
 [6.2587202e-01 3.7412798e-01]
 [4.2234725e-01 5.7765269e-01]
 [4.9739927e-01 5.0260079e-01]
 [6.7797464e-01 3.2202533e-01]
 [5.7887906e-01 4.2112097e-01]
 [5.2593189e-01 4.7406819e-01]
 [4.7249102e-07 9.9999952e-01]
 [7.3567957e-01 2.6432043e-01]
 [5.0211394e-01 4.9788606e-01]
 [9.0512186e-01 9.4878159e-02]
 [5.7126486e-01 4.2873514e-01]
 [6.6159678e-01 3.3840317e-01]
 [8.5046351e-01 1.4953648e-01]
 [7.0568490e-01 2.9431501e-01]
 [6.1577046e-01 3.8422957e-01]
 [7.8937136e-02 9.2106289e-01]
 [5.5786008e-01 4.4213995e-01]
 [1.0000000e+00 5.0413298e-19]
 [1.6647746e-03 9.9833530e-01]
 [1.4116225e-01 8.5883772e-01]
 [3.6780041e-02 9.6322000e-01]
 [5.0167608e-01 4.9832395e-01]
 [2.0650354e-01 7.9349643e-01]
 [5.8571875e-02 9.4142818e-01]
 [8.4228590e-02 9.1577142e-01]
 [5.1613951e-01 4.8386055e-01]
 [1.0321589e-01 8.9678407e-01]
 [4.8788419e-01 5.1211584e-01]
 [6.6341507e-01 3.3658496e-01]
 [5.0825721e-01 4.9174276e-01]
 [6.3308603e-01 3.6691400e-01]
 [2.6586562e-01 7.3413432e-01]
 [6.6864532e-01 3.3135468e-01]
 [3.0252656e-02 9.6974730e-01]
 [5.3148466e-01 4.6851543e-01]
 [4.0685454e-06 9.9999595e-01]
 [6.4282161e-01 3.5717839e-01]
 [1.0435849e-02 9.8956418e-01]
 [5.8705014e-01 4.1294983e-01]
 [5.0457686e-01 4.9542323e-01]
 [4.4058930e-02 9.5594102e-01]
 [2.1676527e-05 9.9997830e-01]
 [7.8741467e-01 2.1258533e-01]
 [5.9046394e-01 4.0953603e-01]
 [6.1610198e-01 3.8389802e-01]
 [3.0807918e-08 1.0000000e+00]
 [7.6990887e-05 9.9992299e-01]
 [4.1740224e-01 5.8259779e-01]
 [1.2054224e-04 9.9987948e-01]
 [5.8563739e-01 4.1436261e-01]
 [7.3726594e-01 2.6273409e-01]
 [6.3248396e-01 3.6751610e-01]
 [6.5030652e-01 3.4969345e-01]
 [3.2379603e-01 6.7620397e-01]
 [6.3299727e-01 3.6700270e-01]
 [6.3268811e-01 3.6731192e-01]
 [6.2834299e-01 3.7165704e-01]
 [6.0520303e-01 3.9479700e-01]
 [6.3330495e-01 3.6669505e-01]]
saved: y_pred_from__cnn_aardvark_aug_concat.py_b_200_mask_c_p_5_n_25_a_kfold_0_l_0.0025
[[57 28]
 [21 16]]
