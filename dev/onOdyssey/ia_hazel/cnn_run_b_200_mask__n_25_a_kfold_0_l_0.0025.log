Using TensorFlow backend.
WARNING:tensorflow:From /n/home00/nchou/.conda/envs/envi/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.
Instructions for updating:
Colocations handled automatically by placer.
cnn_aardvark_aug_concat.py:672: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor("in..., outputs=Tensor("de...)`
  model = Model(input=ins, output=dense2)
WARNING:tensorflow:From /n/home00/nchou/.conda/envs/envi/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.cast instead.
2019-12-10 18:19:41.990538: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
2019-12-10 18:19:42.062586: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2900000000 Hz
2019-12-10 18:19:42.062775: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x556e72dfd180 executing computations on platform Host. Devices:
2019-12-10 18:19:42.062794: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (0): <undefined>, <undefined>
['cnn_aardvark_aug_concat.py', '-b', '200', '--mask', '-n', '25', '-a', '--kfold', '0', '-l', '0.0025']
1
2
Train on 673 samples, validate on 122 samples
Epoch 1/25

200/673 [=======>......................] - ETA: 45s - loss: 0.6939 - acc: 0.5200
400/673 [================>.............] - ETA: 21s - loss: 0.6923 - acc: 0.5150
600/673 [=========================>....] - ETA: 5s - loss: 1.0823 - acc: 0.5033 
673/673 [==============================] - 53s 79ms/step - loss: 1.0427 - acc: 0.4963 - val_loss: 0.8464 - val_acc: 0.3279
Epoch 2/25

200/673 [=======>......................] - ETA: 29s - loss: 0.6622 - acc: 0.5100
400/673 [================>.............] - ETA: 17s - loss: 0.6221 - acc: 0.5900
600/673 [=========================>....] - ETA: 4s - loss: 0.6043 - acc: 0.6217 
673/673 [==============================] - 46s 68ms/step - loss: 0.5988 - acc: 0.6345 - val_loss: 0.9381 - val_acc: 0.4262
Epoch 3/25

200/673 [=======>......................] - ETA: 29s - loss: 0.5496 - acc: 0.6550
400/673 [================>.............] - ETA: 17s - loss: 0.5413 - acc: 0.6675
600/673 [=========================>....] - ETA: 4s - loss: 0.5337 - acc: 0.6883 
673/673 [==============================] - 46s 68ms/step - loss: 0.5313 - acc: 0.6850 - val_loss: 0.9846 - val_acc: 0.5574
Epoch 4/25

200/673 [=======>......................] - ETA: 29s - loss: 0.5226 - acc: 0.7250
400/673 [================>.............] - ETA: 16s - loss: 0.4980 - acc: 0.7350
600/673 [=========================>....] - ETA: 4s - loss: 0.4736 - acc: 0.7517 
673/673 [==============================] - 46s 68ms/step - loss: 0.4722 - acc: 0.7489 - val_loss: 1.1361 - val_acc: 0.5656
Epoch 5/25

200/673 [=======>......................] - ETA: 29s - loss: 0.4119 - acc: 0.7950
400/673 [================>.............] - ETA: 16s - loss: 0.4314 - acc: 0.7700
600/673 [=========================>....] - ETA: 4s - loss: 0.4330 - acc: 0.7683 
673/673 [==============================] - 46s 68ms/step - loss: 0.4366 - acc: 0.7697 - val_loss: 1.1920 - val_acc: 0.5574
Epoch 6/25

200/673 [=======>......................] - ETA: 29s - loss: 0.3757 - acc: 0.7900
400/673 [================>.............] - ETA: 16s - loss: 0.3686 - acc: 0.8025
600/673 [=========================>....] - ETA: 4s - loss: 0.3846 - acc: 0.7900 
673/673 [==============================] - 46s 68ms/step - loss: 0.3819 - acc: 0.7905 - val_loss: 1.3556 - val_acc: 0.4918
Epoch 7/25

200/673 [=======>......................] - ETA: 29s - loss: 0.2721 - acc: 0.9000
400/673 [================>.............] - ETA: 16s - loss: 0.3125 - acc: 0.8400
600/673 [=========================>....] - ETA: 4s - loss: 0.3466 - acc: 0.8183 
673/673 [==============================] - 46s 68ms/step - loss: 0.3469 - acc: 0.8172 - val_loss: 1.3410 - val_acc: 0.5984
Epoch 8/25

200/673 [=======>......................] - ETA: 29s - loss: 0.3125 - acc: 0.8400
400/673 [================>.............] - ETA: 16s - loss: 0.3064 - acc: 0.8575
600/673 [=========================>....] - ETA: 4s - loss: 0.3065 - acc: 0.8600 
673/673 [==============================] - 46s 68ms/step - loss: 0.3031 - acc: 0.8618 - val_loss: 1.5806 - val_acc: 0.5246
Epoch 9/25

200/673 [=======>......................] - ETA: 29s - loss: 0.2507 - acc: 0.8900
400/673 [================>.............] - ETA: 16s - loss: 0.2659 - acc: 0.8725
600/673 [=========================>....] - ETA: 4s - loss: 0.2600 - acc: 0.8750 
673/673 [==============================] - 45s 67ms/step - loss: 0.2614 - acc: 0.8796 - val_loss: 1.8933 - val_acc: 0.5082
Epoch 10/25

200/673 [=======>......................] - ETA: 29s - loss: 0.2316 - acc: 0.8900
400/673 [================>.............] - ETA: 16s - loss: 0.2527 - acc: 0.8825
600/673 [=========================>....] - ETA: 4s - loss: 0.2404 - acc: 0.8833 
673/673 [==============================] - 45s 67ms/step - loss: 0.2317 - acc: 0.8886 - val_loss: 2.0639 - val_acc: 0.5000
Epoch 11/25

200/673 [=======>......................] - ETA: 29s - loss: 0.1848 - acc: 0.9150
400/673 [================>.............] - ETA: 16s - loss: 0.1960 - acc: 0.9125
600/673 [=========================>....] - ETA: 4s - loss: 0.1979 - acc: 0.9117 
673/673 [==============================] - 46s 68ms/step - loss: 0.2011 - acc: 0.9094 - val_loss: 2.1294 - val_acc: 0.5492
Epoch 12/25

200/673 [=======>......................] - ETA: 28s - loss: 0.2118 - acc: 0.8600
400/673 [================>.............] - ETA: 16s - loss: 0.2034 - acc: 0.8750
600/673 [=========================>....] - ETA: 4s - loss: 0.1875 - acc: 0.8950 
673/673 [==============================] - 46s 68ms/step - loss: 0.1875 - acc: 0.9004 - val_loss: 2.2879 - val_acc: 0.4918
Epoch 13/25

200/673 [=======>......................] - ETA: 29s - loss: 0.1631 - acc: 0.9250
400/673 [================>.............] - ETA: 16s - loss: 0.1548 - acc: 0.9325
600/673 [=========================>....] - ETA: 4s - loss: 0.1530 - acc: 0.9333 
673/673 [==============================] - 46s 68ms/step - loss: 0.1518 - acc: 0.9346 - val_loss: 2.5995 - val_acc: 0.4672
Epoch 14/25

200/673 [=======>......................] - ETA: 29s - loss: 0.1357 - acc: 0.9400
400/673 [================>.............] - ETA: 16s - loss: 0.1385 - acc: 0.9350
600/673 [=========================>....] - ETA: 4s - loss: 0.1434 - acc: 0.9367 
673/673 [==============================] - 46s 68ms/step - loss: 0.1392 - acc: 0.9406 - val_loss: 2.6714 - val_acc: 0.4836
Epoch 15/25

200/673 [=======>......................] - ETA: 29s - loss: 0.1046 - acc: 0.9700
400/673 [================>.............] - ETA: 17s - loss: 0.1807 - acc: 0.9475
600/673 [=========================>....] - ETA: 4s - loss: 0.1607 - acc: 0.9533 
673/673 [==============================] - 46s 68ms/step - loss: 0.1567 - acc: 0.9525 - val_loss: 3.0556 - val_acc: 0.4590
Epoch 16/25

200/673 [=======>......................] - ETA: 29s - loss: 0.1203 - acc: 0.9700
400/673 [================>.............] - ETA: 16s - loss: 0.1257 - acc: 0.9625
600/673 [=========================>....] - ETA: 4s - loss: 0.1206 - acc: 0.9583 
673/673 [==============================] - 46s 68ms/step - loss: 0.1217 - acc: 0.9539 - val_loss: 3.3997 - val_acc: 0.4508
Epoch 17/25

200/673 [=======>......................] - ETA: 28s - loss: 0.1184 - acc: 0.9550
400/673 [================>.............] - ETA: 16s - loss: 0.1657 - acc: 0.9550
600/673 [=========================>....] - ETA: 4s - loss: 0.1483 - acc: 0.9617 
673/673 [==============================] - 46s 68ms/step - loss: 0.1458 - acc: 0.9599 - val_loss: 2.9662 - val_acc: 0.4918
Epoch 18/25

200/673 [=======>......................] - ETA: 29s - loss: 0.1216 - acc: 0.9500
400/673 [================>.............] - ETA: 16s - loss: 0.1114 - acc: 0.9575
600/673 [=========================>....] - ETA: 4s - loss: 0.1094 - acc: 0.9667 
673/673 [==============================] - 46s 68ms/step - loss: 0.1063 - acc: 0.9688 - val_loss: 2.9738 - val_acc: 0.5164
Epoch 19/25

200/673 [=======>......................] - ETA: 29s - loss: 0.1055 - acc: 0.9750
400/673 [================>.............] - ETA: 16s - loss: 0.0992 - acc: 0.9800
600/673 [=========================>....] - ETA: 4s - loss: 0.0924 - acc: 0.9817 
673/673 [==============================] - 46s 68ms/step - loss: 0.0873 - acc: 0.9822 - val_loss: 3.0752 - val_acc: 0.5246
Epoch 20/25

200/673 [=======>......................] - ETA: 29s - loss: 0.1006 - acc: 0.9400
400/673 [================>.............] - ETA: 17s - loss: 0.0839 - acc: 0.9650
600/673 [=========================>....] - ETA: 4s - loss: 0.0779 - acc: 0.9700 
673/673 [==============================] - 46s 68ms/step - loss: 0.0720 - acc: 0.9733 - val_loss: 3.2884 - val_acc: 0.5246
Epoch 21/25

200/673 [=======>......................] - ETA: 29s - loss: 0.0518 - acc: 0.9800
400/673 [================>.............] - ETA: 16s - loss: 0.0546 - acc: 0.9800
600/673 [=========================>....] - ETA: 4s - loss: 0.0498 - acc: 0.9850 
673/673 [==============================] - 46s 68ms/step - loss: 0.0518 - acc: 0.9837 - val_loss: 3.3730 - val_acc: 0.5328
Epoch 22/25

200/673 [=======>......................] - ETA: 28s - loss: 0.0462 - acc: 0.9800
400/673 [================>.............] - ETA: 16s - loss: 0.0396 - acc: 0.9825
600/673 [=========================>....] - ETA: 4s - loss: 0.0444 - acc: 0.9833 
673/673 [==============================] - 45s 68ms/step - loss: 0.0444 - acc: 0.9851 - val_loss: 3.0596 - val_acc: 0.5820
Epoch 23/25

200/673 [=======>......................] - ETA: 29s - loss: 0.0819 - acc: 0.9550
400/673 [================>.............] - ETA: 16s - loss: 0.0697 - acc: 0.9625
600/673 [=========================>....] - ETA: 4s - loss: 0.0674 - acc: 0.9700 
673/673 [==============================] - 45s 68ms/step - loss: 0.0689 - acc: 0.9703 - val_loss: 3.4727 - val_acc: 0.5164
Epoch 24/25

200/673 [=======>......................] - ETA: 29s - loss: 0.0359 - acc: 0.9950
400/673 [================>.............] - ETA: 17s - loss: 0.0455 - acc: 0.9875
600/673 [=========================>....] - ETA: 4s - loss: 0.0428 - acc: 0.9883 
673/673 [==============================] - 46s 68ms/step - loss: 0.0461 - acc: 0.9837 - val_loss: 3.3590 - val_acc: 0.5492
Epoch 25/25

200/673 [=======>......................] - ETA: 29s - loss: 0.0415 - acc: 0.9950
400/673 [================>.............] - ETA: 16s - loss: 0.0510 - acc: 0.9875
600/673 [=========================>....] - ETA: 4s - loss: 0.0541 - acc: 0.9850 
673/673 [==============================] - 46s 68ms/step - loss: 0.0523 - acc: 0.9866 - val_loss: 3.5678 - val_acc: 0.5082
[[1.00000000e+00 1.27443448e-18]
 [3.74482401e-09 1.00000000e+00]
 [5.68072379e-01 4.31927592e-01]
 [0.00000000e+00 1.00000000e+00]
 [1.00000000e+00 1.61622408e-12]
 [1.70087517e-08 1.00000000e+00]
 [8.87743890e-01 1.12256080e-01]
 [1.80505017e-36 1.00000000e+00]
 [0.00000000e+00 1.00000000e+00]
 [5.61967157e-02 9.43803310e-01]
 [7.32137835e-08 9.99999881e-01]
 [4.63369608e-01 5.36630392e-01]
 [4.61516349e-04 9.99538541e-01]
 [1.00000000e+00 1.12762955e-14]
 [8.28732664e-05 9.99917150e-01]
 [1.13680393e-01 8.86319578e-01]
 [9.69804049e-01 3.01960111e-02]
 [7.92411387e-01 2.07588583e-01]
 [3.12183667e-02 9.68781590e-01]
 [2.64349325e-07 9.99999762e-01]
 [1.00000000e+00 2.46496268e-21]
 [9.31028306e-01 6.89717308e-02]
 [4.55573589e-01 5.44426382e-01]
 [7.94976801e-02 9.20502365e-01]
 [1.80923164e-01 8.19076836e-01]
 [9.58989561e-01 4.10104655e-02]
 [9.67392087e-01 3.26079577e-02]
 [5.43308318e-01 4.56691712e-01]
 [9.44031715e-01 5.59683628e-02]
 [9.12072122e-01 8.79278556e-02]
 [1.00000000e+00 1.74326883e-25]
 [4.53363299e-01 5.46636701e-01]
 [1.33937895e-01 8.66062105e-01]
 [4.10169922e-03 9.95898306e-01]
 [3.21523141e-09 1.00000000e+00]
 [7.80631904e-04 9.99219298e-01]
 [0.00000000e+00 1.00000000e+00]
 [2.29308940e-02 9.77069080e-01]
 [4.06395566e-15 1.00000000e+00]
 [4.33124304e-01 5.66875756e-01]
 [2.29220793e-01 7.70779252e-01]
 [5.63875890e-11 1.00000000e+00]
 [9.99940157e-01 5.98802217e-05]
 [9.99843955e-01 1.56073715e-04]
 [4.63548064e-01 5.36451936e-01]
 [1.34505335e-05 9.99986529e-01]
 [9.76682186e-01 2.33178325e-02]
 [9.18180507e-04 9.99081850e-01]
 [7.32813597e-01 2.67186403e-01]
 [1.70530645e-15 1.00000000e+00]
 [4.53262687e-01 5.46737313e-01]
 [1.73324242e-01 8.26675773e-01]
 [5.96751647e-07 9.99999404e-01]
 [0.00000000e+00 1.00000000e+00]
 [5.68940759e-01 4.31059301e-01]
 [1.11774094e-01 8.88225913e-01]
 [2.71772712e-01 7.28227258e-01]
 [6.25369310e-01 3.74630690e-01]
 [1.14359216e-04 9.99885678e-01]
 [9.99998450e-01 1.55885243e-06]
 [9.85360444e-01 1.46395816e-02]
 [9.73460257e-01 2.65397504e-02]
 [7.03352690e-01 2.96647310e-01]
 [2.37342064e-07 9.99999762e-01]
 [2.60573183e-03 9.97394204e-01]
 [1.89689711e-01 8.10310304e-01]
 [7.12064266e-01 2.87935704e-01]
 [5.71118712e-01 4.28881317e-01]
 [9.99887466e-01 1.12488240e-04]
 [1.51681849e-14 1.00000000e+00]
 [7.00973719e-02 9.29902613e-01]
 [2.25686678e-03 9.97743130e-01]
 [6.79568231e-01 3.20431739e-01]
 [1.33447059e-14 1.00000000e+00]
 [7.23953187e-01 2.76046753e-01]
 [6.75820112e-01 3.24179858e-01]
 [7.17829943e-01 2.82170057e-01]
 [1.27347335e-01 8.72652709e-01]
 [3.73988994e-04 9.99626040e-01]
 [3.29875126e-02 9.67012465e-01]
 [1.12716099e-02 9.88728404e-01]
 [9.99997020e-01 2.96850408e-06]
 [5.33085043e-09 1.00000000e+00]
 [1.00000000e+00 2.42014063e-18]
 [1.27379671e-01 8.72620285e-01]
 [4.01945377e-04 9.99598086e-01]
 [7.38556046e-05 9.99926090e-01]
 [1.48894265e-04 9.99851108e-01]
 [3.20549816e-01 6.79450214e-01]
 [1.00947950e-09 1.00000000e+00]
 [1.35030092e-07 9.99999881e-01]
 [4.45415020e-01 5.54584980e-01]
 [1.27579272e-01 8.72420728e-01]
 [6.41100228e-01 3.58899772e-01]
 [1.69888198e-01 8.30111742e-01]
 [3.70874316e-01 6.29125714e-01]
 [2.95443475e-01 7.04556465e-01]
 [8.47087428e-02 9.15291309e-01]
 [2.62437018e-13 1.00000000e+00]
 [5.13637125e-01 4.86362875e-01]
 [2.75494013e-18 1.00000000e+00]
 [8.34675729e-01 1.65324315e-01]
 [2.53645062e-01 7.46354938e-01]
 [4.10334615e-04 9.99589622e-01]
 [2.35360722e-23 1.00000000e+00]
 [9.83734846e-01 1.62651259e-02]
 [8.74089777e-01 1.25910193e-01]
 [6.33875728e-01 3.66124272e-01]
 [4.75513552e-26 1.00000000e+00]
 [3.33527455e-16 1.00000000e+00]
 [3.74026895e-01 6.25973105e-01]
 [1.90708220e-34 1.00000000e+00]
 [2.88479418e-01 7.11520553e-01]
 [3.56651611e-07 9.99999642e-01]
 [5.36636412e-01 4.63363588e-01]
 [2.14339167e-01 7.85660863e-01]
 [3.03684022e-10 1.00000000e+00]
 [5.39414346e-01 4.60585624e-01]
 [9.12171900e-01 8.78281668e-02]
 [4.45820093e-01 5.54179847e-01]
 [4.81220707e-02 9.51877952e-01]
 [4.63080704e-01 5.36919296e-01]]
saved: y_pred_from__cnn_aardvark_aug_concat.py_b_200_mask_n_25_a_kfold_0_l_0.0025
[[34 51]
 [ 9 28]]
