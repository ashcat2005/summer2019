Using TensorFlow backend.
WARNING:tensorflow:From /n/home00/nchou/.conda/envs/envi/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.
Instructions for updating:
Colocations handled automatically by placer.
cnn_aardvark_aug_concat.py:672: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor("in..., outputs=Tensor("de...)`
  model = Model(input=ins, output=dense2)
WARNING:tensorflow:From /n/home00/nchou/.conda/envs/envi/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.cast instead.
2019-12-10 18:19:28.169963: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
2019-12-10 18:19:28.200141: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2900000000 Hz
2019-12-10 18:19:28.200267: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x55d8112c1f00 executing computations on platform Host. Devices:
2019-12-10 18:19:28.200280: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (0): <undefined>, <undefined>
['cnn_aardvark_aug_concat.py', '-b', '200', '--mask', '--mp', '5', '-n', '25', '-a', '--kfold', '0', '-l', '0.0025']
1
2
Train on 673 samples, validate on 122 samples
Epoch 1/25

200/673 [=======>......................] - ETA: 17s - loss: 0.6934 - acc: 0.4750
400/673 [================>.............] - ETA: 8s - loss: 0.6912 - acc: 0.5225 
600/673 [=========================>....] - ETA: 2s - loss: 0.6875 - acc: 0.5467
673/673 [==============================] - 23s 34ms/step - loss: 0.6868 - acc: 0.5498 - val_loss: 0.7680 - val_acc: 0.3115
Epoch 2/25

200/673 [=======>......................] - ETA: 13s - loss: 0.6735 - acc: 0.4800
400/673 [================>.............] - ETA: 8s - loss: 0.6521 - acc: 0.5800 
600/673 [=========================>....] - ETA: 2s - loss: 0.6569 - acc: 0.5833
673/673 [==============================] - 21s 32ms/step - loss: 0.6531 - acc: 0.5869 - val_loss: 0.6940 - val_acc: 0.6475
Epoch 3/25

200/673 [=======>......................] - ETA: 13s - loss: 0.6028 - acc: 0.6550
400/673 [================>.............] - ETA: 8s - loss: 0.6075 - acc: 0.6575 
600/673 [=========================>....] - ETA: 2s - loss: 0.6012 - acc: 0.6617
673/673 [==============================] - 21s 32ms/step - loss: 0.6056 - acc: 0.6538 - val_loss: 0.7520 - val_acc: 0.5410
Epoch 4/25

200/673 [=======>......................] - ETA: 13s - loss: 0.5882 - acc: 0.6800
400/673 [================>.............] - ETA: 8s - loss: 0.5971 - acc: 0.6675 
600/673 [=========================>....] - ETA: 2s - loss: 0.5755 - acc: 0.6883
673/673 [==============================] - 21s 32ms/step - loss: 0.5803 - acc: 0.6820 - val_loss: 0.7263 - val_acc: 0.6393
Epoch 5/25

200/673 [=======>......................] - ETA: 13s - loss: 0.5573 - acc: 0.7200
400/673 [================>.............] - ETA: 8s - loss: 0.5567 - acc: 0.6950 
600/673 [=========================>....] - ETA: 2s - loss: 0.5518 - acc: 0.6867
673/673 [==============================] - 21s 32ms/step - loss: 0.5532 - acc: 0.6835 - val_loss: 0.8500 - val_acc: 0.5820
Epoch 6/25

200/673 [=======>......................] - ETA: 13s - loss: 0.5279 - acc: 0.7250
400/673 [================>.............] - ETA: 8s - loss: 0.5223 - acc: 0.7075 
600/673 [=========================>....] - ETA: 2s - loss: 0.5190 - acc: 0.7150
673/673 [==============================] - 21s 32ms/step - loss: 0.5342 - acc: 0.6954 - val_loss: 0.8502 - val_acc: 0.5902
Epoch 7/25

200/673 [=======>......................] - ETA: 13s - loss: 0.4796 - acc: 0.7350
400/673 [================>.............] - ETA: 8s - loss: 0.5213 - acc: 0.6900 
600/673 [=========================>....] - ETA: 2s - loss: 0.5113 - acc: 0.7150
673/673 [==============================] - 21s 32ms/step - loss: 0.5128 - acc: 0.7117 - val_loss: 0.9140 - val_acc: 0.6148
Epoch 8/25

200/673 [=======>......................] - ETA: 13s - loss: 0.5165 - acc: 0.7000
400/673 [================>.............] - ETA: 8s - loss: 0.4998 - acc: 0.7225 
600/673 [=========================>....] - ETA: 2s - loss: 0.4968 - acc: 0.7267
673/673 [==============================] - 21s 32ms/step - loss: 0.4938 - acc: 0.7311 - val_loss: 0.9875 - val_acc: 0.5656
Epoch 9/25

200/673 [=======>......................] - ETA: 13s - loss: 0.4606 - acc: 0.7300
400/673 [================>.............] - ETA: 8s - loss: 0.4809 - acc: 0.7300 
600/673 [=========================>....] - ETA: 2s - loss: 0.4698 - acc: 0.7417
673/673 [==============================] - 21s 32ms/step - loss: 0.4743 - acc: 0.7400 - val_loss: 1.0232 - val_acc: 0.5984
Epoch 10/25

200/673 [=======>......................] - ETA: 13s - loss: 0.4437 - acc: 0.7450
400/673 [================>.............] - ETA: 8s - loss: 0.4592 - acc: 0.7425 
600/673 [=========================>....] - ETA: 2s - loss: 0.4509 - acc: 0.7517
673/673 [==============================] - 21s 32ms/step - loss: 0.4561 - acc: 0.7474 - val_loss: 1.1198 - val_acc: 0.5492
Epoch 11/25

200/673 [=======>......................] - ETA: 13s - loss: 0.4460 - acc: 0.7550
400/673 [================>.............] - ETA: 8s - loss: 0.4433 - acc: 0.7400 
600/673 [=========================>....] - ETA: 2s - loss: 0.4352 - acc: 0.7483
673/673 [==============================] - 22s 32ms/step - loss: 0.4344 - acc: 0.7519 - val_loss: 1.0253 - val_acc: 0.6148
Epoch 12/25

200/673 [=======>......................] - ETA: 13s - loss: 0.4386 - acc: 0.7950
400/673 [================>.............] - ETA: 8s - loss: 0.4420 - acc: 0.7850 
600/673 [=========================>....] - ETA: 2s - loss: 0.4560 - acc: 0.7600
673/673 [==============================] - 21s 32ms/step - loss: 0.4514 - acc: 0.7578 - val_loss: 1.4141 - val_acc: 0.5164
Epoch 13/25

200/673 [=======>......................] - ETA: 13s - loss: 0.4040 - acc: 0.7800
400/673 [================>.............] - ETA: 8s - loss: 0.4345 - acc: 0.7600 
600/673 [=========================>....] - ETA: 2s - loss: 0.4287 - acc: 0.7667
673/673 [==============================] - 21s 32ms/step - loss: 0.4286 - acc: 0.7608 - val_loss: 1.2515 - val_acc: 0.5902
Epoch 14/25

200/673 [=======>......................] - ETA: 13s - loss: 0.3938 - acc: 0.7850
400/673 [================>.............] - ETA: 8s - loss: 0.4046 - acc: 0.7800 
600/673 [=========================>....] - ETA: 2s - loss: 0.4079 - acc: 0.7767
673/673 [==============================] - 21s 32ms/step - loss: 0.4038 - acc: 0.7786 - val_loss: 1.2571 - val_acc: 0.5574
Epoch 15/25

200/673 [=======>......................] - ETA: 14s - loss: 0.4099 - acc: 0.7600
400/673 [================>.............] - ETA: 8s - loss: 0.3860 - acc: 0.7825 
600/673 [=========================>....] - ETA: 2s - loss: 0.3914 - acc: 0.7933
673/673 [==============================] - 21s 32ms/step - loss: 0.3915 - acc: 0.7860 - val_loss: 1.3576 - val_acc: 0.5738
Epoch 16/25

200/673 [=======>......................] - ETA: 13s - loss: 0.3618 - acc: 0.7950
400/673 [================>.............] - ETA: 8s - loss: 0.3800 - acc: 0.7900 
600/673 [=========================>....] - ETA: 2s - loss: 0.3715 - acc: 0.8000
673/673 [==============================] - 22s 32ms/step - loss: 0.3765 - acc: 0.7964 - val_loss: 1.4786 - val_acc: 0.5656
Epoch 17/25

200/673 [=======>......................] - ETA: 14s - loss: 0.3546 - acc: 0.8350
400/673 [================>.............] - ETA: 8s - loss: 0.3436 - acc: 0.8325 
600/673 [=========================>....] - ETA: 2s - loss: 0.3636 - acc: 0.8100
673/673 [==============================] - 21s 32ms/step - loss: 0.3613 - acc: 0.8113 - val_loss: 1.4244 - val_acc: 0.5984
Epoch 18/25

200/673 [=======>......................] - ETA: 14s - loss: 0.3943 - acc: 0.7600
400/673 [================>.............] - ETA: 8s - loss: 0.3586 - acc: 0.7975 
600/673 [=========================>....] - ETA: 2s - loss: 0.3448 - acc: 0.8217
673/673 [==============================] - 22s 32ms/step - loss: 0.3455 - acc: 0.8232 - val_loss: 1.4879 - val_acc: 0.5656
Epoch 19/25

200/673 [=======>......................] - ETA: 13s - loss: 0.2968 - acc: 0.8650
400/673 [================>.............] - ETA: 8s - loss: 0.3201 - acc: 0.8375 
600/673 [=========================>....] - ETA: 2s - loss: 0.3187 - acc: 0.8383
673/673 [==============================] - 21s 32ms/step - loss: 0.3196 - acc: 0.8366 - val_loss: 1.5380 - val_acc: 0.5574
Epoch 20/25

200/673 [=======>......................] - ETA: 13s - loss: 0.2979 - acc: 0.8300
400/673 [================>.............] - ETA: 8s - loss: 0.3057 - acc: 0.8350 
600/673 [=========================>....] - ETA: 2s - loss: 0.2990 - acc: 0.8467
673/673 [==============================] - 21s 32ms/step - loss: 0.3004 - acc: 0.8455 - val_loss: 1.5454 - val_acc: 0.5656
Epoch 21/25

200/673 [=======>......................] - ETA: 13s - loss: 0.3029 - acc: 0.8500
400/673 [================>.............] - ETA: 8s - loss: 0.2787 - acc: 0.8675 
600/673 [=========================>....] - ETA: 2s - loss: 0.2881 - acc: 0.8567
673/673 [==============================] - 22s 32ms/step - loss: 0.2889 - acc: 0.8514 - val_loss: 1.7133 - val_acc: 0.5164
Epoch 22/25

200/673 [=======>......................] - ETA: 13s - loss: 0.2894 - acc: 0.8650
400/673 [================>.............] - ETA: 8s - loss: 0.2800 - acc: 0.8700 
600/673 [=========================>....] - ETA: 2s - loss: 0.2959 - acc: 0.8533
673/673 [==============================] - 21s 32ms/step - loss: 0.2978 - acc: 0.8529 - val_loss: 1.7716 - val_acc: 0.4918
Epoch 23/25

200/673 [=======>......................] - ETA: 13s - loss: 0.2269 - acc: 0.8800
400/673 [================>.............] - ETA: 8s - loss: 0.2607 - acc: 0.8675 
600/673 [=========================>....] - ETA: 2s - loss: 0.2782 - acc: 0.8583
673/673 [==============================] - 21s 32ms/step - loss: 0.2891 - acc: 0.8484 - val_loss: 1.6415 - val_acc: 0.5656
Epoch 24/25

200/673 [=======>......................] - ETA: 13s - loss: 0.2500 - acc: 0.8750
400/673 [================>.............] - ETA: 8s - loss: 0.2607 - acc: 0.8800 
600/673 [=========================>....] - ETA: 2s - loss: 0.2694 - acc: 0.8550
673/673 [==============================] - 21s 32ms/step - loss: 0.2751 - acc: 0.8544 - val_loss: 1.7323 - val_acc: 0.5328
Epoch 25/25

200/673 [=======>......................] - ETA: 13s - loss: 0.2564 - acc: 0.8650
400/673 [================>.............] - ETA: 8s - loss: 0.2559 - acc: 0.8675 
600/673 [=========================>....] - ETA: 2s - loss: 0.2557 - acc: 0.8750
673/673 [==============================] - 21s 32ms/step - loss: 0.2622 - acc: 0.8663 - val_loss: 1.7794 - val_acc: 0.5410
[[9.99999404e-01 5.83024644e-07]
 [1.80846423e-01 8.19153607e-01]
 [7.06148744e-01 2.93851256e-01]
 [2.54175745e-26 1.00000000e+00]
 [9.99639988e-01 3.60061036e-04]
 [7.83285379e-01 2.16714650e-01]
 [9.98649061e-01 1.35091483e-03]
 [7.60447881e-20 1.00000000e+00]
 [2.49873366e-09 1.00000000e+00]
 [9.38238323e-01 6.17615990e-02]
 [1.18883878e-01 8.81116152e-01]
 [6.88732326e-01 3.11267734e-01]
 [6.74255252e-01 3.25744748e-01]
 [2.25460638e-14 1.00000000e+00]
 [3.72014135e-01 6.27985775e-01]
 [7.27051735e-01 2.72948325e-01]
 [8.65194380e-01 1.34805575e-01]
 [7.15916455e-01 2.84083545e-01]
 [4.30704772e-01 5.69295168e-01]
 [3.76243070e-02 9.62375641e-01]
 [9.99848604e-01 1.51327360e-04]
 [9.24431264e-01 7.55687654e-02]
 [6.31727576e-01 3.68272483e-01]
 [7.07352161e-01 2.92647839e-01]
 [5.37213683e-01 4.62786347e-01]
 [5.39032742e-02 9.46096718e-01]
 [3.21180820e-01 6.78819120e-01]
 [2.32094899e-01 7.67905116e-01]
 [7.99198925e-01 2.00801060e-01]
 [6.71639800e-01 3.28360170e-01]
 [9.99998808e-01 1.21520577e-06]
 [5.52033842e-01 4.47966129e-01]
 [6.08937629e-02 9.39106286e-01]
 [1.07175335e-01 8.92824650e-01]
 [2.94762075e-01 7.05237865e-01]
 [3.52489084e-01 6.47510827e-01]
 [8.04972947e-01 1.95026994e-01]
 [4.61057067e-01 5.38942873e-01]
 [4.36326663e-04 9.99563634e-01]
 [6.67885959e-01 3.32114071e-01]
 [6.32502973e-01 3.67497027e-01]
 [1.83802811e-04 9.99816239e-01]
 [9.83939528e-01 1.60604324e-02]
 [5.05958080e-01 4.94041979e-01]
 [6.68249488e-01 3.31750542e-01]
 [3.33040545e-04 9.99666929e-01]
 [8.52090955e-01 1.47909015e-01]
 [9.99873281e-01 1.26729414e-04]
 [7.26394176e-01 2.73605794e-01]
 [1.01296617e-04 9.99898672e-01]
 [6.89359307e-01 3.10640663e-01]
 [4.93140489e-01 5.06859481e-01]
 [2.83013638e-02 9.71698582e-01]
 [4.67522017e-19 1.00000000e+00]
 [8.65722060e-01 1.34277925e-01]
 [3.88303339e-01 6.11696720e-01]
 [9.18954253e-01 8.10456574e-02]
 [8.52052271e-01 1.47947744e-01]
 [2.68169612e-01 7.31830299e-01]
 [9.99374449e-01 6.25598012e-04]
 [9.42256570e-01 5.77434562e-02]
 [9.77581441e-01 2.24185269e-02]
 [7.60312438e-01 2.39687577e-01]
 [1.66819692e-01 8.33180368e-01]
 [3.17601353e-01 6.82398677e-01]
 [5.60084045e-01 4.39916015e-01]
 [8.25608730e-01 1.74391299e-01]
 [6.48334861e-01 3.51665169e-01]
 [9.15708005e-01 8.42920244e-02]
 [7.25854403e-12 1.00000000e+00]
 [6.77555725e-02 9.32244480e-01]
 [4.49223250e-01 5.50776720e-01]
 [3.06488305e-01 6.93511724e-01]
 [3.22043031e-01 6.77956939e-01]
 [9.20232654e-01 7.97673687e-02]
 [8.38067710e-01 1.61932215e-01]
 [8.09923768e-01 1.90076232e-01]
 [3.96733373e-01 6.03266597e-01]
 [5.60869500e-02 9.43913043e-01]
 [5.93917072e-01 4.06082958e-01]
 [1.00000000e+00 1.20568711e-08]
 [9.71318781e-01 2.86812913e-02]
 [6.78049028e-01 3.21950942e-01]
 [1.00000000e+00 2.05950992e-10]
 [5.79175770e-01 4.20824230e-01]
 [3.24795060e-02 9.67520535e-01]
 [5.70084602e-02 9.42991614e-01]
 [1.66614503e-01 8.33385468e-01]
 [7.02205718e-01 2.97794253e-01]
 [6.35138946e-04 9.99364913e-01]
 [1.71937034e-01 8.28062952e-01]
 [6.65161788e-01 3.34838182e-01]
 [7.59737372e-01 2.40262657e-01]
 [7.11853743e-01 2.88146198e-01]
 [3.87252420e-01 6.12747610e-01]
 [6.19305074e-01 3.80694926e-01]
 [5.04224539e-01 4.95775431e-01]
 [7.56294966e-01 2.43705064e-01]
 [1.80530354e-01 8.19469631e-01]
 [7.20541298e-01 2.79458702e-01]
 [1.66985883e-05 9.99983311e-01]
 [8.07091653e-01 1.92908347e-01]
 [3.41497153e-01 6.58502817e-01]
 [2.55190069e-04 9.99744833e-01]
 [8.32529986e-06 9.99991655e-01]
 [8.98567557e-01 1.01432495e-01]
 [6.78320289e-01 3.21679711e-01]
 [7.06837356e-01 2.93162614e-01]
 [1.21608800e-05 9.99987841e-01]
 [1.49298148e-06 9.99998450e-01]
 [4.10840571e-01 5.89159369e-01]
 [1.67038074e-12 1.00000000e+00]
 [6.35149956e-01 3.64850014e-01]
 [2.94183344e-01 7.05816627e-01]
 [6.99893892e-01 3.00106138e-01]
 [6.16159260e-01 3.83840710e-01]
 [9.96858239e-01 3.14169913e-03]
 [6.78343892e-01 3.21656138e-01]
 [8.11705351e-01 1.88294634e-01]
 [6.77757382e-01 3.22242588e-01]
 [6.82579875e-01 3.17420036e-01]
 [6.85938001e-01 3.14061999e-01]]
saved: y_pred_from__cnn_aardvark_aug_concat.py_b_200_mask_mp_5_n_25_a_kfold_0_l_0.0025
[[50 35]
 [21 16]]
