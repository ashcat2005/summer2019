Using TensorFlow backend.
WARNING:tensorflow:From /n/home00/nchou/.conda/envs/envi/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.
Instructions for updating:
Colocations handled automatically by placer.
cnn_aardvark_aug_concat.py:672: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor("in..., outputs=Tensor("de...)`
  model = Model(input=ins, output=dense2)
WARNING:tensorflow:From /n/home00/nchou/.conda/envs/envi/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.cast instead.
2019-12-10 18:19:50.253869: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
2019-12-10 18:19:50.284716: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2900000000 Hz
2019-12-10 18:19:50.284854: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x5603b1a09db0 executing computations on platform Host. Devices:
2019-12-10 18:19:50.284867: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (0): <undefined>, <undefined>
['cnn_aardvark_aug_concat.py', '-b', '200', '--mask', '--mp', '5', '-n', '25', '-a', '--kfold', '0', '-l', '0.0005']
1
2
Train on 673 samples, validate on 122 samples
Epoch 1/25

200/673 [=======>......................] - ETA: 18s - loss: 0.6925 - acc: 0.5350
400/673 [================>.............] - ETA: 9s - loss: 0.6916 - acc: 0.5200 
600/673 [=========================>....] - ETA: 2s - loss: 0.6919 - acc: 0.5033
673/673 [==============================] - 24s 36ms/step - loss: 0.6921 - acc: 0.5022 - val_loss: 0.6954 - val_acc: 0.4672
Epoch 2/25

200/673 [=======>......................] - ETA: 15s - loss: 0.6837 - acc: 0.6600
400/673 [================>.............] - ETA: 8s - loss: 0.6821 - acc: 0.6725 
600/673 [=========================>....] - ETA: 2s - loss: 0.6816 - acc: 0.6833
673/673 [==============================] - 23s 34ms/step - loss: 0.6812 - acc: 0.6776 - val_loss: 0.6885 - val_acc: 0.6066
Epoch 3/25

200/673 [=======>......................] - ETA: 14s - loss: 0.6719 - acc: 0.6550
400/673 [================>.............] - ETA: 8s - loss: 0.6690 - acc: 0.6800 
600/673 [=========================>....] - ETA: 2s - loss: 0.6689 - acc: 0.6817
673/673 [==============================] - 22s 33ms/step - loss: 0.6688 - acc: 0.6716 - val_loss: 0.6830 - val_acc: 0.6311
Epoch 4/25

200/673 [=======>......................] - ETA: 14s - loss: 0.6550 - acc: 0.7150
400/673 [================>.............] - ETA: 8s - loss: 0.6526 - acc: 0.6925 
600/673 [=========================>....] - ETA: 2s - loss: 0.6511 - acc: 0.6817
673/673 [==============================] - 22s 33ms/step - loss: 0.6535 - acc: 0.6731 - val_loss: 0.6771 - val_acc: 0.6803
Epoch 5/25

200/673 [=======>......................] - ETA: 14s - loss: 0.6447 - acc: 0.6900
400/673 [================>.............] - ETA: 8s - loss: 0.6377 - acc: 0.6900 
600/673 [=========================>....] - ETA: 2s - loss: 0.6371 - acc: 0.6833
673/673 [==============================] - 22s 33ms/step - loss: 0.6377 - acc: 0.6761 - val_loss: 0.6640 - val_acc: 0.6967
Epoch 6/25

200/673 [=======>......................] - ETA: 14s - loss: 0.6312 - acc: 0.6400
400/673 [================>.............] - ETA: 8s - loss: 0.6367 - acc: 0.6425 
600/673 [=========================>....] - ETA: 2s - loss: 0.6267 - acc: 0.6750
673/673 [==============================] - 22s 33ms/step - loss: 0.6245 - acc: 0.6761 - val_loss: 0.7054 - val_acc: 0.5738
Epoch 7/25

200/673 [=======>......................] - ETA: 14s - loss: 0.5904 - acc: 0.7350
400/673 [================>.............] - ETA: 8s - loss: 0.6027 - acc: 0.7025 
600/673 [=========================>....] - ETA: 2s - loss: 0.6053 - acc: 0.6900
673/673 [==============================] - 22s 33ms/step - loss: 0.6089 - acc: 0.6790 - val_loss: 0.6694 - val_acc: 0.6557
Epoch 8/25

200/673 [=======>......................] - ETA: 14s - loss: 0.5864 - acc: 0.7050
400/673 [================>.............] - ETA: 8s - loss: 0.5927 - acc: 0.6850 
600/673 [=========================>....] - ETA: 2s - loss: 0.5926 - acc: 0.6800
673/673 [==============================] - 22s 33ms/step - loss: 0.5949 - acc: 0.6805 - val_loss: 0.6883 - val_acc: 0.6311
Epoch 9/25

200/673 [=======>......................] - ETA: 14s - loss: 0.6102 - acc: 0.6600
400/673 [================>.............] - ETA: 8s - loss: 0.5924 - acc: 0.6725 
600/673 [=========================>....] - ETA: 2s - loss: 0.5845 - acc: 0.6750
673/673 [==============================] - 22s 33ms/step - loss: 0.5818 - acc: 0.6805 - val_loss: 0.6970 - val_acc: 0.6311
Epoch 10/25

200/673 [=======>......................] - ETA: 14s - loss: 0.5818 - acc: 0.6850
400/673 [================>.............] - ETA: 8s - loss: 0.5739 - acc: 0.6825 
600/673 [=========================>....] - ETA: 2s - loss: 0.5749 - acc: 0.6817
673/673 [==============================] - 22s 33ms/step - loss: 0.5710 - acc: 0.6850 - val_loss: 0.7167 - val_acc: 0.6393
Epoch 11/25

200/673 [=======>......................] - ETA: 14s - loss: 0.5993 - acc: 0.6750
400/673 [================>.............] - ETA: 8s - loss: 0.5786 - acc: 0.6825 
600/673 [=========================>....] - ETA: 2s - loss: 0.5648 - acc: 0.6883
673/673 [==============================] - 22s 33ms/step - loss: 0.5618 - acc: 0.6969 - val_loss: 0.7085 - val_acc: 0.6393
Epoch 12/25

200/673 [=======>......................] - ETA: 14s - loss: 0.5588 - acc: 0.7250
400/673 [================>.............] - ETA: 8s - loss: 0.5669 - acc: 0.6975 
600/673 [=========================>....] - ETA: 2s - loss: 0.5591 - acc: 0.7100
673/673 [==============================] - 22s 33ms/step - loss: 0.5565 - acc: 0.7073 - val_loss: 0.7338 - val_acc: 0.6311
Epoch 13/25

200/673 [=======>......................] - ETA: 14s - loss: 0.5597 - acc: 0.6900
400/673 [================>.............] - ETA: 8s - loss: 0.5481 - acc: 0.6825 
600/673 [=========================>....] - ETA: 2s - loss: 0.5544 - acc: 0.6917
673/673 [==============================] - 22s 33ms/step - loss: 0.5497 - acc: 0.6895 - val_loss: 0.7822 - val_acc: 0.6066
Epoch 14/25

200/673 [=======>......................] - ETA: 14s - loss: 0.5311 - acc: 0.7050
400/673 [================>.............] - ETA: 8s - loss: 0.5214 - acc: 0.7025 
600/673 [=========================>....] - ETA: 2s - loss: 0.5388 - acc: 0.6917
673/673 [==============================] - 22s 33ms/step - loss: 0.5383 - acc: 0.6984 - val_loss: 0.7255 - val_acc: 0.6230
Epoch 15/25

200/673 [=======>......................] - ETA: 14s - loss: 0.5486 - acc: 0.6950
400/673 [================>.............] - ETA: 8s - loss: 0.5209 - acc: 0.7325 
600/673 [=========================>....] - ETA: 2s - loss: 0.5379 - acc: 0.7083
673/673 [==============================] - 22s 33ms/step - loss: 0.5366 - acc: 0.7103 - val_loss: 0.7567 - val_acc: 0.6230
Epoch 16/25

200/673 [=======>......................] - ETA: 14s - loss: 0.5016 - acc: 0.7300
400/673 [================>.............] - ETA: 8s - loss: 0.5043 - acc: 0.7250 
600/673 [=========================>....] - ETA: 2s - loss: 0.5295 - acc: 0.7000
673/673 [==============================] - 22s 33ms/step - loss: 0.5254 - acc: 0.7028 - val_loss: 0.8035 - val_acc: 0.5984
Epoch 17/25

200/673 [=======>......................] - ETA: 13s - loss: 0.5085 - acc: 0.7500
400/673 [================>.............] - ETA: 8s - loss: 0.5153 - acc: 0.7275 
600/673 [=========================>....] - ETA: 2s - loss: 0.5147 - acc: 0.7250
673/673 [==============================] - 22s 32ms/step - loss: 0.5168 - acc: 0.7296 - val_loss: 0.7653 - val_acc: 0.6393
Epoch 18/25

200/673 [=======>......................] - ETA: 13s - loss: 0.4879 - acc: 0.7700
400/673 [================>.............] - ETA: 8s - loss: 0.5105 - acc: 0.7275 
600/673 [=========================>....] - ETA: 2s - loss: 0.5129 - acc: 0.7200
673/673 [==============================] - 22s 32ms/step - loss: 0.5134 - acc: 0.7207 - val_loss: 0.8039 - val_acc: 0.6311
Epoch 19/25

200/673 [=======>......................] - ETA: 14s - loss: 0.4853 - acc: 0.7350
400/673 [================>.............] - ETA: 8s - loss: 0.4928 - acc: 0.7375 
600/673 [=========================>....] - ETA: 2s - loss: 0.4995 - acc: 0.7250
673/673 [==============================] - 22s 33ms/step - loss: 0.5072 - acc: 0.7147 - val_loss: 0.8338 - val_acc: 0.5902
Epoch 20/25

200/673 [=======>......................] - ETA: 14s - loss: 0.5013 - acc: 0.7050
400/673 [================>.............] - ETA: 8s - loss: 0.4853 - acc: 0.7350 
600/673 [=========================>....] - ETA: 2s - loss: 0.4960 - acc: 0.7217
673/673 [==============================] - 22s 33ms/step - loss: 0.4987 - acc: 0.7221 - val_loss: 0.8045 - val_acc: 0.6393
Epoch 21/25

200/673 [=======>......................] - ETA: 14s - loss: 0.5001 - acc: 0.7400
400/673 [================>.............] - ETA: 8s - loss: 0.4970 - acc: 0.7275 
600/673 [=========================>....] - ETA: 2s - loss: 0.4969 - acc: 0.7283
673/673 [==============================] - 22s 33ms/step - loss: 0.4955 - acc: 0.7296 - val_loss: 0.8395 - val_acc: 0.6311
Epoch 22/25

200/673 [=======>......................] - ETA: 14s - loss: 0.5277 - acc: 0.6900
400/673 [================>.............] - ETA: 8s - loss: 0.5209 - acc: 0.7075 
600/673 [=========================>....] - ETA: 2s - loss: 0.4941 - acc: 0.7283
673/673 [==============================] - 22s 33ms/step - loss: 0.4886 - acc: 0.7325 - val_loss: 0.8485 - val_acc: 0.6393
Epoch 23/25

200/673 [=======>......................] - ETA: 14s - loss: 0.4737 - acc: 0.7550
400/673 [================>.............] - ETA: 8s - loss: 0.4803 - acc: 0.7475 
600/673 [=========================>....] - ETA: 2s - loss: 0.4800 - acc: 0.7400
673/673 [==============================] - 22s 33ms/step - loss: 0.4835 - acc: 0.7385 - val_loss: 0.8485 - val_acc: 0.6311
Epoch 24/25

200/673 [=======>......................] - ETA: 14s - loss: 0.4688 - acc: 0.7450
400/673 [================>.............] - ETA: 8s - loss: 0.4840 - acc: 0.7375 
600/673 [=========================>....] - ETA: 2s - loss: 0.4788 - acc: 0.7350
673/673 [==============================] - 22s 33ms/step - loss: 0.4766 - acc: 0.7415 - val_loss: 0.8903 - val_acc: 0.6230
Epoch 25/25

200/673 [=======>......................] - ETA: 13s - loss: 0.4948 - acc: 0.7400
400/673 [================>.............] - ETA: 8s - loss: 0.4736 - acc: 0.7450 
600/673 [=========================>....] - ETA: 2s - loss: 0.4683 - acc: 0.7433
673/673 [==============================] - 22s 33ms/step - loss: 0.4716 - acc: 0.7444 - val_loss: 0.8916 - val_acc: 0.6557
[[9.3715441e-01 6.2845603e-02]
 [3.8723373e-01 6.1276621e-01]
 [6.2434924e-01 3.7565070e-01]
 [5.3501816e-04 9.9946505e-01]
 [7.3725456e-01 2.6274541e-01]
 [6.6413701e-01 3.3586305e-01]
 [8.1361753e-01 1.8638255e-01]
 [1.6938448e-02 9.8306155e-01]
 [6.9393128e-02 9.3060690e-01]
 [7.0653462e-01 2.9346535e-01]
 [5.0558949e-01 4.9441054e-01]
 [6.4800537e-01 3.5199463e-01]
 [5.9764522e-01 4.0235478e-01]
 [1.7589729e-01 8.2410270e-01]
 [5.5670184e-01 4.4329813e-01]
 [6.3870513e-01 3.6129490e-01]
 [5.9604031e-01 4.0395966e-01]
 [6.6257632e-01 3.3742365e-01]
 [5.5256402e-01 4.4743595e-01]
 [7.3931769e-02 9.2606831e-01]
 [7.4119216e-01 2.5880784e-01]
 [7.5382221e-01 2.4617781e-01]
 [5.2158624e-01 4.7841373e-01]
 [5.5994350e-01 4.4005644e-01]
 [5.7741797e-01 4.2258197e-01]
 [6.1455578e-01 3.8544425e-01]
 [5.2335960e-01 4.7664037e-01]
 [5.3976429e-01 4.6023580e-01]
 [6.6222489e-01 3.3777514e-01]
 [6.0172093e-01 3.9827904e-01]
 [9.9717581e-01 2.8241943e-03]
 [5.2393723e-01 4.7606277e-01]
 [4.6140066e-01 5.3859937e-01]
 [5.9503812e-01 4.0496185e-01]
 [4.2780018e-01 5.7219976e-01]
 [3.7888357e-01 6.2111652e-01]
 [6.5346372e-01 3.4653622e-01]
 [6.7975849e-01 3.2024148e-01]
 [7.4221805e-02 9.2577821e-01]
 [6.1601025e-01 3.8398981e-01]
 [6.8407857e-01 3.1592146e-01]
 [5.3813182e-02 9.4618690e-01]
 [4.7025105e-01 5.2974892e-01]
 [3.7498260e-01 6.2501740e-01]
 [6.4076215e-01 3.5923782e-01]
 [1.8903562e-01 8.1096435e-01]
 [6.9713718e-01 3.0286276e-01]
 [3.0475667e-01 6.9524330e-01]
 [5.8785349e-01 4.1214645e-01]
 [9.7741312e-01 2.2586863e-02]
 [6.5295130e-01 3.4704867e-01]
 [6.0108489e-01 3.9891508e-01]
 [8.2003397e-01 1.7996608e-01]
 [8.9157373e-07 9.9999917e-01]
 [6.8276983e-01 3.1723014e-01]
 [5.3933352e-01 4.6066648e-01]
 [6.2723356e-01 3.7276646e-01]
 [6.0153294e-01 3.9846700e-01]
 [3.1360257e-01 6.8639743e-01]
 [3.0136520e-01 6.9863474e-01]
 [6.9839793e-01 3.0160204e-01]
 [6.6474718e-01 3.3525288e-01]
 [7.5700879e-01 2.4299128e-01]
 [4.5344785e-01 5.4655224e-01]
 [6.2744337e-01 3.7255660e-01]
 [6.2648869e-01 3.7351134e-01]
 [6.9340074e-01 3.0659926e-01]
 [6.2199670e-01 3.7800330e-01]
 [6.2338817e-01 3.7661180e-01]
 [3.2370787e-02 9.6762919e-01]
 [5.0720847e-01 4.9279156e-01]
 [5.6435633e-01 4.3564367e-01]
 [5.0658125e-01 4.9341869e-01]
 [3.8621658e-01 6.1378342e-01]
 [6.6897106e-01 3.3102891e-01]
 [6.1709428e-01 3.8290572e-01]
 [6.7231917e-01 3.2768080e-01]
 [5.1399797e-01 4.8600206e-01]
 [2.1213262e-01 7.8786737e-01]
 [5.8888185e-01 4.1111812e-01]
 [9.9907768e-01 9.2226273e-04]
 [6.4018917e-01 3.5981083e-01]
 [2.8266105e-01 7.1733892e-01]
 [9.2173290e-01 7.8267105e-02]
 [5.4116666e-01 4.5883331e-01]
 [4.8660502e-01 5.1339495e-01]
 [1.8475595e-01 8.1524408e-01]
 [1.6330127e-01 8.3669877e-01]
 [5.5367309e-01 4.4632691e-01]
 [8.9058258e-02 9.1094172e-01]
 [2.6356837e-01 7.3643154e-01]
 [6.4975119e-01 3.5024884e-01]
 [6.8327612e-01 3.1672394e-01]
 [6.5751714e-01 3.4248289e-01]
 [3.4294873e-01 6.5705127e-01]
 [6.2536955e-01 3.7463048e-01]
 [4.8855135e-01 5.1144868e-01]
 [5.4956901e-01 4.5043096e-01]
 [1.5214741e-02 9.8478532e-01]
 [6.2945771e-01 3.7054226e-01]
 [1.5991384e-02 9.8400867e-01]
 [4.8830232e-01 5.1169759e-01]
 [4.4051239e-01 5.5948758e-01]
 [2.0314761e-01 7.9685241e-01]
 [3.4650937e-02 9.6534902e-01]
 [7.2912300e-01 2.7087697e-01]
 [6.0716957e-01 3.9283043e-01]
 [4.8956946e-01 5.1043057e-01]
 [4.7728822e-01 5.2271181e-01]
 [1.9675238e-02 9.8032480e-01]
 [3.8588881e-01 6.1411119e-01]
 [2.7388036e-03 9.9726117e-01]
 [6.4481682e-01 3.5518309e-01]
 [5.0519824e-01 4.9480173e-01]
 [6.3995695e-01 3.6004308e-01]
 [6.1362356e-01 3.8637641e-01]
 [5.3131872e-01 4.6868122e-01]
 [6.2213773e-01 3.7786224e-01]
 [7.1563554e-01 2.8436452e-01]
 [6.5579414e-01 3.4420589e-01]
 [6.9476575e-01 3.0523425e-01]
 [6.6426712e-01 3.3573291e-01]]
saved: y_pred_from__cnn_aardvark_aug_concat.py_b_200_mask_mp_5_n_25_a_kfold_0_l_0.0005
[[62 23]
 [19 18]]
