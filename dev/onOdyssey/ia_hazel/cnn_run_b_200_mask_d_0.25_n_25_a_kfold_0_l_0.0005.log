Using TensorFlow backend.
WARNING:tensorflow:From /n/home00/nchou/.conda/envs/envi/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.
Instructions for updating:
Colocations handled automatically by placer.
WARNING:tensorflow:From /n/home00/nchou/.conda/envs/envi/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.
Instructions for updating:
Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.
cnn_aardvark_aug_concat.py:672: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor("in..., outputs=Tensor("de...)`
  model = Model(input=ins, output=dense2)
WARNING:tensorflow:From /n/home00/nchou/.conda/envs/envi/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.cast instead.
2019-12-10 18:19:59.635775: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
2019-12-10 18:19:59.639783: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2900000000 Hz
2019-12-10 18:19:59.639876: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x55fffde43370 executing computations on platform Host. Devices:
2019-12-10 18:19:59.639884: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (0): <undefined>, <undefined>
['cnn_aardvark_aug_concat.py', '-b', '200', '--mask', '-d', '0.25', '-n', '25', '-a', '--kfold', '0', '-l', '0.0005']
1
2
Train on 673 samples, validate on 122 samples
Epoch 1/25

200/673 [=======>......................] - ETA: 1:05 - loss: 0.6926 - acc: 0.5250
400/673 [================>.............] - ETA: 32s - loss: 0.6867 - acc: 0.5375 
600/673 [=========================>....] - ETA: 8s - loss: 0.6867 - acc: 0.5350 
673/673 [==============================] - 78s 116ms/step - loss: 0.6796 - acc: 0.5468 - val_loss: 0.6694 - val_acc: 0.6967
Epoch 2/25

200/673 [=======>......................] - ETA: 45s - loss: 0.5838 - acc: 0.7050
400/673 [================>.............] - ETA: 25s - loss: 0.5622 - acc: 0.7200
600/673 [=========================>....] - ETA: 6s - loss: 0.5691 - acc: 0.6967 
673/673 [==============================] - 67s 99ms/step - loss: 0.5714 - acc: 0.6939 - val_loss: 0.7037 - val_acc: 0.6393
Epoch 3/25

200/673 [=======>......................] - ETA: 41s - loss: 0.5507 - acc: 0.6600
400/673 [================>.............] - ETA: 24s - loss: 0.5381 - acc: 0.6950
600/673 [=========================>....] - ETA: 6s - loss: 0.5248 - acc: 0.7017 
673/673 [==============================] - 64s 95ms/step - loss: 0.5251 - acc: 0.7043 - val_loss: 0.8020 - val_acc: 0.4836
Epoch 4/25

200/673 [=======>......................] - ETA: 42s - loss: 0.4510 - acc: 0.7650
400/673 [================>.............] - ETA: 23s - loss: 0.4718 - acc: 0.7500
600/673 [=========================>....] - ETA: 6s - loss: 0.4780 - acc: 0.7433 
673/673 [==============================] - 62s 92ms/step - loss: 0.4873 - acc: 0.7296 - val_loss: 0.7805 - val_acc: 0.6066
Epoch 5/25

200/673 [=======>......................] - ETA: 38s - loss: 0.4445 - acc: 0.7500
400/673 [================>.............] - ETA: 22s - loss: 0.4460 - acc: 0.7750
600/673 [=========================>....] - ETA: 5s - loss: 0.4454 - acc: 0.7783 
673/673 [==============================] - 59s 88ms/step - loss: 0.4452 - acc: 0.7786 - val_loss: 0.7997 - val_acc: 0.6557
Epoch 6/25

200/673 [=======>......................] - ETA: 38s - loss: 0.3990 - acc: 0.8000
400/673 [================>.............] - ETA: 22s - loss: 0.4177 - acc: 0.7800
600/673 [=========================>....] - ETA: 5s - loss: 0.4107 - acc: 0.7950 
673/673 [==============================] - 59s 88ms/step - loss: 0.4117 - acc: 0.7905 - val_loss: 0.9158 - val_acc: 0.5656
Epoch 7/25

200/673 [=======>......................] - ETA: 38s - loss: 0.3984 - acc: 0.8050
400/673 [================>.............] - ETA: 22s - loss: 0.4013 - acc: 0.7825
600/673 [=========================>....] - ETA: 6s - loss: 0.3842 - acc: 0.8050 
673/673 [==============================] - 59s 88ms/step - loss: 0.3807 - acc: 0.8068 - val_loss: 0.9547 - val_acc: 0.5902
Epoch 8/25

200/673 [=======>......................] - ETA: 38s - loss: 0.3535 - acc: 0.8150
400/673 [================>.............] - ETA: 22s - loss: 0.3432 - acc: 0.8275
600/673 [=========================>....] - ETA: 6s - loss: 0.3541 - acc: 0.8117 
673/673 [==============================] - 59s 88ms/step - loss: 0.3511 - acc: 0.8217 - val_loss: 0.9660 - val_acc: 0.5902
Epoch 9/25

200/673 [=======>......................] - ETA: 38s - loss: 0.3212 - acc: 0.8300
400/673 [================>.............] - ETA: 22s - loss: 0.3181 - acc: 0.8300
600/673 [=========================>....] - ETA: 6s - loss: 0.3227 - acc: 0.8300 
673/673 [==============================] - 59s 88ms/step - loss: 0.3291 - acc: 0.8276 - val_loss: 1.0823 - val_acc: 0.5082
Epoch 10/25

200/673 [=======>......................] - ETA: 38s - loss: 0.3373 - acc: 0.8250
400/673 [================>.............] - ETA: 22s - loss: 0.3089 - acc: 0.8625
600/673 [=========================>....] - ETA: 6s - loss: 0.2950 - acc: 0.8717 
673/673 [==============================] - 59s 88ms/step - loss: 0.2975 - acc: 0.8663 - val_loss: 1.0626 - val_acc: 0.5738
Epoch 11/25

200/673 [=======>......................] - ETA: 38s - loss: 0.2698 - acc: 0.8650
400/673 [================>.............] - ETA: 22s - loss: 0.2853 - acc: 0.8500
600/673 [=========================>....] - ETA: 5s - loss: 0.2774 - acc: 0.8667 
673/673 [==============================] - 59s 88ms/step - loss: 0.2750 - acc: 0.8633 - val_loss: 1.1895 - val_acc: 0.4754
Epoch 12/25

200/673 [=======>......................] - ETA: 38s - loss: 0.2436 - acc: 0.9000
400/673 [================>.............] - ETA: 22s - loss: 0.2563 - acc: 0.9150
600/673 [=========================>....] - ETA: 5s - loss: 0.2622 - acc: 0.8967 
673/673 [==============================] - 59s 88ms/step - loss: 0.2646 - acc: 0.8975 - val_loss: 1.0980 - val_acc: 0.6066
Epoch 13/25

200/673 [=======>......................] - ETA: 38s - loss: 0.2776 - acc: 0.8400
400/673 [================>.............] - ETA: 22s - loss: 0.2732 - acc: 0.8600
600/673 [=========================>....] - ETA: 5s - loss: 0.2729 - acc: 0.8567 
673/673 [==============================] - 59s 88ms/step - loss: 0.2680 - acc: 0.8618 - val_loss: 1.2808 - val_acc: 0.4590
Epoch 14/25

200/673 [=======>......................] - ETA: 38s - loss: 0.2742 - acc: 0.9000
400/673 [================>.............] - ETA: 22s - loss: 0.2417 - acc: 0.9125
600/673 [=========================>....] - ETA: 5s - loss: 0.2620 - acc: 0.8917 
673/673 [==============================] - 59s 87ms/step - loss: 0.2589 - acc: 0.8856 - val_loss: 1.3441 - val_acc: 0.5246
Epoch 15/25

200/673 [=======>......................] - ETA: 38s - loss: 0.2083 - acc: 0.9000
400/673 [================>.............] - ETA: 22s - loss: 0.2130 - acc: 0.8975
600/673 [=========================>....] - ETA: 5s - loss: 0.2227 - acc: 0.8900 
673/673 [==============================] - 59s 87ms/step - loss: 0.2196 - acc: 0.8930 - val_loss: 1.2905 - val_acc: 0.5246
Epoch 16/25

200/673 [=======>......................] - ETA: 38s - loss: 0.2146 - acc: 0.9050
400/673 [================>.............] - ETA: 22s - loss: 0.2067 - acc: 0.9225
600/673 [=========================>....] - ETA: 5s - loss: 0.2119 - acc: 0.9233 
673/673 [==============================] - 59s 87ms/step - loss: 0.2133 - acc: 0.9198 - val_loss: 1.3758 - val_acc: 0.5246
Epoch 17/25

200/673 [=======>......................] - ETA: 38s - loss: 0.2018 - acc: 0.9300
400/673 [================>.............] - ETA: 22s - loss: 0.2133 - acc: 0.9175
600/673 [=========================>....] - ETA: 5s - loss: 0.1956 - acc: 0.9267 
673/673 [==============================] - 59s 88ms/step - loss: 0.1950 - acc: 0.9272 - val_loss: 1.6123 - val_acc: 0.4672
Epoch 18/25

200/673 [=======>......................] - ETA: 38s - loss: 0.2125 - acc: 0.9050
400/673 [================>.............] - ETA: 22s - loss: 0.1971 - acc: 0.9325
600/673 [=========================>....] - ETA: 5s - loss: 0.1910 - acc: 0.9300 
673/673 [==============================] - 59s 88ms/step - loss: 0.1890 - acc: 0.9287 - val_loss: 1.4765 - val_acc: 0.5328
Epoch 19/25

200/673 [=======>......................] - ETA: 38s - loss: 0.1478 - acc: 0.9500
400/673 [================>.............] - ETA: 22s - loss: 0.1651 - acc: 0.9525
600/673 [=========================>....] - ETA: 5s - loss: 0.1697 - acc: 0.9567 
673/673 [==============================] - 59s 87ms/step - loss: 0.1671 - acc: 0.9584 - val_loss: 1.5598 - val_acc: 0.5328
Epoch 20/25

200/673 [=======>......................] - ETA: 38s - loss: 0.1599 - acc: 0.9500
400/673 [================>.............] - ETA: 22s - loss: 0.1611 - acc: 0.9475
600/673 [=========================>....] - ETA: 5s - loss: 0.1503 - acc: 0.9500 
673/673 [==============================] - 59s 87ms/step - loss: 0.1501 - acc: 0.9495 - val_loss: 1.6510 - val_acc: 0.5082
Epoch 21/25

200/673 [=======>......................] - ETA: 38s - loss: 0.1533 - acc: 0.9250
400/673 [================>.............] - ETA: 22s - loss: 0.1464 - acc: 0.9450
600/673 [=========================>....] - ETA: 5s - loss: 0.1522 - acc: 0.9500 
673/673 [==============================] - 59s 87ms/step - loss: 0.1455 - acc: 0.9554 - val_loss: 1.5234 - val_acc: 0.6066
Epoch 22/25

200/673 [=======>......................] - ETA: 38s - loss: 0.1583 - acc: 0.9100
400/673 [================>.............] - ETA: 22s - loss: 0.1565 - acc: 0.9250
600/673 [=========================>....] - ETA: 5s - loss: 0.1519 - acc: 0.9333 
673/673 [==============================] - 59s 87ms/step - loss: 0.1502 - acc: 0.9376 - val_loss: 1.8713 - val_acc: 0.4672
Epoch 23/25

200/673 [=======>......................] - ETA: 38s - loss: 0.1672 - acc: 0.9450
400/673 [================>.............] - ETA: 22s - loss: 0.1461 - acc: 0.9625
600/673 [=========================>....] - ETA: 5s - loss: 0.1382 - acc: 0.9633 
673/673 [==============================] - 59s 87ms/step - loss: 0.1389 - acc: 0.9599 - val_loss: 1.6176 - val_acc: 0.5492
Epoch 24/25

200/673 [=======>......................] - ETA: 38s - loss: 0.1086 - acc: 0.9750
400/673 [================>.............] - ETA: 22s - loss: 0.1431 - acc: 0.9400
600/673 [=========================>....] - ETA: 5s - loss: 0.1426 - acc: 0.9450 
673/673 [==============================] - 59s 87ms/step - loss: 0.1387 - acc: 0.9480 - val_loss: 1.8152 - val_acc: 0.4918
Epoch 25/25

200/673 [=======>......................] - ETA: 38s - loss: 0.1188 - acc: 0.9800
400/673 [================>.............] - ETA: 22s - loss: 0.1331 - acc: 0.9775
600/673 [=========================>....] - ETA: 5s - loss: 0.1359 - acc: 0.9667 
673/673 [==============================] - 59s 87ms/step - loss: 0.1397 - acc: 0.9629 - val_loss: 1.6095 - val_acc: 0.5164
[[9.9999344e-01 6.5618729e-06]
 [3.0600902e-01 6.9399101e-01]
 [6.4447308e-01 3.5552689e-01]
 [1.3379942e-12 1.0000000e+00]
 [9.9994886e-01 5.1087438e-05]
 [1.1214032e-01 8.8785964e-01]
 [9.8625714e-01 1.3742929e-02]
 [1.1386011e-12 1.0000000e+00]
 [7.7064857e-07 9.9999928e-01]
 [6.9823468e-01 3.0176538e-01]
 [1.3787634e-02 9.8621237e-01]
 [6.9884390e-01 3.0115604e-01]
 [3.4171730e-01 6.5828270e-01]
 [9.9997365e-01 2.6330810e-05]
 [8.4229626e-02 9.1577041e-01]
 [5.2641350e-01 4.7358647e-01]
 [7.6466191e-01 2.3533812e-01]
 [7.0096475e-01 2.9903519e-01]
 [2.7383989e-01 7.2616017e-01]
 [9.3920195e-01 6.0798079e-02]
 [9.9997509e-01 2.4905117e-05]
 [8.2092202e-01 1.7907797e-01]
 [5.5263335e-01 4.4736663e-01]
 [4.3816483e-01 5.6183517e-01]
 [4.8846123e-01 5.1153874e-01]
 [5.1657879e-01 4.8342124e-01]
 [8.4866458e-01 1.5133540e-01]
 [6.1748958e-01 3.8251039e-01]
 [8.1726068e-01 1.8273930e-01]
 [7.9060930e-01 2.0939070e-01]
 [1.0000000e+00 4.6370446e-14]
 [6.2132454e-01 3.7867549e-01]
 [2.5735110e-01 7.4264884e-01]
 [1.4735107e-01 8.5264891e-01]
 [1.6487850e-02 9.8351210e-01]
 [2.9670098e-01 7.0329899e-01]
 [1.8350705e-14 1.0000000e+00]
 [4.2283875e-01 5.7716125e-01]
 [5.1829236e-04 9.9948174e-01]
 [6.1798292e-01 3.8201711e-01]
 [5.6756073e-01 4.3243930e-01]
 [2.5576525e-03 9.9744236e-01]
 [9.2856872e-01 7.1431316e-02]
 [9.5441246e-01 4.5587521e-02]
 [6.8848628e-01 3.1151369e-01]
 [3.4843072e-02 9.6515691e-01]
 [8.2818973e-01 1.7181025e-01]
 [7.7949509e-02 9.2205048e-01]
 [6.7459482e-01 3.2540515e-01]
 [9.9889523e-01 1.1048313e-03]
 [6.3175339e-01 3.6824659e-01]
 [4.6233115e-01 5.3766882e-01]
 [2.4335948e-01 7.5664043e-01]
 [4.6993351e-14 1.0000000e+00]
 [6.7432088e-01 3.2567921e-01]
 [4.7328657e-01 5.2671343e-01]
 [4.9382341e-01 5.0617653e-01]
 [5.8264446e-01 4.1735554e-01]
 [1.7256674e-01 8.2743329e-01]
 [9.9988365e-01 1.1627758e-04]
 [8.9145648e-01 1.0854357e-01]
 [8.6111885e-01 1.3888115e-01]
 [6.9944704e-01 3.0055299e-01]
 [4.4688288e-02 9.5531166e-01]
 [2.2385950e-01 7.7614051e-01]
 [4.7711509e-01 5.2288485e-01]
 [7.9388422e-01 2.0611580e-01]
 [6.3778037e-01 3.6221957e-01]
 [9.0076828e-01 9.9231698e-02]
 [2.2128284e-05 9.9997783e-01]
 [3.6434859e-01 6.3565141e-01]
 [3.8130262e-01 6.1869735e-01]
 [2.4573505e-01 7.5426501e-01]
 [2.1316061e-02 9.7868389e-01]
 [4.6781027e-01 5.3218973e-01]
 [6.7447788e-01 3.2552212e-01]
 [7.2678906e-01 2.7321097e-01]
 [3.9920059e-01 6.0079944e-01]
 [2.1724531e-02 9.7827542e-01]
 [4.2427829e-01 5.7572174e-01]
 [1.0000000e+00 1.6804437e-12]
 [9.8781466e-01 1.2185395e-02]
 [1.4017525e-02 9.8598248e-01]
 [1.0000000e+00 6.9586952e-13]
 [6.2123442e-01 3.7876555e-01]
 [1.8868485e-01 8.1131512e-01]
 [7.5655036e-02 9.2434496e-01]
 [9.3456730e-02 9.0654331e-01]
 [5.6116140e-01 4.3883863e-01]
 [2.7179590e-03 9.9728203e-01]
 [7.2493039e-02 9.2750698e-01]
 [7.0290208e-01 2.9709783e-01]
 [6.3888615e-01 3.6111382e-01]
 [7.5902832e-01 2.4097162e-01]
 [6.3288480e-01 3.6711523e-01]
 [5.5766964e-01 4.4233045e-01]
 [2.9975429e-01 7.0024568e-01]
 [5.6460410e-01 4.3539593e-01]
 [4.8934883e-01 5.1065111e-01]
 [7.0573699e-01 2.9426304e-01]
 [1.0292197e-04 9.9989712e-01]
 [7.4153298e-01 2.5846705e-01]
 [3.4453896e-01 6.5546095e-01]
 [4.9380150e-02 9.5061988e-01]
 [4.5645338e-06 9.9999547e-01]
 [6.9940025e-01 3.0059975e-01]
 [7.5875032e-01 2.4124967e-01]
 [6.0469079e-01 3.9530924e-01]
 [2.4794943e-05 9.9997520e-01]
 [1.3406761e-05 9.9998665e-01]
 [3.6439884e-01 6.3560116e-01]
 [2.0185221e-08 1.0000000e+00]
 [5.3078747e-01 4.6921256e-01]
 [1.2769468e-01 8.7230533e-01]
 [7.1093595e-01 2.8906396e-01]
 [5.4564559e-01 4.5435438e-01]
 [3.7326597e-02 9.6267343e-01]
 [6.9826561e-01 3.0173445e-01]
 [8.0140787e-01 1.9859208e-01]
 [6.1082524e-01 3.8917485e-01]
 [3.8373271e-01 6.1626726e-01]
 [6.4937371e-01 3.5062635e-01]]
saved: y_pred_from__cnn_aardvark_aug_concat.py_b_200_mask_d_0.25_n_25_a_kfold_0_l_0.0005
[[45 40]
 [19 18]]
