Using TensorFlow backend.
WARNING:tensorflow:From /n/home00/nchou/.conda/envs/envi/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.
Instructions for updating:
Colocations handled automatically by placer.
cnn_aardvark_aug_concat.py:672: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor("in..., outputs=Tensor("de...)`
  model = Model(input=ins, output=dense2)
WARNING:tensorflow:From /n/home00/nchou/.conda/envs/envi/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.cast instead.
2019-12-10 18:19:27.997351: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
2019-12-10 18:19:28.046150: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2900000000 Hz
2019-12-10 18:19:28.046330: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x55e7b9c896f0 executing computations on platform Host. Devices:
2019-12-10 18:19:28.046349: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (0): <undefined>, <undefined>
['cnn_aardvark_aug_concat.py', '-b', '200', '--mask', '-c', '-n', '25', '-a', '--kfold', '0', '-l', '0.005']
1
2
Train on 673 samples, validate on 122 samples
Epoch 1/25

200/673 [=======>......................] - ETA: 33s - loss: 0.6935 - acc: 0.5000
400/673 [================>.............] - ETA: 17s - loss: 0.6966 - acc: 0.4925
600/673 [=========================>....] - ETA: 4s - loss: 0.7468 - acc: 0.4900 
673/673 [==============================] - 43s 64ms/step - loss: 0.7406 - acc: 0.4963 - val_loss: 0.7623 - val_acc: 0.3607
Epoch 2/25

200/673 [=======>......................] - ETA: 26s - loss: 0.6661 - acc: 0.5450
400/673 [================>.............] - ETA: 15s - loss: 0.6453 - acc: 0.5875
600/673 [=========================>....] - ETA: 4s - loss: 0.6256 - acc: 0.6317 
673/673 [==============================] - 40s 59ms/step - loss: 0.6347 - acc: 0.6270 - val_loss: 0.8698 - val_acc: 0.5246
Epoch 3/25

200/673 [=======>......................] - ETA: 26s - loss: 0.6244 - acc: 0.6450
400/673 [================>.............] - ETA: 15s - loss: 0.5903 - acc: 0.6725
600/673 [=========================>....] - ETA: 4s - loss: 0.5917 - acc: 0.6583 
673/673 [==============================] - 40s 59ms/step - loss: 0.5944 - acc: 0.6493 - val_loss: 0.9145 - val_acc: 0.4426
Epoch 4/25

200/673 [=======>......................] - ETA: 26s - loss: 0.5489 - acc: 0.6500
400/673 [================>.............] - ETA: 15s - loss: 0.5377 - acc: 0.6600
600/673 [=========================>....] - ETA: 4s - loss: 0.5467 - acc: 0.6567 
673/673 [==============================] - 40s 59ms/step - loss: 0.5581 - acc: 0.6464 - val_loss: 1.0028 - val_acc: 0.5984
Epoch 5/25

200/673 [=======>......................] - ETA: 26s - loss: 0.5042 - acc: 0.7200
400/673 [================>.............] - ETA: 15s - loss: 0.5000 - acc: 0.7325
600/673 [=========================>....] - ETA: 4s - loss: 0.5033 - acc: 0.7200 
673/673 [==============================] - 40s 59ms/step - loss: 0.5262 - acc: 0.6984 - val_loss: 1.0181 - val_acc: 0.5492
Epoch 6/25

200/673 [=======>......................] - ETA: 26s - loss: 0.5004 - acc: 0.7250
400/673 [================>.............] - ETA: 15s - loss: 0.5010 - acc: 0.7100
600/673 [=========================>....] - ETA: 4s - loss: 0.5047 - acc: 0.7200 
673/673 [==============================] - 40s 59ms/step - loss: 0.5105 - acc: 0.7177 - val_loss: 0.9884 - val_acc: 0.5820
Epoch 7/25

200/673 [=======>......................] - ETA: 26s - loss: 0.4554 - acc: 0.7000
400/673 [================>.............] - ETA: 15s - loss: 0.4713 - acc: 0.7175
600/673 [=========================>....] - ETA: 4s - loss: 0.4649 - acc: 0.7217 
673/673 [==============================] - 40s 59ms/step - loss: 0.4642 - acc: 0.7192 - val_loss: 1.2929 - val_acc: 0.5000
Epoch 8/25

200/673 [=======>......................] - ETA: 26s - loss: 0.4497 - acc: 0.7550
400/673 [================>.............] - ETA: 15s - loss: 0.4325 - acc: 0.7550
600/673 [=========================>....] - ETA: 4s - loss: 0.4184 - acc: 0.7633 
673/673 [==============================] - 40s 59ms/step - loss: 0.4176 - acc: 0.7593 - val_loss: 1.3955 - val_acc: 0.5574
Epoch 9/25

200/673 [=======>......................] - ETA: 26s - loss: 0.3795 - acc: 0.7950
400/673 [================>.............] - ETA: 15s - loss: 0.3593 - acc: 0.8050
600/673 [=========================>....] - ETA: 4s - loss: 0.3809 - acc: 0.7783 
673/673 [==============================] - 40s 59ms/step - loss: 0.3700 - acc: 0.7875 - val_loss: 1.6635 - val_acc: 0.5082
Epoch 10/25

200/673 [=======>......................] - ETA: 26s - loss: 0.3691 - acc: 0.7600
400/673 [================>.............] - ETA: 15s - loss: 0.3323 - acc: 0.7925
600/673 [=========================>....] - ETA: 4s - loss: 0.3542 - acc: 0.7950 
673/673 [==============================] - 40s 59ms/step - loss: 0.3424 - acc: 0.8053 - val_loss: 1.7985 - val_acc: 0.5000
Epoch 11/25

200/673 [=======>......................] - ETA: 26s - loss: 0.3048 - acc: 0.8350
400/673 [================>.............] - ETA: 15s - loss: 0.2972 - acc: 0.8400
600/673 [=========================>....] - ETA: 4s - loss: 0.2883 - acc: 0.8533 
673/673 [==============================] - 40s 59ms/step - loss: 0.2864 - acc: 0.8455 - val_loss: 1.9656 - val_acc: 0.5082
Epoch 12/25

200/673 [=======>......................] - ETA: 26s - loss: 0.2186 - acc: 0.9050
400/673 [================>.............] - ETA: 15s - loss: 0.2473 - acc: 0.8850
600/673 [=========================>....] - ETA: 4s - loss: 0.2454 - acc: 0.8700 
673/673 [==============================] - 40s 59ms/step - loss: 0.2546 - acc: 0.8737 - val_loss: 1.8585 - val_acc: 0.5246
Epoch 13/25

200/673 [=======>......................] - ETA: 26s - loss: 0.2881 - acc: 0.8350
400/673 [================>.............] - ETA: 15s - loss: 0.2620 - acc: 0.8575
600/673 [=========================>....] - ETA: 4s - loss: 0.2570 - acc: 0.8567 
673/673 [==============================] - 40s 59ms/step - loss: 0.2500 - acc: 0.8648 - val_loss: 2.2644 - val_acc: 0.4918
Epoch 14/25

200/673 [=======>......................] - ETA: 26s - loss: 0.2096 - acc: 0.9100
400/673 [================>.............] - ETA: 15s - loss: 0.2420 - acc: 0.8875
600/673 [=========================>....] - ETA: 4s - loss: 0.2360 - acc: 0.8850 
673/673 [==============================] - 40s 59ms/step - loss: 0.2323 - acc: 0.8900 - val_loss: 1.8471 - val_acc: 0.5656
Epoch 15/25

200/673 [=======>......................] - ETA: 26s - loss: 0.1650 - acc: 0.9450
400/673 [================>.............] - ETA: 15s - loss: 0.1890 - acc: 0.9225
600/673 [=========================>....] - ETA: 4s - loss: 0.2142 - acc: 0.9067 
673/673 [==============================] - 40s 59ms/step - loss: 0.2157 - acc: 0.9049 - val_loss: 2.4630 - val_acc: 0.5656
Epoch 16/25

200/673 [=======>......................] - ETA: 26s - loss: 0.1868 - acc: 0.8800
400/673 [================>.............] - ETA: 15s - loss: 0.1974 - acc: 0.8975
600/673 [=========================>....] - ETA: 4s - loss: 0.1887 - acc: 0.9033 
673/673 [==============================] - 40s 59ms/step - loss: 0.1906 - acc: 0.9019 - val_loss: 2.2124 - val_acc: 0.5902
Epoch 17/25

200/673 [=======>......................] - ETA: 26s - loss: 0.1794 - acc: 0.9250
400/673 [================>.............] - ETA: 15s - loss: 0.1741 - acc: 0.9175
600/673 [=========================>....] - ETA: 4s - loss: 0.1437 - acc: 0.9367 
673/673 [==============================] - 40s 59ms/step - loss: 0.1529 - acc: 0.9302 - val_loss: 2.8009 - val_acc: 0.5246
Epoch 18/25

200/673 [=======>......................] - ETA: 26s - loss: 0.2117 - acc: 0.9200
400/673 [================>.............] - ETA: 15s - loss: 0.1607 - acc: 0.9350
600/673 [=========================>....] - ETA: 4s - loss: 0.1552 - acc: 0.9283 
673/673 [==============================] - 40s 59ms/step - loss: 0.1581 - acc: 0.9287 - val_loss: 2.4226 - val_acc: 0.5984
Epoch 19/25

200/673 [=======>......................] - ETA: 26s - loss: 0.1741 - acc: 0.9200
400/673 [================>.............] - ETA: 15s - loss: 0.1672 - acc: 0.9375
600/673 [=========================>....] - ETA: 4s - loss: 0.1713 - acc: 0.9383 
673/673 [==============================] - 40s 59ms/step - loss: 0.1648 - acc: 0.9406 - val_loss: 2.7082 - val_acc: 0.5902
Epoch 20/25

200/673 [=======>......................] - ETA: 26s - loss: 0.1633 - acc: 0.9300
400/673 [================>.............] - ETA: 15s - loss: 0.1798 - acc: 0.9425
600/673 [=========================>....] - ETA: 4s - loss: 0.1598 - acc: 0.9500 
673/673 [==============================] - 40s 59ms/step - loss: 0.1646 - acc: 0.9465 - val_loss: 2.6829 - val_acc: 0.5164
Epoch 21/25

200/673 [=======>......................] - ETA: 26s - loss: 0.0921 - acc: 0.9700
400/673 [================>.............] - ETA: 15s - loss: 0.1245 - acc: 0.9600
600/673 [=========================>....] - ETA: 4s - loss: 0.1367 - acc: 0.9567 
673/673 [==============================] - 40s 59ms/step - loss: 0.1537 - acc: 0.9510 - val_loss: 2.8230 - val_acc: 0.5246
Epoch 22/25

200/673 [=======>......................] - ETA: 26s - loss: 0.1018 - acc: 0.9800
400/673 [================>.............] - ETA: 15s - loss: 0.1001 - acc: 0.9725
600/673 [=========================>....] - ETA: 4s - loss: 0.0942 - acc: 0.9767 
673/673 [==============================] - 40s 59ms/step - loss: 0.0970 - acc: 0.9733 - val_loss: 2.9353 - val_acc: 0.5574
Epoch 23/25

200/673 [=======>......................] - ETA: 26s - loss: 0.0802 - acc: 0.9800
400/673 [================>.............] - ETA: 15s - loss: 0.0918 - acc: 0.9825
600/673 [=========================>....] - ETA: 4s - loss: 0.1416 - acc: 0.9733 
673/673 [==============================] - 40s 59ms/step - loss: 0.1587 - acc: 0.9703 - val_loss: 2.9715 - val_acc: 0.5492
Epoch 24/25

200/673 [=======>......................] - ETA: 26s - loss: 0.0721 - acc: 0.9850
400/673 [================>.............] - ETA: 15s - loss: 0.0727 - acc: 0.9800
600/673 [=========================>....] - ETA: 4s - loss: 0.1236 - acc: 0.9783 
673/673 [==============================] - 40s 59ms/step - loss: 0.1189 - acc: 0.9777 - val_loss: 2.6485 - val_acc: 0.6230
Epoch 25/25

200/673 [=======>......................] - ETA: 26s - loss: 0.1320 - acc: 0.9850
400/673 [================>.............] - ETA: 15s - loss: 0.0945 - acc: 0.9850
600/673 [=========================>....] - ETA: 4s - loss: 0.1199 - acc: 0.9750 
673/673 [==============================] - 40s 59ms/step - loss: 0.1112 - acc: 0.9762 - val_loss: 2.8599 - val_acc: 0.5820
[[1.00000000e+00 0.00000000e+00]
 [1.00000000e+00 1.53637864e-15]
 [9.58313644e-01 4.16863225e-02]
 [0.00000000e+00 1.00000000e+00]
 [1.00000000e+00 3.00152764e-22]
 [6.84667340e-12 1.00000000e+00]
 [1.00000000e+00 1.12133906e-10]
 [1.00000000e+00 0.00000000e+00]
 [9.28323151e-24 1.00000000e+00]
 [9.98531818e-01 1.46818755e-03]
 [8.22455715e-03 9.91775393e-01]
 [4.88708496e-01 5.11291504e-01]
 [5.19498903e-03 9.94805038e-01]
 [1.00000000e+00 0.00000000e+00]
 [1.04317591e-02 9.89568293e-01]
 [9.50852811e-01 4.91472110e-02]
 [9.99990106e-01 9.86254690e-06]
 [9.93452191e-01 6.54774858e-03]
 [3.13684507e-03 9.96863127e-01]
 [9.01618405e-05 9.99909878e-01]
 [1.00000000e+00 1.53930515e-31]
 [9.99988437e-01 1.16030369e-05]
 [1.50230853e-02 9.84976888e-01]
 [9.99999762e-01 1.91189187e-07]
 [3.10963690e-01 6.89036250e-01]
 [1.00000000e+00 7.57474439e-09]
 [9.99914765e-01 8.51972072e-05]
 [9.55172122e-01 4.48278710e-02]
 [9.99371111e-01 6.28915324e-04]
 [9.38011289e-01 6.19886480e-02]
 [1.00000000e+00 0.00000000e+00]
 [9.35928166e-01 6.40718639e-02]
 [7.68713381e-13 1.00000000e+00]
 [6.97941659e-03 9.93020594e-01]
 [1.50151182e-20 1.00000000e+00]
 [3.57149929e-01 6.42850101e-01]
 [0.00000000e+00 1.00000000e+00]
 [9.89438832e-01 1.05611822e-02]
 [1.40643620e-04 9.99859333e-01]
 [5.18673778e-01 4.81326222e-01]
 [6.12855434e-01 3.87144595e-01]
 [1.02303317e-03 9.98976946e-01]
 [1.00000000e+00 6.07603621e-21]
 [9.99820054e-01 1.79930343e-04]
 [3.70418727e-01 6.29581273e-01]
 [2.67117994e-09 1.00000000e+00]
 [9.99992371e-01 7.62402306e-06]
 [1.61631882e-01 8.38368118e-01]
 [4.30741280e-01 5.69258749e-01]
 [1.00000000e+00 0.00000000e+00]
 [7.94429243e-01 2.05570772e-01]
 [3.95214468e-01 6.04785502e-01]
 [3.14841121e-01 6.85158908e-01]
 [0.00000000e+00 1.00000000e+00]
 [9.54041898e-01 4.59581167e-02]
 [1.88016176e-01 8.11983824e-01]
 [9.99916077e-01 8.38784472e-05]
 [3.60776126e-01 6.39223814e-01]
 [1.54205933e-02 9.84579444e-01]
 [1.00000000e+00 6.45909341e-17]
 [1.00000000e+00 9.82769643e-10]
 [1.00000000e+00 1.04458011e-12]
 [9.91893172e-01 8.10689479e-03]
 [6.14506789e-05 9.99938488e-01]
 [2.47639342e-04 9.99752343e-01]
 [3.54785621e-02 9.64521468e-01]
 [9.97563839e-01 2.43618921e-03]
 [7.98403680e-01 2.01596335e-01]
 [1.00000000e+00 3.71897679e-10]
 [3.35113121e-21 1.00000000e+00]
 [1.03956663e-04 9.99896049e-01]
 [9.99970794e-01 2.92574732e-05]
 [1.00000000e+00 9.86935824e-18]
 [1.26393658e-07 9.99999881e-01]
 [9.85269845e-01 1.47301424e-02]
 [9.99340951e-01 6.59004785e-04]
 [9.97325778e-01 2.67423410e-03]
 [1.20556347e-01 8.79443705e-01]
 [9.99928117e-01 7.18329247e-05]
 [1.15025595e-01 8.84974420e-01]
 [1.00000000e+00 0.00000000e+00]
 [1.00000000e+00 1.09314977e-12]
 [2.34592221e-06 9.99997616e-01]
 [1.00000000e+00 3.76931624e-21]
 [2.69889981e-01 7.30110049e-01]
 [9.98740256e-01 1.25981728e-03]
 [3.60132498e-03 9.96398687e-01]
 [1.68378241e-02 9.83162165e-01]
 [7.28031397e-02 9.27196860e-01]
 [1.70094753e-03 9.98299062e-01]
 [1.12387678e-02 9.88761246e-01]
 [3.74108940e-01 6.25891089e-01]
 [2.76105050e-02 9.72389519e-01]
 [9.08566773e-01 9.14332122e-02]
 [2.34397963e-01 7.65602052e-01]
 [6.23279214e-01 3.76720816e-01]
 [2.02472452e-02 9.79752779e-01]
 [4.15308982e-01 5.84690988e-01]
 [1.78494956e-05 9.99982119e-01]
 [7.22139001e-01 2.77861029e-01]
 [5.44190248e-10 1.00000000e+00]
 [8.62896860e-01 1.37103111e-01]
 [4.26112473e-01 5.73887527e-01]
 [8.55458482e-11 1.00000000e+00]
 [1.15417088e-05 9.99988437e-01]
 [1.00000000e+00 2.91491331e-10]
 [9.87942278e-01 1.20576741e-02]
 [7.11985826e-01 2.88014144e-01]
 [1.33148692e-31 1.00000000e+00]
 [1.52915707e-08 1.00000000e+00]
 [3.92159909e-01 6.07840121e-01]
 [6.90484603e-09 1.00000000e+00]
 [1.40431970e-01 8.59568059e-01]
 [1.37972907e-04 9.99861956e-01]
 [7.14313865e-01 2.85686105e-01]
 [8.35586712e-02 9.16441321e-01]
 [1.00000000e+00 5.88941688e-19]
 [4.67350751e-01 5.32649219e-01]
 [9.99627113e-01 3.72828479e-04]
 [7.63829470e-01 2.36170575e-01]
 [3.27382863e-01 6.72617078e-01]
 [7.12778807e-01 2.87221253e-01]]
saved: y_pred_from__cnn_aardvark_aug_concat.py_b_200_mask_c_n_25_a_kfold_0_l_0.005
[[47 38]
 [13 24]]
