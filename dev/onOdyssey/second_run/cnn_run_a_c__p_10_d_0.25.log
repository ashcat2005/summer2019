Using TensorFlow backend.
WARNING:tensorflow:From /n/home00/nchou/.conda/envs/envi/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.
Instructions for updating:
Colocations handled automatically by placer.
WARNING:tensorflow:From /n/home00/nchou/.conda/envs/envi/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.
Instructions for updating:
Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.
cnn_aardvark_aug_concat.py:397: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor("in..., outputs=Tensor("de...)`
  model = Model(input=ins, output=dense2)
WARNING:tensorflow:From /n/home00/nchou/.conda/envs/envi/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.cast instead.
2019-11-07 09:03:35.177410: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
2019-11-07 09:03:35.181308: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2900000000 Hz
2019-11-07 09:03:35.181413: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x558293d64550 executing computations on platform Host. Devices:
2019-11-07 09:03:35.181433: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (0): <undefined>, <undefined>
[0.25]
Train on 348 samples, validate on 116 samples
Epoch 1/35

348/348 [==============================] - 21s 60ms/step - loss: 0.6937 - acc: 0.5259 - val_loss: 0.6912 - val_acc: 0.5690
Epoch 2/35

348/348 [==============================] - 20s 56ms/step - loss: 0.6896 - acc: 0.6379 - val_loss: 0.6911 - val_acc: 0.5000
Epoch 3/35

348/348 [==============================] - 20s 56ms/step - loss: 0.6853 - acc: 0.6351 - val_loss: 0.6919 - val_acc: 0.4741
Epoch 4/35

348/348 [==============================] - 19s 56ms/step - loss: 0.6812 - acc: 0.6351 - val_loss: 0.6936 - val_acc: 0.4655
Epoch 5/35

348/348 [==============================] - 19s 56ms/step - loss: 0.6772 - acc: 0.6264 - val_loss: 0.6962 - val_acc: 0.4569
Epoch 6/35

348/348 [==============================] - 19s 56ms/step - loss: 0.6733 - acc: 0.6236 - val_loss: 0.6999 - val_acc: 0.4397
Epoch 7/35

348/348 [==============================] - 19s 56ms/step - loss: 0.6696 - acc: 0.6006 - val_loss: 0.7046 - val_acc: 0.4397
Epoch 8/35

348/348 [==============================] - 20s 56ms/step - loss: 0.6659 - acc: 0.6034 - val_loss: 0.7105 - val_acc: 0.4310
Epoch 9/35

348/348 [==============================] - 19s 56ms/step - loss: 0.6624 - acc: 0.5948 - val_loss: 0.7175 - val_acc: 0.4397
Epoch 10/35

348/348 [==============================] - 20s 56ms/step - loss: 0.6591 - acc: 0.5920 - val_loss: 0.7255 - val_acc: 0.4310
Epoch 11/35

348/348 [==============================] - 20s 56ms/step - loss: 0.6559 - acc: 0.5891 - val_loss: 0.7344 - val_acc: 0.4310
Epoch 12/35

348/348 [==============================] - 20s 56ms/step - loss: 0.6528 - acc: 0.5862 - val_loss: 0.7440 - val_acc: 0.4310
Epoch 13/35

348/348 [==============================] - 19s 56ms/step - loss: 0.6497 - acc: 0.5833 - val_loss: 0.7538 - val_acc: 0.4483
Epoch 14/35

348/348 [==============================] - 20s 56ms/step - loss: 0.6467 - acc: 0.5862 - val_loss: 0.7633 - val_acc: 0.5086
Epoch 15/35

348/348 [==============================] - 19s 56ms/step - loss: 0.6437 - acc: 0.6149 - val_loss: 0.7722 - val_acc: 0.5172
Epoch 16/35

348/348 [==============================] - 19s 56ms/step - loss: 0.6407 - acc: 0.6178 - val_loss: 0.7803 - val_acc: 0.5172
Epoch 17/35

348/348 [==============================] - 19s 56ms/step - loss: 0.6376 - acc: 0.6006 - val_loss: 0.7874 - val_acc: 0.5172
Epoch 18/35

348/348 [==============================] - 19s 56ms/step - loss: 0.6345 - acc: 0.6006 - val_loss: 0.7940 - val_acc: 0.5431
Epoch 19/35

348/348 [==============================] - 19s 56ms/step - loss: 0.6315 - acc: 0.6207 - val_loss: 0.7999 - val_acc: 0.5517
Epoch 20/35

348/348 [==============================] - 19s 56ms/step - loss: 0.6284 - acc: 0.6379 - val_loss: 0.8053 - val_acc: 0.5517
Epoch 21/35

348/348 [==============================] - 19s 56ms/step - loss: 0.6253 - acc: 0.6437 - val_loss: 0.8104 - val_acc: 0.5517
Epoch 22/35

348/348 [==============================] - 19s 56ms/step - loss: 0.6222 - acc: 0.6466 - val_loss: 0.8153 - val_acc: 0.5603
Epoch 23/35

348/348 [==============================] - 19s 56ms/step - loss: 0.6191 - acc: 0.6523 - val_loss: 0.8206 - val_acc: 0.5948
Epoch 24/35

348/348 [==============================] - 19s 56ms/step - loss: 0.6159 - acc: 0.6580 - val_loss: 0.8260 - val_acc: 0.5948
Epoch 25/35

348/348 [==============================] - 19s 56ms/step - loss: 0.6126 - acc: 0.6839 - val_loss: 0.8315 - val_acc: 0.5862
Epoch 26/35

348/348 [==============================] - 19s 55ms/step - loss: 0.6093 - acc: 0.6839 - val_loss: 0.8369 - val_acc: 0.5776
Epoch 27/35

348/348 [==============================] - 19s 55ms/step - loss: 0.6058 - acc: 0.6925 - val_loss: 0.8424 - val_acc: 0.5776
Epoch 28/35

348/348 [==============================] - 19s 56ms/step - loss: 0.6022 - acc: 0.6897 - val_loss: 0.8481 - val_acc: 0.5862
Epoch 29/35

348/348 [==============================] - 19s 55ms/step - loss: 0.5985 - acc: 0.6925 - val_loss: 0.8546 - val_acc: 0.5948
Epoch 30/35

348/348 [==============================] - 19s 55ms/step - loss: 0.5946 - acc: 0.6925 - val_loss: 0.8625 - val_acc: 0.5776
Epoch 31/35

348/348 [==============================] - 19s 55ms/step - loss: 0.5906 - acc: 0.6925 - val_loss: 0.8719 - val_acc: 0.5862
Epoch 32/35

348/348 [==============================] - 19s 56ms/step - loss: 0.5863 - acc: 0.6983 - val_loss: 0.8824 - val_acc: 0.5776
Epoch 33/35

348/348 [==============================] - 19s 55ms/step - loss: 0.5818 - acc: 0.7011 - val_loss: 0.8933 - val_acc: 0.5862
Epoch 34/35

348/348 [==============================] - 19s 56ms/step - loss: 0.5771 - acc: 0.6983 - val_loss: 0.9041 - val_acc: 0.5862
Epoch 35/35

348/348 [==============================] - 19s 55ms/step - loss: 0.5722 - acc: 0.6983 - val_loss: 0.9145 - val_acc: 0.5776
Saved trained model at /n/holylfs03/LABS/berger_lab/nchou/saved_models/aardvark_aug11.h5 
[[6.1022633e-01 3.8977367e-01]
 [5.0404495e-01 4.9595511e-01]
 [6.9645083e-01 3.0354920e-01]
 [7.9031986e-01 2.0968018e-01]
 [6.3305402e-01 3.6694598e-01]
 [4.6954644e-01 5.3045350e-01]
 [2.3100524e-01 7.6899481e-01]
 [8.6870497e-01 1.3129504e-01]
 [5.5115706e-01 4.4884291e-01]
 [6.7221636e-01 3.2778361e-01]
 [3.6847711e-01 6.3152289e-01]
 [5.2752107e-01 4.7247893e-01]
 [4.3968946e-01 5.6031060e-01]
 [4.7894451e-01 5.2105552e-01]
 [4.2358506e-01 5.7641494e-01]
 [9.5313185e-01 4.6868160e-02]
 [3.8480389e-01 6.1519605e-01]
 [4.8566613e-01 5.1433390e-01]
 [6.9500166e-01 3.0499837e-01]
 [4.7008362e-01 5.2991635e-01]
 [2.3100524e-01 7.6899481e-01]
 [3.8480389e-01 6.1519605e-01]
 [2.9031286e-01 7.0968711e-01]
 [6.3305402e-01 3.6694598e-01]
 [4.7894451e-01 5.2105552e-01]
 [4.7572494e-01 5.2427506e-01]
 [4.7888896e-01 5.2111107e-01]
 [3.7005603e-01 6.2994397e-01]
 [4.6494508e-01 5.3505492e-01]
 [4.2358506e-01 5.7641494e-01]
 [4.3595248e-01 5.6404752e-01]
 [4.7829124e-01 5.2170873e-01]
 [4.9517179e-01 5.0482821e-01]
 [4.7790742e-01 5.2209252e-01]
 [9.8212588e-01 1.7874118e-02]
 [6.0804558e-01 3.9195445e-01]
 [9.9055326e-01 9.4467700e-03]
 [5.2752107e-01 4.7247893e-01]
 [4.6376848e-01 5.3623158e-01]
 [4.3595248e-01 5.6404752e-01]
 [3.3599392e-01 6.6400611e-01]
 [4.7302842e-01 5.2697158e-01]
 [7.7813196e-01 2.2186802e-01]
 [6.9645083e-01 3.0354920e-01]
 [3.4582677e-01 6.5417331e-01]
 [3.9079386e-01 6.0920614e-01]
 [4.4076753e-01 5.5923247e-01]
 [4.5471245e-01 5.4528755e-01]
 [4.5327395e-01 5.4672611e-01]
 [9.9055326e-01 9.4467700e-03]
 [1.3803021e-02 9.8619694e-01]
 [9.9055326e-01 9.4467700e-03]
 [9.5313185e-01 4.6868160e-02]
 [4.1533279e-01 5.8466727e-01]
 [5.0598532e-01 4.9401471e-01]
 [3.7751338e-01 6.2248665e-01]
 [4.9322531e-01 5.0677466e-01]
 [4.3595248e-01 5.6404752e-01]
 [4.9199450e-01 5.0800556e-01]
 [6.3305402e-01 3.6694598e-01]
 [8.6870497e-01 1.3129504e-01]
 [4.7572494e-01 5.2427506e-01]
 [4.3595248e-01 5.6404752e-01]
 [4.8828575e-01 5.1171422e-01]
 [2.3100524e-01 7.6899481e-01]
 [6.9654912e-01 3.0345088e-01]
 [4.8828575e-01 5.1171422e-01]
 [4.5327395e-01 5.4672611e-01]
 [4.2926961e-01 5.7073039e-01]
 [3.2491317e-01 6.7508686e-01]
 [9.9970561e-01 2.9434977e-04]
 [4.5965144e-01 5.4034859e-01]
 [4.5327395e-01 5.4672611e-01]
 [9.9753666e-01 2.4633021e-03]
 [4.7302842e-01 5.2697158e-01]
 [4.7885963e-01 5.2114040e-01]
 [5.2739149e-01 4.7260857e-01]
 [8.6870497e-01 1.3129504e-01]
 [5.2752107e-01 4.7247893e-01]
 [5.2752107e-01 4.7247893e-01]
 [9.5313185e-01 4.6868160e-02]
 [4.5983917e-01 5.4016083e-01]
 [3.6213484e-01 6.3786513e-01]
 [4.5471245e-01 5.4528755e-01]
 [3.0166966e-01 6.9833034e-01]
 [6.7221636e-01 3.2778361e-01]
 [2.5343747e-04 9.9974650e-01]
 [4.7829124e-01 5.2170873e-01]
 [9.7074527e-01 2.9254718e-02]
 [3.4956887e-01 6.5043116e-01]
 [4.9517179e-01 5.0482821e-01]
 [4.5069435e-01 5.4930562e-01]
 [1.6814691e-01 8.3185309e-01]
 [7.4480885e-01 2.5519112e-01]
 [8.4451294e-01 1.5548705e-01]
 [7.9031986e-01 2.0968018e-01]
 [8.6870497e-01 1.3129504e-01]
 [4.8271164e-01 5.1728833e-01]
 [4.9517179e-01 5.0482821e-01]
 [4.7543558e-01 5.2456445e-01]
 [5.8484364e-01 4.1515630e-01]
 [7.7813196e-01 2.2186802e-01]
 [6.9645083e-01 3.0354920e-01]
 [4.6206257e-01 5.3793740e-01]
 [4.7305584e-01 5.2694410e-01]
 [6.7221636e-01 3.2778361e-01]
 [5.4909116e-01 4.5090881e-01]
 [4.7885716e-01 5.2114290e-01]
 [9.9594194e-01 4.0580034e-03]
 [5.0598532e-01 4.9401471e-01]
 [4.3595248e-01 5.6404752e-01]
 [4.9014428e-01 5.0985575e-01]
 [4.3595248e-01 5.6404752e-01]
 [9.9594194e-01 4.0580034e-03]
 [4.2908111e-01 5.7091892e-01]
 [3.5735938e-01 6.4264065e-01]]
[0 0 0 0 0 1 1 0 0 0 1 0 1 1 1 0 1 1 0 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 0 0 0
 0 1 1 1 1 0 0 1 1 1 1 1 0 1 0 0 1 0 1 1 1 1 0 0 1 1 1 1 0 1 1 1 1 0 1 1 0
 1 1 0 0 0 0 0 1 1 1 1 0 1 1 0 1 1 1 1 0 0 0 0 1 1 1 0 0 0 1 1 0 0 1 0 0 1
 1 1 0 1 1]

 32/116 [=======>......................] - ETA: 1s
 64/116 [===============>..............] - ETA: 0s
 96/116 [=======================>......] - ETA: 0s
116/116 [==============================] - 2s 15ms/step
Test loss: 0.7173235436965679
Test accuracy: 0.6896551703584606
[[34 24]
 [12 46]]
