Using TensorFlow backend.
WARNING:tensorflow:From /n/home00/nchou/.conda/envs/envi/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.
Instructions for updating:
Colocations handled automatically by placer.
WARNING:tensorflow:From /n/home00/nchou/.conda/envs/envi/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.
Instructions for updating:
Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.
cnn_aardvark_aug_concat.py:397: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor("in..., outputs=Tensor("de...)`
  model = Model(input=ins, output=dense2)
WARNING:tensorflow:From /n/home00/nchou/.conda/envs/envi/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.cast instead.
2019-11-07 11:44:58.522803: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
2019-11-07 11:44:58.661954: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2900000000 Hz
2019-11-07 11:44:58.662231: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x55ec9017b240 executing computations on platform Host. Devices:
2019-11-07 11:44:58.662285: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (0): <undefined>, <undefined>
[0.25]
Train on 522 samples, validate on 174 samples
Epoch 1/40

174/522 [=========>....................] - ETA: 29s - loss: 1.0989 - acc: 0.3563
348/522 [===================>..........] - ETA: 11s - loss: 1.0930 - acc: 0.3822
522/522 [==============================] - 35s 68ms/step - loss: 1.0905 - acc: 0.3812 - val_loss: 1.0390 - val_acc: 0.4080
Epoch 2/40

174/522 [=========>....................] - ETA: 17s - loss: 1.0173 - acc: 0.5172
348/522 [===================>..........] - ETA: 8s - loss: 1.0029 - acc: 0.5230 
522/522 [==============================] - 29s 56ms/step - loss: 0.9846 - acc: 0.5364 - val_loss: 1.0089 - val_acc: 0.3966
Epoch 3/40

174/522 [=========>....................] - ETA: 17s - loss: 0.8772 - acc: 0.6839
348/522 [===================>..........] - ETA: 8s - loss: 0.8821 - acc: 0.6178 
522/522 [==============================] - 30s 57ms/step - loss: 0.8889 - acc: 0.5920 - val_loss: 1.0734 - val_acc: 0.4713
Epoch 4/40

174/522 [=========>....................] - ETA: 17s - loss: 0.8193 - acc: 0.6149
348/522 [===================>..........] - ETA: 8s - loss: 0.7982 - acc: 0.6437 
522/522 [==============================] - 30s 57ms/step - loss: 0.8086 - acc: 0.6418 - val_loss: 1.0851 - val_acc: 0.4885
Epoch 5/40

174/522 [=========>....................] - ETA: 17s - loss: 0.7527 - acc: 0.7414
348/522 [===================>..........] - ETA: 8s - loss: 0.7484 - acc: 0.7241 
522/522 [==============================] - 29s 56ms/step - loss: 0.7308 - acc: 0.7241 - val_loss: 1.1280 - val_acc: 0.4885
Epoch 6/40

174/522 [=========>....................] - ETA: 17s - loss: 0.6721 - acc: 0.7529
348/522 [===================>..........] - ETA: 8s - loss: 0.7006 - acc: 0.7213 
522/522 [==============================] - 29s 56ms/step - loss: 0.6707 - acc: 0.7375 - val_loss: 1.1948 - val_acc: 0.5632
Epoch 7/40

174/522 [=========>....................] - ETA: 17s - loss: 0.6181 - acc: 0.7989
348/522 [===================>..........] - ETA: 8s - loss: 0.6186 - acc: 0.7816 
522/522 [==============================] - 29s 56ms/step - loss: 0.6164 - acc: 0.8027 - val_loss: 1.2465 - val_acc: 0.5690
Epoch 8/40

174/522 [=========>....................] - ETA: 17s - loss: 0.5637 - acc: 0.8563
348/522 [===================>..........] - ETA: 8s - loss: 0.5601 - acc: 0.8391 
522/522 [==============================] - 29s 56ms/step - loss: 0.5632 - acc: 0.8314 - val_loss: 1.2726 - val_acc: 0.5632
Epoch 9/40

174/522 [=========>....................] - ETA: 17s - loss: 0.4965 - acc: 0.8793
348/522 [===================>..........] - ETA: 8s - loss: 0.5109 - acc: 0.8276 
522/522 [==============================] - 29s 57ms/step - loss: 0.5148 - acc: 0.8142 - val_loss: 1.3312 - val_acc: 0.5632
Epoch 10/40

174/522 [=========>....................] - ETA: 17s - loss: 0.5069 - acc: 0.7586
348/522 [===================>..........] - ETA: 8s - loss: 0.4951 - acc: 0.8132 
522/522 [==============================] - 29s 56ms/step - loss: 0.4824 - acc: 0.8238 - val_loss: 1.2764 - val_acc: 0.6092
Epoch 11/40

174/522 [=========>....................] - ETA: 17s - loss: 0.3969 - acc: 0.8908
348/522 [===================>..........] - ETA: 8s - loss: 0.4162 - acc: 0.8966 
522/522 [==============================] - 29s 56ms/step - loss: 0.4404 - acc: 0.8621 - val_loss: 1.3085 - val_acc: 0.6322
Epoch 12/40

174/522 [=========>....................] - ETA: 17s - loss: 0.3614 - acc: 0.9253
348/522 [===================>..........] - ETA: 8s - loss: 0.3973 - acc: 0.8736 
522/522 [==============================] - 30s 57ms/step - loss: 0.4096 - acc: 0.8793 - val_loss: 1.3239 - val_acc: 0.6724
Epoch 13/40

174/522 [=========>....................] - ETA: 17s - loss: 0.3920 - acc: 0.9023
348/522 [===================>..........] - ETA: 8s - loss: 0.3983 - acc: 0.8994 
522/522 [==============================] - 29s 56ms/step - loss: 0.3832 - acc: 0.9042 - val_loss: 1.3339 - val_acc: 0.7069
Epoch 14/40

174/522 [=========>....................] - ETA: 17s - loss: 0.3484 - acc: 0.9080
348/522 [===================>..........] - ETA: 8s - loss: 0.3461 - acc: 0.9023 
522/522 [==============================] - 30s 57ms/step - loss: 0.3675 - acc: 0.8774 - val_loss: 1.3544 - val_acc: 0.6322
Epoch 15/40

174/522 [=========>....................] - ETA: 17s - loss: 0.3021 - acc: 0.8908
348/522 [===================>..........] - ETA: 8s - loss: 0.3269 - acc: 0.8736 
522/522 [==============================] - 29s 56ms/step - loss: 0.3300 - acc: 0.8697 - val_loss: 1.3454 - val_acc: 0.6264
Epoch 16/40

174/522 [=========>....................] - ETA: 17s - loss: 0.3476 - acc: 0.8966
348/522 [===================>..........] - ETA: 8s - loss: 0.3405 - acc: 0.8937 
522/522 [==============================] - 29s 56ms/step - loss: 0.3138 - acc: 0.9061 - val_loss: 1.3277 - val_acc: 0.6322
Epoch 17/40

174/522 [=========>....................] - ETA: 17s - loss: 0.3305 - acc: 0.9310
348/522 [===================>..........] - ETA: 8s - loss: 0.2993 - acc: 0.9339 
522/522 [==============================] - 29s 57ms/step - loss: 0.2969 - acc: 0.9176 - val_loss: 1.3690 - val_acc: 0.6897
Epoch 18/40

174/522 [=========>....................] - ETA: 17s - loss: 0.2545 - acc: 0.9138
348/522 [===================>..........] - ETA: 8s - loss: 0.2564 - acc: 0.9425 
522/522 [==============================] - 29s 57ms/step - loss: 0.2593 - acc: 0.9425 - val_loss: 1.4100 - val_acc: 0.5977
Epoch 19/40

174/522 [=========>....................] - ETA: 17s - loss: 0.2396 - acc: 0.9540
348/522 [===================>..........] - ETA: 8s - loss: 0.2552 - acc: 0.9540 
522/522 [==============================] - 30s 57ms/step - loss: 0.2467 - acc: 0.9483 - val_loss: 1.3843 - val_acc: 0.6724
Epoch 20/40

174/522 [=========>....................] - ETA: 17s - loss: 0.2227 - acc: 0.9310
348/522 [===================>..........] - ETA: 8s - loss: 0.2284 - acc: 0.9310 
522/522 [==============================] - 30s 57ms/step - loss: 0.2264 - acc: 0.9349 - val_loss: 1.3576 - val_acc: 0.6379
Epoch 21/40

174/522 [=========>....................] - ETA: 17s - loss: 0.2222 - acc: 0.9655
348/522 [===================>..........] - ETA: 8s - loss: 0.2252 - acc: 0.9598 
522/522 [==============================] - 30s 57ms/step - loss: 0.2089 - acc: 0.9617 - val_loss: 1.3617 - val_acc: 0.6782
Epoch 22/40

174/522 [=========>....................] - ETA: 17s - loss: 0.1614 - acc: 0.9655
348/522 [===================>..........] - ETA: 8s - loss: 0.1832 - acc: 0.9684 
522/522 [==============================] - 30s 57ms/step - loss: 0.1884 - acc: 0.9636 - val_loss: 1.3670 - val_acc: 0.7069
Epoch 23/40

174/522 [=========>....................] - ETA: 17s - loss: 0.1829 - acc: 0.9425
348/522 [===================>..........] - ETA: 8s - loss: 0.1780 - acc: 0.9684 
522/522 [==============================] - 30s 57ms/step - loss: 0.1682 - acc: 0.9751 - val_loss: 1.3985 - val_acc: 0.6839
Epoch 24/40

174/522 [=========>....................] - ETA: 17s - loss: 0.1471 - acc: 0.9828
348/522 [===================>..........] - ETA: 8s - loss: 0.1609 - acc: 0.9828 
522/522 [==============================] - 30s 57ms/step - loss: 0.1554 - acc: 0.9808 - val_loss: 1.4102 - val_acc: 0.7069
Epoch 25/40

174/522 [=========>....................] - ETA: 17s - loss: 0.1357 - acc: 0.9828
348/522 [===================>..........] - ETA: 8s - loss: 0.1438 - acc: 0.9885 
522/522 [==============================] - 30s 57ms/step - loss: 0.1391 - acc: 0.9904 - val_loss: 1.4418 - val_acc: 0.7011
Epoch 26/40

174/522 [=========>....................] - ETA: 17s - loss: 0.1171 - acc: 0.9943
348/522 [===================>..........] - ETA: 8s - loss: 0.1335 - acc: 0.9943 
522/522 [==============================] - 30s 57ms/step - loss: 0.1254 - acc: 0.9943 - val_loss: 1.4628 - val_acc: 0.7069
Epoch 27/40

174/522 [=========>....................] - ETA: 17s - loss: 0.1050 - acc: 0.9885
348/522 [===================>..........] - ETA: 8s - loss: 0.1030 - acc: 0.9943 
522/522 [==============================] - 30s 57ms/step - loss: 0.1135 - acc: 0.9923 - val_loss: 1.4905 - val_acc: 0.6782
Epoch 28/40

174/522 [=========>....................] - ETA: 17s - loss: 0.1178 - acc: 0.9943
348/522 [===================>..........] - ETA: 8s - loss: 0.1176 - acc: 0.9943 
522/522 [==============================] - 30s 57ms/step - loss: 0.1052 - acc: 0.9943 - val_loss: 1.5051 - val_acc: 0.6954
Epoch 29/40

174/522 [=========>....................] - ETA: 17s - loss: 0.1157 - acc: 0.9943
348/522 [===================>..........] - ETA: 8s - loss: 0.1009 - acc: 0.9943 
522/522 [==============================] - 30s 57ms/step - loss: 0.0959 - acc: 0.9943 - val_loss: 1.4978 - val_acc: 0.7011
Epoch 30/40

174/522 [=========>....................] - ETA: 17s - loss: 0.0959 - acc: 1.0000
348/522 [===================>..........] - ETA: 8s - loss: 0.0861 - acc: 1.0000 
522/522 [==============================] - 30s 57ms/step - loss: 0.0869 - acc: 0.9981 - val_loss: 1.5082 - val_acc: 0.6724
Epoch 31/40

174/522 [=========>....................] - ETA: 17s - loss: 0.0713 - acc: 1.0000
348/522 [===================>..........] - ETA: 8s - loss: 0.0763 - acc: 0.9971 
522/522 [==============================] - 30s 57ms/step - loss: 0.0800 - acc: 0.9962 - val_loss: 1.5034 - val_acc: 0.6954
Epoch 32/40

174/522 [=========>....................] - ETA: 17s - loss: 0.0787 - acc: 0.9943
348/522 [===================>..........] - ETA: 8s - loss: 0.0771 - acc: 0.9885 
522/522 [==============================] - 30s 57ms/step - loss: 0.0756 - acc: 0.9923 - val_loss: 1.5087 - val_acc: 0.6609
Epoch 33/40

174/522 [=========>....................] - ETA: 17s - loss: 0.0645 - acc: 1.0000
348/522 [===================>..........] - ETA: 8s - loss: 0.0666 - acc: 1.0000 
522/522 [==============================] - 30s 57ms/step - loss: 0.0704 - acc: 1.0000 - val_loss: 1.5065 - val_acc: 0.6954
Epoch 34/40

174/522 [=========>....................] - ETA: 17s - loss: 0.0488 - acc: 1.0000
348/522 [===================>..........] - ETA: 8s - loss: 0.0618 - acc: 1.0000 
522/522 [==============================] - 30s 57ms/step - loss: 0.0611 - acc: 1.0000 - val_loss: 1.5162 - val_acc: 0.7069
Epoch 35/40

174/522 [=========>....................] - ETA: 17s - loss: 0.0685 - acc: 0.9943
348/522 [===================>..........] - ETA: 8s - loss: 0.0579 - acc: 0.9971 
522/522 [==============================] - 30s 57ms/step - loss: 0.0572 - acc: 0.9981 - val_loss: 1.5333 - val_acc: 0.7069
Epoch 36/40

174/522 [=========>....................] - ETA: 17s - loss: 0.0467 - acc: 1.0000
348/522 [===================>..........] - ETA: 8s - loss: 0.0498 - acc: 1.0000 
522/522 [==============================] - 30s 57ms/step - loss: 0.0530 - acc: 1.0000 - val_loss: 1.5272 - val_acc: 0.6954
Epoch 37/40

174/522 [=========>....................] - ETA: 17s - loss: 0.0462 - acc: 1.0000
348/522 [===================>..........] - ETA: 8s - loss: 0.0479 - acc: 1.0000 
522/522 [==============================] - 30s 57ms/step - loss: 0.0468 - acc: 1.0000 - val_loss: 1.5311 - val_acc: 0.6897
Epoch 38/40

174/522 [=========>....................] - ETA: 17s - loss: 0.0499 - acc: 1.0000
348/522 [===================>..........] - ETA: 8s - loss: 0.0489 - acc: 1.0000 
522/522 [==============================] - 30s 57ms/step - loss: 0.0438 - acc: 1.0000 - val_loss: 1.5427 - val_acc: 0.6954
Epoch 39/40

174/522 [=========>....................] - ETA: 17s - loss: 0.0429 - acc: 1.0000
348/522 [===================>..........] - ETA: 8s - loss: 0.0442 - acc: 1.0000 
522/522 [==============================] - 30s 57ms/step - loss: 0.0413 - acc: 1.0000 - val_loss: 1.5561 - val_acc: 0.6897
Epoch 40/40

174/522 [=========>....................] - ETA: 17s - loss: 0.0319 - acc: 1.0000
348/522 [===================>..........] - ETA: 8s - loss: 0.0368 - acc: 1.0000 
522/522 [==============================] - 30s 57ms/step - loss: 0.0369 - acc: 1.0000 - val_loss: 1.5500 - val_acc: 0.6839
Saved trained model at /n/holylfs03/LABS/berger_lab/nchou/saved_models/aardvark_aug11.h5 
[[2.31677696e-01 3.76564562e-01 3.91757816e-01]
 [3.66146386e-01 4.40742224e-01 1.93111435e-01]
 [3.43225747e-01 4.19423759e-01 2.37350389e-01]
 [1.56144381e-01 2.02472042e-02 8.23608398e-01]
 [9.86553967e-01 2.78017507e-03 1.06658284e-02]
 [9.99302626e-01 6.97415730e-04 2.55744143e-30]
 [2.89983958e-01 3.44764203e-01 3.65251839e-01]
 [9.42535475e-02 5.38446724e-01 3.67299706e-01]
 [6.99293613e-02 8.19072247e-01 1.10998444e-01]
 [2.29500070e-01 3.31691712e-01 4.38808262e-01]
 [9.96971130e-01 4.31486151e-05 2.98574357e-03]
 [8.57161105e-01 1.32404026e-02 1.29598558e-01]
 [8.64932090e-02 4.20011990e-02 8.71505558e-01]
 [3.59741016e-03 9.82149661e-01 1.42528461e-02]
 [4.86534089e-01 7.21833156e-03 5.06247580e-01]
 [9.01894569e-01 2.34312192e-03 9.57622081e-02]
 [1.22360067e-09 8.31385842e-06 9.99991655e-01]
 [1.24772429e-01 8.16006362e-01 5.92212453e-02]
 [1.00000000e+00 0.00000000e+00 2.93008011e-18]
 [3.77509773e-01 4.30107862e-01 1.92382261e-01]
 [5.95595837e-02 5.90309268e-03 9.34537351e-01]
 [2.63237525e-02 3.83192004e-04 9.73293006e-01]
 [9.81817007e-01 1.62485417e-03 1.65580772e-02]
 [9.82019961e-01 1.71945672e-02 7.85509881e-04]
 [9.81817007e-01 1.62485417e-03 1.65580772e-02]
 [5.23024142e-01 1.94419026e-01 2.82556832e-01]
 [8.86628151e-01 9.68880430e-02 1.64838117e-02]
 [4.02502906e-07 9.99223590e-01 7.76097877e-04]
 [3.08879721e-03 9.81300473e-01 1.56107461e-02]
 [1.52362585e-01 7.70781398e-01 7.68560246e-02]
 [1.00000000e+00 2.38461248e-17 1.16837040e-21]
 [9.81817007e-01 1.62485417e-03 1.65580772e-02]
 [9.99888182e-01 4.23018428e-05 6.94973569e-05]
 [4.28368300e-01 2.16395110e-01 3.55236620e-01]
 [1.14717970e-22 0.00000000e+00 1.00000000e+00]
 [9.29502010e-01 3.90972709e-04 7.01070949e-02]
 [1.39636174e-01 7.98870981e-01 6.14927560e-02]
 [9.34441745e-01 3.45709175e-02 3.09873354e-02]
 [9.97194886e-01 1.92664957e-05 2.78587826e-03]
 [1.71289906e-01 5.79217002e-02 7.70788372e-01]
 [3.25770396e-15 1.00000000e+00 1.25658427e-38]
 [9.34441745e-01 3.45709175e-02 3.09873354e-02]
 [1.33762240e-01 4.84299004e-01 3.81938756e-01]
 [1.00000000e+00 7.88825959e-24 1.67116848e-15]
 [1.00000000e+00 7.88825959e-24 1.67116848e-15]
 [5.62200904e-01 2.20673651e-01 2.17125446e-01]
 [6.77090734e-02 9.74330353e-04 9.31316614e-01]
 [1.53248310e-01 7.40275502e-01 1.06476143e-01]
 [9.97194886e-01 1.92664957e-05 2.78587826e-03]
 [2.57024378e-01 8.82602483e-02 6.54715359e-01]
 [8.86628151e-01 9.68880430e-02 1.64838117e-02]
 [2.05667913e-01 5.06817818e-01 2.87514299e-01]
 [9.93446648e-01 1.28686166e-04 6.42459281e-03]
 [2.74763316e-01 2.58533508e-01 4.66703176e-01]
 [1.96879730e-01 1.18341707e-01 6.84778512e-01]
 [9.93941963e-01 5.93359582e-03 1.24406943e-04]
 [9.68211532e-01 6.00709609e-05 3.17284204e-02]
 [9.75028798e-03 1.09019529e-05 9.90238786e-01]
 [4.13709022e-05 9.97276127e-01 2.68252240e-03]
 [6.99293613e-02 8.19072247e-01 1.10998444e-01]
 [9.81817007e-01 1.62485417e-03 1.65580772e-02]
 [9.90637124e-01 2.81529780e-03 6.54754881e-03]
 [1.57543141e-02 9.78357017e-01 5.88877965e-03]
 [1.00000000e+00 2.78898092e-16 3.24419639e-24]
 [3.00694978e-07 9.98809099e-01 1.19053887e-03]
 [1.00000000e+00 2.38461248e-17 1.16837040e-21]
 [3.25770396e-15 1.00000000e+00 1.25658427e-38]
 [6.44672770e-12 1.00000000e+00 1.90171701e-08]
 [9.99888182e-01 4.23018428e-05 6.94973569e-05]
 [3.00119191e-01 5.02641976e-01 1.97238803e-01]
 [4.44050044e-01 3.22463572e-01 2.33486399e-01]
 [5.84966829e-03 1.11686799e-03 9.93033409e-01]
 [9.34441745e-01 3.45709175e-02 3.09873354e-02]
 [2.79986411e-01 4.77835149e-01 2.42178410e-01]
 [5.19406865e-04 7.83147849e-03 9.91649151e-01]
 [1.00000000e+00 0.00000000e+00 5.79603999e-16]
 [9.99999523e-01 2.68359571e-07 2.16592170e-07]
 [6.58133010e-12 3.21669427e-11 1.00000000e+00]
 [7.24962652e-02 5.50633311e-01 3.76870453e-01]
 [9.69662443e-02 1.64659042e-02 8.86567891e-01]
 [1.70601852e-04 9.94722009e-01 5.10738790e-03]
 [3.20331991e-01 6.76656306e-01 3.01174936e-03]
 [9.68435526e-01 1.68625023e-02 1.47020491e-02]
 [1.88719213e-01 2.95087218e-01 5.16193628e-01]
 [3.76124084e-01 3.26252341e-01 2.97623634e-01]
 [9.09255818e-03 1.37134409e-02 9.77194071e-01]
 [1.62623897e-01 3.57497215e-01 4.79878932e-01]
 [1.00000000e+00 2.38461248e-17 1.16837040e-21]
 [9.86553967e-01 2.78017507e-03 1.06658284e-02]
 [1.00000000e+00 2.78898092e-16 3.24419639e-24]
 [9.99302626e-01 6.97415730e-04 2.55744143e-30]
 [4.30809289e-01 3.29150796e-01 2.40039900e-01]
 [5.84966829e-03 1.11686799e-03 9.93033409e-01]
 [9.61708428e-32 0.00000000e+00 1.00000000e+00]
 [6.53680861e-02 1.66709125e-01 7.67922759e-01]
 [7.29358345e-02 3.34938079e-01 5.92126131e-01]
 [1.93651333e-01 4.94570553e-01 3.11778098e-01]
 [1.00000000e+00 0.00000000e+00 2.93008011e-18]
 [2.88007110e-01 5.70551991e-01 1.41440913e-01]
 [1.00000000e+00 3.61623839e-12 4.83343639e-15]
 [3.83405477e-01 3.52130473e-01 2.64464110e-01]
 [1.00000000e+00 2.20250985e-28 2.40401934e-11]
 [2.61029512e-01 3.48605365e-01 3.90365064e-01]
 [1.48928300e-01 5.68684161e-01 2.82387555e-01]
 [7.03144353e-04 9.96225715e-01 3.07113514e-03]
 [1.00000000e+00 3.61623839e-12 4.83343639e-15]
 [1.70601852e-04 9.94722009e-01 5.10738790e-03]
 [9.99987483e-01 4.32324825e-08 1.24893377e-05]
 [9.99888182e-01 4.23018428e-05 6.94973569e-05]
 [1.49706432e-06 9.98663783e-01 1.33469759e-03]
 [3.62355083e-01 3.59073848e-01 2.78571069e-01]
 [1.39636174e-01 7.98870981e-01 6.14927560e-02]
 [2.63237525e-02 3.83192004e-04 9.73293006e-01]
 [4.04703200e-01 2.03292266e-01 3.92004520e-01]
 [9.81817007e-01 1.62485417e-03 1.65580772e-02]
 [6.86695423e-10 5.34656238e-06 9.99994636e-01]
 [7.15292633e-01 2.54732728e-01 2.99746450e-02]
 [2.51368880e-01 4.89000440e-01 2.59630650e-01]
 [2.18676299e-01 5.49217045e-01 2.32106626e-01]
 [6.99293613e-02 8.19072247e-01 1.10998444e-01]
 [9.29502010e-01 3.90972709e-04 7.01070949e-02]
 [7.95285644e-07 9.95152593e-01 4.84659895e-03]
 [9.99999762e-01 2.39397309e-07 3.99001188e-08]
 [9.09255818e-03 1.37134409e-02 9.77194071e-01]
 [1.00000000e+00 3.36830759e-12 3.12893406e-10]
 [1.00000000e+00 7.88825959e-24 1.67116848e-15]
 [3.76624726e-02 7.24388927e-04 9.61613119e-01]
 [9.99302626e-01 6.97415730e-04 2.55744143e-30]
 [7.59669244e-02 2.14257643e-01 7.09775448e-01]
 [3.82321398e-03 7.32918322e-01 2.63258398e-01]
 [2.54858673e-01 4.80435461e-01 2.64705837e-01]
 [1.25692889e-01 4.51548398e-03 8.69791627e-01]
 [1.00000000e+00 0.00000000e+00 1.71919927e-15]
 [3.93650085e-01 3.22382838e-01 2.83967078e-01]
 [1.00000000e+00 5.39602923e-26 7.15723952e-15]
 [1.59192547e-01 2.60597058e-02 8.14747751e-01]
 [1.62522718e-01 7.83416688e-01 5.40605672e-02]
 [1.00000000e+00 0.00000000e+00 0.00000000e+00]
 [9.17972803e-01 2.32734941e-02 5.87536134e-02]
 [7.15292633e-01 2.54732728e-01 2.99746450e-02]
 [2.80832319e-04 9.93423939e-01 6.29521953e-03]
 [5.43380380e-02 1.35710955e-01 8.09951067e-01]
 [2.00849637e-01 3.47707123e-01 4.51443285e-01]
 [5.43368515e-03 3.60501988e-04 9.94205892e-01]
 [5.46143055e-01 2.31994078e-01 2.21862808e-01]
 [1.70601852e-04 9.94722009e-01 5.10738790e-03]
 [5.73395823e-07 9.98484075e-01 1.51536113e-03]
 [4.14814562e-01 2.96259075e-01 2.88926363e-01]
 [6.64908669e-07 9.31561708e-01 6.84375986e-02]
 [6.58977747e-01 2.49855086e-01 9.11671445e-02]
 [4.78621244e-01 2.92478651e-01 2.28900045e-01]
 [2.89983958e-01 3.44764203e-01 3.65251839e-01]
 [3.11138362e-01 5.25811970e-01 1.63049638e-01]
 [9.81817007e-01 1.62485417e-03 1.65580772e-02]
 [1.00000000e+00 7.88825959e-24 1.67116848e-15]
 [1.00000000e+00 3.15958046e-17 5.75162368e-13]
 [5.84966829e-03 1.11686799e-03 9.93033409e-01]
 [1.00000000e+00 7.12385306e-09 2.98864723e-17]
 [3.20331991e-01 6.76656306e-01 3.01174936e-03]
 [1.30052626e-01 2.37840757e-01 6.32106602e-01]
 [1.19111349e-03 3.04515415e-04 9.98504400e-01]
 [1.00000000e+00 2.78898092e-16 3.24419639e-24]
 [9.34441745e-01 3.45709175e-02 3.09873354e-02]
 [7.06171542e-02 2.70315289e-01 6.59067571e-01]
 [9.74960029e-02 2.56136090e-01 6.46367908e-01]
 [1.28856540e-01 7.60250032e-01 1.10893354e-01]
 [9.88949776e-01 1.06483046e-02 4.01909172e-04]
 [1.00000000e+00 0.00000000e+00 2.93008011e-18]
 [9.79591906e-01 4.17043775e-05 2.03664191e-02]
 [1.27377600e-04 9.99849916e-01 2.26880002e-05]
 [2.85134882e-01 6.83602035e-01 3.12630646e-02]
 [7.10237101e-02 7.94803202e-01 1.34173110e-01]
 [1.34751469e-01 4.90439236e-01 3.74809355e-01]
 [3.88824850e-01 4.51081097e-01 1.60094067e-01]]
[2 1 1 2 0 0 2 1 1 2 0 0 2 1 2 0 2 1 0 1 2 2 0 0 0 0 0 1 1 1 0 0 0 0 2 0 1
 0 0 2 1 0 1 0 0 0 2 1 0 2 0 1 0 2 2 0 0 2 1 1 0 0 1 0 1 0 1 1 0 1 0 2 0 1
 2 0 0 2 1 2 1 1 0 2 0 2 2 0 0 0 0 0 2 2 2 2 1 0 1 0 0 0 2 1 1 0 1 0 0 1 0
 1 2 0 0 2 0 1 1 1 0 1 0 2 0 0 2 0 2 1 1 2 0 0 0 2 1 0 0 0 1 2 2 2 0 1 1 0
 1 0 0 2 1 0 0 0 2 0 1 2 2 0 0 2 2 1 0 0 0 1 1 1 1 1]

 32/174 [====>.........................] - ETA: 2s
 64/174 [==========>...................] - ETA: 1s
 96/174 [===============>..............] - ETA: 1s
128/174 [=====================>........] - ETA: 0s
160/174 [==========================>...] - ETA: 0s
174/174 [==============================] - 3s 18ms/step
Test loss: 2.1290821659153907
Test accuracy: 0.6666666680368883
[[46  8  4]
 [10 39  9]
 [22  5 31]]
