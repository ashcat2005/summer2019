Using TensorFlow backend.
WARNING:tensorflow:From /n/home00/nchou/.conda/envs/envi/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.
Instructions for updating:
Colocations handled automatically by placer.
WARNING:tensorflow:From /n/home00/nchou/.conda/envs/envi/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.
Instructions for updating:
Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.
cnn_aardvark_aug_concat.py:397: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor("in..., outputs=Tensor("de...)`
  model = Model(input=ins, output=dense2)
WARNING:tensorflow:From /n/home00/nchou/.conda/envs/envi/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.cast instead.
2019-11-07 09:04:05.427726: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
2019-11-07 09:04:05.431632: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2900000000 Hz
2019-11-07 09:04:05.431741: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x55f249a81f90 executing computations on platform Host. Devices:
2019-11-07 09:04:05.431760: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (0): <undefined>, <undefined>
[0.5]
Train on 348 samples, validate on 116 samples
Epoch 1/15

 58/348 [====>.........................] - ETA: 53s - loss: 0.6928 - acc: 0.4828
116/348 [=========>....................] - ETA: 31s - loss: 0.6914 - acc: 0.5431
174/348 [==============>...............] - ETA: 20s - loss: 0.6910 - acc: 0.5057
232/348 [===================>..........] - ETA: 12s - loss: 0.6921 - acc: 0.5259
290/348 [========================>.....] - ETA: 6s - loss: 0.6906 - acc: 0.5414 
348/348 [==============================] - 37s 107ms/step - loss: 0.6950 - acc: 0.5316 - val_loss: 0.6697 - val_acc: 0.5086
Epoch 2/15

 58/348 [====>.........................] - ETA: 23s - loss: 0.6470 - acc: 0.6207
116/348 [=========>....................] - ETA: 19s - loss: 0.6268 - acc: 0.6724
174/348 [==============>...............] - ETA: 14s - loss: 0.6146 - acc: 0.7126
232/348 [===================>..........] - ETA: 9s - loss: 0.6180 - acc: 0.6983 
290/348 [========================>.....] - ETA: 4s - loss: 0.6040 - acc: 0.7000
348/348 [==============================] - 30s 88ms/step - loss: 0.6014 - acc: 0.6868 - val_loss: 0.6592 - val_acc: 0.5776
Epoch 3/15

 58/348 [====>.........................] - ETA: 23s - loss: 0.5359 - acc: 0.8103
116/348 [=========>....................] - ETA: 18s - loss: 0.5321 - acc: 0.7328
174/348 [==============>...............] - ETA: 14s - loss: 0.5308 - acc: 0.7184
232/348 [===================>..........] - ETA: 9s - loss: 0.5227 - acc: 0.7198 
290/348 [========================>.....] - ETA: 4s - loss: 0.5169 - acc: 0.7310
348/348 [==============================] - 30s 87ms/step - loss: 0.5129 - acc: 0.7299 - val_loss: 0.7002 - val_acc: 0.5690
Epoch 4/15

 58/348 [====>.........................] - ETA: 23s - loss: 0.4873 - acc: 0.6897
116/348 [=========>....................] - ETA: 18s - loss: 0.4422 - acc: 0.7845
174/348 [==============>...............] - ETA: 14s - loss: 0.4368 - acc: 0.7989
232/348 [===================>..........] - ETA: 9s - loss: 0.4274 - acc: 0.8060 
290/348 [========================>.....] - ETA: 4s - loss: 0.4321 - acc: 0.8000
348/348 [==============================] - 30s 87ms/step - loss: 0.4313 - acc: 0.8103 - val_loss: 0.8168 - val_acc: 0.5517
Epoch 5/15

 58/348 [====>.........................] - ETA: 23s - loss: 0.4906 - acc: 0.6552
116/348 [=========>....................] - ETA: 18s - loss: 0.4334 - acc: 0.7241
174/348 [==============>...............] - ETA: 14s - loss: 0.4021 - acc: 0.7701
232/348 [===================>..........] - ETA: 9s - loss: 0.3847 - acc: 0.8147 
290/348 [========================>.....] - ETA: 4s - loss: 0.3748 - acc: 0.8345
348/348 [==============================] - 30s 87ms/step - loss: 0.3693 - acc: 0.8391 - val_loss: 0.8324 - val_acc: 0.6466
Epoch 6/15

 58/348 [====>.........................] - ETA: 23s - loss: 0.3674 - acc: 0.8103
116/348 [=========>....................] - ETA: 18s - loss: 0.3404 - acc: 0.8534
174/348 [==============>...............] - ETA: 13s - loss: 0.3304 - acc: 0.8621
232/348 [===================>..........] - ETA: 9s - loss: 0.3238 - acc: 0.8578 
290/348 [========================>.....] - ETA: 4s - loss: 0.3175 - acc: 0.8586
348/348 [==============================] - 30s 87ms/step - loss: 0.3124 - acc: 0.8592 - val_loss: 1.0130 - val_acc: 0.6466
Epoch 7/15

 58/348 [====>.........................] - ETA: 23s - loss: 0.2553 - acc: 0.9138
116/348 [=========>....................] - ETA: 18s - loss: 0.3083 - acc: 0.8362
174/348 [==============>...............] - ETA: 14s - loss: 0.2856 - acc: 0.8793
232/348 [===================>..........] - ETA: 9s - loss: 0.2854 - acc: 0.8879 
290/348 [========================>.....] - ETA: 4s - loss: 0.2772 - acc: 0.9000
348/348 [==============================] - 30s 88ms/step - loss: 0.2877 - acc: 0.8966 - val_loss: 1.1402 - val_acc: 0.6552
Epoch 8/15

 58/348 [====>.........................] - ETA: 23s - loss: 0.2636 - acc: 0.8966
116/348 [=========>....................] - ETA: 18s - loss: 0.2497 - acc: 0.9052
174/348 [==============>...............] - ETA: 14s - loss: 0.2478 - acc: 0.9080
232/348 [===================>..........] - ETA: 9s - loss: 0.2419 - acc: 0.9095 
290/348 [========================>.....] - ETA: 4s - loss: 0.2448 - acc: 0.9103
348/348 [==============================] - 30s 88ms/step - loss: 0.2330 - acc: 0.9224 - val_loss: 1.2228 - val_acc: 0.6207
Epoch 9/15

 58/348 [====>.........................] - ETA: 23s - loss: 0.1982 - acc: 0.9655
116/348 [=========>....................] - ETA: 18s - loss: 0.1927 - acc: 0.9483
174/348 [==============>...............] - ETA: 14s - loss: 0.1870 - acc: 0.9368
232/348 [===================>..........] - ETA: 9s - loss: 0.2000 - acc: 0.9310 
290/348 [========================>.....] - ETA: 4s - loss: 0.2025 - acc: 0.9379
348/348 [==============================] - 30s 87ms/step - loss: 0.1991 - acc: 0.9397 - val_loss: 1.3027 - val_acc: 0.6638
Epoch 10/15

 58/348 [====>.........................] - ETA: 23s - loss: 0.1859 - acc: 0.9655
116/348 [=========>....................] - ETA: 18s - loss: 0.1805 - acc: 0.9828
174/348 [==============>...............] - ETA: 14s - loss: 0.1757 - acc: 0.9770
232/348 [===================>..........] - ETA: 9s - loss: 0.1643 - acc: 0.9741 
290/348 [========================>.....] - ETA: 4s - loss: 0.1654 - acc: 0.9690
348/348 [==============================] - 30s 87ms/step - loss: 0.1676 - acc: 0.9598 - val_loss: 1.3312 - val_acc: 0.7155
Epoch 11/15

 58/348 [====>.........................] - ETA: 23s - loss: 0.1450 - acc: 0.9828
116/348 [=========>....................] - ETA: 18s - loss: 0.1634 - acc: 0.9655
174/348 [==============>...............] - ETA: 14s - loss: 0.1533 - acc: 0.9770
232/348 [===================>..........] - ETA: 9s - loss: 0.1486 - acc: 0.9698 
290/348 [========================>.....] - ETA: 4s - loss: 0.1409 - acc: 0.9724
348/348 [==============================] - 30s 87ms/step - loss: 0.1426 - acc: 0.9684 - val_loss: 1.3181 - val_acc: 0.7328
Epoch 12/15

 58/348 [====>.........................] - ETA: 23s - loss: 0.1105 - acc: 1.0000
116/348 [=========>....................] - ETA: 18s - loss: 0.1181 - acc: 0.9914
174/348 [==============>...............] - ETA: 14s - loss: 0.1098 - acc: 0.9943
232/348 [===================>..........] - ETA: 9s - loss: 0.1154 - acc: 0.9914 
290/348 [========================>.....] - ETA: 4s - loss: 0.1116 - acc: 0.9931
348/348 [==============================] - 30s 87ms/step - loss: 0.1147 - acc: 0.9828 - val_loss: 1.3166 - val_acc: 0.7500
Epoch 13/15

 58/348 [====>.........................] - ETA: 23s - loss: 0.0685 - acc: 1.0000
116/348 [=========>....................] - ETA: 18s - loss: 0.0971 - acc: 0.9914
174/348 [==============>...............] - ETA: 14s - loss: 0.1016 - acc: 0.9828
232/348 [===================>..........] - ETA: 9s - loss: 0.0986 - acc: 0.9871 
290/348 [========================>.....] - ETA: 4s - loss: 0.0953 - acc: 0.9862
348/348 [==============================] - 30s 87ms/step - loss: 0.0947 - acc: 0.9856 - val_loss: 1.3512 - val_acc: 0.7155
Epoch 14/15

 58/348 [====>.........................] - ETA: 23s - loss: 0.0691 - acc: 1.0000
116/348 [=========>....................] - ETA: 18s - loss: 0.0714 - acc: 1.0000
174/348 [==============>...............] - ETA: 13s - loss: 0.0709 - acc: 1.0000
232/348 [===================>..........] - ETA: 9s - loss: 0.0877 - acc: 0.9871 
290/348 [========================>.....] - ETA: 4s - loss: 0.0855 - acc: 0.9897
348/348 [==============================] - 30s 87ms/step - loss: 0.0826 - acc: 0.9914 - val_loss: 1.4367 - val_acc: 0.6638
Epoch 15/15

 58/348 [====>.........................] - ETA: 23s - loss: 0.0540 - acc: 1.0000
116/348 [=========>....................] - ETA: 18s - loss: 0.0762 - acc: 0.9741
174/348 [==============>...............] - ETA: 14s - loss: 0.0748 - acc: 0.9828
232/348 [===================>..........] - ETA: 9s - loss: 0.0730 - acc: 0.9871 
290/348 [========================>.....] - ETA: 4s - loss: 0.0688 - acc: 0.9897
348/348 [==============================] - 30s 87ms/step - loss: 0.0719 - acc: 0.9914 - val_loss: 1.3505 - val_acc: 0.8017
Saved trained model at /n/holylfs03/LABS/berger_lab/nchou/saved_models/aardvark_aug11.h5 
[[9.82747316e-01 1.72526781e-02]
 [2.36892074e-01 7.63107896e-01]
 [9.99999881e-01 1.62194738e-07]
 [9.76588964e-01 2.34111026e-02]
 [9.77040410e-01 2.29595676e-02]
 [3.11523825e-01 6.88476145e-01]
 [3.92434376e-05 9.99960780e-01]
 [1.00000000e+00 3.90960875e-12]
 [9.97641087e-01 2.35890411e-03]
 [1.00000000e+00 1.87919564e-08]
 [9.99059856e-01 9.40135098e-04]
 [8.33155692e-01 1.66844264e-01]
 [2.26311207e-01 7.73688793e-01]
 [3.39301497e-01 6.60698473e-01]
 [3.26671153e-01 6.73328817e-01]
 [9.99873638e-01 1.26308136e-04]
 [1.87562313e-02 9.81243789e-01]
 [3.11200649e-01 6.88799381e-01]
 [9.94227648e-01 5.77238761e-03]
 [1.12886795e-04 9.99887109e-01]
 [3.92434376e-05 9.99960780e-01]
 [1.87562313e-02 9.81243789e-01]
 [2.27237160e-06 9.99997735e-01]
 [9.77040410e-01 2.29595676e-02]
 [3.39301497e-01 6.60698473e-01]
 [4.75172520e-01 5.24827480e-01]
 [2.20518023e-01 7.79481947e-01]
 [9.98693287e-01 1.30667526e-03]
 [4.95725989e-01 5.04274011e-01]
 [3.26671153e-01 6.73328817e-01]
 [8.81506205e-01 1.18493751e-01]
 [2.49608502e-01 7.50391424e-01]
 [8.19323808e-02 9.18067634e-01]
 [3.09860140e-01 6.90139949e-01]
 [1.00000000e+00 8.21757105e-13]
 [5.15847714e-05 9.99948382e-01]
 [1.00000000e+00 1.85850514e-14]
 [8.33155692e-01 1.66844264e-01]
 [1.54418185e-01 8.45581830e-01]
 [8.81506205e-01 1.18493751e-01]
 [8.62429082e-01 1.37570873e-01]
 [2.17294618e-02 9.78270531e-01]
 [5.17896304e-09 1.00000000e+00]
 [9.99999881e-01 1.62194738e-07]
 [1.45823702e-01 8.54176342e-01]
 [9.98505473e-01 1.49457192e-03]
 [9.70902801e-01 2.90972516e-02]
 [6.59067035e-01 3.40932935e-01]
 [7.86280818e-03 9.92137134e-01]
 [1.00000000e+00 1.85850514e-14]
 [2.45281753e-05 9.99975443e-01]
 [1.00000000e+00 1.85850514e-14]
 [9.99873638e-01 1.26308136e-04]
 [9.97352004e-01 2.64804787e-03]
 [2.30525181e-01 7.69474804e-01]
 [9.61338937e-01 3.86610068e-02]
 [6.51575103e-02 9.34842467e-01]
 [8.81506205e-01 1.18493751e-01]
 [2.32295945e-01 7.67704070e-01]
 [9.77040410e-01 2.29595676e-02]
 [1.00000000e+00 3.90960875e-12]
 [4.75172520e-01 5.24827480e-01]
 [8.81506205e-01 1.18493751e-01]
 [7.15052903e-01 2.84947097e-01]
 [3.92434376e-05 9.99960780e-01]
 [4.15333360e-03 9.95846689e-01]
 [7.15052903e-01 2.84947097e-01]
 [7.86280818e-03 9.92137134e-01]
 [4.56989765e-01 5.43010235e-01]
 [5.01013994e-01 4.98985916e-01]
 [2.16771618e-11 1.00000000e+00]
 [2.18959481e-01 7.81040549e-01]
 [7.86280818e-03 9.92137134e-01]
 [9.31946793e-22 1.00000000e+00]
 [2.17294618e-02 9.78270531e-01]
 [3.33217502e-01 6.66782498e-01]
 [2.07117602e-01 7.92882442e-01]
 [1.00000000e+00 3.90960875e-12]
 [8.33155692e-01 1.66844264e-01]
 [8.33155692e-01 1.66844264e-01]
 [9.99873638e-01 1.26308136e-04]
 [7.92042255e-01 2.07957774e-01]
 [4.73464847e-01 5.26535213e-01]
 [6.59067035e-01 3.40932935e-01]
 [5.71260937e-02 9.42873955e-01]
 [1.00000000e+00 1.87919564e-08]
 [1.00000000e+00 8.74216394e-11]
 [2.49608502e-01 7.50391424e-01]
 [1.00000000e+00 5.00484020e-14]
 [1.84723452e-01 8.15276563e-01]
 [8.19323808e-02 9.18067634e-01]
 [1.66839570e-01 8.33160460e-01]
 [9.99999762e-01 2.97972008e-07]
 [1.00000000e+00 3.86953136e-09]
 [9.99527454e-01 4.72581363e-04]
 [9.76588964e-01 2.34111026e-02]
 [1.00000000e+00 3.90960875e-12]
 [2.58704871e-01 7.41295099e-01]
 [8.19323808e-02 9.18067634e-01]
 [3.76204491e-01 6.23795569e-01]
 [9.05832350e-01 9.41676348e-02]
 [5.17896304e-09 1.00000000e+00]
 [9.99999881e-01 1.62194738e-07]
 [5.15292883e-01 4.84707147e-01]
 [2.57152110e-01 7.42847860e-01]
 [1.00000000e+00 1.87919564e-08]
 [7.63604476e-04 9.99236465e-01]
 [4.26489621e-01 5.73510408e-01]
 [1.00000000e+00 8.12626273e-21]
 [2.30525181e-01 7.69474804e-01]
 [8.81506205e-01 1.18493751e-01]
 [8.90581608e-01 1.09418377e-01]
 [8.81506205e-01 1.18493751e-01]
 [1.00000000e+00 8.12626273e-21]
 [5.94262600e-01 4.05737400e-01]
 [2.21126869e-01 7.78873086e-01]]
[0 1 0 0 0 1 1 0 0 0 0 0 1 1 1 0 1 1 0 1 1 1 1 0 1 1 1 0 1 1 0 1 1 1 0 1 0
 0 1 0 0 1 1 0 1 0 0 0 1 0 1 0 0 0 1 0 1 0 1 0 0 1 0 0 1 1 0 1 1 0 1 1 1 1
 1 1 1 0 0 0 0 0 1 0 1 0 0 1 0 1 1 1 0 0 0 0 0 1 1 1 0 1 0 0 1 0 1 1 0 1 0
 0 0 0 0 1]

 32/116 [=======>......................] - ETA: 1s
 64/116 [===============>..............] - ETA: 0s
 96/116 [=======================>......] - ETA: 0s
116/116 [==============================] - 2s 19ms/step
Test loss: 2.281471507302646
Test accuracy: 0.7327586227449877
[[43 15]
 [16 42]]
