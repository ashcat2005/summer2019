Using TensorFlow backend.
WARNING:tensorflow:From /n/home00/nchou/.conda/envs/envi/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.
Instructions for updating:
Colocations handled automatically by placer.
WARNING:tensorflow:From /n/home00/nchou/.conda/envs/envi/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.
Instructions for updating:
Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.
cnn_aardvark_aug_concat.py:397: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor("in..., outputs=Tensor("de...)`
  model = Model(input=ins, output=dense2)
WARNING:tensorflow:From /n/home00/nchou/.conda/envs/envi/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.cast instead.
2019-11-07 09:05:02.477385: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
2019-11-07 09:05:02.543691: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2900000000 Hz
2019-11-07 09:05:02.543906: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x558945811cf0 executing computations on platform Host. Devices:
2019-11-07 09:05:02.543956: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (0): <undefined>, <undefined>
[0.25]
Train on 348 samples, validate on 116 samples
Epoch 1/15

 58/348 [====>.........................] - ETA: 29s - loss: 0.6955 - acc: 0.4483
116/348 [=========>....................] - ETA: 19s - loss: 0.6939 - acc: 0.5172
174/348 [==============>...............] - ETA: 13s - loss: 0.6975 - acc: 0.4713
232/348 [===================>..........] - ETA: 8s - loss: 0.7093 - acc: 0.4310 
290/348 [========================>.....] - ETA: 4s - loss: 0.7034 - acc: 0.4517
348/348 [==============================] - 26s 76ms/step - loss: 0.7022 - acc: 0.4598 - val_loss: 0.6763 - val_acc: 0.5172
Epoch 2/15

 58/348 [====>.........................] - ETA: 17s - loss: 0.6691 - acc: 0.5172
116/348 [=========>....................] - ETA: 14s - loss: 0.6582 - acc: 0.5603
174/348 [==============>...............] - ETA: 10s - loss: 0.6588 - acc: 0.5747
232/348 [===================>..........] - ETA: 7s - loss: 0.6486 - acc: 0.5948 
290/348 [========================>.....] - ETA: 3s - loss: 0.6533 - acc: 0.5828
348/348 [==============================] - 24s 68ms/step - loss: 0.6527 - acc: 0.5776 - val_loss: 0.7217 - val_acc: 0.5862
Epoch 3/15

 58/348 [====>.........................] - ETA: 18s - loss: 0.6330 - acc: 0.6379
116/348 [=========>....................] - ETA: 14s - loss: 0.6596 - acc: 0.5948
174/348 [==============>...............] - ETA: 10s - loss: 0.6323 - acc: 0.6034
232/348 [===================>..........] - ETA: 7s - loss: 0.6620 - acc: 0.5819 
290/348 [========================>.....] - ETA: 3s - loss: 0.6509 - acc: 0.5897
348/348 [==============================] - 24s 68ms/step - loss: 0.6436 - acc: 0.5891 - val_loss: 0.7117 - val_acc: 0.5948
Epoch 4/15

 58/348 [====>.........................] - ETA: 17s - loss: 0.6752 - acc: 0.5517
116/348 [=========>....................] - ETA: 14s - loss: 0.5935 - acc: 0.6466
174/348 [==============>...............] - ETA: 10s - loss: 0.5972 - acc: 0.6207
232/348 [===================>..........] - ETA: 7s - loss: 0.6075 - acc: 0.5991 
290/348 [========================>.....] - ETA: 3s - loss: 0.5965 - acc: 0.6172
348/348 [==============================] - 24s 68ms/step - loss: 0.5922 - acc: 0.6236 - val_loss: 0.7123 - val_acc: 0.6034
Epoch 5/15

 58/348 [====>.........................] - ETA: 17s - loss: 0.5585 - acc: 0.6552
116/348 [=========>....................] - ETA: 14s - loss: 0.5291 - acc: 0.7069
174/348 [==============>...............] - ETA: 10s - loss: 0.5267 - acc: 0.6897
232/348 [===================>..........] - ETA: 7s - loss: 0.5084 - acc: 0.7112 
290/348 [========================>.....] - ETA: 3s - loss: 0.5144 - acc: 0.7103
348/348 [==============================] - 24s 68ms/step - loss: 0.5124 - acc: 0.7126 - val_loss: 0.7509 - val_acc: 0.5948
Epoch 6/15

 58/348 [====>.........................] - ETA: 17s - loss: 0.4466 - acc: 0.8276
116/348 [=========>....................] - ETA: 14s - loss: 0.4777 - acc: 0.7414
174/348 [==============>...............] - ETA: 10s - loss: 0.4687 - acc: 0.7586
232/348 [===================>..........] - ETA: 7s - loss: 0.4851 - acc: 0.7414 
290/348 [========================>.....] - ETA: 3s - loss: 0.4811 - acc: 0.7379
348/348 [==============================] - 24s 68ms/step - loss: 0.4746 - acc: 0.7500 - val_loss: 0.8154 - val_acc: 0.5948
Epoch 7/15

 58/348 [====>.........................] - ETA: 17s - loss: 0.4823 - acc: 0.7414
116/348 [=========>....................] - ETA: 14s - loss: 0.4386 - acc: 0.7931
174/348 [==============>...............] - ETA: 10s - loss: 0.4124 - acc: 0.8103
232/348 [===================>..........] - ETA: 7s - loss: 0.4141 - acc: 0.8103 
290/348 [========================>.....] - ETA: 3s - loss: 0.4300 - acc: 0.7897
348/348 [==============================] - 24s 68ms/step - loss: 0.4307 - acc: 0.7816 - val_loss: 0.9167 - val_acc: 0.5690
Epoch 8/15

 58/348 [====>.........................] - ETA: 17s - loss: 0.4535 - acc: 0.7414
116/348 [=========>....................] - ETA: 14s - loss: 0.4288 - acc: 0.7586
174/348 [==============>...............] - ETA: 10s - loss: 0.4326 - acc: 0.7586
232/348 [===================>..........] - ETA: 7s - loss: 0.4223 - acc: 0.7716 
290/348 [========================>.....] - ETA: 3s - loss: 0.4201 - acc: 0.7655
348/348 [==============================] - 24s 68ms/step - loss: 0.3951 - acc: 0.7874 - val_loss: 1.0335 - val_acc: 0.6034
Epoch 9/15

 58/348 [====>.........................] - ETA: 18s - loss: 0.3991 - acc: 0.7931
116/348 [=========>....................] - ETA: 14s - loss: 0.3900 - acc: 0.7845
174/348 [==============>...............] - ETA: 10s - loss: 0.3929 - acc: 0.7701
232/348 [===================>..........] - ETA: 7s - loss: 0.3726 - acc: 0.7802 
290/348 [========================>.....] - ETA: 3s - loss: 0.3641 - acc: 0.7828
348/348 [==============================] - 24s 68ms/step - loss: 0.3654 - acc: 0.7874 - val_loss: 1.1596 - val_acc: 0.6293
Epoch 10/15

 58/348 [====>.........................] - ETA: 17s - loss: 0.4879 - acc: 0.7069
116/348 [=========>....................] - ETA: 14s - loss: 0.3866 - acc: 0.8017
174/348 [==============>...............] - ETA: 10s - loss: 0.3618 - acc: 0.8161
232/348 [===================>..........] - ETA: 7s - loss: 0.3335 - acc: 0.8319 
290/348 [========================>.....] - ETA: 3s - loss: 0.3353 - acc: 0.8241
348/348 [==============================] - 24s 68ms/step - loss: 0.3332 - acc: 0.8276 - val_loss: 1.3455 - val_acc: 0.6207
Epoch 11/15

 58/348 [====>.........................] - ETA: 18s - loss: 0.4539 - acc: 0.7931
116/348 [=========>....................] - ETA: 14s - loss: 0.3866 - acc: 0.8190
174/348 [==============>...............] - ETA: 10s - loss: 0.3614 - acc: 0.8103
232/348 [===================>..........] - ETA: 7s - loss: 0.3352 - acc: 0.8319 
290/348 [========================>.....] - ETA: 3s - loss: 0.3430 - acc: 0.8138
348/348 [==============================] - 24s 68ms/step - loss: 0.3339 - acc: 0.8161 - val_loss: 1.2793 - val_acc: 0.6379
Epoch 12/15

 58/348 [====>.........................] - ETA: 17s - loss: 0.2357 - acc: 0.9483
116/348 [=========>....................] - ETA: 14s - loss: 0.2763 - acc: 0.8966
174/348 [==============>...............] - ETA: 10s - loss: 0.3237 - acc: 0.8563
232/348 [===================>..........] - ETA: 7s - loss: 0.3055 - acc: 0.8707 
290/348 [========================>.....] - ETA: 3s - loss: 0.2795 - acc: 0.8793
348/348 [==============================] - 23s 67ms/step - loss: 0.2886 - acc: 0.8736 - val_loss: 1.3391 - val_acc: 0.6034
Epoch 13/15

 58/348 [====>.........................] - ETA: 17s - loss: 0.2445 - acc: 0.8966
116/348 [=========>....................] - ETA: 14s - loss: 0.2285 - acc: 0.8966
174/348 [==============>...............] - ETA: 10s - loss: 0.2435 - acc: 0.8793
232/348 [===================>..........] - ETA: 7s - loss: 0.2439 - acc: 0.8750 
290/348 [========================>.....] - ETA: 3s - loss: 0.2484 - acc: 0.8759
348/348 [==============================] - 23s 67ms/step - loss: 0.2580 - acc: 0.8793 - val_loss: 1.3218 - val_acc: 0.6466
Epoch 14/15

 58/348 [====>.........................] - ETA: 17s - loss: 0.2354 - acc: 0.8966
116/348 [=========>....................] - ETA: 14s - loss: 0.2370 - acc: 0.9052
174/348 [==============>...............] - ETA: 10s - loss: 0.2454 - acc: 0.8966
232/348 [===================>..........] - ETA: 7s - loss: 0.2398 - acc: 0.8966 
290/348 [========================>.....] - ETA: 3s - loss: 0.2279 - acc: 0.9069
348/348 [==============================] - 23s 67ms/step - loss: 0.2296 - acc: 0.9109 - val_loss: 1.4030 - val_acc: 0.6293
Epoch 15/15

 58/348 [====>.........................] - ETA: 17s - loss: 0.2024 - acc: 0.8966
116/348 [=========>....................] - ETA: 14s - loss: 0.1691 - acc: 0.9138
174/348 [==============>...............] - ETA: 10s - loss: 0.2007 - acc: 0.8966
232/348 [===================>..........] - ETA: 7s - loss: 0.1993 - acc: 0.9009 
290/348 [========================>.....] - ETA: 3s - loss: 0.2019 - acc: 0.9069
348/348 [==============================] - 23s 67ms/step - loss: 0.2019 - acc: 0.9080 - val_loss: 1.3375 - val_acc: 0.6810
Saved trained model at /n/holylfs03/LABS/berger_lab/nchou/saved_models/aardvark_aug11.h5 
[[8.60133529e-01 1.39866427e-01]
 [3.86272818e-01 6.13727152e-01]
 [1.00000000e+00 4.93961261e-10]
 [8.97393763e-01 1.02606215e-01]
 [8.99741650e-01 1.00258343e-01]
 [3.84064645e-01 6.15935385e-01]
 [6.82042355e-06 9.99993205e-01]
 [1.00000000e+00 2.09583657e-21]
 [9.90388691e-01 9.61128529e-03]
 [1.00000000e+00 6.96592645e-11]
 [9.98411059e-01 1.58887007e-03]
 [4.81805682e-01 5.18194318e-01]
 [2.67651021e-01 7.32348979e-01]
 [4.13373083e-01 5.86626947e-01]
 [4.20827717e-02 9.57917273e-01]
 [9.99549448e-01 4.50528518e-04]
 [3.00082237e-01 6.99917734e-01]
 [4.60876822e-01 5.39123178e-01]
 [9.99837637e-01 1.62369368e-04]
 [1.58499068e-04 9.99841452e-01]
 [6.82042355e-06 9.99993205e-01]
 [3.00082237e-01 6.99917734e-01]
 [2.15406453e-05 9.99978423e-01]
 [8.99741650e-01 1.00258343e-01]
 [4.13373083e-01 5.86626947e-01]
 [4.68733817e-01 5.31266272e-01]
 [2.76954442e-01 7.23045528e-01]
 [9.99983430e-01 1.65674701e-05]
 [6.42965555e-01 3.57034475e-01]
 [4.20827717e-02 9.57917273e-01]
 [2.79439569e-01 7.20560431e-01]
 [3.72630417e-01 6.27369583e-01]
 [2.44203836e-01 7.55796254e-01]
 [4.45727050e-01 5.54272890e-01]
 [1.00000000e+00 4.16617949e-20]
 [7.38034898e-04 9.99261916e-01]
 [9.99787867e-01 2.12197920e-04]
 [4.81805682e-01 5.18194318e-01]
 [4.14992183e-01 5.85007787e-01]
 [2.79439569e-01 7.20560431e-01]
 [4.96818900e-01 5.03181100e-01]
 [9.56854150e-02 9.04314518e-01]
 [1.46700859e-05 9.99985337e-01]
 [1.00000000e+00 4.93961261e-10]
 [1.90571368e-01 8.09428692e-01]
 [1.72273397e-01 8.27726543e-01]
 [9.54981923e-01 4.50180732e-02]
 [6.08588338e-01 3.91411602e-01]
 [1.13388486e-01 8.86611581e-01]
 [9.99787867e-01 2.12197920e-04]
 [1.05435996e-04 9.99894500e-01]
 [9.99787867e-01 2.12197920e-04]
 [9.99549448e-01 4.50528518e-04]
 [9.95450437e-01 4.54954803e-03]
 [5.17811656e-01 4.82188314e-01]
 [9.99982476e-01 1.75822934e-05]
 [5.71096838e-01 4.28903133e-01]
 [2.79439569e-01 7.20560431e-01]
 [3.81823957e-01 6.18176043e-01]
 [8.99741650e-01 1.00258343e-01]
 [1.00000000e+00 2.09583657e-21]
 [4.68733817e-01 5.31266272e-01]
 [2.79439569e-01 7.20560431e-01]
 [6.62845075e-01 3.37154895e-01]
 [6.82042355e-06 9.99993205e-01]
 [2.47277655e-02 9.75272238e-01]
 [6.62845075e-01 3.37154895e-01]
 [1.13388486e-01 8.86611581e-01]
 [9.29662511e-02 9.07033741e-01]
 [3.58129561e-01 6.41870439e-01]
 [3.38678530e-11 1.00000000e+00]
 [3.38477284e-01 6.61522686e-01]
 [1.13388486e-01 8.86611581e-01]
 [6.72780906e-16 1.00000000e+00]
 [9.56854150e-02 9.04314518e-01]
 [5.07603705e-01 4.92396325e-01]
 [7.85770535e-01 2.14229524e-01]
 [1.00000000e+00 2.09583657e-21]
 [4.81805682e-01 5.18194318e-01]
 [4.81805682e-01 5.18194318e-01]
 [9.99549448e-01 4.50528518e-04]
 [8.64762127e-01 1.35237813e-01]
 [4.56176341e-01 5.43823659e-01]
 [6.08588338e-01 3.91411602e-01]
 [6.87891394e-02 9.31210816e-01]
 [1.00000000e+00 6.96592645e-11]
 [1.00000000e+00 2.19636093e-12]
 [3.72630417e-01 6.27369583e-01]
 [1.00000000e+00 1.14206753e-13]
 [2.21696839e-01 7.78303146e-01]
 [2.44203836e-01 7.55796254e-01]
 [3.69117469e-01 6.30882561e-01]
 [1.00000000e+00 2.36214763e-08]
 [1.00000000e+00 1.08355242e-17]
 [9.98317838e-01 1.68221619e-03]
 [8.97393763e-01 1.02606215e-01]
 [1.00000000e+00 2.09583657e-21]
 [3.11203718e-01 6.88796282e-01]
 [2.44203836e-01 7.55796254e-01]
 [4.75781262e-01 5.24218798e-01]
 [9.57435787e-01 4.25642654e-02]
 [1.46700859e-05 9.99985337e-01]
 [1.00000000e+00 4.93961261e-10]
 [6.39352977e-01 3.60646993e-01]
 [3.66879523e-01 6.33120477e-01]
 [1.00000000e+00 6.96592645e-11]
 [4.66485275e-03 9.95335162e-01]
 [5.34863412e-01 4.65136647e-01]
 [1.00000000e+00 1.00707296e-18]
 [5.17811656e-01 4.82188314e-01]
 [2.79439569e-01 7.20560431e-01]
 [8.57893765e-01 1.42106220e-01]
 [2.79439569e-01 7.20560431e-01]
 [1.00000000e+00 1.00707296e-18]
 [7.99394101e-02 9.20060575e-01]
 [3.97741973e-01 6.02257967e-01]]
[0 1 0 0 0 1 1 0 0 0 0 1 1 1 1 0 1 1 0 1 1 1 1 0 1 1 1 0 0 1 1 1 1 1 0 1 0
 1 1 1 1 1 1 0 1 1 0 0 1 0 1 0 0 0 0 0 0 1 1 0 0 1 1 0 1 1 0 1 1 1 1 1 1 1
 1 0 0 0 1 1 0 0 1 0 1 0 0 1 0 1 1 1 0 0 0 0 0 1 1 1 0 1 0 0 1 0 1 0 0 0 1
 0 1 0 1 1]

 32/116 [=======>......................] - ETA: 1s
 64/116 [===============>..............] - ETA: 0s
 96/116 [=======================>......] - ETA: 0s
116/116 [==============================] - 2s 18ms/step
Test loss: 2.2345780257521004
Test accuracy: 0.6379310303720934
[[34 24]
 [18 40]]
