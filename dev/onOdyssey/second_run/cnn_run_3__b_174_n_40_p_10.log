Using TensorFlow backend.
WARNING:tensorflow:From /n/home00/nchou/.conda/envs/envi/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.
Instructions for updating:
Colocations handled automatically by placer.
cnn_aardvark_aug_concat.py:397: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor("in..., outputs=Tensor("de...)`
  model = Model(input=ins, output=dense2)
WARNING:tensorflow:From /n/home00/nchou/.conda/envs/envi/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.cast instead.
2019-11-07 11:44:56.865845: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
2019-11-07 11:44:56.901077: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2900000000 Hz
2019-11-07 11:44:56.901334: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x5569aeea9e70 executing computations on platform Host. Devices:
2019-11-07 11:44:56.901380: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (0): <undefined>, <undefined>
None
Train on 522 samples, validate on 174 samples
Epoch 1/40

174/522 [=========>....................] - ETA: 14s - loss: 1.1001 - acc: 0.3218
348/522 [===================>..........] - ETA: 6s - loss: 1.1002 - acc: 0.3477 
522/522 [==============================] - 20s 37ms/step - loss: 1.0988 - acc: 0.3621 - val_loss: 1.0912 - val_acc: 0.4655
Epoch 2/40

174/522 [=========>....................] - ETA: 10s - loss: 1.0819 - acc: 0.5057
348/522 [===================>..........] - ETA: 5s - loss: 1.0867 - acc: 0.5029 
522/522 [==============================] - 17s 33ms/step - loss: 1.0828 - acc: 0.5077 - val_loss: 1.0809 - val_acc: 0.4138
Epoch 3/40

174/522 [=========>....................] - ETA: 10s - loss: 1.0748 - acc: 0.5632
348/522 [===================>..........] - ETA: 5s - loss: 1.0696 - acc: 0.5805 
522/522 [==============================] - 17s 33ms/step - loss: 1.0666 - acc: 0.5498 - val_loss: 1.0728 - val_acc: 0.3908
Epoch 4/40

174/522 [=========>....................] - ETA: 10s - loss: 1.0658 - acc: 0.5402
348/522 [===================>..........] - ETA: 5s - loss: 1.0519 - acc: 0.5776 
522/522 [==============================] - 17s 33ms/step - loss: 1.0520 - acc: 0.5575 - val_loss: 1.0671 - val_acc: 0.4828
Epoch 5/40

174/522 [=========>....................] - ETA: 10s - loss: 1.0415 - acc: 0.5460
348/522 [===================>..........] - ETA: 5s - loss: 1.0420 - acc: 0.5345 
522/522 [==============================] - 17s 33ms/step - loss: 1.0368 - acc: 0.5326 - val_loss: 1.0628 - val_acc: 0.4713
Epoch 6/40

174/522 [=========>....................] - ETA: 10s - loss: 1.0186 - acc: 0.5172
348/522 [===================>..........] - ETA: 5s - loss: 1.0258 - acc: 0.5115 
522/522 [==============================] - 17s 33ms/step - loss: 1.0220 - acc: 0.5287 - val_loss: 1.0610 - val_acc: 0.4770
Epoch 7/40

174/522 [=========>....................] - ETA: 10s - loss: 1.0169 - acc: 0.5057
348/522 [===================>..........] - ETA: 5s - loss: 1.0161 - acc: 0.5201 
522/522 [==============================] - 17s 33ms/step - loss: 1.0062 - acc: 0.5134 - val_loss: 1.0619 - val_acc: 0.4483
Epoch 8/40

174/522 [=========>....................] - ETA: 10s - loss: 1.0002 - acc: 0.5575
348/522 [===================>..........] - ETA: 5s - loss: 0.9842 - acc: 0.5575 
522/522 [==============================] - 17s 33ms/step - loss: 0.9919 - acc: 0.5307 - val_loss: 1.0664 - val_acc: 0.4655
Epoch 9/40

174/522 [=========>....................] - ETA: 10s - loss: 0.9856 - acc: 0.5460
348/522 [===================>..........] - ETA: 5s - loss: 0.9865 - acc: 0.5259 
522/522 [==============================] - 17s 33ms/step - loss: 0.9748 - acc: 0.5268 - val_loss: 1.0738 - val_acc: 0.4655
Epoch 10/40

174/522 [=========>....................] - ETA: 10s - loss: 0.9561 - acc: 0.5402
348/522 [===================>..........] - ETA: 5s - loss: 0.9738 - acc: 0.5172 
522/522 [==============================] - 18s 34ms/step - loss: 0.9594 - acc: 0.5211 - val_loss: 1.0834 - val_acc: 0.4425
Epoch 11/40

174/522 [=========>....................] - ETA: 10s - loss: 0.9565 - acc: 0.5287
348/522 [===================>..........] - ETA: 5s - loss: 0.9360 - acc: 0.5172 
522/522 [==============================] - 18s 34ms/step - loss: 0.9442 - acc: 0.5115 - val_loss: 1.0969 - val_acc: 0.4770
Epoch 12/40

174/522 [=========>....................] - ETA: 10s - loss: 0.9768 - acc: 0.5172
348/522 [===================>..........] - ETA: 5s - loss: 0.9343 - acc: 0.5345 
522/522 [==============================] - 18s 34ms/step - loss: 0.9287 - acc: 0.5326 - val_loss: 1.1136 - val_acc: 0.4540
Epoch 13/40

174/522 [=========>....................] - ETA: 10s - loss: 0.9452 - acc: 0.5287
348/522 [===================>..........] - ETA: 5s - loss: 0.9072 - acc: 0.5460 
522/522 [==============================] - 18s 34ms/step - loss: 0.9146 - acc: 0.5402 - val_loss: 1.1307 - val_acc: 0.4598
Epoch 14/40

174/522 [=========>....................] - ETA: 10s - loss: 0.9322 - acc: 0.5057
348/522 [===================>..........] - ETA: 5s - loss: 0.9060 - acc: 0.5287 
522/522 [==============================] - 18s 34ms/step - loss: 0.9001 - acc: 0.5517 - val_loss: 1.1484 - val_acc: 0.4540
Epoch 15/40

174/522 [=========>....................] - ETA: 10s - loss: 0.9328 - acc: 0.4885
348/522 [===================>..........] - ETA: 5s - loss: 0.8878 - acc: 0.5517 
522/522 [==============================] - 18s 34ms/step - loss: 0.8859 - acc: 0.5594 - val_loss: 1.1669 - val_acc: 0.4655
Epoch 16/40

174/522 [=========>....................] - ETA: 10s - loss: 0.8764 - acc: 0.5690
348/522 [===================>..........] - ETA: 5s - loss: 0.8611 - acc: 0.5862 
522/522 [==============================] - 18s 34ms/step - loss: 0.8735 - acc: 0.5670 - val_loss: 1.1886 - val_acc: 0.4540
Epoch 17/40

174/522 [=========>....................] - ETA: 10s - loss: 0.8398 - acc: 0.6207
348/522 [===================>..........] - ETA: 5s - loss: 0.8524 - acc: 0.6034 
522/522 [==============================] - 18s 34ms/step - loss: 0.8609 - acc: 0.5805 - val_loss: 1.2108 - val_acc: 0.4540
Epoch 18/40

174/522 [=========>....................] - ETA: 10s - loss: 0.8493 - acc: 0.5805
348/522 [===================>..........] - ETA: 5s - loss: 0.8402 - acc: 0.5948 
522/522 [==============================] - 18s 34ms/step - loss: 0.8489 - acc: 0.5862 - val_loss: 1.2273 - val_acc: 0.4540
Epoch 19/40

174/522 [=========>....................] - ETA: 10s - loss: 0.8546 - acc: 0.5632
348/522 [===================>..........] - ETA: 5s - loss: 0.8419 - acc: 0.5948 
522/522 [==============================] - 18s 34ms/step - loss: 0.8381 - acc: 0.5996 - val_loss: 1.2430 - val_acc: 0.4943
Epoch 20/40

174/522 [=========>....................] - ETA: 10s - loss: 0.8577 - acc: 0.5805
348/522 [===================>..........] - ETA: 5s - loss: 0.8222 - acc: 0.5948 
522/522 [==============================] - 17s 33ms/step - loss: 0.8254 - acc: 0.6073 - val_loss: 1.2640 - val_acc: 0.4483
Epoch 21/40

174/522 [=========>....................] - ETA: 10s - loss: 0.8024 - acc: 0.6264
348/522 [===================>..........] - ETA: 5s - loss: 0.8126 - acc: 0.6408 
522/522 [==============================] - 17s 33ms/step - loss: 0.8143 - acc: 0.6379 - val_loss: 1.2731 - val_acc: 0.4885
Epoch 22/40

174/522 [=========>....................] - ETA: 10s - loss: 0.7618 - acc: 0.6552
348/522 [===================>..........] - ETA: 5s - loss: 0.8107 - acc: 0.6293 
522/522 [==============================] - 18s 34ms/step - loss: 0.8020 - acc: 0.6398 - val_loss: 1.2816 - val_acc: 0.4885
Epoch 23/40

174/522 [=========>....................] - ETA: 10s - loss: 0.8021 - acc: 0.6494
348/522 [===================>..........] - ETA: 5s - loss: 0.7950 - acc: 0.6437 
522/522 [==============================] - 18s 34ms/step - loss: 0.7923 - acc: 0.6303 - val_loss: 1.2892 - val_acc: 0.4943
Epoch 24/40

174/522 [=========>....................] - ETA: 10s - loss: 0.7932 - acc: 0.6322
348/522 [===================>..........] - ETA: 5s - loss: 0.7862 - acc: 0.6609 
522/522 [==============================] - 18s 34ms/step - loss: 0.7800 - acc: 0.6552 - val_loss: 1.2979 - val_acc: 0.4713
Epoch 25/40

174/522 [=========>....................] - ETA: 10s - loss: 0.7530 - acc: 0.6494
348/522 [===================>..........] - ETA: 5s - loss: 0.7930 - acc: 0.6178 
522/522 [==============================] - 18s 34ms/step - loss: 0.7727 - acc: 0.6494 - val_loss: 1.3068 - val_acc: 0.4483
Epoch 26/40

174/522 [=========>....................] - ETA: 10s - loss: 0.7741 - acc: 0.6609
348/522 [===================>..........] - ETA: 5s - loss: 0.7731 - acc: 0.6552 
522/522 [==============================] - 18s 34ms/step - loss: 0.7614 - acc: 0.6513 - val_loss: 1.3042 - val_acc: 0.4770
Epoch 27/40

174/522 [=========>....................] - ETA: 10s - loss: 0.7401 - acc: 0.6609
348/522 [===================>..........] - ETA: 5s - loss: 0.7418 - acc: 0.6868 
522/522 [==============================] - 18s 34ms/step - loss: 0.7522 - acc: 0.6628 - val_loss: 1.3110 - val_acc: 0.5057
Epoch 28/40

174/522 [=========>....................] - ETA: 10s - loss: 0.7326 - acc: 0.6667
348/522 [===================>..........] - ETA: 5s - loss: 0.7290 - acc: 0.6695 
522/522 [==============================] - 18s 34ms/step - loss: 0.7417 - acc: 0.6648 - val_loss: 1.3158 - val_acc: 0.4885
Epoch 29/40

174/522 [=========>....................] - ETA: 10s - loss: 0.7150 - acc: 0.6782
348/522 [===================>..........] - ETA: 5s - loss: 0.6949 - acc: 0.6925 
522/522 [==============================] - 18s 34ms/step - loss: 0.7328 - acc: 0.6590 - val_loss: 1.3166 - val_acc: 0.4655
Epoch 30/40

174/522 [=========>....................] - ETA: 10s - loss: 0.7397 - acc: 0.6609
348/522 [===================>..........] - ETA: 5s - loss: 0.7256 - acc: 0.6609 
522/522 [==============================] - 18s 34ms/step - loss: 0.7239 - acc: 0.6590 - val_loss: 1.3186 - val_acc: 0.4943
Epoch 31/40

174/522 [=========>....................] - ETA: 10s - loss: 0.7190 - acc: 0.6494
348/522 [===================>..........] - ETA: 5s - loss: 0.7212 - acc: 0.6638 
522/522 [==============================] - 17s 33ms/step - loss: 0.7161 - acc: 0.6743 - val_loss: 1.3183 - val_acc: 0.4828
Epoch 32/40

174/522 [=========>....................] - ETA: 10s - loss: 0.7198 - acc: 0.7069
348/522 [===================>..........] - ETA: 5s - loss: 0.6927 - acc: 0.6954 
522/522 [==============================] - 17s 33ms/step - loss: 0.7070 - acc: 0.6839 - val_loss: 1.3236 - val_acc: 0.5057
Epoch 33/40

174/522 [=========>....................] - ETA: 10s - loss: 0.7422 - acc: 0.6782
348/522 [===================>..........] - ETA: 5s - loss: 0.7126 - acc: 0.6868 
522/522 [==============================] - 17s 33ms/step - loss: 0.7010 - acc: 0.6935 - val_loss: 1.3253 - val_acc: 0.4598
Epoch 34/40

174/522 [=========>....................] - ETA: 10s - loss: 0.6710 - acc: 0.7126
348/522 [===================>..........] - ETA: 5s - loss: 0.6896 - acc: 0.6782 
522/522 [==============================] - 18s 34ms/step - loss: 0.6896 - acc: 0.6897 - val_loss: 1.3233 - val_acc: 0.4885
Epoch 35/40

174/522 [=========>....................] - ETA: 10s - loss: 0.6651 - acc: 0.7011
348/522 [===================>..........] - ETA: 5s - loss: 0.6797 - acc: 0.7098 
522/522 [==============================] - 17s 33ms/step - loss: 0.6823 - acc: 0.6935 - val_loss: 1.3203 - val_acc: 0.4770
Epoch 36/40

174/522 [=========>....................] - ETA: 10s - loss: 0.6572 - acc: 0.6897
348/522 [===================>..........] - ETA: 5s - loss: 0.6505 - acc: 0.7040 
522/522 [==============================] - 18s 34ms/step - loss: 0.6738 - acc: 0.6935 - val_loss: 1.3246 - val_acc: 0.4770
Epoch 37/40

174/522 [=========>....................] - ETA: 10s - loss: 0.6657 - acc: 0.6782
348/522 [===================>..........] - ETA: 5s - loss: 0.6696 - acc: 0.6868 
522/522 [==============================] - 17s 33ms/step - loss: 0.6693 - acc: 0.6935 - val_loss: 1.3242 - val_acc: 0.5230
Epoch 38/40

174/522 [=========>....................] - ETA: 10s - loss: 0.7098 - acc: 0.6839
348/522 [===================>..........] - ETA: 5s - loss: 0.6741 - acc: 0.7040 
522/522 [==============================] - 17s 33ms/step - loss: 0.6592 - acc: 0.7126 - val_loss: 1.3184 - val_acc: 0.4770
Epoch 39/40

174/522 [=========>....................] - ETA: 10s - loss: 0.6690 - acc: 0.6667
348/522 [===================>..........] - ETA: 5s - loss: 0.6547 - acc: 0.7011 
522/522 [==============================] - 18s 34ms/step - loss: 0.6554 - acc: 0.7069 - val_loss: 1.3266 - val_acc: 0.4943
Epoch 40/40

174/522 [=========>....................] - ETA: 10s - loss: 0.6293 - acc: 0.6782
348/522 [===================>..........] - ETA: 5s - loss: 0.6350 - acc: 0.7213 
522/522 [==============================] - 18s 34ms/step - loss: 0.6426 - acc: 0.7203 - val_loss: 1.3179 - val_acc: 0.5057
Saved trained model at /n/holylfs03/LABS/berger_lab/nchou/saved_models/aardvark_aug11.h5 
[[3.49392474e-01 3.01572919e-01 3.49034607e-01]
 [2.54292607e-01 3.81191969e-01 3.64515483e-01]
 [2.60586977e-01 3.71861964e-01 3.67550969e-01]
 [1.80421144e-01 4.02467102e-01 4.17111814e-01]
 [3.11150998e-01 1.35584906e-01 5.53264081e-01]
 [9.98659253e-01 1.30780507e-03 3.29444374e-05]
 [3.51483643e-01 3.01780999e-01 3.46735328e-01]
 [2.69798696e-01 3.50376040e-01 3.79825264e-01]
 [1.61447734e-01 4.28521216e-01 4.10031110e-01]
 [2.67545402e-01 3.33321214e-01 3.99133384e-01]
 [5.67429364e-01 3.31321508e-01 1.01249114e-01]
 [2.20241010e-01 2.52671242e-01 5.27087808e-01]
 [3.49697053e-01 2.31694028e-01 4.18608963e-01]
 [2.64982671e-01 6.12613082e-01 1.22404158e-01]
 [4.53066111e-01 5.12939952e-02 4.95639890e-01]
 [4.83705521e-01 3.46062303e-01 1.70232192e-01]
 [6.67437911e-04 4.85482020e-03 9.94477749e-01]
 [2.25356326e-01 3.18054885e-01 4.56588775e-01]
 [9.53813016e-01 2.26664227e-02 2.35205293e-02]
 [2.55462766e-01 3.38078499e-01 4.06458706e-01]
 [2.30234578e-01 1.16754591e-01 6.53010845e-01]
 [8.55680704e-02 5.71927965e-01 3.42503935e-01]
 [3.90579462e-01 2.21253067e-01 3.88167471e-01]
 [1.16127707e-01 4.93651718e-01 3.90220553e-01]
 [3.90579462e-01 2.21253067e-01 3.88167471e-01]
 [2.91153967e-01 2.91652381e-01 4.17193651e-01]
 [2.96152920e-01 4.53328788e-01 2.50518292e-01]
 [5.66294156e-02 7.24724174e-01 2.18646348e-01]
 [1.14317164e-01 6.31950319e-01 2.53732502e-01]
 [2.22732157e-01 3.48456711e-01 4.28811163e-01]
 [9.99990702e-01 6.91009045e-13 9.24732012e-06]
 [3.90579462e-01 2.21253067e-01 3.88167471e-01]
 [3.36167306e-01 2.54852086e-01 4.08980668e-01]
 [2.44832337e-01 2.89535344e-01 4.65632290e-01]
 [6.44591260e-13 1.98812813e-10 1.00000000e+00]
 [1.65336058e-01 6.23496473e-01 2.11167514e-01]
 [2.23296821e-01 3.20204198e-01 4.56498981e-01]
 [1.68579116e-01 2.80234784e-01 5.51186085e-01]
 [7.89331377e-01 6.32428452e-02 1.47425845e-01]
 [3.85816664e-01 2.74508744e-01 3.39674562e-01]
 [9.99999881e-01 8.15991830e-10 1.52410138e-07]
 [1.68579116e-01 2.80234784e-01 5.51186085e-01]
 [8.22227001e-01 3.01454612e-03 1.74758554e-01]
 [9.47488129e-01 2.76242827e-06 5.25091849e-02]
 [9.47488129e-01 2.76242827e-06 5.25091849e-02]
 [3.16260785e-01 2.98397511e-01 3.85341674e-01]
 [3.03143173e-01 3.94338936e-01 3.02517891e-01]
 [1.95342109e-01 3.59151214e-01 4.45506722e-01]
 [7.89331377e-01 6.32428452e-02 1.47425845e-01]
 [2.92198420e-01 2.71658242e-01 4.36143368e-01]
 [2.96152920e-01 4.53328788e-01 2.50518292e-01]
 [2.95767456e-01 3.15009832e-01 3.89222711e-01]
 [2.53499866e-01 6.78951502e-01 6.75486252e-02]
 [1.96992010e-01 3.47091347e-01 4.55916584e-01]
 [3.19583505e-01 2.10089371e-01 4.70327139e-01]
 [4.04446423e-01 5.63403606e-01 3.21499445e-02]
 [6.94769546e-02 6.99259400e-01 2.31263578e-01]
 [7.66002059e-01 1.93285242e-01 4.07126844e-02]
 [2.19842583e-01 3.67440850e-01 4.12716627e-01]
 [1.61447734e-01 4.28521216e-01 4.10031110e-01]
 [3.90579462e-01 2.21253067e-01 3.88167471e-01]
 [5.39390922e-01 2.24283010e-01 2.36326054e-01]
 [4.01762098e-01 3.13388228e-01 2.84849703e-01]
 [1.55280446e-04 9.99843836e-01 7.87272768e-07]
 [2.23089363e-02 7.16815889e-01 2.60875255e-01]
 [9.99990702e-01 6.91009045e-13 9.24732012e-06]
 [9.99999881e-01 8.15991830e-10 1.52410138e-07]
 [9.99496460e-01 8.47325209e-05 4.18835058e-04]
 [3.36167306e-01 2.54852086e-01 4.08980668e-01]
 [2.98741251e-01 3.37663293e-01 3.63595515e-01]
 [3.21465313e-01 3.30077887e-01 3.48456860e-01]
 [1.95648327e-01 1.76666617e-01 6.27685070e-01]
 [1.68579116e-01 2.80234784e-01 5.51186085e-01]
 [2.28893667e-01 3.47963512e-01 4.23142791e-01]
 [1.78874508e-01 1.49079580e-02 8.06217551e-01]
 [2.99027647e-07 9.82425570e-01 1.75740607e-02]
 [1.69733524e-01 6.34182930e-01 1.96083516e-01]
 [2.18928412e-01 3.02536517e-01 4.78535026e-01]
 [2.65737355e-01 3.88774276e-01 3.45488399e-01]
 [1.74208164e-01 4.01266187e-01 4.24525648e-01]
 [5.93478838e-03 2.59121448e-01 7.34943748e-01]
 [1.01591647e-01 5.45398712e-01 3.53009611e-01]
 [3.36488694e-01 4.06499654e-01 2.57011712e-01]
 [1.85447320e-01 4.15985674e-01 3.98567021e-01]
 [3.87690514e-01 2.67477363e-01 3.44832093e-01]
 [1.38970926e-01 4.92985517e-01 3.68043542e-01]
 [2.21140310e-01 3.96083146e-01 3.82776499e-01]
 [9.99990702e-01 6.91009045e-13 9.24732012e-06]
 [3.11150998e-01 1.35584906e-01 5.53264081e-01]
 [1.55280446e-04 9.99843836e-01 7.87272768e-07]
 [9.98659253e-01 1.30780507e-03 3.29444374e-05]
 [2.69169062e-01 3.48940611e-01 3.81890357e-01]
 [1.95648327e-01 1.76666617e-01 6.27685070e-01]
 [1.00000000e+00 0.00000000e+00 4.99199116e-28]
 [2.50060707e-01 3.32567811e-01 4.17371511e-01]
 [1.83361098e-01 4.58620131e-01 3.58018786e-01]
 [1.99624389e-01 3.49447310e-01 4.50928390e-01]
 [9.53813016e-01 2.26664227e-02 2.35205293e-02]
 [3.13404858e-01 3.88683379e-01 2.97911823e-01]
 [4.44069759e-09 4.96789042e-18 1.00000000e+00]
 [3.54365438e-01 2.99833030e-01 3.45801562e-01]
 [9.99455512e-01 5.44436043e-04 1.55244144e-13]
 [2.20553875e-01 3.71661305e-01 4.07784879e-01]
 [2.45150059e-01 3.37228656e-01 4.17621255e-01]
 [1.41369268e-01 6.29742801e-01 2.28887960e-01]
 [4.44069759e-09 4.96789042e-18 1.00000000e+00]
 [5.93478838e-03 2.59121448e-01 7.34943748e-01]
 [2.13446006e-01 3.88049364e-01 3.98504645e-01]
 [3.36167306e-01 2.54852086e-01 4.08980668e-01]
 [2.59087328e-02 7.36415684e-01 2.37675592e-01]
 [2.32064486e-01 3.40629667e-01 4.27305907e-01]
 [2.23296821e-01 3.20204198e-01 4.56498981e-01]
 [8.55680704e-02 5.71927965e-01 3.42503935e-01]
 [2.90101409e-01 3.45358163e-01 3.64540458e-01]
 [3.90579462e-01 2.21253067e-01 3.88167471e-01]
 [1.70489661e-02 6.83053136e-01 2.99897999e-01]
 [6.26355410e-01 2.29547188e-01 1.44097462e-01]
 [2.41872177e-01 2.88998485e-01 4.69129354e-01]
 [2.92235464e-01 3.31137747e-01 3.76626760e-01]
 [1.61447734e-01 4.28521216e-01 4.10031110e-01]
 [1.65336058e-01 6.23496473e-01 2.11167514e-01]
 [1.33489311e-01 5.47709346e-01 3.18801314e-01]
 [9.96811926e-01 3.41691455e-04 2.84646219e-03]
 [1.38970926e-01 4.92985517e-01 3.68043542e-01]
 [2.37644687e-01 2.19396661e-05 7.62333333e-01]
 [9.47488129e-01 2.76242827e-06 5.25091849e-02]
 [2.02725813e-01 1.13973007e-01 6.83301210e-01]
 [9.98659253e-01 1.30780507e-03 3.29444374e-05]
 [3.25939298e-01 3.43498081e-01 3.30562562e-01]
 [7.32635260e-02 4.26993519e-01 4.99742985e-01]
 [2.99649388e-01 3.56932759e-01 3.43417883e-01]
 [4.02074337e-01 2.20963240e-01 3.76962394e-01]
 [7.05948310e-07 9.71097708e-01 2.89016478e-02]
 [3.65459174e-01 2.97823012e-01 3.36717844e-01]
 [7.29340081e-06 9.99992609e-01 6.03726278e-08]
 [8.52905661e-02 6.64843738e-01 2.49865726e-01]
 [3.31796080e-01 3.03864390e-01 3.64339560e-01]
 [9.99999881e-01 1.04725778e-07 2.01062171e-08]
 [4.83898729e-01 1.71297431e-01 3.44803810e-01]
 [6.26355410e-01 2.29547188e-01 1.44097462e-01]
 [1.08241523e-03 2.21647394e-08 9.98917580e-01]
 [2.55265832e-01 3.16131055e-01 4.28603053e-01]
 [2.29053542e-01 3.68089378e-01 4.02857095e-01]
 [3.34227949e-01 4.78800505e-01 1.86971530e-01]
 [3.83645147e-01 2.86753923e-01 3.29601020e-01]
 [5.93478838e-03 2.59121448e-01 7.34943748e-01]
 [2.45464668e-02 7.21783876e-01 2.53669679e-01]
 [3.66359890e-01 2.99133271e-01 3.34506929e-01]
 [1.10612288e-01 5.75242817e-01 3.14144909e-01]
 [2.79967487e-01 3.82831842e-01 3.37200761e-01]
 [3.29211086e-01 3.11112076e-01 3.59676808e-01]
 [3.51483643e-01 3.01780999e-01 3.46735328e-01]
 [1.78902283e-01 4.00659800e-01 4.20437843e-01]
 [3.90579462e-01 2.21253067e-01 3.88167471e-01]
 [9.47488129e-01 2.76242827e-06 5.25091849e-02]
 [7.21189916e-01 1.45753443e-01 1.33056596e-01]
 [1.95648327e-01 1.76666617e-01 6.27685070e-01]
 [1.66856928e-03 9.98331487e-01 5.46700019e-10]
 [1.01591647e-01 5.45398712e-01 3.53009611e-01]
 [3.76674384e-01 2.57249892e-01 3.66075784e-01]
 [7.60196447e-02 3.90767574e-01 5.33212781e-01]
 [1.55280446e-04 9.99843836e-01 7.87272768e-07]
 [1.68579116e-01 2.80234784e-01 5.51186085e-01]
 [2.30562359e-01 4.23591048e-01 3.45846593e-01]
 [2.63697863e-01 2.76928842e-01 4.59373325e-01]
 [3.09580654e-01 3.61007780e-01 3.29411566e-01]
 [1.31635949e-01 4.08582777e-01 4.59781379e-01]
 [9.53813016e-01 2.26664227e-02 2.35205293e-02]
 [4.15017754e-01 2.62152344e-01 3.22829872e-01]
 [3.66632968e-01 3.54321390e-01 2.79045582e-01]
 [2.32020304e-01 3.50360870e-01 4.17618841e-01]
 [3.44748795e-01 3.33413810e-01 3.21837336e-01]
 [1.86921775e-01 4.18757111e-01 3.94321114e-01]
 [3.35710377e-01 3.24751019e-01 3.39538634e-01]]
[0 1 1 2 2 0 0 2 1 2 0 2 2 1 2 0 2 2 0 2 2 1 0 1 0 2 1 1 1 2 0 0 2 2 2 1 2
 2 0 0 0 2 0 0 0 2 1 2 0 2 1 2 1 2 2 1 1 0 2 1 0 0 0 1 1 0 0 0 2 2 2 2 2 2
 2 1 1 2 1 2 2 1 1 1 0 1 1 0 2 1 0 2 2 0 2 1 2 0 1 2 0 0 2 2 1 2 2 2 2 1 2
 2 1 2 0 1 0 2 2 1 1 1 0 1 2 0 2 0 1 2 1 0 1 0 1 1 2 0 0 0 2 2 2 1 0 2 1 0
 1 1 2 0 2 0 0 0 2 1 1 0 2 1 2 1 2 1 2 0 0 0 2 0 1 2]

 32/174 [====>.........................] - ETA: 1s
 64/174 [==========>...................] - ETA: 1s
 96/174 [===============>..............] - ETA: 0s
128/174 [=====================>........] - ETA: 0s
160/174 [==========================>...] - ETA: 0s
174/174 [==============================] - 2s 11ms/step
Test loss: 1.7347579742300099
Test accuracy: 0.4252873564931168
[[33  8 17]
 [ 8 19 31]
 [11 25 22]]
