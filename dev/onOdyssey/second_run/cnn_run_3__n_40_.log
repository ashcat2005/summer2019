Using TensorFlow backend.
WARNING:tensorflow:From /n/home00/nchou/.conda/envs/envi/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.
Instructions for updating:
Colocations handled automatically by placer.
cnn_aardvark_aug_concat.py:397: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor("in..., outputs=Tensor("de...)`
  model = Model(input=ins, output=dense2)
WARNING:tensorflow:From /n/home00/nchou/.conda/envs/envi/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.cast instead.
2019-11-07 11:44:53.747042: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
2019-11-07 11:44:53.930996: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2900000000 Hz
2019-11-07 11:44:53.931261: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x55eb59685e30 executing computations on platform Host. Devices:
2019-11-07 11:44:53.931313: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (0): <undefined>, <undefined>
None
Train on 522 samples, validate on 174 samples
Epoch 1/40

522/522 [==============================] - 35s 67ms/step - loss: 1.0984 - acc: 0.3525 - val_loss: 1.0746 - val_acc: 0.3966
Epoch 2/40

522/522 [==============================] - 28s 54ms/step - loss: 1.0656 - acc: 0.5613 - val_loss: 1.0475 - val_acc: 0.3851
Epoch 3/40

522/522 [==============================] - 28s 54ms/step - loss: 1.0243 - acc: 0.5268 - val_loss: 1.0270 - val_acc: 0.3851
Epoch 4/40

522/522 [==============================] - 28s 54ms/step - loss: 0.9798 - acc: 0.5402 - val_loss: 1.0250 - val_acc: 0.4368
Epoch 5/40

522/522 [==============================] - 28s 54ms/step - loss: 0.9417 - acc: 0.5594 - val_loss: 1.0337 - val_acc: 0.3851
Epoch 6/40

522/522 [==============================] - 28s 54ms/step - loss: 0.9085 - acc: 0.5402 - val_loss: 1.0330 - val_acc: 0.4080
Epoch 7/40

522/522 [==============================] - 28s 54ms/step - loss: 0.8742 - acc: 0.5747 - val_loss: 1.0473 - val_acc: 0.4655
Epoch 8/40

522/522 [==============================] - 28s 54ms/step - loss: 0.8350 - acc: 0.6475 - val_loss: 1.0623 - val_acc: 0.3851
Epoch 9/40

522/522 [==============================] - 28s 54ms/step - loss: 0.8073 - acc: 0.6015 - val_loss: 1.0621 - val_acc: 0.3793
Epoch 10/40

522/522 [==============================] - 28s 54ms/step - loss: 0.7746 - acc: 0.6590 - val_loss: 1.0709 - val_acc: 0.4540
Epoch 11/40

522/522 [==============================] - 28s 54ms/step - loss: 0.7483 - acc: 0.7510 - val_loss: 1.0889 - val_acc: 0.4540
Epoch 12/40

522/522 [==============================] - 28s 54ms/step - loss: 0.7214 - acc: 0.7720 - val_loss: 1.1086 - val_acc: 0.5402
Epoch 13/40

522/522 [==============================] - 28s 54ms/step - loss: 0.6914 - acc: 0.7835 - val_loss: 1.1309 - val_acc: 0.4828
Epoch 14/40

522/522 [==============================] - 28s 54ms/step - loss: 0.6699 - acc: 0.7088 - val_loss: 1.1370 - val_acc: 0.5517
Epoch 15/40

522/522 [==============================] - 28s 54ms/step - loss: 0.6399 - acc: 0.8295 - val_loss: 1.1572 - val_acc: 0.5287
Epoch 16/40

522/522 [==============================] - 28s 54ms/step - loss: 0.6213 - acc: 0.8161 - val_loss: 1.1614 - val_acc: 0.5805
Epoch 17/40

522/522 [==============================] - 28s 54ms/step - loss: 0.5933 - acc: 0.8448 - val_loss: 1.1769 - val_acc: 0.5345
Epoch 18/40

522/522 [==============================] - 28s 54ms/step - loss: 0.5765 - acc: 0.8103 - val_loss: 1.1795 - val_acc: 0.5920
Epoch 19/40

522/522 [==============================] - 28s 54ms/step - loss: 0.5529 - acc: 0.8314 - val_loss: 1.1764 - val_acc: 0.6034
Epoch 20/40

522/522 [==============================] - 28s 54ms/step - loss: 0.5344 - acc: 0.8678 - val_loss: 1.1876 - val_acc: 0.6034
Epoch 21/40

522/522 [==============================] - 28s 54ms/step - loss: 0.5152 - acc: 0.8525 - val_loss: 1.1943 - val_acc: 0.6149
Epoch 22/40

522/522 [==============================] - 28s 54ms/step - loss: 0.4947 - acc: 0.8314 - val_loss: 1.1946 - val_acc: 0.6379
Epoch 23/40

522/522 [==============================] - 28s 54ms/step - loss: 0.4823 - acc: 0.8678 - val_loss: 1.2161 - val_acc: 0.6207
Epoch 24/40

522/522 [==============================] - 28s 54ms/step - loss: 0.4617 - acc: 0.8391 - val_loss: 1.2181 - val_acc: 0.6552
Epoch 25/40

522/522 [==============================] - 28s 54ms/step - loss: 0.4476 - acc: 0.8851 - val_loss: 1.2361 - val_acc: 0.6724
Epoch 26/40

522/522 [==============================] - 29s 55ms/step - loss: 0.4346 - acc: 0.8851 - val_loss: 1.2285 - val_acc: 0.6379
Epoch 27/40

522/522 [==============================] - 28s 54ms/step - loss: 0.4144 - acc: 0.9080 - val_loss: 1.2529 - val_acc: 0.6552
Epoch 28/40

522/522 [==============================] - 28s 55ms/step - loss: 0.4025 - acc: 0.8602 - val_loss: 1.2423 - val_acc: 0.6954
Epoch 29/40

522/522 [==============================] - 28s 54ms/step - loss: 0.3836 - acc: 0.9042 - val_loss: 1.2434 - val_acc: 0.6667
Epoch 30/40

522/522 [==============================] - 28s 55ms/step - loss: 0.3737 - acc: 0.9272 - val_loss: 1.2685 - val_acc: 0.6609
Epoch 31/40

522/522 [==============================] - 28s 54ms/step - loss: 0.3614 - acc: 0.8736 - val_loss: 1.2584 - val_acc: 0.6207
Epoch 32/40

522/522 [==============================] - 28s 55ms/step - loss: 0.3538 - acc: 0.9310 - val_loss: 1.3037 - val_acc: 0.6322
Epoch 33/40

522/522 [==============================] - 28s 54ms/step - loss: 0.3572 - acc: 0.8774 - val_loss: 1.2552 - val_acc: 0.6379
Epoch 34/40

522/522 [==============================] - 29s 55ms/step - loss: 0.3294 - acc: 0.9425 - val_loss: 1.2739 - val_acc: 0.6782
Epoch 35/40

522/522 [==============================] - 28s 54ms/step - loss: 0.3171 - acc: 0.9176 - val_loss: 1.2942 - val_acc: 0.6609
Epoch 36/40

522/522 [==============================] - 28s 54ms/step - loss: 0.3143 - acc: 0.8908 - val_loss: 1.2600 - val_acc: 0.6897
Epoch 37/40

522/522 [==============================] - 28s 54ms/step - loss: 0.3018 - acc: 0.9464 - val_loss: 1.2552 - val_acc: 0.6667
Epoch 38/40

522/522 [==============================] - 28s 54ms/step - loss: 0.2844 - acc: 0.9598 - val_loss: 1.2950 - val_acc: 0.6667
Epoch 39/40

522/522 [==============================] - 28s 54ms/step - loss: 0.2869 - acc: 0.8889 - val_loss: 1.2554 - val_acc: 0.7011
Epoch 40/40

522/522 [==============================] - 28s 54ms/step - loss: 0.2629 - acc: 0.9617 - val_loss: 1.2586 - val_acc: 0.6724
Saved trained model at /n/holylfs03/LABS/berger_lab/nchou/saved_models/aardvark_aug11.h5 
[[2.63646275e-01 3.26134235e-01 4.10219491e-01]
 [3.63880038e-01 2.85037905e-01 3.51082116e-01]
 [3.42296571e-01 2.83382326e-01 3.74321073e-01]
 [1.32752836e-01 6.31690398e-02 8.04078162e-01]
 [6.39090776e-01 1.07059777e-01 2.53849566e-01]
 [9.94767904e-01 5.23212366e-03 4.31773970e-18]
 [3.46918643e-01 2.62629718e-01 3.90451640e-01]
 [2.68245190e-01 3.33392859e-01 3.98361951e-01]
 [2.40233108e-01 3.79659921e-01 3.80106956e-01]
 [4.19904739e-01 2.02590972e-01 3.77504379e-01]
 [9.24092233e-01 1.84941553e-02 5.74136563e-02]
 [3.92545402e-01 2.89903522e-01 3.17551076e-01]
 [3.86877239e-01 1.23352252e-01 4.89770502e-01]
 [1.00519538e-01 7.35442817e-01 1.64037645e-01]
 [3.01887900e-01 8.75415951e-02 6.10570431e-01]
 [4.99587625e-01 6.15208223e-02 4.38891530e-01]
 [3.81911887e-05 1.85752090e-03 9.98104215e-01]
 [3.50368381e-01 3.44255030e-01 3.05376619e-01]
 [1.00000000e+00 1.97996666e-20 4.12666325e-11]
 [3.88534367e-01 2.80338436e-01 3.31127167e-01]
 [1.02699235e-01 1.61412299e-01 7.35888481e-01]
 [9.13521722e-02 3.91933098e-02 8.69454563e-01]
 [4.44410294e-01 1.44674152e-01 4.10915494e-01]
 [6.40476525e-01 2.08292738e-01 1.51230767e-01]
 [4.44410294e-01 1.44674152e-01 4.10915494e-01]
 [4.10926133e-01 2.01258793e-01 3.87815088e-01]
 [7.06594288e-01 1.04630478e-01 1.88775241e-01]
 [8.12571729e-04 9.47141767e-01 5.20456359e-02]
 [3.25630084e-02 8.64257157e-01 1.03179805e-01]
 [3.37679625e-01 3.38768959e-01 3.23551387e-01]
 [1.00000000e+00 1.35441951e-12 1.35075100e-12]
 [4.44410294e-01 1.44674152e-01 4.10915494e-01]
 [9.94999647e-01 2.14907108e-03 2.85131810e-03]
 [3.51291776e-01 2.52044499e-01 3.96663725e-01]
 [8.80547524e-10 5.43619790e-17 1.00000000e+00]
 [2.38954172e-01 4.24278565e-02 7.18617976e-01]
 [3.66018593e-01 3.27162504e-01 3.06818873e-01]
 [2.97529578e-01 2.51715928e-01 4.50754493e-01]
 [9.71706569e-01 9.06636589e-04 2.73867697e-02]
 [3.46418470e-01 2.04791769e-01 4.48789716e-01]
 [7.29281176e-03 9.92707193e-01 2.45083875e-18]
 [2.97529578e-01 2.51715928e-01 4.50754493e-01]
 [2.40454730e-02 9.36293364e-01 3.96610722e-02]
 [1.00000000e+00 2.59460693e-13 5.67956846e-08]
 [1.00000000e+00 2.59460693e-13 5.67956846e-08]
 [3.44676673e-01 2.96260118e-01 3.59063208e-01]
 [2.39916444e-01 3.98969799e-02 7.20186591e-01]
 [3.00283402e-01 3.92931372e-01 3.06785226e-01]
 [9.71706569e-01 9.06636589e-04 2.73867697e-02]
 [2.89133489e-01 1.76120773e-01 5.34745693e-01]
 [7.06594288e-01 1.04630478e-01 1.88775241e-01]
 [3.45224351e-01 3.11423510e-01 3.43352050e-01]
 [5.57806134e-01 1.25854030e-01 3.16339821e-01]
 [3.05421501e-01 2.50128388e-01 4.44450200e-01]
 [3.04839343e-01 2.03213915e-01 4.91946757e-01]
 [9.48775709e-01 3.74726318e-02 1.37516698e-02]
 [4.13980424e-01 1.81582030e-02 5.67861438e-01]
 [1.21158399e-02 4.11055749e-03 9.83773589e-01]
 [6.95071463e-03 7.26811886e-01 2.66237319e-01]
 [2.40233108e-01 3.79659921e-01 3.80106956e-01]
 [4.44410294e-01 1.44674152e-01 4.10915494e-01]
 [8.73589635e-01 4.58169766e-02 8.05933625e-02]
 [4.07306463e-01 4.71925288e-01 1.20768197e-01]
 [1.00000000e+00 4.82766894e-15 5.59063133e-15]
 [1.16290688e-03 9.50547814e-01 4.82893065e-02]
 [1.00000000e+00 1.35441951e-12 1.35075100e-12]
 [7.29281176e-03 9.92707193e-01 2.45083875e-18]
 [1.85298438e-06 9.99975443e-01 2.26603333e-05]
 [9.94999647e-01 2.14907108e-03 2.85131810e-03]
 [3.15377504e-01 3.59635621e-01 3.24986875e-01]
 [3.33739996e-01 3.28325272e-01 3.37934703e-01]
 [1.05487578e-01 1.98876988e-02 8.74624729e-01]
 [2.97529578e-01 2.51715928e-01 4.50754493e-01]
 [3.72136176e-01 2.42534682e-01 3.85329157e-01]
 [2.60005683e-01 4.21094801e-03 7.35783458e-01]
 [1.00000000e+00 1.82471649e-16 3.28617446e-11]
 [8.87118280e-01 6.21184185e-02 5.07633053e-02]
 [5.55365441e-05 2.38770997e-04 9.99705613e-01]
 [2.75754243e-01 3.14013004e-01 4.10232782e-01]
 [1.00197144e-01 5.80837913e-02 8.41719091e-01]
 [4.88338526e-03 8.16008091e-01 1.79108545e-01]
 [3.08088720e-01 5.12697279e-01 1.79214075e-01]
 [5.09009242e-01 2.25881711e-01 2.65109003e-01]
 [1.80492431e-01 2.84412950e-01 5.35094619e-01]
 [4.54878449e-01 2.01073155e-01 3.44048411e-01]
 [1.39675036e-01 1.48636311e-01 7.11688638e-01]
 [2.29371339e-01 3.29418510e-01 4.41210210e-01]
 [1.00000000e+00 1.35441951e-12 1.35075100e-12]
 [6.39090776e-01 1.07059777e-01 2.53849566e-01]
 [1.00000000e+00 4.82766894e-15 5.59063133e-15]
 [9.94767904e-01 5.23212366e-03 4.31773970e-18]
 [3.09553444e-01 3.27292025e-01 3.63154560e-01]
 [1.05487578e-01 1.98876988e-02 8.74624729e-01]
 [2.06386391e-03 9.73023101e-19 9.97936130e-01]
 [1.93108231e-01 2.56364256e-01 5.50527453e-01]
 [2.54915178e-01 2.28197858e-01 5.16886950e-01]
 [2.44181350e-01 3.37437928e-01 4.18380678e-01]
 [1.00000000e+00 1.97996666e-20 4.12666325e-11]
 [3.89103711e-01 2.84825712e-01 3.26070607e-01]
 [1.00000000e+00 3.65000974e-10 2.46554999e-10]
 [4.20872092e-01 2.05992803e-01 3.73135090e-01]
 [1.00000000e+00 1.03110955e-12 4.82076844e-11]
 [3.01198125e-01 2.46000186e-01 4.52801645e-01]
 [3.01303118e-01 3.31920445e-01 3.66776496e-01]
 [2.14462485e-02 9.40414369e-01 3.81393954e-02]
 [1.00000000e+00 3.65000974e-10 2.46554999e-10]
 [4.88338526e-03 8.16008091e-01 1.79108545e-01]
 [9.93826210e-01 3.48834670e-04 5.82495844e-03]
 [9.94999647e-01 2.14907108e-03 2.85131810e-03]
 [1.67719414e-03 9.52105582e-01 4.62172441e-02]
 [3.55461478e-01 2.76947528e-01 3.67591023e-01]
 [3.66018593e-01 3.27162504e-01 3.06818873e-01]
 [9.13521722e-02 3.91933098e-02 8.69454563e-01]
 [3.57821226e-01 2.49529824e-01 3.92648995e-01]
 [4.44410294e-01 1.44674152e-01 4.10915494e-01]
 [4.17446390e-05 1.07070608e-02 9.89251196e-01]
 [6.02068186e-01 2.40383998e-01 1.57547802e-01]
 [2.78213263e-01 3.39282274e-01 3.82504404e-01]
 [3.53230059e-01 2.92326063e-01 3.54443848e-01]
 [2.40233108e-01 3.79659921e-01 3.80106956e-01]
 [2.38954172e-01 4.24278565e-02 7.18617976e-01]
 [5.22895891e-04 6.68305039e-01 3.31172168e-01]
 [9.99053061e-01 9.37939563e-04 9.02944066e-06]
 [1.39675036e-01 1.48636311e-01 7.11688638e-01]
 [9.99998808e-01 1.65450032e-07 1.02342983e-06]
 [1.00000000e+00 2.59460693e-13 5.67956846e-08]
 [1.03465118e-01 3.91670316e-02 8.57367873e-01]
 [9.94767904e-01 5.23212366e-03 4.31773970e-18]
 [2.03562200e-01 2.76583701e-01 5.19854009e-01]
 [1.72696263e-02 4.02800173e-01 5.79930186e-01]
 [3.58158499e-01 2.73741245e-01 3.68100256e-01]
 [1.87640235e-01 4.21173349e-02 7.70242453e-01]
 [1.00000000e+00 7.60660865e-17 3.48534743e-11]
 [3.70476186e-01 2.53720254e-01 3.75803560e-01]
 [9.97581244e-01 3.39547075e-13 2.41872435e-03]
 [1.78087026e-01 1.01515077e-01 7.20397830e-01]
 [3.57567191e-01 3.47004294e-01 2.95428514e-01]
 [1.00000000e+00 2.96739464e-23 2.19155430e-22]
 [6.65375054e-01 6.20986670e-02 2.72526324e-01]
 [6.02068186e-01 2.40383998e-01 1.57547802e-01]
 [2.05471709e-01 1.50993373e-03 7.93018341e-01]
 [1.88808411e-01 2.32461587e-01 5.78729987e-01]
 [2.52916873e-01 3.15289140e-01 4.31794047e-01]
 [8.33495036e-02 5.41924760e-02 8.62457991e-01]
 [4.38924074e-01 2.14507177e-01 3.46568704e-01]
 [4.88338526e-03 8.16008091e-01 1.79108545e-01]
 [1.37075305e-03 9.46824670e-01 5.18045910e-02]
 [3.81456822e-01 2.49091372e-01 3.69451851e-01]
 [1.33276079e-03 4.75135148e-01 5.23532093e-01]
 [4.48417932e-01 2.94154555e-01 2.57427484e-01]
 [3.52458566e-01 2.97254384e-01 3.50287080e-01]
 [3.46918643e-01 2.62629718e-01 3.90451640e-01]
 [3.21457118e-01 3.48494977e-01 3.30047965e-01]
 [4.44410294e-01 1.44674152e-01 4.10915494e-01]
 [1.00000000e+00 2.59460693e-13 5.67956846e-08]
 [9.99992132e-01 6.95170712e-08 7.77636433e-06]
 [1.05487578e-01 1.98876988e-02 8.74624729e-01]
 [9.99992251e-01 7.77642435e-06 3.80582286e-08]
 [3.08088720e-01 5.12697279e-01 1.79214075e-01]
 [2.53295958e-01 2.70239592e-01 4.76464480e-01]
 [3.18742171e-02 3.75653170e-02 9.30560470e-01]
 [1.00000000e+00 4.82766894e-15 5.59063133e-15]
 [2.97529578e-01 2.51715928e-01 4.50754493e-01]
 [2.06024587e-01 3.27612668e-01 4.66362774e-01]
 [2.33974487e-01 2.47512966e-01 5.18512487e-01]
 [3.43545020e-01 3.55335683e-01 3.01119268e-01]
 [9.17997420e-01 6.28378848e-03 7.57188126e-02]
 [1.00000000e+00 1.97996666e-20 4.12666325e-11]
 [7.84182966e-01 8.81477911e-03 2.07002267e-01]
 [2.18527541e-02 9.23423111e-01 5.47242090e-02]
 [3.94587427e-01 3.61004472e-01 2.44408116e-01]
 [3.17279309e-01 3.32326323e-01 3.50394398e-01]
 [2.10622743e-01 3.25838923e-01 4.63538349e-01]
 [3.87654305e-01 2.77584463e-01 3.34761232e-01]]
[2 0 2 2 0 0 2 2 2 0 0 0 2 1 2 0 2 0 0 0 2 2 0 0 0 0 0 1 1 1 0 0 0 2 2 2 0
 2 0 2 1 2 1 0 0 2 2 1 0 2 0 0 0 2 2 0 2 2 1 2 0 0 1 0 1 0 1 1 0 1 2 2 2 2
 2 0 0 2 2 2 1 1 0 2 0 2 2 0 0 0 0 2 2 2 2 2 2 0 0 0 0 0 2 2 1 0 1 0 0 1 2
 0 2 2 0 2 0 2 2 2 2 1 0 2 0 0 2 0 2 2 2 2 0 2 0 2 0 0 0 0 2 2 2 2 0 1 1 0
 2 0 0 2 1 0 0 0 2 0 1 2 2 0 2 2 2 1 0 0 0 1 0 2 2 0]

 32/174 [====>.........................] - ETA: 2s
 64/174 [==========>...................] - ETA: 1s
 96/174 [===============>..............] - ETA: 1s
128/174 [=====================>........] - ETA: 0s
160/174 [==========================>...] - ETA: 0s
174/174 [==============================] - 3s 18ms/step
Test loss: 1.7558732991931083
Test accuracy: 0.5344827586206896
[[41  8  9]
 [15 15 28]
 [19  2 37]]
