Using TensorFlow backend.
WARNING:tensorflow:From /n/home00/nchou/.conda/envs/envi/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.
Instructions for updating:
Colocations handled automatically by placer.
cnn_aardvark_aug_concat.py:397: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor("in..., outputs=Tensor("de...)`
  model = Model(input=ins, output=dense2)
WARNING:tensorflow:From /n/home00/nchou/.conda/envs/envi/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.cast instead.
2019-11-07 11:44:42.551051: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
2019-11-07 11:44:42.639563: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2900000000 Hz
2019-11-07 11:44:42.639819: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x55d08112d0b0 executing computations on platform Host. Devices:
2019-11-07 11:44:42.639871: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (0): <undefined>, <undefined>
None
Train on 522 samples, validate on 174 samples
Epoch 1/40

522/522 [==============================] - 32s 61ms/step - loss: 1.0986 - acc: 0.3333 - val_loss: 1.0916 - val_acc: 0.3851
Epoch 2/40

522/522 [==============================] - 28s 54ms/step - loss: 1.0949 - acc: 0.3678 - val_loss: 1.0883 - val_acc: 0.3851
Epoch 3/40

522/522 [==============================] - 28s 53ms/step - loss: 1.0908 - acc: 0.4234 - val_loss: 1.0851 - val_acc: 0.3966
Epoch 4/40

522/522 [==============================] - 28s 53ms/step - loss: 1.0864 - acc: 0.4425 - val_loss: 1.0821 - val_acc: 0.4195
Epoch 5/40

522/522 [==============================] - 28s 54ms/step - loss: 1.0820 - acc: 0.4368 - val_loss: 1.0796 - val_acc: 0.4023
Epoch 6/40

522/522 [==============================] - 28s 53ms/step - loss: 1.0773 - acc: 0.4291 - val_loss: 1.0775 - val_acc: 0.4368
Epoch 7/40

522/522 [==============================] - 28s 54ms/step - loss: 1.0726 - acc: 0.4483 - val_loss: 1.0761 - val_acc: 0.4310
Epoch 8/40

522/522 [==============================] - 28s 53ms/step - loss: 1.0678 - acc: 0.4502 - val_loss: 1.0754 - val_acc: 0.4195
Epoch 9/40

522/522 [==============================] - 28s 54ms/step - loss: 1.0630 - acc: 0.4483 - val_loss: 1.0757 - val_acc: 0.4080
Epoch 10/40

522/522 [==============================] - 28s 53ms/step - loss: 1.0582 - acc: 0.4559 - val_loss: 1.0770 - val_acc: 0.4138
Epoch 11/40

522/522 [==============================] - 28s 54ms/step - loss: 1.0534 - acc: 0.4559 - val_loss: 1.0794 - val_acc: 0.4253
Epoch 12/40

522/522 [==============================] - 28s 53ms/step - loss: 1.0487 - acc: 0.4636 - val_loss: 1.0828 - val_acc: 0.4080
Epoch 13/40

522/522 [==============================] - 28s 54ms/step - loss: 1.0441 - acc: 0.4751 - val_loss: 1.0874 - val_acc: 0.4023
Epoch 14/40

522/522 [==============================] - 28s 53ms/step - loss: 1.0395 - acc: 0.4751 - val_loss: 1.0930 - val_acc: 0.4138
Epoch 15/40

522/522 [==============================] - 28s 53ms/step - loss: 1.0350 - acc: 0.4770 - val_loss: 1.0995 - val_acc: 0.4253
Epoch 16/40

522/522 [==============================] - 28s 53ms/step - loss: 1.0306 - acc: 0.4655 - val_loss: 1.1069 - val_acc: 0.4253
Epoch 17/40

522/522 [==============================] - 28s 53ms/step - loss: 1.0262 - acc: 0.4713 - val_loss: 1.1151 - val_acc: 0.4253
Epoch 18/40

522/522 [==============================] - 28s 53ms/step - loss: 1.0219 - acc: 0.4693 - val_loss: 1.1237 - val_acc: 0.4253
Epoch 19/40

522/522 [==============================] - 28s 54ms/step - loss: 1.0176 - acc: 0.4444 - val_loss: 1.1326 - val_acc: 0.4195
Epoch 20/40

522/522 [==============================] - 28s 53ms/step - loss: 1.0132 - acc: 0.4502 - val_loss: 1.1420 - val_acc: 0.4195
Epoch 21/40

522/522 [==============================] - 28s 54ms/step - loss: 1.0089 - acc: 0.4579 - val_loss: 1.1517 - val_acc: 0.4540
Epoch 22/40

522/522 [==============================] - 28s 53ms/step - loss: 1.0046 - acc: 0.4559 - val_loss: 1.1614 - val_acc: 0.4540
Epoch 23/40

522/522 [==============================] - 28s 54ms/step - loss: 1.0004 - acc: 0.4617 - val_loss: 1.1712 - val_acc: 0.4655
Epoch 24/40

522/522 [==============================] - 28s 54ms/step - loss: 0.9961 - acc: 0.4732 - val_loss: 1.1811 - val_acc: 0.4598
Epoch 25/40

522/522 [==============================] - 28s 54ms/step - loss: 0.9918 - acc: 0.4693 - val_loss: 1.1911 - val_acc: 0.4483
Epoch 26/40

522/522 [==============================] - 28s 54ms/step - loss: 0.9875 - acc: 0.4693 - val_loss: 1.1925 - val_acc: 0.4483
Epoch 27/40

522/522 [==============================] - 28s 54ms/step - loss: 0.9830 - acc: 0.4732 - val_loss: 1.1899 - val_acc: 0.4598
Epoch 28/40

522/522 [==============================] - 28s 54ms/step - loss: 0.9785 - acc: 0.4943 - val_loss: 1.1879 - val_acc: 0.4598
Epoch 29/40

522/522 [==============================] - 28s 54ms/step - loss: 0.9739 - acc: 0.5019 - val_loss: 1.1868 - val_acc: 0.4598
Epoch 30/40

522/522 [==============================] - 28s 54ms/step - loss: 0.9693 - acc: 0.5038 - val_loss: 1.1865 - val_acc: 0.4483
Epoch 31/40

522/522 [==============================] - 28s 54ms/step - loss: 0.9647 - acc: 0.5057 - val_loss: 1.1870 - val_acc: 0.4483
Epoch 32/40

522/522 [==============================] - 28s 54ms/step - loss: 0.9601 - acc: 0.5153 - val_loss: 1.1883 - val_acc: 0.4655
Epoch 33/40

522/522 [==============================] - 28s 54ms/step - loss: 0.9553 - acc: 0.5134 - val_loss: 1.1900 - val_acc: 0.4770
Epoch 34/40

522/522 [==============================] - 28s 54ms/step - loss: 0.9503 - acc: 0.5096 - val_loss: 1.1919 - val_acc: 0.4713
Epoch 35/40

522/522 [==============================] - 28s 54ms/step - loss: 0.9452 - acc: 0.5192 - val_loss: 1.1941 - val_acc: 0.4885
Epoch 36/40

522/522 [==============================] - 28s 54ms/step - loss: 0.9398 - acc: 0.5268 - val_loss: 1.1963 - val_acc: 0.4828
Epoch 37/40

522/522 [==============================] - 28s 54ms/step - loss: 0.9343 - acc: 0.5326 - val_loss: 1.1985 - val_acc: 0.4655
Epoch 38/40

522/522 [==============================] - 28s 54ms/step - loss: 0.9285 - acc: 0.5307 - val_loss: 1.2005 - val_acc: 0.4425
Epoch 39/40

522/522 [==============================] - 28s 54ms/step - loss: 0.9226 - acc: 0.5383 - val_loss: 1.2023 - val_acc: 0.4540
Epoch 40/40

522/522 [==============================] - 28s 54ms/step - loss: 0.9165 - acc: 0.5383 - val_loss: 1.2038 - val_acc: 0.4598
Saved trained model at /n/holylfs03/LABS/berger_lab/nchou/saved_models/aardvark_aug11.h5 
[[3.15981716e-01 3.45693529e-01 3.38324755e-01]
 [2.98804492e-01 3.66128772e-01 3.35066766e-01]
 [2.99546719e-01 3.66098493e-01 3.34354758e-01]
 [1.98990628e-01 4.24249887e-01 3.76759440e-01]
 [3.23212951e-01 2.86168069e-01 3.90619010e-01]
 [9.86543596e-01 4.64152865e-04 1.29921697e-02]
 [3.12334269e-01 3.40218008e-01 3.47447723e-01]
 [3.13656032e-01 3.15120429e-01 3.71223569e-01]
 [3.32326502e-01 3.50091010e-01 3.17582428e-01]
 [3.16638947e-01 3.33016783e-01 3.50344300e-01]
 [3.88469011e-01 3.89145106e-01 2.22385928e-01]
 [2.72975147e-01 4.12584335e-01 3.14440489e-01]
 [3.08284074e-01 3.23251396e-01 3.68464500e-01]
 [2.74026722e-01 4.64239091e-01 2.61734158e-01]
 [1.98633105e-01 3.88872981e-01 4.12493914e-01]
 [2.85637051e-01 4.73990351e-01 2.40372643e-01]
 [7.29649654e-03 5.63872494e-02 9.36316252e-01]
 [3.27707916e-01 2.99009234e-01 3.73282820e-01]
 [8.37866187e-01 6.62686750e-02 9.58651826e-02]
 [2.96817750e-01 3.25884610e-01 3.77297640e-01]
 [1.91468760e-01 4.27141398e-01 3.81389827e-01]
 [2.28686288e-01 3.11939210e-01 4.59374487e-01]
 [2.76089072e-01 4.17774767e-01 3.06136250e-01]
 [1.87690794e-01 3.90300721e-01 4.22008544e-01]
 [2.76089072e-01 4.17774767e-01 3.06136250e-01]
 [2.93763459e-01 3.22178006e-01 3.84058535e-01]
 [3.02555293e-01 4.48871911e-01 2.48572767e-01]
 [3.61096859e-01 4.13779497e-01 2.25123659e-01]
 [2.87900597e-01 4.04829353e-01 3.07270080e-01]
 [2.99611419e-01 3.24993879e-01 3.75394642e-01]
 [7.61325777e-01 1.07527978e-06 2.38673121e-01]
 [2.76089072e-01 4.17774767e-01 3.06136250e-01]
 [4.16360289e-01 3.18100661e-01 2.65539080e-01]
 [3.14160496e-01 3.38429719e-01 3.47409785e-01]
 [1.75211462e-05 3.05496142e-05 9.99951959e-01]
 [2.79236138e-01 4.16103154e-01 3.04660678e-01]
 [3.28998387e-01 3.00413370e-01 3.70588273e-01]
 [3.30309153e-01 3.70684832e-01 2.99005985e-01]
 [5.81235290e-01 2.53603905e-01 1.65160760e-01]
 [3.02915782e-01 3.27995598e-01 3.69088560e-01]
 [2.87284613e-01 2.29589103e-04 7.12485790e-01]
 [3.30309153e-01 3.70684832e-01 2.99005985e-01]
 [3.40039700e-01 3.52004051e-01 3.07956219e-01]
 [8.86470020e-01 2.96046352e-03 1.10569499e-01]
 [8.86470020e-01 2.96046352e-03 1.10569499e-01]
 [3.06636930e-01 3.44310850e-01 3.49052250e-01]
 [2.09718987e-01 3.86027724e-01 4.04253274e-01]
 [2.81261981e-01 3.46303225e-01 3.72434855e-01]
 [5.81235290e-01 2.53603905e-01 1.65160760e-01]
 [3.11665803e-01 3.34046185e-01 3.54288012e-01]
 [3.02555293e-01 4.48871911e-01 2.48572767e-01]
 [3.12930346e-01 3.31437439e-01 3.55632246e-01]
 [3.07228893e-01 4.48984772e-01 2.43786335e-01]
 [3.06248933e-01 3.34321439e-01 3.59429657e-01]
 [3.16245943e-01 3.38134736e-01 3.45619261e-01]
 [2.95992017e-01 3.81667018e-01 3.22340995e-01]
 [2.43851423e-01 3.83606255e-01 3.72542322e-01]
 [6.26113951e-01 2.86132962e-01 8.77531320e-02]
 [1.91188768e-01 3.78531814e-01 4.30279374e-01]
 [3.32326502e-01 3.50091010e-01 3.17582428e-01]
 [2.76089072e-01 4.17774767e-01 3.06136250e-01]
 [3.97185415e-01 3.99116665e-01 2.03697875e-01]
 [3.48294228e-01 3.60955566e-01 2.90750235e-01]
 [8.49386632e-01 1.49781704e-01 8.31637532e-04]
 [3.53431314e-01 4.10243154e-01 2.36325428e-01]
 [7.61325777e-01 1.07527978e-06 2.38673121e-01]
 [2.87284613e-01 2.29589103e-04 7.12485790e-01]
 [9.92476404e-01 7.52336485e-03 2.81279085e-07]
 [4.16360289e-01 3.18100661e-01 2.65539080e-01]
 [3.05082709e-01 3.30895931e-01 3.64021391e-01]
 [3.08576167e-01 3.49938601e-01 3.41485202e-01]
 [3.36509168e-01 2.46618867e-01 4.16871965e-01]
 [3.30309153e-01 3.70684832e-01 2.99005985e-01]
 [3.13398987e-01 3.38494092e-01 3.48106980e-01]
 [3.42244416e-01 2.29542360e-01 4.28213239e-01]
 [5.93855120e-02 9.40225899e-01 3.88638262e-04]
 [3.52312505e-01 4.79906201e-01 1.67781264e-01]
 [4.29737657e-01 2.53936112e-01 3.16326171e-01]
 [3.29550982e-01 3.48356485e-01 3.22092533e-01]
 [1.97221085e-01 4.28414553e-01 3.74364376e-01]
 [1.21649705e-01 3.97792608e-01 4.80557740e-01]
 [3.13214451e-01 3.17945838e-01 3.68839681e-01]
 [3.02028030e-01 4.34461474e-01 2.63510466e-01]
 [2.74249196e-01 3.80505949e-01 3.45244855e-01]
 [3.16775978e-01 3.37908655e-01 3.45315427e-01]
 [2.91745782e-01 3.76397908e-01 3.31856251e-01]
 [2.85332739e-01 3.64007086e-01 3.50660175e-01]
 [7.61325777e-01 1.07527978e-06 2.38673121e-01]
 [3.23212951e-01 2.86168069e-01 3.90619010e-01]
 [8.49386632e-01 1.49781704e-01 8.31637532e-04]
 [9.86543596e-01 4.64152865e-04 1.29921697e-02]
 [3.19284141e-01 3.43391329e-01 3.37324500e-01]
 [3.36509168e-01 2.46618867e-01 4.16871965e-01]
 [8.86202753e-01 1.28200358e-12 1.13797307e-01]
 [2.80122012e-01 3.51551116e-01 3.68326873e-01]
 [3.25627923e-01 3.54059070e-01 3.20313036e-01]
 [3.04543257e-01 3.32730561e-01 3.62726152e-01]
 [8.37866187e-01 6.62686750e-02 9.58651826e-02]
 [3.21176052e-01 3.29077691e-01 3.49746257e-01]
 [8.40770245e-01 1.62320504e-10 1.59229726e-01]
 [3.03731859e-01 3.52291197e-01 3.43976915e-01]
 [9.97550666e-01 2.39847484e-03 5.08532939e-05]
 [3.12816620e-01 3.14996213e-01 3.72187197e-01]
 [3.10804635e-01 3.32014143e-01 3.57181221e-01]
 [2.78437078e-01 4.17493314e-01 3.04069549e-01]
 [8.40770245e-01 1.62320504e-10 1.59229726e-01]
 [1.21649705e-01 3.97792608e-01 4.80557740e-01]
 [1.95678249e-01 1.56396016e-01 6.47925735e-01]
 [4.16360289e-01 3.18100661e-01 2.65539080e-01]
 [3.51986229e-01 4.14395332e-01 2.33618394e-01]
 [3.09911758e-01 3.31719667e-01 3.58368546e-01]
 [3.28998387e-01 3.00413370e-01 3.70588273e-01]
 [2.28686288e-01 3.11939210e-01 4.59374487e-01]
 [2.84811884e-01 3.57157290e-01 3.58030826e-01]
 [2.76089072e-01 4.17774767e-01 3.06136250e-01]
 [1.46048382e-01 2.22859830e-01 6.31091833e-01]
 [3.19148809e-01 3.82410586e-01 2.98440605e-01]
 [3.04321468e-01 3.17422360e-01 3.78256172e-01]
 [3.16587180e-01 3.32567900e-01 3.50844860e-01]
 [3.32326502e-01 3.50091010e-01 3.17582428e-01]
 [2.79236138e-01 4.16103154e-01 3.04660678e-01]
 [2.84292221e-01 3.53994668e-01 3.61713141e-01]
 [7.90742755e-01 1.56446174e-01 5.28110228e-02]
 [2.91745782e-01 3.76397908e-01 3.31856251e-01]
 [5.13155639e-01 2.55543995e-03 4.84288901e-01]
 [8.86470020e-01 2.96046352e-03 1.10569499e-01]
 [1.82962522e-01 4.06607717e-01 4.10429746e-01]
 [9.86543596e-01 4.64152865e-04 1.29921697e-02]
 [3.09475988e-01 3.54451686e-01 3.36072296e-01]
 [1.65569305e-01 4.25302118e-01 4.09128577e-01]
 [3.06210995e-01 3.33347023e-01 3.60442013e-01]
 [3.25586766e-01 3.11453819e-01 3.62959445e-01]
 [1.64369896e-01 8.34552348e-01 1.07769645e-03]
 [3.24881405e-01 3.35190892e-01 3.39927733e-01]
 [3.98643278e-02 1.20519744e-02 9.48083758e-01]
 [2.28946298e-01 5.03473759e-01 2.67579913e-01]
 [3.23298514e-01 3.29066336e-01 3.47635150e-01]
 [9.90396142e-01 9.19070281e-03 4.13069385e-04]
 [3.25245202e-01 2.96643347e-01 3.78111392e-01]
 [3.19148809e-01 3.82410586e-01 2.98440605e-01]
 [5.12046814e-01 1.13066517e-01 3.74886692e-01]
 [2.81127989e-01 3.51916075e-01 3.66955966e-01]
 [2.92986393e-01 3.45630139e-01 3.61383468e-01]
 [2.98051536e-01 4.65741038e-01 2.36207396e-01]
 [3.20072770e-01 3.25360060e-01 3.54567200e-01]
 [1.21649705e-01 3.97792608e-01 4.80557740e-01]
 [3.53097409e-01 4.11347896e-01 2.35554680e-01]
 [3.24959248e-01 3.35008025e-01 3.40032727e-01]
 [3.43867809e-01 3.90739799e-01 2.65392393e-01]
 [3.05376709e-01 3.28081548e-01 3.66541773e-01]
 [3.04603904e-01 3.41992736e-01 3.53403360e-01]
 [3.12334269e-01 3.40218008e-01 3.47447723e-01]
 [2.82012850e-01 3.45193714e-01 3.72793496e-01]
 [2.76089072e-01 4.17774767e-01 3.06136250e-01]
 [8.86470020e-01 2.96046352e-03 1.10569499e-01]
 [5.86020052e-01 3.20689619e-01 9.32904109e-02]
 [3.36509168e-01 2.46618867e-01 4.16871965e-01]
 [9.88465190e-01 1.13468627e-02 1.87946411e-04]
 [3.13214451e-01 3.17945838e-01 3.68839681e-01]
 [3.42816472e-01 3.09944868e-01 3.47238660e-01]
 [2.44323313e-01 4.41532075e-01 3.14144582e-01]
 [8.49386632e-01 1.49781704e-01 8.31637532e-04]
 [3.30309153e-01 3.70684832e-01 2.99005985e-01]
 [2.79684424e-01 3.78222138e-01 3.42093408e-01]
 [3.17409009e-01 3.21040839e-01 3.61550122e-01]
 [3.09618115e-01 3.23669910e-01 3.66712004e-01]
 [2.87163496e-01 3.44870090e-01 3.67966413e-01]
 [8.37866187e-01 6.62686750e-02 9.58651826e-02]
 [2.73044229e-01 3.96593601e-01 3.30362201e-01]
 [3.33385319e-01 3.27639550e-01 3.38975132e-01]
 [2.98782766e-01 3.24089646e-01 3.77127618e-01]
 [3.24745417e-01 3.39031965e-01 3.36222678e-01]
 [2.74788976e-01 3.80635470e-01 3.44575554e-01]
 [2.98776060e-01 3.21267515e-01 3.79956424e-01]]
[1 1 1 1 2 0 2 2 1 2 1 1 2 1 2 1 2 2 0 2 1 2 1 2 1 2 1 1 1 2 0 1 0 2 2 1 2
 1 0 2 2 1 1 0 0 2 2 2 0 2 1 2 1 2 2 1 1 0 2 1 1 1 1 0 1 0 2 0 0 2 1 2 1 2
 2 1 1 0 1 1 2 2 1 1 2 1 1 0 2 0 0 1 2 0 2 1 2 0 2 0 1 0 2 2 1 0 2 2 0 1 2
 2 2 2 1 2 1 2 2 1 1 2 0 1 0 0 2 0 1 1 2 2 1 2 2 1 2 0 2 1 0 2 2 1 2 2 1 2
 1 2 2 2 2 1 0 0 2 0 2 2 1 0 1 1 2 2 2 0 1 2 2 1 1 2]

 32/174 [====>.........................] - ETA: 2s
 64/174 [==========>...................] - ETA: 1s
 96/174 [===============>..............] - ETA: 1s
128/174 [=====================>........] - ETA: 0s
160/174 [==========================>...] - ETA: 0s
174/174 [==============================] - 3s 15ms/step
Test loss: 1.2514326709440384
Test accuracy: 0.37931034534141933
[[24 20 14]
 [ 0 19 39]
 [10 25 23]]
