Using TensorFlow backend.
WARNING:tensorflow:From /n/home00/nchou/.conda/envs/envi/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.
Instructions for updating:
Colocations handled automatically by placer.
WARNING:tensorflow:From /n/home00/nchou/.conda/envs/envi/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.
Instructions for updating:
Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.
cnn_aardvark_aug_concat.py:397: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor("in..., outputs=Tensor("de...)`
  model = Model(input=ins, output=dense2)
WARNING:tensorflow:From /n/home00/nchou/.conda/envs/envi/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.cast instead.
2019-11-07 11:44:45.054014: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
2019-11-07 11:44:45.174314: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2900000000 Hz
2019-11-07 11:44:45.174586: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x55c5eb3487f0 executing computations on platform Host. Devices:
2019-11-07 11:44:45.174638: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (0): <undefined>, <undefined>
[0.5]
Train on 522 samples, validate on 174 samples
Epoch 1/40

174/522 [=========>....................] - ETA: 25s - loss: 1.0975 - acc: 0.3448
348/522 [===================>..........] - ETA: 10s - loss: 1.0963 - acc: 0.3506
522/522 [==============================] - 33s 64ms/step - loss: 1.0948 - acc: 0.3621 - val_loss: 1.0729 - val_acc: 0.3793
Epoch 2/40

174/522 [=========>....................] - ETA: 18s - loss: 1.0531 - acc: 0.4195
348/522 [===================>..........] - ETA: 9s - loss: 1.0509 - acc: 0.4425 
522/522 [==============================] - 30s 58ms/step - loss: 1.0467 - acc: 0.4330 - val_loss: 1.0464 - val_acc: 0.4253
Epoch 3/40

174/522 [=========>....................] - ETA: 18s - loss: 0.9990 - acc: 0.4770
348/522 [===================>..........] - ETA: 9s - loss: 1.0224 - acc: 0.4425 
522/522 [==============================] - 30s 58ms/step - loss: 1.0028 - acc: 0.4636 - val_loss: 1.0938 - val_acc: 0.4195
Epoch 4/40

174/522 [=========>....................] - ETA: 18s - loss: 0.9522 - acc: 0.5057
348/522 [===================>..........] - ETA: 9s - loss: 0.9294 - acc: 0.5287 
522/522 [==============================] - 31s 59ms/step - loss: 0.9675 - acc: 0.5019 - val_loss: 1.0898 - val_acc: 0.3966
Epoch 5/40

174/522 [=========>....................] - ETA: 18s - loss: 0.9015 - acc: 0.5115
348/522 [===================>..........] - ETA: 9s - loss: 1.0099 - acc: 0.4684 
522/522 [==============================] - 31s 59ms/step - loss: 1.0018 - acc: 0.4521 - val_loss: 1.2716 - val_acc: 0.3563
Epoch 6/40

174/522 [=========>....................] - ETA: 18s - loss: 1.1615 - acc: 0.3908
348/522 [===================>..........] - ETA: 9s - loss: 1.0157 - acc: 0.4483 
522/522 [==============================] - 30s 58ms/step - loss: 1.0313 - acc: 0.4521 - val_loss: 1.0734 - val_acc: 0.3966
Epoch 7/40

174/522 [=========>....................] - ETA: 18s - loss: 0.8567 - acc: 0.5460
348/522 [===================>..........] - ETA: 9s - loss: 0.9636 - acc: 0.5000 
522/522 [==============================] - 31s 58ms/step - loss: 0.9233 - acc: 0.5153 - val_loss: 1.2838 - val_acc: 0.4483
Epoch 8/40

174/522 [=========>....................] - ETA: 18s - loss: 1.0397 - acc: 0.4828
348/522 [===================>..........] - ETA: 9s - loss: 0.9788 - acc: 0.5000 
522/522 [==============================] - 30s 58ms/step - loss: 0.9486 - acc: 0.4981 - val_loss: 1.2321 - val_acc: 0.4195
Epoch 9/40

174/522 [=========>....................] - ETA: 18s - loss: 0.9242 - acc: 0.5402
348/522 [===================>..........] - ETA: 9s - loss: 0.8643 - acc: 0.5948 
522/522 [==============================] - 31s 59ms/step - loss: 0.8712 - acc: 0.5805 - val_loss: 1.2826 - val_acc: 0.4540
Epoch 10/40

174/522 [=========>....................] - ETA: 18s - loss: 0.8890 - acc: 0.5460
348/522 [===================>..........] - ETA: 9s - loss: 0.8655 - acc: 0.5460 
522/522 [==============================] - 31s 59ms/step - loss: 0.8603 - acc: 0.5632 - val_loss: 1.1900 - val_acc: 0.4770
Epoch 11/40

174/522 [=========>....................] - ETA: 18s - loss: 0.8581 - acc: 0.5172
348/522 [===================>..........] - ETA: 8s - loss: 0.8541 - acc: 0.5747 
522/522 [==============================] - 30s 57ms/step - loss: 0.8442 - acc: 0.5785 - val_loss: 1.3418 - val_acc: 0.4253
Epoch 12/40

174/522 [=========>....................] - ETA: 18s - loss: 0.8422 - acc: 0.5632
348/522 [===================>..........] - ETA: 9s - loss: 0.8785 - acc: 0.5316 
522/522 [==============================] - 30s 58ms/step - loss: 0.8615 - acc: 0.5383 - val_loss: 1.4434 - val_acc: 0.4770
Epoch 13/40

174/522 [=========>....................] - ETA: 17s - loss: 0.9650 - acc: 0.5057
348/522 [===================>..........] - ETA: 9s - loss: 0.8647 - acc: 0.5603 
522/522 [==============================] - 30s 58ms/step - loss: 0.8433 - acc: 0.5651 - val_loss: 1.4199 - val_acc: 0.4195
Epoch 14/40

174/522 [=========>....................] - ETA: 18s - loss: 0.8537 - acc: 0.5632
348/522 [===================>..........] - ETA: 9s - loss: 0.7864 - acc: 0.5920 
522/522 [==============================] - 31s 59ms/step - loss: 0.7737 - acc: 0.6015 - val_loss: 1.4321 - val_acc: 0.4483
Epoch 15/40

174/522 [=========>....................] - ETA: 18s - loss: 0.8942 - acc: 0.6034
348/522 [===================>..........] - ETA: 9s - loss: 0.7954 - acc: 0.6466 
522/522 [==============================] - 31s 59ms/step - loss: 0.7879 - acc: 0.6245 - val_loss: 1.4037 - val_acc: 0.4540
Epoch 16/40

174/522 [=========>....................] - ETA: 17s - loss: 0.7964 - acc: 0.5460
348/522 [===================>..........] - ETA: 8s - loss: 0.7416 - acc: 0.5948 
522/522 [==============================] - 30s 57ms/step - loss: 0.7464 - acc: 0.6149 - val_loss: 1.3170 - val_acc: 0.4770
Epoch 17/40

174/522 [=========>....................] - ETA: 18s - loss: 0.7084 - acc: 0.7011
348/522 [===================>..........] - ETA: 9s - loss: 0.6839 - acc: 0.7011 
522/522 [==============================] - 30s 58ms/step - loss: 0.6680 - acc: 0.6820 - val_loss: 1.3044 - val_acc: 0.4828
Epoch 18/40

174/522 [=========>....................] - ETA: 18s - loss: 0.6886 - acc: 0.6149
348/522 [===================>..........] - ETA: 9s - loss: 0.6667 - acc: 0.6609 
522/522 [==============================] - 30s 58ms/step - loss: 0.6603 - acc: 0.6648 - val_loss: 1.2996 - val_acc: 0.5517
Epoch 19/40

174/522 [=========>....................] - ETA: 18s - loss: 0.6010 - acc: 0.7299
348/522 [===================>..........] - ETA: 9s - loss: 0.6043 - acc: 0.7069 
522/522 [==============================] - 31s 59ms/step - loss: 0.6027 - acc: 0.7146 - val_loss: 1.2924 - val_acc: 0.4713
Epoch 20/40

174/522 [=========>....................] - ETA: 18s - loss: 0.6227 - acc: 0.7126
348/522 [===================>..........] - ETA: 9s - loss: 0.5923 - acc: 0.7270 
522/522 [==============================] - 30s 58ms/step - loss: 0.5910 - acc: 0.7299 - val_loss: 1.3037 - val_acc: 0.5805
Epoch 21/40

174/522 [=========>....................] - ETA: 17s - loss: 0.5562 - acc: 0.7586
348/522 [===================>..........] - ETA: 9s - loss: 0.5658 - acc: 0.7471 
522/522 [==============================] - 30s 57ms/step - loss: 0.5721 - acc: 0.7510 - val_loss: 1.3220 - val_acc: 0.5517
Epoch 22/40

174/522 [=========>....................] - ETA: 18s - loss: 0.5157 - acc: 0.7586
348/522 [===================>..........] - ETA: 9s - loss: 0.5481 - acc: 0.7500 
522/522 [==============================] - 30s 58ms/step - loss: 0.5420 - acc: 0.7605 - val_loss: 1.3448 - val_acc: 0.5230
Epoch 23/40

174/522 [=========>....................] - ETA: 18s - loss: 0.5774 - acc: 0.7529
348/522 [===================>..........] - ETA: 9s - loss: 0.5228 - acc: 0.7730 
522/522 [==============================] - 31s 59ms/step - loss: 0.5330 - acc: 0.7739 - val_loss: 1.3827 - val_acc: 0.5747
Epoch 24/40

174/522 [=========>....................] - ETA: 18s - loss: 0.5641 - acc: 0.7356
348/522 [===================>..........] - ETA: 9s - loss: 0.5407 - acc: 0.7557 
522/522 [==============================] - 31s 59ms/step - loss: 0.5223 - acc: 0.7739 - val_loss: 1.3565 - val_acc: 0.5862
Epoch 25/40

174/522 [=========>....................] - ETA: 18s - loss: 0.5025 - acc: 0.7644
348/522 [===================>..........] - ETA: 9s - loss: 0.4941 - acc: 0.7787 
522/522 [==============================] - 30s 58ms/step - loss: 0.4959 - acc: 0.7893 - val_loss: 1.4131 - val_acc: 0.5690
Epoch 26/40

174/522 [=========>....................] - ETA: 17s - loss: 0.4747 - acc: 0.8103
348/522 [===================>..........] - ETA: 9s - loss: 0.4667 - acc: 0.7989 
522/522 [==============================] - 30s 58ms/step - loss: 0.4669 - acc: 0.8027 - val_loss: 1.4303 - val_acc: 0.6149
Epoch 27/40

174/522 [=========>....................] - ETA: 18s - loss: 0.5006 - acc: 0.7644
348/522 [===================>..........] - ETA: 9s - loss: 0.4491 - acc: 0.7902 
522/522 [==============================] - 30s 58ms/step - loss: 0.4600 - acc: 0.7969 - val_loss: 1.4420 - val_acc: 0.6034
Epoch 28/40

174/522 [=========>....................] - ETA: 18s - loss: 0.4012 - acc: 0.8333
348/522 [===================>..........] - ETA: 9s - loss: 0.4334 - acc: 0.8190 
522/522 [==============================] - 31s 59ms/step - loss: 0.4319 - acc: 0.8180 - val_loss: 1.4152 - val_acc: 0.6092
Epoch 29/40

174/522 [=========>....................] - ETA: 18s - loss: 0.3700 - acc: 0.8793
348/522 [===================>..........] - ETA: 9s - loss: 0.4105 - acc: 0.8506 
522/522 [==============================] - 30s 58ms/step - loss: 0.4125 - acc: 0.8448 - val_loss: 1.4527 - val_acc: 0.6322
Epoch 30/40

174/522 [=========>....................] - ETA: 18s - loss: 0.4406 - acc: 0.7931
348/522 [===================>..........] - ETA: 9s - loss: 0.4080 - acc: 0.8333 
522/522 [==============================] - 30s 58ms/step - loss: 0.3950 - acc: 0.8429 - val_loss: 1.4535 - val_acc: 0.6034
Epoch 31/40

174/522 [=========>....................] - ETA: 18s - loss: 0.3787 - acc: 0.8391
348/522 [===================>..........] - ETA: 9s - loss: 0.3670 - acc: 0.8621 
522/522 [==============================] - 30s 58ms/step - loss: 0.3779 - acc: 0.8582 - val_loss: 1.4544 - val_acc: 0.6379
Epoch 32/40

174/522 [=========>....................] - ETA: 18s - loss: 0.3975 - acc: 0.8563
348/522 [===================>..........] - ETA: 9s - loss: 0.3657 - acc: 0.8736 
522/522 [==============================] - 31s 59ms/step - loss: 0.3581 - acc: 0.8755 - val_loss: 1.4348 - val_acc: 0.6437
Epoch 33/40

174/522 [=========>....................] - ETA: 18s - loss: 0.3071 - acc: 0.9195
348/522 [===================>..........] - ETA: 9s - loss: 0.3384 - acc: 0.8879 
522/522 [==============================] - 30s 58ms/step - loss: 0.3376 - acc: 0.8851 - val_loss: 1.4416 - val_acc: 0.6437
Epoch 34/40

174/522 [=========>....................] - ETA: 18s - loss: 0.3247 - acc: 0.8966
348/522 [===================>..........] - ETA: 9s - loss: 0.3062 - acc: 0.9052 
522/522 [==============================] - 30s 58ms/step - loss: 0.3228 - acc: 0.8946 - val_loss: 1.4806 - val_acc: 0.6207
Epoch 35/40

174/522 [=========>....................] - ETA: 18s - loss: 0.3285 - acc: 0.8908
348/522 [===================>..........] - ETA: 9s - loss: 0.3314 - acc: 0.8764 
522/522 [==============================] - 30s 58ms/step - loss: 0.3115 - acc: 0.8851 - val_loss: 1.5067 - val_acc: 0.6092
Epoch 36/40

174/522 [=========>....................] - ETA: 18s - loss: 0.2601 - acc: 0.9080
348/522 [===================>..........] - ETA: 9s - loss: 0.2789 - acc: 0.9023 
522/522 [==============================] - 31s 59ms/step - loss: 0.2910 - acc: 0.8966 - val_loss: 1.5745 - val_acc: 0.6264
Epoch 37/40

174/522 [=========>....................] - ETA: 17s - loss: 0.3649 - acc: 0.8563
348/522 [===================>..........] - ETA: 9s - loss: 0.3003 - acc: 0.8994 
522/522 [==============================] - 30s 58ms/step - loss: 0.3195 - acc: 0.8908 - val_loss: 1.6701 - val_acc: 0.6149
Epoch 38/40

174/522 [=========>....................] - ETA: 18s - loss: 0.4690 - acc: 0.7816
348/522 [===================>..........] - ETA: 9s - loss: 0.3453 - acc: 0.8563 
522/522 [==============================] - 30s 58ms/step - loss: 0.4188 - acc: 0.8142 - val_loss: 1.9950 - val_acc: 0.5747
Epoch 39/40

174/522 [=========>....................] - ETA: 18s - loss: 0.6661 - acc: 0.7701
348/522 [===================>..........] - ETA: 9s - loss: 0.5118 - acc: 0.8247 
522/522 [==============================] - 30s 58ms/step - loss: 0.7960 - acc: 0.7452 - val_loss: 3.2084 - val_acc: 0.5230
Epoch 40/40

174/522 [=========>....................] - ETA: 18s - loss: 1.4124 - acc: 0.6897
348/522 [===================>..........] - ETA: 9s - loss: 1.8066 - acc: 0.6092 
522/522 [==============================] - 30s 58ms/step - loss: 2.2908 - acc: 0.6188 - val_loss: 5.3121 - val_acc: 0.4598
Saved trained model at /n/holylfs03/LABS/berger_lab/nchou/saved_models/aardvark_aug11.h5 
[[2.64201940e-08 9.72773910e-01 2.72261053e-02]
 [1.54755035e-08 9.91810501e-01 8.18958785e-03]
 [1.33730245e-08 9.89560246e-01 1.04397293e-02]
 [6.05208550e-09 3.40455830e-01 6.59544170e-01]
 [1.05458560e-06 9.51613784e-01 4.83851284e-02]
 [6.55836351e-15 1.00000000e+00 0.00000000e+00]
 [2.16185665e-08 9.81103659e-01 1.88963842e-02]
 [3.64881672e-08 9.87017810e-01 1.29822288e-02]
 [1.94555145e-08 9.77419615e-01 2.25803703e-02]
 [1.06089004e-08 9.73236203e-01 2.67637651e-02]
 [4.50646257e-06 8.62537026e-01 1.37458503e-01]
 [4.55160021e-10 9.98951554e-01 1.04843534e-03]
 [1.69808754e-08 9.19123054e-01 8.08769688e-02]
 [2.21973911e-10 9.99951363e-01 4.85891251e-05]
 [3.50532119e-08 9.46745276e-01 5.32547273e-02]
 [2.67394825e-07 9.70585585e-01 2.94141788e-02]
 [4.96797635e-16 5.12045808e-03 9.94879484e-01]
 [7.18140170e-09 9.96715903e-01 3.28411441e-03]
 [1.00000000e+00 7.85833494e-34 1.52912561e-11]
 [2.19908038e-08 9.93217051e-01 6.78293454e-03]
 [1.36503986e-09 9.72541034e-01 2.74589863e-02]
 [4.02115719e-09 1.66016787e-01 8.33983183e-01]
 [6.30916341e-09 9.96797979e-01 3.20204208e-03]
 [3.21318550e-09 9.71944034e-01 2.80559659e-02]
 [6.30916341e-09 9.96797979e-01 3.20204208e-03]
 [4.69816150e-08 9.65936184e-01 3.40637863e-02]
 [4.66519836e-08 9.97702420e-01 2.29763123e-03]
 [1.41412159e-14 9.98182058e-01 1.81792851e-03]
 [2.55498844e-10 9.98779714e-01 1.22026331e-03]
 [8.83163231e-09 9.96327221e-01 3.67279164e-03]
 [1.00000000e+00 6.83348524e-34 1.64865175e-38]
 [6.30916341e-09 9.96797979e-01 3.20204208e-03]
 [4.00569319e-04 9.65345025e-01 3.42543945e-02]
 [1.61798667e-07 9.43745017e-01 5.62548935e-02]
 [2.05808257e-38 0.00000000e+00 1.00000000e+00]
 [5.49154633e-09 9.62606132e-01 3.73939276e-02]
 [6.73131995e-09 9.96693730e-01 3.30623356e-03]
 [5.82002135e-09 9.75926101e-01 2.40738653e-02]
 [2.19907379e-05 4.84802485e-01 5.15175581e-01]
 [7.54173684e-08 9.81927454e-01 1.80724170e-02]
 [1.24839814e-18 1.00000000e+00 0.00000000e+00]
 [5.82002135e-09 9.75926101e-01 2.40738653e-02]
 [2.13070561e-09 9.99892712e-01 1.07231703e-04]
 [1.00000000e+00 0.00000000e+00 1.69219955e-12]
 [1.00000000e+00 0.00000000e+00 1.69219955e-12]
 [4.54952271e-08 9.91361320e-01 8.63869209e-03]
 [4.26541611e-08 3.18513393e-01 6.81486607e-01]
 [2.59580712e-08 9.96504545e-01 3.49551695e-03]
 [2.19907379e-05 4.84802485e-01 5.15175581e-01]
 [4.31118004e-08 9.41489995e-01 5.85100614e-02]
 [4.66519836e-08 9.97702420e-01 2.29763123e-03]
 [6.42998899e-09 9.95645702e-01 4.35431255e-03]
 [3.82829413e-08 9.97851729e-01 2.14831042e-03]
 [6.54972894e-08 9.61478531e-01 3.85213383e-02]
 [6.54173036e-08 9.16620851e-01 8.33790451e-02]
 [1.83787336e-07 9.99939561e-01 6.02279360e-05]
 [2.19153321e-07 4.67567027e-01 5.32432735e-01]
 [1.81482135e-10 1.09119834e-02 9.89088058e-01]
 [1.15560703e-11 8.06520522e-01 1.93479478e-01]
 [1.94555145e-08 9.77419615e-01 2.25803703e-02]
 [6.30916341e-09 9.96797979e-01 3.20204208e-03]
 [2.75189564e-07 9.96972680e-01 3.02711176e-03]
 [1.37257405e-09 9.99836087e-01 1.63936420e-04]
 [1.00000000e+00 3.99564748e-20 4.49395911e-17]
 [1.70697925e-14 9.98490095e-01 1.50993757e-03]
 [1.00000000e+00 6.83348524e-34 1.64865175e-38]
 [1.24839814e-18 1.00000000e+00 0.00000000e+00]
 [1.48486594e-23 1.00000000e+00 2.75372885e-20]
 [4.00569319e-04 9.65345025e-01 3.42543945e-02]
 [4.20967332e-08 9.93666470e-01 6.33354764e-03]
 [2.91158386e-08 9.92672741e-01 7.32719852e-03]
 [4.98840924e-09 2.02711329e-01 7.97288656e-01]
 [5.82002135e-09 9.75926101e-01 2.40738653e-02]
 [4.31109326e-09 9.90942419e-01 9.05762706e-03]
 [3.76461362e-10 1.60366471e-03 9.98396337e-01]
 [1.00000000e+00 5.73401606e-26 1.23329269e-20]
 [4.79614091e-12 1.00000000e+00 2.16989426e-09]
 [9.26680100e-19 2.48964909e-07 9.99999762e-01]
 [6.92880375e-09 9.89985347e-01 1.00146718e-02]
 [3.17184790e-09 2.64122039e-01 7.35877931e-01]
 [5.69356489e-16 9.96670663e-01 3.32934153e-03]
 [4.93645036e-09 9.99715865e-01 2.84111593e-04]
 [1.13964926e-08 9.98020887e-01 1.97909889e-03]
 [1.78761947e-08 9.70241368e-01 2.97586210e-02]
 [1.77038277e-08 9.90390062e-01 9.60989203e-03]
 [6.07400086e-09 9.54869628e-01 4.51304279e-02]
 [2.00776196e-08 9.87054825e-01 1.29451929e-02]
 [1.00000000e+00 6.83348524e-34 1.64865175e-38]
 [1.05458560e-06 9.51613784e-01 4.83851284e-02]
 [1.00000000e+00 3.99564748e-20 4.49395911e-17]
 [6.55836351e-15 1.00000000e+00 0.00000000e+00]
 [3.69671440e-08 9.87218380e-01 1.27815744e-02]
 [4.98840924e-09 2.02711329e-01 7.97288656e-01]
 [7.87728839e-03 9.91087281e-29 9.92122710e-01]
 [1.90889775e-08 9.19424534e-01 8.05753991e-02]
 [1.26625457e-08 9.58177686e-01 4.18223105e-02]
 [2.88909447e-08 9.83906746e-01 1.60932671e-02]
 [1.00000000e+00 7.85833494e-34 1.52912561e-11]
 [1.67257745e-08 9.93623078e-01 6.37689885e-03]
 [1.00000000e+00 1.98100122e-13 7.89823795e-36]
 [1.16802772e-08 9.86674726e-01 1.33252544e-02]
 [1.00000000e+00 1.90874942e-26 1.09454685e-21]
 [1.21662138e-08 9.77187812e-01 2.28121895e-02]
 [6.55388854e-09 9.95992243e-01 4.00777627e-03]
 [1.94258845e-10 9.99773204e-01 2.26766439e-04]
 [1.00000000e+00 1.98100122e-13 7.89823795e-36]
 [5.69356489e-16 9.96670663e-01 3.32934153e-03]
 [6.58354224e-08 9.99994516e-01 5.34141964e-06]
 [4.00569319e-04 9.65345025e-01 3.42543945e-02]
 [3.00157340e-14 9.98570323e-01 1.42967037e-03]
 [1.44916710e-08 9.88114417e-01 1.18855564e-02]
 [6.73131995e-09 9.96693730e-01 3.30623356e-03]
 [4.02115719e-09 1.66016787e-01 8.33983183e-01]
 [6.81521186e-08 9.71916020e-01 2.80838683e-02]
 [6.30916341e-09 9.96797979e-01 3.20204208e-03]
 [6.03779550e-19 1.82388686e-02 9.81761158e-01]
 [5.79989035e-08 9.99088764e-01 9.11284762e-04]
 [3.70864726e-08 9.85092223e-01 1.49077429e-02]
 [9.43184641e-09 9.91950870e-01 8.04914348e-03]
 [1.94555145e-08 9.77419615e-01 2.25803703e-02]
 [5.49154633e-09 9.62606132e-01 3.73939276e-02]
 [8.73729190e-14 9.26198542e-01 7.38014802e-02]
 [2.38703610e-03 9.97612715e-01 1.99579773e-07]
 [6.07400086e-09 9.54869628e-01 4.51304279e-02]
 [9.99739230e-01 2.58989836e-04 1.83387863e-06]
 [1.00000000e+00 0.00000000e+00 1.69219955e-12]
 [7.87696486e-09 6.21401966e-01 3.78598094e-01]
 [6.55836351e-15 1.00000000e+00 0.00000000e+00]
 [1.48655541e-08 9.32010472e-01 6.79895505e-02]
 [4.56554239e-12 6.66743696e-01 3.33256304e-01]
 [1.55354343e-08 9.89979982e-01 1.00200064e-02]
 [2.02457002e-08 1.68115690e-01 8.31884265e-01]
 [1.00000000e+00 1.72922008e-26 1.80623076e-18]
 [2.83168884e-08 9.80816305e-01 1.91836730e-02]
 [1.00000000e+00 4.11653735e-15 1.82740718e-14]
 [1.56049662e-08 7.10392892e-01 2.89607078e-01]
 [9.98634242e-09 9.96324837e-01 3.67519190e-03]
 [1.00000000e+00 0.00000000e+00 0.00000000e+00]
 [1.12098303e-06 9.55185354e-01 4.48134430e-02]
 [5.79989035e-08 9.99088764e-01 9.11284762e-04]
 [2.05629344e-14 7.26555925e-07 9.99999285e-01]
 [2.03341930e-08 8.95247996e-01 1.04752019e-01]
 [1.22142794e-08 9.84084427e-01 1.59156434e-02]
 [6.46763576e-09 6.58506930e-01 3.41493040e-01]
 [4.47249136e-08 9.89271998e-01 1.07280454e-02]
 [5.69356489e-16 9.96670663e-01 3.32934153e-03]
 [2.26922092e-14 9.98398125e-01 1.60181359e-03]
 [3.04865111e-08 9.81098950e-01 1.89010147e-02]
 [7.82701540e-14 9.68244493e-01 3.17554474e-02]
 [2.05587600e-08 9.97334361e-01 2.66565848e-03]
 [7.45189652e-08 9.80869770e-01 1.91300903e-02]
 [2.16185665e-08 9.81103659e-01 1.88963842e-02]
 [2.86517956e-08 9.94707704e-01 5.29230479e-03]
 [6.30916341e-09 9.96797979e-01 3.20204208e-03]
 [1.00000000e+00 0.00000000e+00 1.69219955e-12]
 [9.99988794e-01 1.12246034e-05 2.89343993e-09]
 [4.98840924e-09 2.02711329e-01 7.97288656e-01]
 [4.00562641e-07 9.99999642e-01 3.36043462e-22]
 [4.93645036e-09 9.99715865e-01 2.84111593e-04]
 [4.15394048e-08 9.62254524e-01 3.77454236e-02]
 [5.27488997e-10 3.40221196e-01 6.59778833e-01]
 [1.00000000e+00 3.99564748e-20 4.49395911e-17]
 [5.82002135e-09 9.75926101e-01 2.40738653e-02]
 [9.31120869e-09 9.93319392e-01 6.68063574e-03]
 [3.46150948e-08 9.45389688e-01 5.46103306e-02]
 [7.04509251e-09 9.96873558e-01 3.12650553e-03]
 [1.84740001e-10 9.97583985e-01 2.41599209e-03]
 [1.00000000e+00 7.85833494e-34 1.52912561e-11]
 [4.89377726e-06 8.82818997e-01 1.17176056e-01]
 [6.90764460e-12 9.99996662e-01 3.29444333e-06]
 [1.20549393e-08 9.98204827e-01 1.79512776e-03]
 [5.02679054e-09 9.94740188e-01 5.25982678e-03]
 [1.59465845e-08 9.86910760e-01 1.30893076e-02]
 [1.89667517e-08 9.93699312e-01 6.30067335e-03]]
[1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 2 1 0 1 1 2 1 1 1 1 1 1 1 1 0 1 1 1 2 1 1
 1 2 1 1 1 1 0 0 1 2 1 2 1 1 1 1 1 1 1 2 2 1 1 1 1 1 0 1 0 1 1 1 1 1 2 1 1
 2 0 1 2 1 2 1 1 1 1 1 1 1 0 1 0 1 1 2 2 1 1 1 0 1 0 1 0 1 1 1 0 1 1 1 1 1
 1 2 1 1 2 1 1 1 1 1 1 1 1 0 0 1 1 1 1 1 2 0 1 0 1 1 0 1 1 2 1 1 1 1 1 1 1
 1 1 1 1 1 1 0 0 2 1 1 1 2 0 1 1 1 1 1 0 1 1 1 1 1 1]

 32/174 [====>.........................] - ETA: 2s
 64/174 [==========>...................] - ETA: 1s
 96/174 [===============>..............] - ETA: 1s
128/174 [=====================>........] - ETA: 0s
160/174 [==========================>...] - ETA: 0s
174/174 [==============================] - 3s 16ms/step
Test loss: 5.495672878177687
Test accuracy: 0.5114942549288958
[[14 40  4]
 [ 0 58  0]
 [ 8 33 17]]
