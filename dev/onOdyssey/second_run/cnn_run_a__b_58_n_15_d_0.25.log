Using TensorFlow backend.
WARNING:tensorflow:From /n/home00/nchou/.conda/envs/envi/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.
Instructions for updating:
Colocations handled automatically by placer.
WARNING:tensorflow:From /n/home00/nchou/.conda/envs/envi/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.
Instructions for updating:
Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.
cnn_aardvark_aug_concat.py:397: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor("in..., outputs=Tensor("de...)`
  model = Model(input=ins, output=dense2)
WARNING:tensorflow:From /n/home00/nchou/.conda/envs/envi/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.cast instead.
2019-11-07 09:04:02.720729: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
2019-11-07 09:04:02.725139: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2900000000 Hz
2019-11-07 09:04:02.725259: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x55d1feb49920 executing computations on platform Host. Devices:
2019-11-07 09:04:02.725279: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (0): <undefined>, <undefined>
[0.25]
Train on 348 samples, validate on 116 samples
Epoch 1/15

 58/348 [====>.........................] - ETA: 1:08 - loss: 0.6936 - acc: 0.4138
116/348 [=========>....................] - ETA: 40s - loss: 0.6961 - acc: 0.4310 
174/348 [==============>...............] - ETA: 27s - loss: 0.6914 - acc: 0.4483
232/348 [===================>..........] - ETA: 16s - loss: 0.6899 - acc: 0.4871
290/348 [========================>.....] - ETA: 7s - loss: 0.6832 - acc: 0.5069 
348/348 [==============================] - 49s 141ms/step - loss: 0.6789 - acc: 0.5287 - val_loss: 0.6437 - val_acc: 0.5862
Epoch 2/15

 58/348 [====>.........................] - ETA: 32s - loss: 0.6106 - acc: 0.7241
116/348 [=========>....................] - ETA: 25s - loss: 0.6055 - acc: 0.7241
174/348 [==============>...............] - ETA: 19s - loss: 0.5904 - acc: 0.7471
232/348 [===================>..........] - ETA: 12s - loss: 0.5725 - acc: 0.7500
290/348 [========================>.....] - ETA: 6s - loss: 0.5795 - acc: 0.7241 
348/348 [==============================] - 42s 120ms/step - loss: 0.5737 - acc: 0.7241 - val_loss: 0.6821 - val_acc: 0.5948
Epoch 3/15

 58/348 [====>.........................] - ETA: 32s - loss: 0.4900 - acc: 0.7414
116/348 [=========>....................] - ETA: 25s - loss: 0.4777 - acc: 0.7328
174/348 [==============>...............] - ETA: 19s - loss: 0.4805 - acc: 0.7471
232/348 [===================>..........] - ETA: 12s - loss: 0.4672 - acc: 0.7629
290/348 [========================>.....] - ETA: 6s - loss: 0.4631 - acc: 0.7793 
348/348 [==============================] - 41s 116ms/step - loss: 0.4679 - acc: 0.7759 - val_loss: 0.7700 - val_acc: 0.5517
Epoch 4/15

 58/348 [====>.........................] - ETA: 31s - loss: 0.3953 - acc: 0.8448
116/348 [=========>....................] - ETA: 24s - loss: 0.4021 - acc: 0.8276
174/348 [==============>...............] - ETA: 18s - loss: 0.4079 - acc: 0.8046
232/348 [===================>..........] - ETA: 12s - loss: 0.4003 - acc: 0.8190
290/348 [========================>.....] - ETA: 6s - loss: 0.3930 - acc: 0.8345 
348/348 [==============================] - 38s 108ms/step - loss: 0.3962 - acc: 0.8276 - val_loss: 0.8846 - val_acc: 0.6379
Epoch 5/15

 58/348 [====>.........................] - ETA: 27s - loss: 0.3851 - acc: 0.8966
116/348 [=========>....................] - ETA: 21s - loss: 0.3720 - acc: 0.8534
174/348 [==============>...............] - ETA: 16s - loss: 0.3696 - acc: 0.8333
232/348 [===================>..........] - ETA: 10s - loss: 0.3414 - acc: 0.8534
290/348 [========================>.....] - ETA: 5s - loss: 0.3444 - acc: 0.8483 
348/348 [==============================] - 35s 99ms/step - loss: 0.3334 - acc: 0.8534 - val_loss: 1.0799 - val_acc: 0.5517
Epoch 6/15

 58/348 [====>.........................] - ETA: 26s - loss: 0.3413 - acc: 0.7931
116/348 [=========>....................] - ETA: 21s - loss: 0.3639 - acc: 0.7931
174/348 [==============>...............] - ETA: 15s - loss: 0.3237 - acc: 0.8448
232/348 [===================>..........] - ETA: 10s - loss: 0.3102 - acc: 0.8534
290/348 [========================>.....] - ETA: 5s - loss: 0.2944 - acc: 0.8690 
348/348 [==============================] - 34s 97ms/step - loss: 0.2903 - acc: 0.8764 - val_loss: 1.1074 - val_acc: 0.6293
Epoch 7/15

 58/348 [====>.........................] - ETA: 25s - loss: 0.2348 - acc: 0.9310
116/348 [=========>....................] - ETA: 20s - loss: 0.2535 - acc: 0.9310
174/348 [==============>...............] - ETA: 15s - loss: 0.2468 - acc: 0.9253
232/348 [===================>..........] - ETA: 10s - loss: 0.2450 - acc: 0.9181
290/348 [========================>.....] - ETA: 5s - loss: 0.2396 - acc: 0.9172 
348/348 [==============================] - 33s 96ms/step - loss: 0.2414 - acc: 0.9224 - val_loss: 1.2216 - val_acc: 0.6552
Epoch 8/15

 58/348 [====>.........................] - ETA: 25s - loss: 0.2016 - acc: 0.9655
116/348 [=========>....................] - ETA: 20s - loss: 0.1908 - acc: 0.9569
174/348 [==============>...............] - ETA: 15s - loss: 0.2041 - acc: 0.9425
232/348 [===================>..........] - ETA: 10s - loss: 0.1913 - acc: 0.9483
290/348 [========================>.....] - ETA: 5s - loss: 0.2038 - acc: 0.9483 
348/348 [==============================] - 33s 96ms/step - loss: 0.2058 - acc: 0.9397 - val_loss: 1.2848 - val_acc: 0.6897
Epoch 9/15

 58/348 [====>.........................] - ETA: 26s - loss: 0.2227 - acc: 0.9483
116/348 [=========>....................] - ETA: 20s - loss: 0.2222 - acc: 0.9397
174/348 [==============>...............] - ETA: 15s - loss: 0.2011 - acc: 0.9425
232/348 [===================>..........] - ETA: 10s - loss: 0.1930 - acc: 0.9483
290/348 [========================>.....] - ETA: 5s - loss: 0.1884 - acc: 0.9448 
348/348 [==============================] - 33s 96ms/step - loss: 0.1831 - acc: 0.9511 - val_loss: 1.2948 - val_acc: 0.7069
Epoch 10/15

 58/348 [====>.........................] - ETA: 25s - loss: 0.1510 - acc: 0.9483
116/348 [=========>....................] - ETA: 20s - loss: 0.1242 - acc: 0.9655
174/348 [==============>...............] - ETA: 15s - loss: 0.1402 - acc: 0.9425
232/348 [===================>..........] - ETA: 10s - loss: 0.1564 - acc: 0.9310
290/348 [========================>.....] - ETA: 5s - loss: 0.1500 - acc: 0.9448 
348/348 [==============================] - 33s 94ms/step - loss: 0.1611 - acc: 0.9425 - val_loss: 1.3508 - val_acc: 0.6466
Epoch 11/15

 58/348 [====>.........................] - ETA: 26s - loss: 0.1093 - acc: 0.9828
116/348 [=========>....................] - ETA: 20s - loss: 0.1400 - acc: 0.9828
174/348 [==============>...............] - ETA: 15s - loss: 0.1451 - acc: 0.9828
232/348 [===================>..........] - ETA: 10s - loss: 0.1297 - acc: 0.9828
290/348 [========================>.....] - ETA: 5s - loss: 0.1266 - acc: 0.9793 
348/348 [==============================] - 33s 95ms/step - loss: 0.1355 - acc: 0.9684 - val_loss: 1.2740 - val_acc: 0.7759
Epoch 12/15

 58/348 [====>.........................] - ETA: 25s - loss: 0.1539 - acc: 0.9483
116/348 [=========>....................] - ETA: 20s - loss: 0.1174 - acc: 0.9655
174/348 [==============>...............] - ETA: 15s - loss: 0.1163 - acc: 0.9655
232/348 [===================>..........] - ETA: 10s - loss: 0.1198 - acc: 0.9741
290/348 [========================>.....] - ETA: 5s - loss: 0.1154 - acc: 0.9759 
348/348 [==============================] - 32s 92ms/step - loss: 0.1133 - acc: 0.9770 - val_loss: 1.3102 - val_acc: 0.6810
Epoch 13/15

 58/348 [====>.........................] - ETA: 24s - loss: 0.1280 - acc: 0.9828
116/348 [=========>....................] - ETA: 19s - loss: 0.1078 - acc: 0.9741
174/348 [==============>...............] - ETA: 14s - loss: 0.0954 - acc: 0.9770
232/348 [===================>..........] - ETA: 9s - loss: 0.0962 - acc: 0.9741 
290/348 [========================>.....] - ETA: 4s - loss: 0.0901 - acc: 0.9759
348/348 [==============================] - 31s 88ms/step - loss: 0.0940 - acc: 0.9770 - val_loss: 1.3173 - val_acc: 0.6983
Epoch 14/15

 58/348 [====>.........................] - ETA: 22s - loss: 0.0695 - acc: 1.0000
116/348 [=========>....................] - ETA: 18s - loss: 0.0685 - acc: 1.0000
174/348 [==============>...............] - ETA: 13s - loss: 0.0725 - acc: 1.0000
232/348 [===================>..........] - ETA: 9s - loss: 0.0697 - acc: 1.0000 
290/348 [========================>.....] - ETA: 4s - loss: 0.0769 - acc: 1.0000
348/348 [==============================] - 30s 85ms/step - loss: 0.0749 - acc: 1.0000 - val_loss: 1.3463 - val_acc: 0.7845
Epoch 15/15

 58/348 [====>.........................] - ETA: 23s - loss: 0.0879 - acc: 0.9655
116/348 [=========>....................] - ETA: 18s - loss: 0.0729 - acc: 0.9828
174/348 [==============>...............] - ETA: 13s - loss: 0.0738 - acc: 0.9828
232/348 [===================>..........] - ETA: 9s - loss: 0.0696 - acc: 0.9828 
290/348 [========================>.....] - ETA: 4s - loss: 0.0666 - acc: 0.9862
348/348 [==============================] - 30s 86ms/step - loss: 0.0687 - acc: 0.9856 - val_loss: 1.4967 - val_acc: 0.6810
Saved trained model at /n/holylfs03/LABS/berger_lab/nchou/saved_models/aardvark_aug11.h5 
[[9.9701583e-01 2.9842290e-03]
 [5.4449672e-01 4.5550326e-01]
 [1.0000000e+00 9.8001652e-13]
 [9.9781454e-01 2.1854432e-03]
 [9.9431074e-01 5.6892238e-03]
 [6.0904944e-01 3.9095053e-01]
 [1.6423274e-04 9.9983573e-01]
 [1.0000000e+00 1.9671686e-12]
 [9.9940979e-01 5.9019687e-04]
 [1.0000000e+00 3.6347467e-10]
 [9.9999642e-01 3.5869487e-06]
 [9.6102065e-01 3.8979311e-02]
 [4.5361435e-01 5.4638571e-01]
 [7.3280346e-01 2.6719654e-01]
 [8.6042690e-01 1.3957311e-01]
 [1.0000000e+00 2.3053443e-11]
 [2.4286091e-01 7.5713915e-01]
 [7.3398107e-01 2.6601893e-01]
 [9.9997342e-01 2.6607031e-05]
 [2.4998935e-03 9.9750012e-01]
 [1.6423274e-04 9.9983573e-01]
 [2.4286091e-01 7.5713915e-01]
 [4.3116847e-06 9.9999571e-01]
 [9.9431074e-01 5.6892238e-03]
 [7.3280346e-01 2.6719654e-01]
 [8.2639414e-01 1.7360589e-01]
 [6.2325716e-01 3.7674287e-01]
 [9.9999845e-01 1.5782161e-06]
 [8.2665628e-01 1.7334370e-01]
 [8.6042690e-01 1.3957311e-01]
 [9.9454284e-01 5.4571829e-03]
 [5.7194591e-01 4.2805412e-01]
 [1.9389720e-01 8.0610281e-01]
 [5.7732463e-01 4.2267534e-01]
 [1.0000000e+00 5.9105629e-15]
 [2.7234072e-04 9.9972767e-01]
 [1.0000000e+00 6.0642364e-18]
 [9.6102065e-01 3.8979311e-02]
 [3.4445578e-01 6.5554422e-01]
 [9.9454284e-01 5.4571829e-03]
 [9.9811304e-01 1.8870207e-03]
 [5.1706564e-02 9.4829351e-01]
 [1.2425759e-06 9.9999881e-01]
 [1.0000000e+00 9.8001652e-13]
 [5.8949286e-01 4.1050717e-01]
 [9.9983680e-01 1.6315855e-04]
 [9.9880183e-01 1.1981546e-03]
 [9.0559870e-01 9.4401322e-02]
 [3.9932735e-02 9.6006727e-01]
 [1.0000000e+00 6.0642364e-18]
 [3.0975146e-04 9.9969029e-01]
 [1.0000000e+00 6.0642364e-18]
 [1.0000000e+00 2.3053443e-11]
 [9.9934918e-01 6.5087300e-04]
 [6.9068390e-01 3.0931610e-01]
 [9.8236382e-01 1.7636191e-02]
 [1.6103771e-01 8.3896232e-01]
 [9.9454284e-01 5.4571829e-03]
 [5.6324190e-01 4.3675813e-01]
 [9.9431074e-01 5.6892238e-03]
 [1.0000000e+00 1.9671686e-12]
 [8.2639414e-01 1.7360589e-01]
 [9.9454284e-01 5.4571829e-03]
 [9.2342341e-01 7.6576628e-02]
 [1.6423274e-04 9.9983573e-01]
 [1.7537124e-02 9.8246288e-01]
 [9.2342341e-01 7.6576628e-02]
 [3.9932735e-02 9.6006727e-01]
 [9.6401721e-01 3.5982717e-02]
 [9.2682850e-01 7.3171534e-02]
 [3.1534247e-11 1.0000000e+00]
 [4.5635125e-01 5.4364878e-01]
 [3.9932735e-02 9.6006727e-01]
 [8.8432656e-24 1.0000000e+00]
 [5.1706564e-02 9.4829351e-01]
 [6.6465622e-01 3.3534381e-01]
 [5.1483375e-01 4.8516631e-01]
 [1.0000000e+00 1.9671686e-12]
 [9.6102065e-01 3.8979311e-02]
 [9.6102065e-01 3.8979311e-02]
 [1.0000000e+00 2.3053443e-11]
 [9.7636729e-01 2.3632664e-02]
 [9.2028940e-01 7.9710633e-02]
 [9.0559870e-01 9.4401322e-02]
 [4.3035427e-01 5.6964570e-01]
 [1.0000000e+00 3.6347467e-10]
 [1.0000000e+00 5.5317382e-16]
 [5.7194591e-01 4.2805412e-01]
 [1.0000000e+00 6.4352865e-17]
 [6.6774869e-01 3.3225131e-01]
 [1.9389720e-01 8.0610281e-01]
 [3.6447653e-01 6.3552350e-01]
 [1.0000000e+00 7.8688922e-12]
 [1.0000000e+00 1.0013356e-12]
 [9.9996150e-01 3.8532904e-05]
 [9.9781454e-01 2.1854432e-03]
 [1.0000000e+00 1.9671686e-12]
 [6.0525674e-01 3.9474326e-01]
 [1.9389720e-01 8.0610281e-01]
 [6.6959590e-01 3.3040407e-01]
 [9.7231883e-01 2.7681157e-02]
 [1.2425759e-06 9.9999881e-01]
 [1.0000000e+00 9.8001652e-13]
 [8.4547240e-01 1.5452763e-01]
 [6.7947268e-01 3.2052729e-01]
 [1.0000000e+00 3.6347467e-10]
 [9.5859542e-04 9.9904138e-01]
 [7.3849869e-01 2.6150131e-01]
 [1.0000000e+00 4.0876082e-28]
 [6.9068390e-01 3.0931610e-01]
 [9.9454284e-01 5.4571829e-03]
 [9.8719597e-01 1.2804050e-02]
 [9.9454284e-01 5.4571829e-03]
 [1.0000000e+00 4.0876082e-28]
 [9.6948022e-01 3.0519782e-02]
 [7.5547945e-01 2.4452056e-01]]
[0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 1 0 0 1 1 1 1 0 0 0 0 0 0 0 0 0 1 0 0 1 0
 0 1 0 0 1 1 0 0 0 0 0 1 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 1 1 0 1 0 0 1 1 1 1
 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 1 0 0 0 0 0 0 1 0 0 1 0 0 0 0 1 0 0 0 0
 0 0 0 0 0]

 32/116 [=======>......................] - ETA: 1s
 64/116 [===============>..............] - ETA: 0s
 96/116 [=======================>......] - ETA: 0s
116/116 [==============================] - 2s 19ms/step
Test loss: 2.523111442039753
Test accuracy: 0.6293103489382513
[[51  7]
 [36 22]]
