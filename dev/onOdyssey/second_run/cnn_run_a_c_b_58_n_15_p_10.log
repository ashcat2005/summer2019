Using TensorFlow backend.
WARNING:tensorflow:From /n/home00/nchou/.conda/envs/envi/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.
Instructions for updating:
Colocations handled automatically by placer.
cnn_aardvark_aug_concat.py:397: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor("in..., outputs=Tensor("de...)`
  model = Model(input=ins, output=dense2)
WARNING:tensorflow:From /n/home00/nchou/.conda/envs/envi/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.cast instead.
2019-11-07 09:04:15.784620: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
2019-11-07 09:04:15.788537: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2900000000 Hz
2019-11-07 09:04:15.788648: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x563142e2c080 executing computations on platform Host. Devices:
2019-11-07 09:04:15.788667: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (0): <undefined>, <undefined>
None
Train on 348 samples, validate on 116 samples
Epoch 1/15

 58/348 [====>.........................] - ETA: 15s - loss: 0.6980 - acc: 0.5345
116/348 [=========>....................] - ETA: 11s - loss: 0.6974 - acc: 0.5000
174/348 [==============>...............] - ETA: 8s - loss: 0.6998 - acc: 0.5057 
232/348 [===================>..........] - ETA: 5s - loss: 0.6991 - acc: 0.4914
290/348 [========================>.....] - ETA: 2s - loss: 0.6971 - acc: 0.5000
348/348 [==============================] - 19s 55ms/step - loss: 0.6962 - acc: 0.4943 - val_loss: 0.6890 - val_acc: 0.4655
Epoch 2/15

 58/348 [====>.........................] - ETA: 13s - loss: 0.6867 - acc: 0.5345
116/348 [=========>....................] - ETA: 11s - loss: 0.6907 - acc: 0.4914
174/348 [==============>...............] - ETA: 8s - loss: 0.6894 - acc: 0.5057 
232/348 [===================>..........] - ETA: 5s - loss: 0.6855 - acc: 0.5517
290/348 [========================>.....] - ETA: 2s - loss: 0.6854 - acc: 0.5552
348/348 [==============================] - 19s 53ms/step - loss: 0.6776 - acc: 0.5690 - val_loss: 0.6904 - val_acc: 0.5431
Epoch 3/15

 58/348 [====>.........................] - ETA: 13s - loss: 0.6724 - acc: 0.6379
116/348 [=========>....................] - ETA: 11s - loss: 0.6786 - acc: 0.5948
174/348 [==============>...............] - ETA: 8s - loss: 0.6723 - acc: 0.6322 
232/348 [===================>..........] - ETA: 5s - loss: 0.6647 - acc: 0.6164
290/348 [========================>.....] - ETA: 2s - loss: 0.6651 - acc: 0.6207
348/348 [==============================] - 19s 53ms/step - loss: 0.6653 - acc: 0.6092 - val_loss: 0.7036 - val_acc: 0.4655
Epoch 4/15

 58/348 [====>.........................] - ETA: 13s - loss: 0.6830 - acc: 0.5690
116/348 [=========>....................] - ETA: 11s - loss: 0.6687 - acc: 0.5776
174/348 [==============>...............] - ETA: 8s - loss: 0.6673 - acc: 0.5862 
232/348 [===================>..........] - ETA: 5s - loss: 0.6620 - acc: 0.5905
290/348 [========================>.....] - ETA: 2s - loss: 0.6541 - acc: 0.6000
348/348 [==============================] - 19s 54ms/step - loss: 0.6533 - acc: 0.5948 - val_loss: 0.7268 - val_acc: 0.5259
Epoch 5/15

 58/348 [====>.........................] - ETA: 13s - loss: 0.6404 - acc: 0.5690
116/348 [=========>....................] - ETA: 11s - loss: 0.6582 - acc: 0.5431
174/348 [==============>...............] - ETA: 8s - loss: 0.6484 - acc: 0.5805 
232/348 [===================>..........] - ETA: 5s - loss: 0.6459 - acc: 0.5862
290/348 [========================>.....] - ETA: 2s - loss: 0.6423 - acc: 0.5828
348/348 [==============================] - 19s 54ms/step - loss: 0.6435 - acc: 0.5833 - val_loss: 0.7546 - val_acc: 0.4914
Epoch 6/15

 58/348 [====>.........................] - ETA: 13s - loss: 0.5816 - acc: 0.6207
116/348 [=========>....................] - ETA: 11s - loss: 0.6038 - acc: 0.6379
174/348 [==============>...............] - ETA: 8s - loss: 0.6080 - acc: 0.6552 
232/348 [===================>..........] - ETA: 5s - loss: 0.6230 - acc: 0.6379
290/348 [========================>.....] - ETA: 2s - loss: 0.6360 - acc: 0.6103
348/348 [==============================] - 19s 54ms/step - loss: 0.6365 - acc: 0.6006 - val_loss: 0.7891 - val_acc: 0.4914
Epoch 7/15

 58/348 [====>.........................] - ETA: 13s - loss: 0.6190 - acc: 0.6724
116/348 [=========>....................] - ETA: 11s - loss: 0.6291 - acc: 0.6293
174/348 [==============>...............] - ETA: 8s - loss: 0.6330 - acc: 0.6322 
232/348 [===================>..........] - ETA: 5s - loss: 0.6256 - acc: 0.6379
290/348 [========================>.....] - ETA: 2s - loss: 0.6267 - acc: 0.6517
348/348 [==============================] - 19s 54ms/step - loss: 0.6268 - acc: 0.6379 - val_loss: 0.7946 - val_acc: 0.5776
Epoch 8/15

 58/348 [====>.........................] - ETA: 14s - loss: 0.6074 - acc: 0.6897
116/348 [=========>....................] - ETA: 11s - loss: 0.6288 - acc: 0.6466
174/348 [==============>...............] - ETA: 8s - loss: 0.6098 - acc: 0.6667 
232/348 [===================>..........] - ETA: 5s - loss: 0.6184 - acc: 0.6466
290/348 [========================>.....] - ETA: 2s - loss: 0.6150 - acc: 0.6621
348/348 [==============================] - 19s 54ms/step - loss: 0.6162 - acc: 0.6580 - val_loss: 0.8155 - val_acc: 0.5776
Epoch 9/15

 58/348 [====>.........................] - ETA: 14s - loss: 0.5890 - acc: 0.7414
116/348 [=========>....................] - ETA: 11s - loss: 0.6004 - acc: 0.6983
174/348 [==============>...............] - ETA: 8s - loss: 0.6054 - acc: 0.7126 
232/348 [===================>..........] - ETA: 5s - loss: 0.6147 - acc: 0.6897
290/348 [========================>.....] - ETA: 2s - loss: 0.6048 - acc: 0.6966
348/348 [==============================] - 19s 54ms/step - loss: 0.6069 - acc: 0.6753 - val_loss: 0.8265 - val_acc: 0.5776
Epoch 10/15

 58/348 [====>.........................] - ETA: 13s - loss: 0.6150 - acc: 0.7069
116/348 [=========>....................] - ETA: 11s - loss: 0.5966 - acc: 0.6983
174/348 [==============>...............] - ETA: 8s - loss: 0.5771 - acc: 0.7069 
232/348 [===================>..........] - ETA: 5s - loss: 0.5804 - acc: 0.7112
290/348 [========================>.....] - ETA: 2s - loss: 0.5891 - acc: 0.6966
348/348 [==============================] - 19s 54ms/step - loss: 0.5977 - acc: 0.6897 - val_loss: 0.8346 - val_acc: 0.6034
Epoch 11/15

 58/348 [====>.........................] - ETA: 14s - loss: 0.5874 - acc: 0.6552
116/348 [=========>....................] - ETA: 11s - loss: 0.5470 - acc: 0.7328
174/348 [==============>...............] - ETA: 8s - loss: 0.5649 - acc: 0.6954 
232/348 [===================>..........] - ETA: 5s - loss: 0.5859 - acc: 0.6724
290/348 [========================>.....] - ETA: 2s - loss: 0.5789 - acc: 0.6897
348/348 [==============================] - 19s 54ms/step - loss: 0.5886 - acc: 0.6724 - val_loss: 0.8526 - val_acc: 0.6207
Epoch 12/15

 58/348 [====>.........................] - ETA: 14s - loss: 0.5174 - acc: 0.7414
116/348 [=========>....................] - ETA: 11s - loss: 0.5673 - acc: 0.7069
174/348 [==============>...............] - ETA: 8s - loss: 0.5626 - acc: 0.7184 
232/348 [===================>..........] - ETA: 5s - loss: 0.5684 - acc: 0.7284
290/348 [========================>.....] - ETA: 2s - loss: 0.5801 - acc: 0.7000
348/348 [==============================] - 19s 54ms/step - loss: 0.5746 - acc: 0.7011 - val_loss: 0.8971 - val_acc: 0.5948
Epoch 13/15

 58/348 [====>.........................] - ETA: 14s - loss: 0.5637 - acc: 0.7069
116/348 [=========>....................] - ETA: 11s - loss: 0.5716 - acc: 0.6724
174/348 [==============>...............] - ETA: 8s - loss: 0.5903 - acc: 0.6494 
232/348 [===================>..........] - ETA: 5s - loss: 0.5691 - acc: 0.6853
290/348 [========================>.....] - ETA: 2s - loss: 0.5611 - acc: 0.6966
348/348 [==============================] - 19s 54ms/step - loss: 0.5614 - acc: 0.6897 - val_loss: 0.8906 - val_acc: 0.6034
Epoch 14/15

 58/348 [====>.........................] - ETA: 14s - loss: 0.5828 - acc: 0.6897
116/348 [=========>....................] - ETA: 11s - loss: 0.5700 - acc: 0.6638
174/348 [==============>...............] - ETA: 8s - loss: 0.5511 - acc: 0.7069 
232/348 [===================>..........] - ETA: 5s - loss: 0.5465 - acc: 0.7155
290/348 [========================>.....] - ETA: 2s - loss: 0.5457 - acc: 0.7103
348/348 [==============================] - 19s 54ms/step - loss: 0.5461 - acc: 0.7069 - val_loss: 0.9106 - val_acc: 0.5948
Epoch 15/15

 58/348 [====>.........................] - ETA: 13s - loss: 0.5948 - acc: 0.6207
116/348 [=========>....................] - ETA: 11s - loss: 0.5246 - acc: 0.7069
174/348 [==============>...............] - ETA: 8s - loss: 0.5367 - acc: 0.6839 
232/348 [===================>..........] - ETA: 5s - loss: 0.5472 - acc: 0.6552
290/348 [========================>.....] - ETA: 2s - loss: 0.5417 - acc: 0.6793
348/348 [==============================] - 19s 54ms/step - loss: 0.5407 - acc: 0.6810 - val_loss: 0.9147 - val_acc: 0.6121
Saved trained model at /n/holylfs03/LABS/berger_lab/nchou/saved_models/aardvark_aug11.h5 
[[6.72819793e-01 3.27180237e-01]
 [4.66446728e-01 5.33553243e-01]
 [7.13935256e-01 2.86064684e-01]
 [8.45492601e-01 1.54507384e-01]
 [6.43639088e-01 3.56360912e-01]
 [4.45567429e-01 5.54432631e-01]
 [2.87422508e-01 7.12577462e-01]
 [8.47347319e-01 1.52652696e-01]
 [5.96133769e-01 4.03866231e-01]
 [9.04785633e-01 9.52143297e-02]
 [1.83962390e-01 8.16037595e-01]
 [5.38795352e-01 4.61204678e-01]
 [4.25555199e-01 5.74444771e-01]
 [4.76952910e-01 5.23047149e-01]
 [3.84593606e-01 6.15406394e-01]
 [9.91203666e-01 8.79637990e-03]
 [4.20821339e-01 5.79178691e-01]
 [4.82116789e-01 5.17883301e-01]
 [6.80092871e-01 3.19907188e-01]
 [4.35429901e-01 5.64570069e-01]
 [2.87422508e-01 7.12577462e-01]
 [4.20821339e-01 5.79178691e-01]
 [1.37825280e-01 8.62174690e-01]
 [6.43639088e-01 3.56360912e-01]
 [4.76952910e-01 5.23047149e-01]
 [4.55586851e-01 5.44413149e-01]
 [4.69467580e-01 5.30532420e-01]
 [3.13922197e-01 6.86077833e-01]
 [4.43539709e-01 5.56460321e-01]
 [3.84593606e-01 6.15406394e-01]
 [4.17618334e-01 5.82381666e-01]
 [4.68541771e-01 5.31458139e-01]
 [4.93683517e-01 5.06316543e-01]
 [4.80966836e-01 5.19033194e-01]
 [9.12299156e-01 8.77008215e-02]
 [6.24029458e-01 3.75970542e-01]
 [9.88172591e-01 1.18273739e-02]
 [5.38795352e-01 4.61204678e-01]
 [4.49983209e-01 5.50016761e-01]
 [4.17618334e-01 5.82381666e-01]
 [3.86405259e-01 6.13594830e-01]
 [4.61739451e-01 5.38260520e-01]
 [9.81775403e-01 1.82245839e-02]
 [7.13935256e-01 2.86064684e-01]
 [3.36702853e-01 6.63297176e-01]
 [1.77523360e-01 8.22476625e-01]
 [3.97027522e-01 6.02972448e-01]
 [4.40957934e-01 5.59042096e-01]
 [4.32109177e-01 5.67890882e-01]
 [9.88172591e-01 1.18273739e-02]
 [4.42892266e-03 9.95571077e-01]
 [9.88172591e-01 1.18273739e-02]
 [9.91203666e-01 8.79637990e-03]
 [3.69898885e-01 6.30101144e-01]
 [4.82392102e-01 5.17607868e-01]
 [4.05128598e-01 5.94871402e-01]
 [4.23797578e-01 5.76202452e-01]
 [4.17618334e-01 5.82381666e-01]
 [4.93535429e-01 5.06464541e-01]
 [6.43639088e-01 3.56360912e-01]
 [8.47347319e-01 1.52652696e-01]
 [4.55586851e-01 5.44413149e-01]
 [4.17618334e-01 5.82381666e-01]
 [4.60078210e-01 5.39921761e-01]
 [2.87422508e-01 7.12577462e-01]
 [6.62130833e-01 3.37869197e-01]
 [4.60078210e-01 5.39921761e-01]
 [4.32109177e-01 5.67890882e-01]
 [3.59361708e-01 6.40638351e-01]
 [2.57365853e-01 7.42634118e-01]
 [9.99894261e-01 1.05766805e-04]
 [4.56840932e-01 5.43159068e-01]
 [4.32109177e-01 5.67890882e-01]
 [9.93967056e-01 6.03295630e-03]
 [4.61739451e-01 5.38260520e-01]
 [4.60019410e-01 5.39980590e-01]
 [5.08369446e-01 4.91630584e-01]
 [8.47347319e-01 1.52652696e-01]
 [5.38795352e-01 4.61204678e-01]
 [5.38795352e-01 4.61204678e-01]
 [9.91203666e-01 8.79637990e-03]
 [4.29839492e-01 5.70160449e-01]
 [3.02847296e-01 6.97152674e-01]
 [4.40957934e-01 5.59042096e-01]
 [2.46417329e-01 7.53582656e-01]
 [9.04785633e-01 9.52143297e-02]
 [1.07633396e-05 9.99989271e-01]
 [4.68541771e-01 5.31458139e-01]
 [9.24061894e-01 7.59381130e-02]
 [3.41816872e-01 6.58183157e-01]
 [4.93683517e-01 5.06316543e-01]
 [4.45435941e-01 5.54563999e-01]
 [1.22692123e-01 8.77307832e-01]
 [5.61542630e-01 4.38457340e-01]
 [8.59258771e-01 1.40741289e-01]
 [8.45492601e-01 1.54507384e-01]
 [8.47347319e-01 1.52652696e-01]
 [4.75832790e-01 5.24167240e-01]
 [4.93683517e-01 5.06316543e-01]
 [4.63644296e-01 5.36355674e-01]
 [4.42341268e-01 5.57658732e-01]
 [9.81775403e-01 1.82245839e-02]
 [7.13935256e-01 2.86064684e-01]
 [4.43329453e-01 5.56670547e-01]
 [4.73343581e-01 5.26656449e-01]
 [9.04785633e-01 9.52143297e-02]
 [5.36492825e-01 4.63507175e-01]
 [4.72323298e-01 5.27676761e-01]
 [9.91016865e-01 8.98308493e-03]
 [4.82392102e-01 5.17607868e-01]
 [4.17618334e-01 5.82381666e-01]
 [4.61353213e-01 5.38646758e-01]
 [4.17618334e-01 5.82381666e-01]
 [9.91016865e-01 8.98308493e-03]
 [4.07435149e-01 5.92564821e-01]
 [3.43722910e-01 6.56277061e-01]]
[0 1 0 0 0 1 1 0 0 0 1 0 1 1 1 0 1 1 0 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 0 0 0
 0 1 1 1 1 0 0 1 1 1 1 1 0 1 0 0 1 1 1 1 1 1 0 0 1 1 1 1 0 1 1 1 1 0 1 1 0
 1 1 0 0 0 0 0 1 1 1 1 0 1 1 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 1 1 0 0 1 0 1 1
 1 1 0 1 1]

 32/116 [=======>......................] - ETA: 1s
 64/116 [===============>..............] - ETA: 0s
 96/116 [=======================>......] - ETA: 0s
116/116 [==============================] - 2s 15ms/step
Test loss: 0.6673168108381075
Test accuracy: 0.6896551703584606
[[32 26]
 [10 48]]
