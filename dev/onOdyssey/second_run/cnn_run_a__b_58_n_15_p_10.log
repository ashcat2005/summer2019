Using TensorFlow backend.
WARNING:tensorflow:From /n/home00/nchou/.conda/envs/envi/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.
Instructions for updating:
Colocations handled automatically by placer.
cnn_aardvark_aug_concat.py:397: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor("in..., outputs=Tensor("de...)`
  model = Model(input=ins, output=dense2)
WARNING:tensorflow:From /n/home00/nchou/.conda/envs/envi/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.cast instead.
2019-11-07 09:05:02.647120: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
2019-11-07 09:05:02.734252: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2900000000 Hz
2019-11-07 09:05:02.734481: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x56507aecee30 executing computations on platform Host. Devices:
2019-11-07 09:05:02.734533: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (0): <undefined>, <undefined>
None
Train on 348 samples, validate on 116 samples
Epoch 1/15

 58/348 [====>.........................] - ETA: 22s - loss: 0.6875 - acc: 0.5517
116/348 [=========>....................] - ETA: 12s - loss: 0.6972 - acc: 0.5345
174/348 [==============>...............] - ETA: 8s - loss: 0.7027 - acc: 0.5000 
232/348 [===================>..........] - ETA: 5s - loss: 0.6966 - acc: 0.5259
290/348 [========================>.....] - ETA: 2s - loss: 0.6967 - acc: 0.5138
348/348 [==============================] - 15s 44ms/step - loss: 0.6946 - acc: 0.5259 - val_loss: 0.6903 - val_acc: 0.5517
Epoch 2/15

 58/348 [====>.........................] - ETA: 9s - loss: 0.6826 - acc: 0.6897
116/348 [=========>....................] - ETA: 7s - loss: 0.6784 - acc: 0.6897
174/348 [==============>...............] - ETA: 5s - loss: 0.6758 - acc: 0.6897
232/348 [===================>..........] - ETA: 3s - loss: 0.6678 - acc: 0.6897
290/348 [========================>.....] - ETA: 1s - loss: 0.6677 - acc: 0.6897
348/348 [==============================] - 12s 36ms/step - loss: 0.6675 - acc: 0.6782 - val_loss: 0.6929 - val_acc: 0.4483
Epoch 3/15

 58/348 [====>.........................] - ETA: 9s - loss: 0.6623 - acc: 0.6552
116/348 [=========>....................] - ETA: 7s - loss: 0.6589 - acc: 0.6552
174/348 [==============>...............] - ETA: 5s - loss: 0.6522 - acc: 0.6552
232/348 [===================>..........] - ETA: 3s - loss: 0.6494 - acc: 0.6897
290/348 [========================>.....] - ETA: 1s - loss: 0.6479 - acc: 0.6828
348/348 [==============================] - 12s 36ms/step - loss: 0.6473 - acc: 0.6695 - val_loss: 0.7046 - val_acc: 0.5690
Epoch 4/15

 58/348 [====>.........................] - ETA: 9s - loss: 0.6412 - acc: 0.6724
116/348 [=========>....................] - ETA: 7s - loss: 0.6220 - acc: 0.7155
174/348 [==============>...............] - ETA: 5s - loss: 0.6240 - acc: 0.7184
232/348 [===================>..........] - ETA: 3s - loss: 0.6196 - acc: 0.7241
290/348 [========================>.....] - ETA: 1s - loss: 0.6243 - acc: 0.7069
348/348 [==============================] - 13s 36ms/step - loss: 0.6276 - acc: 0.7040 - val_loss: 0.7243 - val_acc: 0.5776
Epoch 5/15

 58/348 [====>.........................] - ETA: 9s - loss: 0.6232 - acc: 0.6552
116/348 [=========>....................] - ETA: 7s - loss: 0.5961 - acc: 0.7328
174/348 [==============>...............] - ETA: 5s - loss: 0.6033 - acc: 0.7299
232/348 [===================>..........] - ETA: 3s - loss: 0.6083 - acc: 0.7069
290/348 [========================>.....] - ETA: 1s - loss: 0.6061 - acc: 0.6966
348/348 [==============================] - 12s 36ms/step - loss: 0.6065 - acc: 0.7040 - val_loss: 0.7544 - val_acc: 0.5690
Epoch 6/15

 58/348 [====>.........................] - ETA: 9s - loss: 0.5812 - acc: 0.7586
116/348 [=========>....................] - ETA: 7s - loss: 0.6042 - acc: 0.7069
174/348 [==============>...............] - ETA: 5s - loss: 0.5918 - acc: 0.7126
232/348 [===================>..........] - ETA: 3s - loss: 0.5907 - acc: 0.7198
290/348 [========================>.....] - ETA: 1s - loss: 0.5853 - acc: 0.7103
348/348 [==============================] - 12s 36ms/step - loss: 0.5850 - acc: 0.7040 - val_loss: 0.7991 - val_acc: 0.5690
Epoch 7/15

 58/348 [====>.........................] - ETA: 9s - loss: 0.5807 - acc: 0.6897
116/348 [=========>....................] - ETA: 7s - loss: 0.5911 - acc: 0.6724
174/348 [==============>...............] - ETA: 5s - loss: 0.5742 - acc: 0.6954
232/348 [===================>..........] - ETA: 3s - loss: 0.5625 - acc: 0.7198
290/348 [========================>.....] - ETA: 1s - loss: 0.5614 - acc: 0.7172
348/348 [==============================] - 13s 36ms/step - loss: 0.5630 - acc: 0.7069 - val_loss: 0.8426 - val_acc: 0.5862
Epoch 8/15

 58/348 [====>.........................] - ETA: 9s - loss: 0.6093 - acc: 0.6552
116/348 [=========>....................] - ETA: 7s - loss: 0.5799 - acc: 0.6810
174/348 [==============>...............] - ETA: 5s - loss: 0.5592 - acc: 0.6839
232/348 [===================>..........] - ETA: 3s - loss: 0.5588 - acc: 0.6940
290/348 [========================>.....] - ETA: 1s - loss: 0.5462 - acc: 0.7172
348/348 [==============================] - 12s 36ms/step - loss: 0.5437 - acc: 0.7184 - val_loss: 0.9050 - val_acc: 0.5862
Epoch 9/15

 58/348 [====>.........................] - ETA: 9s - loss: 0.5171 - acc: 0.7759
116/348 [=========>....................] - ETA: 7s - loss: 0.5188 - acc: 0.7414
174/348 [==============>...............] - ETA: 5s - loss: 0.5147 - acc: 0.7471
232/348 [===================>..........] - ETA: 3s - loss: 0.5275 - acc: 0.7284
290/348 [========================>.....] - ETA: 1s - loss: 0.5233 - acc: 0.7172
348/348 [==============================] - 12s 36ms/step - loss: 0.5242 - acc: 0.7126 - val_loss: 0.9590 - val_acc: 0.5690
Epoch 10/15

 58/348 [====>.........................] - ETA: 9s - loss: 0.5438 - acc: 0.6897
116/348 [=========>....................] - ETA: 7s - loss: 0.5349 - acc: 0.7155
174/348 [==============>...............] - ETA: 5s - loss: 0.5451 - acc: 0.6954
232/348 [===================>..........] - ETA: 3s - loss: 0.5190 - acc: 0.7328
290/348 [========================>.....] - ETA: 1s - loss: 0.5203 - acc: 0.7276
348/348 [==============================] - 13s 36ms/step - loss: 0.5058 - acc: 0.7356 - val_loss: 1.0194 - val_acc: 0.5948
Epoch 11/15

 58/348 [====>.........................] - ETA: 9s - loss: 0.5029 - acc: 0.7759
116/348 [=========>....................] - ETA: 7s - loss: 0.5031 - acc: 0.7414
174/348 [==============>...............] - ETA: 5s - loss: 0.4969 - acc: 0.7414
232/348 [===================>..........] - ETA: 3s - loss: 0.4905 - acc: 0.7414
290/348 [========================>.....] - ETA: 1s - loss: 0.4958 - acc: 0.7345
348/348 [==============================] - 13s 36ms/step - loss: 0.4912 - acc: 0.7328 - val_loss: 1.0552 - val_acc: 0.5862
Epoch 12/15

 58/348 [====>.........................] - ETA: 9s - loss: 0.4852 - acc: 0.7414
116/348 [=========>....................] - ETA: 7s - loss: 0.5014 - acc: 0.7241
174/348 [==============>...............] - ETA: 5s - loss: 0.5000 - acc: 0.7184
232/348 [===================>..........] - ETA: 3s - loss: 0.4829 - acc: 0.7457
290/348 [========================>.....] - ETA: 1s - loss: 0.4783 - acc: 0.7552
348/348 [==============================] - 12s 36ms/step - loss: 0.4742 - acc: 0.7586 - val_loss: 1.0962 - val_acc: 0.5948
Epoch 13/15

 58/348 [====>.........................] - ETA: 9s - loss: 0.4477 - acc: 0.7586
116/348 [=========>....................] - ETA: 7s - loss: 0.4544 - acc: 0.7931
174/348 [==============>...............] - ETA: 5s - loss: 0.4423 - acc: 0.8046
232/348 [===================>..........] - ETA: 3s - loss: 0.4430 - acc: 0.7931
290/348 [========================>.....] - ETA: 1s - loss: 0.4450 - acc: 0.7931
348/348 [==============================] - 12s 36ms/step - loss: 0.4595 - acc: 0.7759 - val_loss: 1.1669 - val_acc: 0.5517
Epoch 14/15

 58/348 [====>.........................] - ETA: 9s - loss: 0.4794 - acc: 0.8103
116/348 [=========>....................] - ETA: 7s - loss: 0.4785 - acc: 0.7845
174/348 [==============>...............] - ETA: 5s - loss: 0.4438 - acc: 0.7989
232/348 [===================>..........] - ETA: 3s - loss: 0.4419 - acc: 0.7974
290/348 [========================>.....] - ETA: 1s - loss: 0.4381 - acc: 0.7966
348/348 [==============================] - 12s 36ms/step - loss: 0.4461 - acc: 0.7816 - val_loss: 1.2085 - val_acc: 0.6121
Epoch 15/15

 58/348 [====>.........................] - ETA: 9s - loss: 0.4469 - acc: 0.8276
116/348 [=========>....................] - ETA: 7s - loss: 0.4129 - acc: 0.8190
174/348 [==============>...............] - ETA: 5s - loss: 0.4122 - acc: 0.7989
232/348 [===================>..........] - ETA: 3s - loss: 0.4221 - acc: 0.7931
290/348 [========================>.....] - ETA: 1s - loss: 0.4322 - acc: 0.7897
348/348 [==============================] - 13s 36ms/step - loss: 0.4306 - acc: 0.7902 - val_loss: 1.2551 - val_acc: 0.5690
Saved trained model at /n/holylfs03/LABS/berger_lab/nchou/saved_models/aardvark_aug11.h5 
[[7.4384832e-01 2.5615165e-01]
 [4.2368245e-01 5.7631761e-01]
 [9.6646655e-01 3.3533439e-02]
 [8.7540692e-01 1.2459302e-01]
 [5.2788991e-01 4.7211006e-01]
 [5.0145811e-01 4.9854183e-01]
 [4.5104735e-03 9.9548954e-01]
 [9.5401043e-01 4.5989539e-02]
 [6.0614824e-01 3.9385176e-01]
 [9.9143255e-01 8.5674552e-03]
 [6.1766231e-01 3.8233766e-01]
 [4.9871415e-01 5.0128579e-01]
 [4.4093728e-01 5.5906272e-01]
 [4.1222933e-01 5.8777070e-01]
 [3.1587130e-01 6.8412876e-01]
 [9.9880624e-01 1.1937682e-03]
 [2.4408391e-01 7.5591612e-01]
 [5.5793929e-01 4.4206077e-01]
 [6.3455409e-01 3.6544588e-01]
 [1.0773561e-01 8.9226443e-01]
 [4.5104735e-03 9.9548954e-01]
 [2.4408391e-01 7.5591612e-01]
 [2.0855188e-01 7.9144818e-01]
 [5.2788991e-01 4.7211006e-01]
 [4.1222933e-01 5.8777070e-01]
 [2.6140273e-01 7.3859727e-01]
 [4.3844423e-01 5.6155574e-01]
 [5.7282919e-01 4.2717078e-01]
 [5.5961281e-01 4.4038722e-01]
 [3.1587130e-01 6.8412876e-01]
 [5.2721673e-01 4.7278324e-01]
 [5.3349364e-01 4.6650630e-01]
 [3.8438606e-01 6.1561394e-01]
 [6.0230649e-01 3.9769351e-01]
 [9.5295763e-01 4.7042292e-02]
 [4.1826344e-01 5.8173656e-01]
 [1.9778365e-05 9.9998021e-01]
 [4.9871415e-01 5.0128579e-01]
 [5.3587943e-01 4.6412063e-01]
 [5.2721673e-01 4.7278324e-01]
 [2.9874405e-01 7.0125592e-01]
 [3.9612406e-01 6.0387599e-01]
 [1.6250399e-12 1.0000000e+00]
 [9.6646655e-01 3.3533439e-02]
 [4.0880874e-01 5.9119129e-01]
 [6.8000531e-01 3.1999469e-01]
 [3.1647226e-01 6.8352777e-01]
 [4.3420923e-01 5.6579083e-01]
 [3.5016063e-01 6.4983940e-01]
 [1.9778365e-05 9.9998021e-01]
 [6.8227719e-03 9.9317718e-01]
 [1.9778365e-05 9.9998021e-01]
 [9.9880624e-01 1.1937682e-03]
 [7.6370496e-01 2.3629504e-01]
 [5.5944425e-01 4.4055572e-01]
 [1.7005466e-03 9.9829942e-01]
 [6.4969575e-01 3.5030425e-01]
 [5.2721673e-01 4.7278324e-01]
 [5.0418603e-01 4.9581403e-01]
 [5.2788991e-01 4.7211006e-01]
 [9.5401043e-01 4.5989539e-02]
 [2.6140273e-01 7.3859727e-01]
 [5.2721673e-01 4.7278324e-01]
 [7.6542389e-01 2.3457614e-01]
 [4.5104735e-03 9.9548954e-01]
 [7.2322094e-01 2.7677909e-01]
 [7.6542389e-01 2.3457614e-01]
 [3.5016063e-01 6.4983940e-01]
 [4.3101165e-01 5.6898838e-01]
 [5.7115340e-01 4.2884657e-01]
 [9.0163335e-02 9.0983659e-01]
 [4.4418555e-01 5.5581445e-01]
 [3.5016063e-01 6.4983940e-01]
 [1.0000000e+00 3.3611677e-14]
 [3.9612406e-01 6.0387599e-01]
 [5.2305162e-01 4.7694832e-01]
 [6.8621290e-01 3.1378716e-01]
 [9.5401043e-01 4.5989539e-02]
 [4.9871415e-01 5.0128579e-01]
 [4.9871415e-01 5.0128579e-01]
 [9.9880624e-01 1.1937682e-03]
 [6.8446159e-01 3.1553844e-01]
 [3.1206277e-01 6.8793720e-01]
 [4.3420923e-01 5.6579083e-01]
 [3.5406464e-01 6.4593536e-01]
 [9.9143255e-01 8.5674552e-03]
 [4.9830967e-13 1.0000000e+00]
 [5.3349364e-01 4.6650630e-01]
 [2.4271719e-06 9.9999762e-01]
 [4.0381873e-01 5.9618127e-01]
 [3.8438606e-01 6.1561394e-01]
 [4.8314419e-01 5.1685590e-01]
 [1.1765390e-03 9.9882346e-01]
 [9.9953377e-01 4.6629127e-04]
 [9.6057916e-01 3.9420802e-02]
 [8.7540692e-01 1.2459302e-01]
 [9.5401043e-01 4.5989539e-02]
 [4.1118434e-01 5.8881563e-01]
 [3.8438606e-01 6.1561394e-01]
 [4.9479693e-01 5.0520313e-01]
 [9.6744072e-01 3.2559264e-02]
 [1.6250399e-12 1.0000000e+00]
 [9.6646655e-01 3.3533439e-02]
 [6.7251325e-01 3.2748678e-01]
 [4.9443805e-01 5.0556201e-01]
 [9.9143255e-01 8.5674552e-03]
 [4.2278761e-01 5.7721239e-01]
 [5.1696914e-01 4.8303083e-01]
 [9.9999976e-01 1.9974202e-07]
 [5.5944425e-01 4.4055572e-01]
 [5.2721673e-01 4.7278324e-01]
 [6.0149437e-01 3.9850557e-01]
 [5.2721673e-01 4.7278324e-01]
 [9.9999976e-01 1.9974202e-07]
 [3.8032380e-01 6.1967623e-01]
 [3.7330639e-01 6.2669367e-01]]
[0 1 0 0 0 0 1 0 0 0 0 1 1 1 1 0 1 0 0 1 1 1 1 0 1 1 1 0 0 1 0 0 1 0 0 1 1
 1 0 0 1 1 1 0 1 0 1 1 1 1 1 1 0 0 0 1 0 0 0 0 0 1 0 0 1 0 0 1 1 0 1 1 1 0
 1 0 0 0 1 1 0 0 1 1 1 0 1 0 1 1 1 1 1 0 0 0 0 1 1 1 0 1 0 0 1 0 1 0 0 0 0
 0 0 0 1 1]

 32/116 [=======>......................] - ETA: 1s
 64/116 [===============>..............] - ETA: 0s
 96/116 [=======================>......] - ETA: 0s
116/116 [==============================] - 2s 13ms/step
Test loss: 1.0240028192257058
Test accuracy: 0.6810344827586207
[[40 18]
 [19 39]]
