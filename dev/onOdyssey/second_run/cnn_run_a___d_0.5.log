Using TensorFlow backend.
WARNING:tensorflow:From /n/home00/nchou/.conda/envs/envi/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.
Instructions for updating:
Colocations handled automatically by placer.
WARNING:tensorflow:From /n/home00/nchou/.conda/envs/envi/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.
Instructions for updating:
Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.
cnn_aardvark_aug_concat.py:397: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor("in..., outputs=Tensor("de...)`
  model = Model(input=ins, output=dense2)
WARNING:tensorflow:From /n/home00/nchou/.conda/envs/envi/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.cast instead.
2019-11-07 09:04:53.587019: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
2019-11-07 09:04:53.632416: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2900000000 Hz
2019-11-07 09:04:53.632643: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x55b2b2a45ec0 executing computations on platform Host. Devices:
2019-11-07 09:04:53.632687: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (0): <undefined>, <undefined>
[0.5]
Train on 348 samples, validate on 116 samples
Epoch 1/35

348/348 [==============================] - 23s 66ms/step - loss: 0.6937 - acc: 0.4684 - val_loss: 0.6708 - val_acc: 0.5776
Epoch 2/35

348/348 [==============================] - 19s 53ms/step - loss: 0.6511 - acc: 0.7644 - val_loss: 0.6557 - val_acc: 0.5603
Epoch 3/35

348/348 [==============================] - 19s 53ms/step - loss: 0.6043 - acc: 0.7557 - val_loss: 0.6587 - val_acc: 0.5431
Epoch 4/35

348/348 [==============================] - 19s 54ms/step - loss: 0.5593 - acc: 0.7069 - val_loss: 0.6637 - val_acc: 0.6293
Epoch 5/35

348/348 [==============================] - 19s 54ms/step - loss: 0.5198 - acc: 0.8333 - val_loss: 0.6980 - val_acc: 0.5345
Epoch 6/35

348/348 [==============================] - 19s 54ms/step - loss: 0.4899 - acc: 0.7126 - val_loss: 0.7049 - val_acc: 0.6121
Epoch 7/35

348/348 [==============================] - 19s 54ms/step - loss: 0.4668 - acc: 0.7730 - val_loss: 0.7261 - val_acc: 0.5948
Epoch 8/35

348/348 [==============================] - 19s 53ms/step - loss: 0.4281 - acc: 0.8218 - val_loss: 0.7720 - val_acc: 0.5517
Epoch 9/35

348/348 [==============================] - 19s 53ms/step - loss: 0.4148 - acc: 0.7644 - val_loss: 0.7814 - val_acc: 0.6552
Epoch 10/35

348/348 [==============================] - 19s 53ms/step - loss: 0.3877 - acc: 0.8649 - val_loss: 0.8120 - val_acc: 0.6121
Epoch 11/35

348/348 [==============================] - 19s 53ms/step - loss: 0.3762 - acc: 0.8362 - val_loss: 0.8507 - val_acc: 0.6379
Epoch 12/35

348/348 [==============================] - 19s 54ms/step - loss: 0.3547 - acc: 0.8678 - val_loss: 0.9090 - val_acc: 0.6034
Epoch 13/35

348/348 [==============================] - 19s 54ms/step - loss: 0.3408 - acc: 0.8448 - val_loss: 0.9546 - val_acc: 0.6121
Epoch 14/35

348/348 [==============================] - 19s 54ms/step - loss: 0.3263 - acc: 0.8563 - val_loss: 0.9837 - val_acc: 0.6466
Epoch 15/35

348/348 [==============================] - 19s 54ms/step - loss: 0.3106 - acc: 0.8879 - val_loss: 1.0296 - val_acc: 0.6293
Epoch 16/35

348/348 [==============================] - 19s 54ms/step - loss: 0.3000 - acc: 0.8879 - val_loss: 1.0767 - val_acc: 0.6724
Epoch 17/35

348/348 [==============================] - 19s 53ms/step - loss: 0.2842 - acc: 0.9138 - val_loss: 1.1277 - val_acc: 0.6293
Epoch 18/35

348/348 [==============================] - 19s 54ms/step - loss: 0.2755 - acc: 0.8879 - val_loss: 1.1491 - val_acc: 0.6638
Epoch 19/35

348/348 [==============================] - 19s 54ms/step - loss: 0.2609 - acc: 0.9167 - val_loss: 1.1829 - val_acc: 0.6466
Epoch 20/35

348/348 [==============================] - 19s 54ms/step - loss: 0.2529 - acc: 0.9080 - val_loss: 1.2229 - val_acc: 0.6724
Epoch 21/35

348/348 [==============================] - 19s 54ms/step - loss: 0.2396 - acc: 0.9339 - val_loss: 1.2488 - val_acc: 0.6638
Epoch 22/35

348/348 [==============================] - 19s 54ms/step - loss: 0.2318 - acc: 0.9368 - val_loss: 1.2474 - val_acc: 0.6724
Epoch 23/35

348/348 [==============================] - 19s 54ms/step - loss: 0.2204 - acc: 0.9224 - val_loss: 1.2621 - val_acc: 0.6724
Epoch 24/35

348/348 [==============================] - 19s 54ms/step - loss: 0.2113 - acc: 0.9253 - val_loss: 1.2949 - val_acc: 0.6638
Epoch 25/35

348/348 [==============================] - 18s 53ms/step - loss: 0.2033 - acc: 0.9540 - val_loss: 1.2962 - val_acc: 0.6810
Epoch 26/35

348/348 [==============================] - 19s 54ms/step - loss: 0.1921 - acc: 0.9483 - val_loss: 1.3057 - val_acc: 0.6724
Epoch 27/35

348/348 [==============================] - 19s 53ms/step - loss: 0.1855 - acc: 0.9425 - val_loss: 1.3288 - val_acc: 0.6552
Epoch 28/35

348/348 [==============================] - 19s 53ms/step - loss: 0.1779 - acc: 0.9626 - val_loss: 1.3213 - val_acc: 0.6724
Epoch 29/35

348/348 [==============================] - 19s 54ms/step - loss: 0.1679 - acc: 0.9598 - val_loss: 1.3263 - val_acc: 0.6810
Epoch 30/35

348/348 [==============================] - 19s 54ms/step - loss: 0.1603 - acc: 0.9655 - val_loss: 1.3471 - val_acc: 0.6638
Epoch 31/35

348/348 [==============================] - 19s 54ms/step - loss: 0.1550 - acc: 0.9713 - val_loss: 1.3312 - val_acc: 0.7069
Epoch 32/35

348/348 [==============================] - 19s 54ms/step - loss: 0.1492 - acc: 0.9511 - val_loss: 1.3524 - val_acc: 0.6810
Epoch 33/35

348/348 [==============================] - 18s 53ms/step - loss: 0.1411 - acc: 0.9713 - val_loss: 1.3315 - val_acc: 0.6810
Epoch 34/35

348/348 [==============================] - 19s 54ms/step - loss: 0.1327 - acc: 0.9741 - val_loss: 1.3334 - val_acc: 0.7069
Epoch 35/35

348/348 [==============================] - 19s 53ms/step - loss: 0.1258 - acc: 0.9828 - val_loss: 1.3435 - val_acc: 0.6724
Saved trained model at /n/holylfs03/LABS/berger_lab/nchou/saved_models/aardvark_aug11.h5 
[[9.77275670e-01 2.27242690e-02]
 [2.64606535e-01 7.35393465e-01]
 [1.00000000e+00 1.82470998e-08]
 [9.75561798e-01 2.44382340e-02]
 [9.84823465e-01 1.51765440e-02]
 [4.30004150e-01 5.69995880e-01]
 [2.65669398e-04 9.99734342e-01]
 [1.00000000e+00 5.59700940e-12]
 [9.95773613e-01 4.22636047e-03]
 [1.00000000e+00 1.08722373e-08]
 [9.96308863e-01 3.69116943e-03]
 [6.43993497e-01 3.56006503e-01]
 [3.50258976e-01 6.49740934e-01]
 [5.54911435e-01 4.45088536e-01]
 [2.92447478e-01 7.07552493e-01]
 [9.99974847e-01 2.51203928e-05]
 [1.83284611e-01 8.16715419e-01]
 [5.83931327e-01 4.16068643e-01]
 [9.98513520e-01 1.48646301e-03]
 [3.82979313e-04 9.99616981e-01]
 [2.65669398e-04 9.99734342e-01]
 [1.83284611e-01 8.16715419e-01]
 [7.29591775e-05 9.99927044e-01]
 [9.84823465e-01 1.51765440e-02]
 [5.54911435e-01 4.45088536e-01]
 [5.32986224e-01 4.67013806e-01]
 [5.29848874e-01 4.70151037e-01]
 [9.99684334e-01 3.15714016e-04]
 [6.29560590e-01 3.70439380e-01]
 [2.92447478e-01 7.07552493e-01]
 [7.14689076e-01 2.85310954e-01]
 [4.64346111e-01 5.35653830e-01]
 [2.90883988e-01 7.09115982e-01]
 [4.63502467e-01 5.36497533e-01]
 [1.00000000e+00 6.07063987e-13]
 [5.48658601e-04 9.99451339e-01]
 [1.00000000e+00 8.74961562e-12]
 [6.43993497e-01 3.56006503e-01]
 [3.93730402e-01 6.06269598e-01]
 [7.14689076e-01 2.85310954e-01]
 [8.70908856e-01 1.29091099e-01]
 [1.23112485e-01 8.76887560e-01]
 [5.53363085e-11 1.00000000e+00]
 [1.00000000e+00 1.82470998e-08]
 [3.49408269e-01 6.50591791e-01]
 [9.80177164e-01 1.98228601e-02]
 [9.63362932e-01 3.66371088e-02]
 [6.77018702e-01 3.22981238e-01]
 [1.32475689e-01 8.67524326e-01]
 [1.00000000e+00 8.74961562e-12]
 [1.62502343e-03 9.98374939e-01]
 [1.00000000e+00 8.74961562e-12]
 [9.99974847e-01 2.51203928e-05]
 [9.92533922e-01 7.46609783e-03]
 [6.22501910e-01 3.77498031e-01]
 [9.83724117e-01 1.62759032e-02]
 [3.69146079e-01 6.30853951e-01]
 [7.14689076e-01 2.85310954e-01]
 [4.53670800e-01 5.46329200e-01]
 [9.84823465e-01 1.51765440e-02]
 [1.00000000e+00 5.59700940e-12]
 [5.32986224e-01 4.67013806e-01]
 [7.14689076e-01 2.85310954e-01]
 [7.22054958e-01 2.77945012e-01]
 [2.65669398e-04 9.99734342e-01]
 [1.19276037e-02 9.88072395e-01]
 [7.22054958e-01 2.77945012e-01]
 [1.32475689e-01 8.67524326e-01]
 [2.54017651e-01 7.45982349e-01]
 [6.52459800e-01 3.47540200e-01]
 [1.27978055e-08 1.00000000e+00]
 [3.53467733e-01 6.46532238e-01]
 [1.32475689e-01 8.67524326e-01]
 [1.03693646e-14 1.00000000e+00]
 [1.23112485e-01 8.76887560e-01]
 [5.38572133e-01 4.61427897e-01]
 [5.04296482e-01 4.95703518e-01]
 [1.00000000e+00 5.59700940e-12]
 [6.43993497e-01 3.56006503e-01]
 [6.43993497e-01 3.56006503e-01]
 [9.99974847e-01 2.51203928e-05]
 [8.46491575e-01 1.53508365e-01]
 [4.54906642e-01 5.45093417e-01]
 [6.77018702e-01 3.22981238e-01]
 [2.57178366e-01 7.42821693e-01]
 [1.00000000e+00 1.08722373e-08]
 [1.00000000e+00 2.30088552e-11]
 [4.64346111e-01 5.35653830e-01]
 [1.00000000e+00 6.08822770e-10]
 [4.04834092e-01 5.95165968e-01]
 [2.90883988e-01 7.09115982e-01]
 [3.49847436e-01 6.50152564e-01]
 [9.75177348e-01 2.48227231e-02]
 [1.00000000e+00 5.38031344e-08]
 [9.99228477e-01 7.71475141e-04]
 [9.75561798e-01 2.44382340e-02]
 [1.00000000e+00 5.59700940e-12]
 [4.65384871e-01 5.34615159e-01]
 [2.90883988e-01 7.09115982e-01]
 [5.05576968e-01 4.94423032e-01]
 [8.80674601e-01 1.19325384e-01]
 [5.53363085e-11 1.00000000e+00]
 [1.00000000e+00 1.82470998e-08]
 [6.32780790e-01 3.67219210e-01]
 [6.07481539e-01 3.92518461e-01]
 [1.00000000e+00 1.08722373e-08]
 [4.65511205e-03 9.95344818e-01]
 [5.48496783e-01 4.51503247e-01]
 [1.00000000e+00 4.69163660e-20]
 [6.22501910e-01 3.77498031e-01]
 [7.14689076e-01 2.85310954e-01]
 [8.90807450e-01 1.09192602e-01]
 [7.14689076e-01 2.85310954e-01]
 [1.00000000e+00 4.69163660e-20]
 [3.86336476e-01 6.13663554e-01]
 [4.73716050e-01 5.26283979e-01]]
[0 1 0 0 0 1 1 0 0 0 0 0 1 0 1 0 1 0 0 1 1 1 1 0 0 0 0 0 0 1 0 1 1 1 0 1 0
 0 1 0 0 1 1 0 1 0 0 0 1 0 1 0 0 0 0 0 1 0 1 0 0 0 0 0 1 1 0 1 1 0 1 1 1 1
 1 0 0 0 0 0 0 0 1 0 1 0 0 1 0 1 1 1 0 0 0 0 0 1 1 0 0 1 0 0 0 0 1 0 0 0 0
 0 0 0 1 1]

 32/116 [=======>......................] - ETA: 1s
 64/116 [===============>..............] - ETA: 0s
 96/116 [=======================>......] - ETA: 0s
116/116 [==============================] - 2s 18ms/step
Test loss: 2.186308009871121
Test accuracy: 0.6896551683031279
[[47 11]
 [25 33]]
