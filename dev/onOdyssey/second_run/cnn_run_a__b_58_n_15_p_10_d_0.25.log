Using TensorFlow backend.
WARNING:tensorflow:From /n/home00/nchou/.conda/envs/envi/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.
Instructions for updating:
Colocations handled automatically by placer.
WARNING:tensorflow:From /n/home00/nchou/.conda/envs/envi/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.
Instructions for updating:
Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.
cnn_aardvark_aug_concat.py:397: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor("in..., outputs=Tensor("de...)`
  model = Model(input=ins, output=dense2)
WARNING:tensorflow:From /n/home00/nchou/.conda/envs/envi/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.cast instead.
2019-11-07 09:03:31.608356: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
2019-11-07 09:03:31.612292: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2900000000 Hz
2019-11-07 09:03:31.612402: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x5640d33d79f0 executing computations on platform Host. Devices:
2019-11-07 09:03:31.612435: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (0): <undefined>, <undefined>
[0.25]
Train on 348 samples, validate on 116 samples
Epoch 1/15

 58/348 [====>.........................] - ETA: 10s - loss: 0.6956 - acc: 0.5517
116/348 [=========>....................] - ETA: 8s - loss: 0.6934 - acc: 0.5776 
174/348 [==============>...............] - ETA: 6s - loss: 0.6922 - acc: 0.5977
232/348 [===================>..........] - ETA: 3s - loss: 0.6907 - acc: 0.5819
290/348 [========================>.....] - ETA: 1s - loss: 0.6914 - acc: 0.5552
348/348 [==============================] - 13s 38ms/step - loss: 0.6908 - acc: 0.5632 - val_loss: 0.6879 - val_acc: 0.5517
Epoch 2/15

 58/348 [====>.........................] - ETA: 9s - loss: 0.6678 - acc: 0.7241
116/348 [=========>....................] - ETA: 7s - loss: 0.6700 - acc: 0.6983
174/348 [==============>...............] - ETA: 5s - loss: 0.6693 - acc: 0.6667
232/348 [===================>..........] - ETA: 3s - loss: 0.6653 - acc: 0.6810
290/348 [========================>.....] - ETA: 1s - loss: 0.6677 - acc: 0.6759
348/348 [==============================] - 13s 37ms/step - loss: 0.6685 - acc: 0.6897 - val_loss: 0.6865 - val_acc: 0.4655
Epoch 3/15

 58/348 [====>.........................] - ETA: 9s - loss: 0.6560 - acc: 0.6724
116/348 [=========>....................] - ETA: 7s - loss: 0.6591 - acc: 0.6810
174/348 [==============>...............] - ETA: 5s - loss: 0.6529 - acc: 0.6897
232/348 [===================>..........] - ETA: 3s - loss: 0.6492 - acc: 0.6940
290/348 [========================>.....] - ETA: 1s - loss: 0.6492 - acc: 0.6862
348/348 [==============================] - 13s 37ms/step - loss: 0.6497 - acc: 0.6925 - val_loss: 0.6929 - val_acc: 0.5603
Epoch 4/15

 58/348 [====>.........................] - ETA: 9s - loss: 0.6562 - acc: 0.7069
116/348 [=========>....................] - ETA: 7s - loss: 0.6387 - acc: 0.7328
174/348 [==============>...............] - ETA: 5s - loss: 0.6366 - acc: 0.6954
232/348 [===================>..........] - ETA: 3s - loss: 0.6397 - acc: 0.6595
290/348 [========================>.....] - ETA: 1s - loss: 0.6374 - acc: 0.6517
348/348 [==============================] - 13s 37ms/step - loss: 0.6325 - acc: 0.6724 - val_loss: 0.7132 - val_acc: 0.5690
Epoch 5/15

 58/348 [====>.........................] - ETA: 9s - loss: 0.5918 - acc: 0.6897
116/348 [=========>....................] - ETA: 7s - loss: 0.6144 - acc: 0.7069
174/348 [==============>...............] - ETA: 5s - loss: 0.6074 - acc: 0.7299
232/348 [===================>..........] - ETA: 3s - loss: 0.6121 - acc: 0.7241
290/348 [========================>.....] - ETA: 1s - loss: 0.6150 - acc: 0.7241
348/348 [==============================] - 13s 37ms/step - loss: 0.6131 - acc: 0.7069 - val_loss: 0.7398 - val_acc: 0.5517
Epoch 6/15

 58/348 [====>.........................] - ETA: 9s - loss: 0.6240 - acc: 0.6552
116/348 [=========>....................] - ETA: 7s - loss: 0.5756 - acc: 0.7155
174/348 [==============>...............] - ETA: 5s - loss: 0.5697 - acc: 0.7184
232/348 [===================>..........] - ETA: 3s - loss: 0.5804 - acc: 0.7069
290/348 [========================>.....] - ETA: 1s - loss: 0.5818 - acc: 0.7172
348/348 [==============================] - 13s 37ms/step - loss: 0.5935 - acc: 0.7098 - val_loss: 0.7803 - val_acc: 0.5776
Epoch 7/15

 58/348 [====>.........................] - ETA: 9s - loss: 0.5793 - acc: 0.6379
116/348 [=========>....................] - ETA: 7s - loss: 0.5842 - acc: 0.6810
174/348 [==============>...............] - ETA: 5s - loss: 0.5921 - acc: 0.6609
232/348 [===================>..........] - ETA: 3s - loss: 0.5758 - acc: 0.7155
290/348 [========================>.....] - ETA: 1s - loss: 0.5669 - acc: 0.7138
348/348 [==============================] - 13s 37ms/step - loss: 0.5727 - acc: 0.7069 - val_loss: 0.8166 - val_acc: 0.5690
Epoch 8/15

 58/348 [====>.........................] - ETA: 9s - loss: 0.5525 - acc: 0.7586
116/348 [=========>....................] - ETA: 7s - loss: 0.5404 - acc: 0.7672
174/348 [==============>...............] - ETA: 5s - loss: 0.5475 - acc: 0.7471
232/348 [===================>..........] - ETA: 3s - loss: 0.5549 - acc: 0.7155
290/348 [========================>.....] - ETA: 1s - loss: 0.5564 - acc: 0.7000
348/348 [==============================] - 13s 37ms/step - loss: 0.5546 - acc: 0.7011 - val_loss: 0.8674 - val_acc: 0.5690
Epoch 9/15

 58/348 [====>.........................] - ETA: 9s - loss: 0.4640 - acc: 0.7586
116/348 [=========>....................] - ETA: 7s - loss: 0.4925 - acc: 0.7328
174/348 [==============>...............] - ETA: 5s - loss: 0.5180 - acc: 0.7241
232/348 [===================>..........] - ETA: 3s - loss: 0.5514 - acc: 0.6853
290/348 [========================>.....] - ETA: 1s - loss: 0.5359 - acc: 0.6966
348/348 [==============================] - 13s 37ms/step - loss: 0.5369 - acc: 0.6983 - val_loss: 0.9085 - val_acc: 0.5776
Epoch 10/15

 58/348 [====>.........................] - ETA: 9s - loss: 0.5531 - acc: 0.7414
116/348 [=========>....................] - ETA: 7s - loss: 0.5106 - acc: 0.7759
174/348 [==============>...............] - ETA: 5s - loss: 0.5189 - acc: 0.7414
232/348 [===================>..........] - ETA: 3s - loss: 0.5300 - acc: 0.7069
290/348 [========================>.....] - ETA: 1s - loss: 0.5268 - acc: 0.6966
348/348 [==============================] - 13s 37ms/step - loss: 0.5183 - acc: 0.7213 - val_loss: 0.9624 - val_acc: 0.5690
Epoch 11/15

 58/348 [====>.........................] - ETA: 9s - loss: 0.4757 - acc: 0.7069
116/348 [=========>....................] - ETA: 7s - loss: 0.5087 - acc: 0.6897
174/348 [==============>...............] - ETA: 5s - loss: 0.5325 - acc: 0.7011
232/348 [===================>..........] - ETA: 3s - loss: 0.5197 - acc: 0.7069
290/348 [========================>.....] - ETA: 1s - loss: 0.4982 - acc: 0.7207
348/348 [==============================] - 13s 37ms/step - loss: 0.5022 - acc: 0.7155 - val_loss: 1.0191 - val_acc: 0.5690
Epoch 12/15

 58/348 [====>.........................] - ETA: 9s - loss: 0.4739 - acc: 0.7931
116/348 [=========>....................] - ETA: 7s - loss: 0.4758 - acc: 0.7414
174/348 [==============>...............] - ETA: 5s - loss: 0.4683 - acc: 0.7644
232/348 [===================>..........] - ETA: 3s - loss: 0.4917 - acc: 0.7543
290/348 [========================>.....] - ETA: 1s - loss: 0.4942 - acc: 0.7552
348/348 [==============================] - 13s 37ms/step - loss: 0.4893 - acc: 0.7557 - val_loss: 1.0602 - val_acc: 0.5862
Epoch 13/15

 58/348 [====>.........................] - ETA: 9s - loss: 0.4917 - acc: 0.7414
116/348 [=========>....................] - ETA: 7s - loss: 0.4525 - acc: 0.7759
174/348 [==============>...............] - ETA: 5s - loss: 0.4463 - acc: 0.7874
232/348 [===================>..........] - ETA: 3s - loss: 0.4625 - acc: 0.7716
290/348 [========================>.....] - ETA: 1s - loss: 0.4716 - acc: 0.7586
348/348 [==============================] - 13s 37ms/step - loss: 0.4784 - acc: 0.7500 - val_loss: 1.0959 - val_acc: 0.5948
Epoch 14/15

 58/348 [====>.........................] - ETA: 9s - loss: 0.5442 - acc: 0.6724
116/348 [=========>....................] - ETA: 7s - loss: 0.4879 - acc: 0.7414
174/348 [==============>...............] - ETA: 5s - loss: 0.4652 - acc: 0.7701
232/348 [===================>..........] - ETA: 3s - loss: 0.4732 - acc: 0.7543
290/348 [========================>.....] - ETA: 1s - loss: 0.4682 - acc: 0.7621
348/348 [==============================] - 13s 37ms/step - loss: 0.4561 - acc: 0.7730 - val_loss: 1.1543 - val_acc: 0.5431
Epoch 15/15

 58/348 [====>.........................] - ETA: 9s - loss: 0.4321 - acc: 0.8276
116/348 [=========>....................] - ETA: 7s - loss: 0.4553 - acc: 0.7759
174/348 [==============>...............] - ETA: 5s - loss: 0.4658 - acc: 0.7644
232/348 [===================>..........] - ETA: 3s - loss: 0.4576 - acc: 0.7802
290/348 [========================>.....] - ETA: 1s - loss: 0.4431 - acc: 0.7793
348/348 [==============================] - 13s 37ms/step - loss: 0.4466 - acc: 0.7845 - val_loss: 1.1773 - val_acc: 0.6034
Saved trained model at /n/holylfs03/LABS/berger_lab/nchou/saved_models/aardvark_aug11.h5 
[[6.76337659e-01 3.23662341e-01]
 [3.71217310e-01 6.28782690e-01]
 [9.39553916e-01 6.04461208e-02]
 [8.22900414e-01 1.77099586e-01]
 [4.03403401e-01 5.96596658e-01]
 [4.36612993e-01 5.63387036e-01]
 [9.73678473e-03 9.90263224e-01]
 [9.40216184e-01 5.97837716e-02]
 [5.34684479e-01 4.65315521e-01]
 [9.89017010e-01 1.09829949e-02]
 [4.29044336e-01 5.70955634e-01]
 [4.07544166e-01 5.92455804e-01]
 [3.87164026e-01 6.12836003e-01]
 [3.55063558e-01 6.44936442e-01]
 [2.75166869e-01 7.24833071e-01]
 [9.88180280e-01 1.18197808e-02]
 [2.15076312e-01 7.84923673e-01]
 [4.79029715e-01 5.20970285e-01]
 [5.31240404e-01 4.68759656e-01]
 [1.14484981e-01 8.85515034e-01]
 [9.73678473e-03 9.90263224e-01]
 [2.15076312e-01 7.84923673e-01]
 [1.46923512e-01 8.53076458e-01]
 [4.03403401e-01 5.96596658e-01]
 [3.55063558e-01 6.44936442e-01]
 [2.42878154e-01 7.57121861e-01]
 [3.82260054e-01 6.17739916e-01]
 [4.21903372e-01 5.78096569e-01]
 [4.76036578e-01 5.23963392e-01]
 [2.75166869e-01 7.24833071e-01]
 [4.48604643e-01 5.51395416e-01]
 [4.59197193e-01 5.40802777e-01]
 [3.39646429e-01 6.60353482e-01]
 [5.18195868e-01 4.81804073e-01]
 [9.53005075e-01 4.69949804e-02]
 [3.74291837e-01 6.25708103e-01]
 [7.10733366e-05 9.99928951e-01]
 [4.07544166e-01 5.92455804e-01]
 [4.65536565e-01 5.34463465e-01]
 [4.48604643e-01 5.51395416e-01]
 [2.52113491e-01 7.47886539e-01]
 [3.52015346e-01 6.47984684e-01]
 [1.45845072e-11 1.00000000e+00]
 [9.39553916e-01 6.04461208e-02]
 [3.47514451e-01 6.52485549e-01]
 [7.10026979e-01 2.89972991e-01]
 [2.65630037e-01 7.34369934e-01]
 [3.73800099e-01 6.26199901e-01]
 [2.94586241e-01 7.05413759e-01]
 [7.10733366e-05 9.99928951e-01]
 [1.00010745e-02 9.89998877e-01]
 [7.10733366e-05 9.99928951e-01]
 [9.88180280e-01 1.18197808e-02]
 [6.98503613e-01 3.01496387e-01]
 [4.94375050e-01 5.05625010e-01]
 [7.08267733e-04 9.99291658e-01]
 [5.26634455e-01 4.73365545e-01]
 [4.48604643e-01 5.51395416e-01]
 [4.33081001e-01 5.66918969e-01]
 [4.03403401e-01 5.96596658e-01]
 [9.40216184e-01 5.97837716e-02]
 [2.42878154e-01 7.57121861e-01]
 [4.48604643e-01 5.51395416e-01]
 [6.78867161e-01 3.21132839e-01]
 [9.73678473e-03 9.90263224e-01]
 [6.65993392e-01 3.34006637e-01]
 [6.78867161e-01 3.21132839e-01]
 [2.94586241e-01 7.05413759e-01]
 [3.40948880e-01 6.59051120e-01]
 [5.21873236e-01 4.78126705e-01]
 [4.48436707e-01 5.51563263e-01]
 [3.85262966e-01 6.14737034e-01]
 [2.94586241e-01 7.05413759e-01]
 [1.00000000e+00 3.11171265e-16]
 [3.52015346e-01 6.47984684e-01]
 [4.50961411e-01 5.49038589e-01]
 [5.87774396e-01 4.12225634e-01]
 [9.40216184e-01 5.97837716e-02]
 [4.07544166e-01 5.92455804e-01]
 [4.07544166e-01 5.92455804e-01]
 [9.88180280e-01 1.18197808e-02]
 [5.72005808e-01 4.27994221e-01]
 [2.54708111e-01 7.45291948e-01]
 [3.73800099e-01 6.26199901e-01]
 [3.15600663e-01 6.84399307e-01]
 [9.89017010e-01 1.09829949e-02]
 [4.86003571e-10 1.00000000e+00]
 [4.59197193e-01 5.40802777e-01]
 [8.76571812e-06 9.99991179e-01]
 [3.45657557e-01 6.54342473e-01]
 [3.39646429e-01 6.60353482e-01]
 [4.18751091e-01 5.81248879e-01]
 [2.50900886e-03 9.97491002e-01]
 [9.99651194e-01 3.48814006e-04]
 [9.57546353e-01 4.24536467e-02]
 [8.22900414e-01 1.77099586e-01]
 [9.40216184e-01 5.97837716e-02]
 [3.66963923e-01 6.33036077e-01]
 [3.39646429e-01 6.60353482e-01]
 [4.32316631e-01 5.67683399e-01]
 [9.68913853e-01 3.10862157e-02]
 [1.45845072e-11 1.00000000e+00]
 [9.39553916e-01 6.04461208e-02]
 [5.62919855e-01 4.37080145e-01]
 [4.31880027e-01 5.68119943e-01]
 [9.89017010e-01 1.09829949e-02]
 [3.40803623e-01 6.59196436e-01]
 [4.51163650e-01 5.48836291e-01]
 [9.99997616e-01 2.43903105e-06]
 [4.94375050e-01 5.05625010e-01]
 [4.48604643e-01 5.51395416e-01]
 [5.20150900e-01 4.79849100e-01]
 [4.48604643e-01 5.51395416e-01]
 [9.99997616e-01 2.43903105e-06]
 [3.20378751e-01 6.79621220e-01]
 [3.41329426e-01 6.58670604e-01]]
[0 1 0 0 1 1 1 0 0 0 1 1 1 1 1 0 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 1 1
 1 1 1 1 1 1 0 1 0 1 1 1 1 1 1 0 0 1 1 0 1 1 1 0 1 1 0 1 0 0 1 1 0 1 1 1 0
 1 1 0 0 1 1 0 0 1 1 1 0 1 1 1 1 1 1 1 0 0 0 0 1 1 1 0 1 0 0 1 0 1 1 0 1 1
 0 1 0 1 1]

 32/116 [=======>......................] - ETA: 1s
 64/116 [===============>..............] - ETA: 0s
 96/116 [=======================>......] - ETA: 0s
116/116 [==============================] - 1s 12ms/step
Test loss: 0.9926346992624218
Test accuracy: 0.629310340716921
[[26 32]
 [11 47]]
