Using TensorFlow backend.
WARNING:tensorflow:From /n/home00/nchou/.conda/envs/envi/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.
Instructions for updating:
Colocations handled automatically by placer.
WARNING:tensorflow:From /n/home00/nchou/.conda/envs/envi/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.
Instructions for updating:
Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.
cnn_aardvark_aug_concat.py:397: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor("in..., outputs=Tensor("de...)`
  model = Model(input=ins, output=dense2)
WARNING:tensorflow:From /n/home00/nchou/.conda/envs/envi/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.cast instead.
2019-11-07 09:04:09.013250: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
2019-11-07 09:04:09.017235: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2900000000 Hz
2019-11-07 09:04:09.017356: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x55ba799b44a0 executing computations on platform Host. Devices:
2019-11-07 09:04:09.017376: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (0): <undefined>, <undefined>
[0.25]
Train on 348 samples, validate on 116 samples
Epoch 1/15

 58/348 [====>.........................] - ETA: 16s - loss: 0.6878 - acc: 0.5000
116/348 [=========>....................] - ETA: 12s - loss: 0.6926 - acc: 0.4310
174/348 [==============>...............] - ETA: 9s - loss: 0.6935 - acc: 0.4770 
232/348 [===================>..........] - ETA: 5s - loss: 0.6935 - acc: 0.5043
290/348 [========================>.....] - ETA: 2s - loss: 0.6924 - acc: 0.5069
348/348 [==============================] - 20s 56ms/step - loss: 0.6914 - acc: 0.5172 - val_loss: 0.6817 - val_acc: 0.6207
Epoch 2/15

 58/348 [====>.........................] - ETA: 14s - loss: 0.6750 - acc: 0.6207
116/348 [=========>....................] - ETA: 11s - loss: 0.6806 - acc: 0.6293
174/348 [==============>...............] - ETA: 8s - loss: 0.6772 - acc: 0.6149 
232/348 [===================>..........] - ETA: 5s - loss: 0.6774 - acc: 0.5776
290/348 [========================>.....] - ETA: 2s - loss: 0.6787 - acc: 0.5793
348/348 [==============================] - 19s 55ms/step - loss: 0.6762 - acc: 0.5776 - val_loss: 0.6854 - val_acc: 0.5948
Epoch 3/15

 58/348 [====>.........................] - ETA: 14s - loss: 0.6637 - acc: 0.6207
116/348 [=========>....................] - ETA: 11s - loss: 0.6667 - acc: 0.5776
174/348 [==============>...............] - ETA: 8s - loss: 0.6630 - acc: 0.6207 
232/348 [===================>..........] - ETA: 5s - loss: 0.6639 - acc: 0.6164
290/348 [========================>.....] - ETA: 2s - loss: 0.6641 - acc: 0.6034
348/348 [==============================] - 19s 55ms/step - loss: 0.6632 - acc: 0.5948 - val_loss: 0.6999 - val_acc: 0.5345
Epoch 4/15

 58/348 [====>.........................] - ETA: 14s - loss: 0.6664 - acc: 0.7414
116/348 [=========>....................] - ETA: 11s - loss: 0.6558 - acc: 0.6897
174/348 [==============>...............] - ETA: 8s - loss: 0.6538 - acc: 0.6322 
232/348 [===================>..........] - ETA: 5s - loss: 0.6584 - acc: 0.6250
290/348 [========================>.....] - ETA: 2s - loss: 0.6484 - acc: 0.6138
348/348 [==============================] - 19s 55ms/step - loss: 0.6524 - acc: 0.5977 - val_loss: 0.7299 - val_acc: 0.5000
Epoch 5/15

 58/348 [====>.........................] - ETA: 14s - loss: 0.6428 - acc: 0.5862
116/348 [=========>....................] - ETA: 11s - loss: 0.6339 - acc: 0.6293
174/348 [==============>...............] - ETA: 8s - loss: 0.6412 - acc: 0.6609 
232/348 [===================>..........] - ETA: 5s - loss: 0.6448 - acc: 0.6422
290/348 [========================>.....] - ETA: 2s - loss: 0.6405 - acc: 0.6276
348/348 [==============================] - 19s 55ms/step - loss: 0.6430 - acc: 0.6063 - val_loss: 0.7556 - val_acc: 0.5345
Epoch 6/15

 58/348 [====>.........................] - ETA: 14s - loss: 0.6561 - acc: 0.6034
116/348 [=========>....................] - ETA: 11s - loss: 0.6642 - acc: 0.5862
174/348 [==============>...............] - ETA: 8s - loss: 0.6447 - acc: 0.5977 
232/348 [===================>..........] - ETA: 5s - loss: 0.6465 - acc: 0.5948
290/348 [========================>.....] - ETA: 2s - loss: 0.6359 - acc: 0.6103
348/348 [==============================] - 19s 55ms/step - loss: 0.6337 - acc: 0.6121 - val_loss: 0.7750 - val_acc: 0.5345
Epoch 7/15

 58/348 [====>.........................] - ETA: 14s - loss: 0.6370 - acc: 0.5862
116/348 [=========>....................] - ETA: 11s - loss: 0.6226 - acc: 0.6293
174/348 [==============>...............] - ETA: 8s - loss: 0.6391 - acc: 0.6207 
232/348 [===================>..........] - ETA: 5s - loss: 0.6315 - acc: 0.6164
290/348 [========================>.....] - ETA: 2s - loss: 0.6213 - acc: 0.6345
348/348 [==============================] - 19s 55ms/step - loss: 0.6249 - acc: 0.6236 - val_loss: 0.7932 - val_acc: 0.5259
Epoch 8/15

 58/348 [====>.........................] - ETA: 14s - loss: 0.6393 - acc: 0.6724
116/348 [=========>....................] - ETA: 11s - loss: 0.6199 - acc: 0.6638
174/348 [==============>...............] - ETA: 8s - loss: 0.6224 - acc: 0.6552 
232/348 [===================>..........] - ETA: 5s - loss: 0.6193 - acc: 0.6509
290/348 [========================>.....] - ETA: 2s - loss: 0.6190 - acc: 0.6552
348/348 [==============================] - 19s 55ms/step - loss: 0.6179 - acc: 0.6667 - val_loss: 0.8146 - val_acc: 0.5776
Epoch 9/15

 58/348 [====>.........................] - ETA: 14s - loss: 0.5867 - acc: 0.6897
116/348 [=========>....................] - ETA: 11s - loss: 0.5964 - acc: 0.6810
174/348 [==============>...............] - ETA: 8s - loss: 0.5890 - acc: 0.7069 
232/348 [===================>..........] - ETA: 5s - loss: 0.5919 - acc: 0.6983
290/348 [========================>.....] - ETA: 2s - loss: 0.5960 - acc: 0.6966
348/348 [==============================] - 19s 55ms/step - loss: 0.6092 - acc: 0.6810 - val_loss: 0.8354 - val_acc: 0.5776
Epoch 10/15

 58/348 [====>.........................] - ETA: 14s - loss: 0.6585 - acc: 0.6207
116/348 [=========>....................] - ETA: 11s - loss: 0.6424 - acc: 0.6897
174/348 [==============>...............] - ETA: 8s - loss: 0.6253 - acc: 0.6782 
232/348 [===================>..........] - ETA: 5s - loss: 0.6142 - acc: 0.6897
290/348 [========================>.....] - ETA: 2s - loss: 0.6107 - acc: 0.6759
348/348 [==============================] - 19s 55ms/step - loss: 0.6001 - acc: 0.6897 - val_loss: 0.8683 - val_acc: 0.5690
Epoch 11/15

 58/348 [====>.........................] - ETA: 14s - loss: 0.5654 - acc: 0.7931
116/348 [=========>....................] - ETA: 11s - loss: 0.5837 - acc: 0.7241
174/348 [==============>...............] - ETA: 8s - loss: 0.5836 - acc: 0.7414 
232/348 [===================>..........] - ETA: 5s - loss: 0.5827 - acc: 0.7328
290/348 [========================>.....] - ETA: 2s - loss: 0.5826 - acc: 0.7241
348/348 [==============================] - 19s 55ms/step - loss: 0.5908 - acc: 0.7011 - val_loss: 0.8807 - val_acc: 0.5948
Epoch 12/15

 58/348 [====>.........................] - ETA: 14s - loss: 0.5562 - acc: 0.6724
116/348 [=========>....................] - ETA: 11s - loss: 0.5565 - acc: 0.6983
174/348 [==============>...............] - ETA: 8s - loss: 0.5618 - acc: 0.6897 
232/348 [===================>..........] - ETA: 5s - loss: 0.5789 - acc: 0.6724
290/348 [========================>.....] - ETA: 2s - loss: 0.5817 - acc: 0.6724
348/348 [==============================] - 19s 55ms/step - loss: 0.5756 - acc: 0.6925 - val_loss: 0.9205 - val_acc: 0.6207
Epoch 13/15

 58/348 [====>.........................] - ETA: 14s - loss: 0.6077 - acc: 0.6034
116/348 [=========>....................] - ETA: 11s - loss: 0.5946 - acc: 0.6466
174/348 [==============>...............] - ETA: 8s - loss: 0.5553 - acc: 0.7011 
232/348 [===================>..........] - ETA: 5s - loss: 0.5663 - acc: 0.6810
290/348 [========================>.....] - ETA: 2s - loss: 0.5658 - acc: 0.6828
348/348 [==============================] - 19s 55ms/step - loss: 0.5664 - acc: 0.6925 - val_loss: 0.9190 - val_acc: 0.5862
Epoch 14/15

 58/348 [====>.........................] - ETA: 14s - loss: 0.5843 - acc: 0.7069
116/348 [=========>....................] - ETA: 11s - loss: 0.5505 - acc: 0.7414
174/348 [==============>...............] - ETA: 8s - loss: 0.5400 - acc: 0.7529 
232/348 [===================>..........] - ETA: 5s - loss: 0.5378 - acc: 0.7414
290/348 [========================>.....] - ETA: 2s - loss: 0.5403 - acc: 0.7276
348/348 [==============================] - 19s 55ms/step - loss: 0.5515 - acc: 0.7040 - val_loss: 0.9495 - val_acc: 0.6121
Epoch 15/15

 58/348 [====>.........................] - ETA: 14s - loss: 0.5276 - acc: 0.7069
116/348 [=========>....................] - ETA: 11s - loss: 0.5399 - acc: 0.6897
174/348 [==============>...............] - ETA: 8s - loss: 0.5407 - acc: 0.6839 
232/348 [===================>..........] - ETA: 5s - loss: 0.5296 - acc: 0.6983
290/348 [========================>.....] - ETA: 2s - loss: 0.5253 - acc: 0.7138
348/348 [==============================] - 19s 55ms/step - loss: 0.5337 - acc: 0.7213 - val_loss: 1.0021 - val_acc: 0.6379
Saved trained model at /n/holylfs03/LABS/berger_lab/nchou/saved_models/aardvark_aug11.h5 
[[7.6712257e-01 2.3287742e-01]
 [5.0473708e-01 4.9526292e-01]
 [7.8974515e-01 2.1025483e-01]
 [8.8917929e-01 1.1082070e-01]
 [6.8008786e-01 3.1991211e-01]
 [4.8084265e-01 5.1915735e-01]
 [2.5526908e-01 7.4473089e-01]
 [9.0790635e-01 9.2093661e-02]
 [5.8337289e-01 4.1662714e-01]
 [7.9977804e-01 2.0022191e-01]
 [2.1463482e-01 7.8536516e-01]
 [5.5400646e-01 4.4599360e-01]
 [4.5325732e-01 5.4674268e-01]
 [4.9429882e-01 5.0570112e-01]
 [4.5431590e-01 5.4568410e-01]
 [9.8207754e-01 1.7922437e-02]
 [4.8069495e-01 5.1930505e-01]
 [5.0347465e-01 4.9652532e-01]
 [7.8315073e-01 2.1684927e-01]
 [4.6750933e-01 5.3249067e-01]
 [2.5526908e-01 7.4473089e-01]
 [4.8069495e-01 5.1930505e-01]
 [2.4414472e-01 7.5585526e-01]
 [6.8008786e-01 3.1991211e-01]
 [4.9429882e-01 5.0570112e-01]
 [5.0597191e-01 4.9402809e-01]
 [4.9719191e-01 5.0280809e-01]
 [5.4837042e-01 4.5162955e-01]
 [4.6904513e-01 5.3095490e-01]
 [4.5431590e-01 5.4568410e-01]
 [4.9874517e-01 5.0125486e-01]
 [4.9229199e-01 5.0770795e-01]
 [5.2038312e-01 4.7961685e-01]
 [4.9279031e-01 5.0720972e-01]
 [9.6765018e-01 3.2349825e-02]
 [6.6298568e-01 3.3701429e-01]
 [9.9799985e-01 2.0001372e-03]
 [5.5400646e-01 4.4599360e-01]
 [4.7385213e-01 5.2614796e-01]
 [4.9874517e-01 5.0125486e-01]
 [3.9660338e-01 6.0339659e-01]
 [4.8455000e-01 5.1545000e-01]
 [9.4643527e-01 5.3564686e-02]
 [7.8974515e-01 2.1025483e-01]
 [3.8767904e-01 6.1232102e-01]
 [5.3121644e-01 4.6878356e-01]
 [4.3742704e-01 5.6257290e-01]
 [4.7661176e-01 5.2338821e-01]
 [4.8041588e-01 5.1958406e-01]
 [9.9799985e-01 2.0001372e-03]
 [5.5611231e-03 9.9443889e-01]
 [9.9799985e-01 2.0001372e-03]
 [9.8207754e-01 1.7922437e-02]
 [4.2588511e-01 5.7411492e-01]
 [5.3564090e-01 4.6435905e-01]
 [4.4656986e-01 5.5343020e-01]
 [4.7904468e-01 5.2095532e-01]
 [4.9874517e-01 5.0125486e-01]
 [5.1246738e-01 4.8753268e-01]
 [6.8008786e-01 3.1991211e-01]
 [9.0790635e-01 9.2093661e-02]
 [5.0597191e-01 4.9402809e-01]
 [4.9874517e-01 5.0125486e-01]
 [5.1910967e-01 4.8089027e-01]
 [2.5526908e-01 7.4473089e-01]
 [7.1957844e-01 2.8042156e-01]
 [5.1910967e-01 4.8089027e-01]
 [4.8041588e-01 5.1958406e-01]
 [4.0980759e-01 5.9019232e-01]
 [3.3822709e-01 6.6177291e-01]
 [9.9999678e-01 3.1660304e-06]
 [4.8706475e-01 5.1293528e-01]
 [4.8041588e-01 5.1958406e-01]
 [9.9981529e-01 1.8468432e-04]
 [4.8455000e-01 5.1545000e-01]
 [4.9391067e-01 5.0608933e-01]
 [5.5013114e-01 4.4986880e-01]
 [9.0790635e-01 9.2093661e-02]
 [5.5400646e-01 4.4599360e-01]
 [5.5400646e-01 4.4599360e-01]
 [9.8207754e-01 1.7922437e-02]
 [4.7158453e-01 5.2841550e-01]
 [3.7500596e-01 6.2499404e-01]
 [4.7661176e-01 5.2338821e-01]
 [3.1949201e-01 6.8050802e-01]
 [7.9977804e-01 2.0022191e-01]
 [1.9737947e-06 9.9999797e-01]
 [4.9229199e-01 5.0770795e-01]
 [9.7099799e-01 2.9002028e-02]
 [3.9506498e-01 6.0493505e-01]
 [5.2038312e-01 4.7961685e-01]
 [4.7027656e-01 5.2972341e-01]
 [3.1751301e-02 9.6824872e-01]
 [4.9781403e-01 5.0218600e-01]
 [9.8291367e-01 1.7086286e-02]
 [8.8917929e-01 1.1082070e-01]
 [9.0790635e-01 9.2093661e-02]
 [5.0031608e-01 4.9968392e-01]
 [5.2038312e-01 4.7961685e-01]
 [4.8894423e-01 5.1105583e-01]
 [9.2521054e-01 7.4789479e-02]
 [9.4643527e-01 5.3564686e-02]
 [7.8974515e-01 2.1025483e-01]
 [4.8803735e-01 5.1196265e-01]
 [4.9538228e-01 5.0461775e-01]
 [7.9977804e-01 2.0022191e-01]
 [5.6860375e-01 4.3139628e-01]
 [4.9846980e-01 5.0153023e-01]
 [9.9780697e-01 2.1930181e-03]
 [5.3564090e-01 4.6435905e-01]
 [4.9874517e-01 5.0125486e-01]
 [5.1148391e-01 4.8851606e-01]
 [4.9874517e-01 5.0125486e-01]
 [9.9780697e-01 2.1930181e-03]
 [4.8281959e-01 5.1718044e-01]
 [3.9676329e-01 6.0323668e-01]]
[0 0 0 0 0 1 1 0 0 0 1 0 1 1 1 0 1 0 0 1 1 1 1 0 1 0 1 0 1 1 1 1 0 1 0 0 0
 0 1 1 1 1 0 0 1 0 1 1 1 0 1 0 0 1 0 1 1 1 0 0 0 0 1 0 1 0 0 1 1 1 0 1 1 0
 1 1 0 0 0 0 0 1 1 1 1 0 1 1 0 1 0 1 1 1 0 0 0 0 0 1 0 0 0 1 1 0 0 1 0 0 1
 0 1 0 1 1]

 32/116 [=======>......................] - ETA: 1s
 64/116 [===============>..............] - ETA: 0s
 96/116 [=======================>......] - ETA: 0s
116/116 [==============================] - 2s 15ms/step
Test loss: 0.7641863617403754
Test accuracy: 0.6724137889927831
[[39 19]
 [19 39]]
