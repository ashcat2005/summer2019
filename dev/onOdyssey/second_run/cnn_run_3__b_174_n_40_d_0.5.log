Using TensorFlow backend.
WARNING:tensorflow:From /n/home00/nchou/.conda/envs/envi/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.
Instructions for updating:
Colocations handled automatically by placer.
WARNING:tensorflow:From /n/home00/nchou/.conda/envs/envi/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.
Instructions for updating:
Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.
cnn_aardvark_aug_concat.py:397: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor("in..., outputs=Tensor("de...)`
  model = Model(input=ins, output=dense2)
WARNING:tensorflow:From /n/home00/nchou/.conda/envs/envi/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.cast instead.
2019-11-07 11:44:44.080000: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
2019-11-07 11:44:44.129251: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2900000000 Hz
2019-11-07 11:44:44.129519: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x556d329674c0 executing computations on platform Host. Devices:
2019-11-07 11:44:44.129571: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (0): <undefined>, <undefined>
[0.5]
Train on 522 samples, validate on 174 samples
Epoch 1/40

174/522 [=========>....................] - ETA: 28s - loss: 1.0995 - acc: 0.3448
348/522 [===================>..........] - ETA: 11s - loss: 1.0985 - acc: 0.3448
522/522 [==============================] - 35s 67ms/step - loss: 1.0929 - acc: 0.3678 - val_loss: 1.0503 - val_acc: 0.3851
Epoch 2/40

174/522 [=========>....................] - ETA: 17s - loss: 1.0508 - acc: 0.4540
348/522 [===================>..........] - ETA: 8s - loss: 1.0285 - acc: 0.5201 
522/522 [==============================] - 30s 57ms/step - loss: 1.0150 - acc: 0.5632 - val_loss: 1.0173 - val_acc: 0.3851
Epoch 3/40

174/522 [=========>....................] - ETA: 17s - loss: 0.9496 - acc: 0.5402
348/522 [===================>..........] - ETA: 8s - loss: 0.9329 - acc: 0.5575 
522/522 [==============================] - 30s 57ms/step - loss: 0.9202 - acc: 0.5690 - val_loss: 1.0252 - val_acc: 0.4023
Epoch 4/40

174/522 [=========>....................] - ETA: 17s - loss: 0.8967 - acc: 0.5632
348/522 [===================>..........] - ETA: 8s - loss: 0.8671 - acc: 0.5891 
522/522 [==============================] - 30s 57ms/step - loss: 0.8429 - acc: 0.6226 - val_loss: 1.0776 - val_acc: 0.3851
Epoch 5/40

174/522 [=========>....................] - ETA: 17s - loss: 0.7910 - acc: 0.5747
348/522 [===================>..........] - ETA: 8s - loss: 0.7705 - acc: 0.6580 
522/522 [==============================] - 30s 57ms/step - loss: 0.7740 - acc: 0.6609 - val_loss: 1.0861 - val_acc: 0.4253
Epoch 6/40

174/522 [=========>....................] - ETA: 17s - loss: 0.6967 - acc: 0.7586
348/522 [===================>..........] - ETA: 8s - loss: 0.6859 - acc: 0.7557 
522/522 [==============================] - 30s 57ms/step - loss: 0.7076 - acc: 0.7299 - val_loss: 1.1302 - val_acc: 0.4598
Epoch 7/40

174/522 [=========>....................] - ETA: 17s - loss: 0.6186 - acc: 0.7816
348/522 [===================>..........] - ETA: 8s - loss: 0.6601 - acc: 0.7184 
522/522 [==============================] - 30s 57ms/step - loss: 0.6466 - acc: 0.7395 - val_loss: 1.1730 - val_acc: 0.5230
Epoch 8/40

174/522 [=========>....................] - ETA: 17s - loss: 0.5898 - acc: 0.8678
348/522 [===================>..........] - ETA: 8s - loss: 0.6177 - acc: 0.7989 
522/522 [==============================] - 30s 57ms/step - loss: 0.5979 - acc: 0.8065 - val_loss: 1.2121 - val_acc: 0.4885
Epoch 9/40

174/522 [=========>....................] - ETA: 17s - loss: 0.5687 - acc: 0.7874
348/522 [===================>..........] - ETA: 8s - loss: 0.5610 - acc: 0.7701 
522/522 [==============================] - 30s 57ms/step - loss: 0.5442 - acc: 0.8142 - val_loss: 1.2236 - val_acc: 0.6092
Epoch 10/40

174/522 [=========>....................] - ETA: 17s - loss: 0.5424 - acc: 0.8103
348/522 [===================>..........] - ETA: 8s - loss: 0.5406 - acc: 0.8247 
522/522 [==============================] - 30s 57ms/step - loss: 0.5108 - acc: 0.8467 - val_loss: 1.2126 - val_acc: 0.6437
Epoch 11/40

174/522 [=========>....................] - ETA: 17s - loss: 0.4516 - acc: 0.9253
348/522 [===================>..........] - ETA: 8s - loss: 0.4583 - acc: 0.9080 
522/522 [==============================] - 30s 57ms/step - loss: 0.4547 - acc: 0.8927 - val_loss: 1.2473 - val_acc: 0.6322
Epoch 12/40

174/522 [=========>....................] - ETA: 17s - loss: 0.4127 - acc: 0.8851
348/522 [===================>..........] - ETA: 8s - loss: 0.4331 - acc: 0.8764 
522/522 [==============================] - 30s 57ms/step - loss: 0.4171 - acc: 0.8736 - val_loss: 1.2820 - val_acc: 0.6782
Epoch 13/40

174/522 [=========>....................] - ETA: 17s - loss: 0.4085 - acc: 0.8908
348/522 [===================>..........] - ETA: 8s - loss: 0.3750 - acc: 0.9138 
522/522 [==============================] - 30s 57ms/step - loss: 0.3720 - acc: 0.9195 - val_loss: 1.2881 - val_acc: 0.5920
Epoch 14/40

174/522 [=========>....................] - ETA: 17s - loss: 0.4114 - acc: 0.8736
348/522 [===================>..........] - ETA: 8s - loss: 0.3689 - acc: 0.8994 
522/522 [==============================] - 30s 57ms/step - loss: 0.3547 - acc: 0.9176 - val_loss: 1.2878 - val_acc: 0.6954
Epoch 15/40

174/522 [=========>....................] - ETA: 17s - loss: 0.3233 - acc: 0.8851
348/522 [===================>..........] - ETA: 8s - loss: 0.3119 - acc: 0.8994 
522/522 [==============================] - 30s 57ms/step - loss: 0.3154 - acc: 0.8946 - val_loss: 1.2443 - val_acc: 0.6092
Epoch 16/40

174/522 [=========>....................] - ETA: 17s - loss: 0.2854 - acc: 0.9425
348/522 [===================>..........] - ETA: 8s - loss: 0.2986 - acc: 0.9454 
522/522 [==============================] - 30s 57ms/step - loss: 0.2978 - acc: 0.9234 - val_loss: 1.2566 - val_acc: 0.7011
Epoch 17/40

174/522 [=========>....................] - ETA: 17s - loss: 0.2499 - acc: 0.9483
348/522 [===================>..........] - ETA: 8s - loss: 0.2795 - acc: 0.9368 
522/522 [==============================] - 30s 57ms/step - loss: 0.2693 - acc: 0.9444 - val_loss: 1.2316 - val_acc: 0.7126
Epoch 18/40

174/522 [=========>....................] - ETA: 17s - loss: 0.2356 - acc: 0.9540
348/522 [===================>..........] - ETA: 8s - loss: 0.2474 - acc: 0.9368 
522/522 [==============================] - 30s 57ms/step - loss: 0.2415 - acc: 0.9387 - val_loss: 1.1985 - val_acc: 0.6724
Epoch 19/40

174/522 [=========>....................] - ETA: 17s - loss: 0.2166 - acc: 0.9885
348/522 [===================>..........] - ETA: 8s - loss: 0.2197 - acc: 0.9741 
522/522 [==============================] - 30s 57ms/step - loss: 0.2201 - acc: 0.9770 - val_loss: 1.2300 - val_acc: 0.7184
Epoch 20/40

174/522 [=========>....................] - ETA: 17s - loss: 0.2326 - acc: 0.9195
348/522 [===================>..........] - ETA: 8s - loss: 0.2093 - acc: 0.9339 
522/522 [==============================] - 30s 57ms/step - loss: 0.1993 - acc: 0.9540 - val_loss: 1.2164 - val_acc: 0.6897
Epoch 21/40

174/522 [=========>....................] - ETA: 17s - loss: 0.1830 - acc: 0.9828
348/522 [===================>..........] - ETA: 8s - loss: 0.1797 - acc: 0.9799 
522/522 [==============================] - 30s 57ms/step - loss: 0.1824 - acc: 0.9789 - val_loss: 1.2862 - val_acc: 0.6954
Epoch 22/40

174/522 [=========>....................] - ETA: 17s - loss: 0.1867 - acc: 0.9368
348/522 [===================>..........] - ETA: 8s - loss: 0.1754 - acc: 0.9454 
522/522 [==============================] - 30s 57ms/step - loss: 0.1692 - acc: 0.9559 - val_loss: 1.2596 - val_acc: 0.6724
Epoch 23/40

174/522 [=========>....................] - ETA: 17s - loss: 0.1671 - acc: 0.9943
348/522 [===================>..........] - ETA: 8s - loss: 0.1390 - acc: 0.9971 
522/522 [==============================] - 30s 57ms/step - loss: 0.1636 - acc: 0.9770 - val_loss: 1.2362 - val_acc: 0.7184
Epoch 24/40

174/522 [=========>....................] - ETA: 17s - loss: 0.1355 - acc: 0.9885
348/522 [===================>..........] - ETA: 8s - loss: 0.1395 - acc: 0.9856 
522/522 [==============================] - 30s 57ms/step - loss: 0.1437 - acc: 0.9904 - val_loss: 1.2880 - val_acc: 0.6954
Epoch 25/40

174/522 [=========>....................] - ETA: 17s - loss: 0.1275 - acc: 0.9885
348/522 [===================>..........] - ETA: 8s - loss: 0.1241 - acc: 0.9828 
522/522 [==============================] - 30s 57ms/step - loss: 0.1313 - acc: 0.9789 - val_loss: 1.3331 - val_acc: 0.6954
Epoch 26/40

174/522 [=========>....................] - ETA: 17s - loss: 0.1291 - acc: 0.9828
348/522 [===================>..........] - ETA: 8s - loss: 0.1238 - acc: 0.9885 
522/522 [==============================] - 30s 57ms/step - loss: 0.1224 - acc: 0.9923 - val_loss: 1.3568 - val_acc: 0.6954
Epoch 27/40

174/522 [=========>....................] - ETA: 17s - loss: 0.0813 - acc: 1.0000
348/522 [===================>..........] - ETA: 8s - loss: 0.1012 - acc: 0.9856 
522/522 [==============================] - 30s 57ms/step - loss: 0.1087 - acc: 0.9808 - val_loss: 1.3722 - val_acc: 0.7011
Epoch 28/40

174/522 [=========>....................] - ETA: 17s - loss: 0.0926 - acc: 0.9943
348/522 [===================>..........] - ETA: 8s - loss: 0.1006 - acc: 0.9914 
522/522 [==============================] - 30s 57ms/step - loss: 0.1073 - acc: 0.9904 - val_loss: 1.4031 - val_acc: 0.6897
Epoch 29/40

174/522 [=========>....................] - ETA: 17s - loss: 0.0812 - acc: 1.0000
348/522 [===================>..........] - ETA: 8s - loss: 0.0980 - acc: 0.9856 
522/522 [==============================] - 30s 57ms/step - loss: 0.1088 - acc: 0.9828 - val_loss: 1.4226 - val_acc: 0.7126
Epoch 30/40

174/522 [=========>....................] - ETA: 17s - loss: 0.0747 - acc: 0.9943
348/522 [===================>..........] - ETA: 8s - loss: 0.0869 - acc: 0.9943 
522/522 [==============================] - 30s 57ms/step - loss: 0.0854 - acc: 0.9943 - val_loss: 1.5234 - val_acc: 0.6724
Epoch 31/40

174/522 [=========>....................] - ETA: 17s - loss: 0.1018 - acc: 0.9885
348/522 [===================>..........] - ETA: 8s - loss: 0.1036 - acc: 0.9799 
522/522 [==============================] - 30s 57ms/step - loss: 0.0962 - acc: 0.9847 - val_loss: 1.5146 - val_acc: 0.7011
Epoch 32/40

174/522 [=========>....................] - ETA: 17s - loss: 0.0861 - acc: 0.9885
348/522 [===================>..........] - ETA: 8s - loss: 0.0956 - acc: 0.9856 
522/522 [==============================] - 30s 57ms/step - loss: 0.0914 - acc: 0.9885 - val_loss: 1.5245 - val_acc: 0.6897
Epoch 33/40

174/522 [=========>....................] - ETA: 17s - loss: 0.0947 - acc: 0.9885
348/522 [===================>..........] - ETA: 8s - loss: 0.0904 - acc: 0.9914 
522/522 [==============================] - 30s 57ms/step - loss: 0.0852 - acc: 0.9943 - val_loss: 1.5004 - val_acc: 0.6897
Epoch 34/40

174/522 [=========>....................] - ETA: 17s - loss: 0.0767 - acc: 1.0000
348/522 [===================>..........] - ETA: 8s - loss: 0.0649 - acc: 1.0000 
522/522 [==============================] - 30s 57ms/step - loss: 0.0631 - acc: 1.0000 - val_loss: 1.4973 - val_acc: 0.7011
Epoch 35/40

174/522 [=========>....................] - ETA: 17s - loss: 0.0743 - acc: 0.9885
348/522 [===================>..........] - ETA: 8s - loss: 0.0627 - acc: 0.9943 
522/522 [==============================] - 30s 57ms/step - loss: 0.0563 - acc: 0.9962 - val_loss: 1.5235 - val_acc: 0.6897
Epoch 36/40

174/522 [=========>....................] - ETA: 17s - loss: 0.0540 - acc: 1.0000
348/522 [===================>..........] - ETA: 8s - loss: 0.0578 - acc: 1.0000 
522/522 [==============================] - 30s 57ms/step - loss: 0.0543 - acc: 1.0000 - val_loss: 1.5100 - val_acc: 0.6954
Epoch 37/40

174/522 [=========>....................] - ETA: 17s - loss: 0.0509 - acc: 1.0000
348/522 [===================>..........] - ETA: 8s - loss: 0.0544 - acc: 0.9971 
522/522 [==============================] - 30s 57ms/step - loss: 0.0493 - acc: 0.9981 - val_loss: 1.5232 - val_acc: 0.7011
Epoch 38/40

174/522 [=========>....................] - ETA: 17s - loss: 0.0444 - acc: 1.0000
348/522 [===================>..........] - ETA: 8s - loss: 0.0429 - acc: 1.0000 
522/522 [==============================] - 30s 57ms/step - loss: 0.0425 - acc: 1.0000 - val_loss: 1.5300 - val_acc: 0.6954
Epoch 39/40

174/522 [=========>....................] - ETA: 17s - loss: 0.0462 - acc: 1.0000
348/522 [===================>..........] - ETA: 8s - loss: 0.0417 - acc: 1.0000 
522/522 [==============================] - 30s 57ms/step - loss: 0.0389 - acc: 1.0000 - val_loss: 1.5199 - val_acc: 0.6839
Epoch 40/40

174/522 [=========>....................] - ETA: 17s - loss: 0.0364 - acc: 1.0000
348/522 [===================>..........] - ETA: 9s - loss: 0.0392 - acc: 1.0000 
522/522 [==============================] - 30s 57ms/step - loss: 0.0367 - acc: 1.0000 - val_loss: 1.5318 - val_acc: 0.7069
Saved trained model at /n/holylfs03/LABS/berger_lab/nchou/saved_models/aardvark_aug11.h5 
[[2.54409134e-01 3.74580324e-01 3.71010572e-01]
 [3.35615873e-01 4.98137653e-01 1.66246518e-01]
 [3.28806609e-01 4.59908515e-01 2.11284921e-01]
 [1.62049755e-01 3.07592321e-02 8.07191014e-01]
 [9.83206511e-01 3.67833884e-03 1.31152086e-02]
 [9.99976277e-01 2.37216354e-05 0.00000000e+00]
 [3.02752286e-01 3.64208847e-01 3.33038896e-01]
 [1.24141008e-01 5.26659727e-01 3.49199235e-01]
 [8.16274434e-02 7.95615137e-01 1.22757375e-01]
 [2.22869053e-01 3.84426862e-01 3.92704129e-01]
 [9.96180534e-01 1.28107538e-04 3.69130634e-03]
 [8.87918293e-01 2.79533081e-02 8.41284096e-02]
 [8.39813650e-02 8.27173740e-02 8.33301246e-01]
 [6.54678233e-03 9.35708106e-01 5.77451214e-02]
 [5.23572266e-01 8.28790106e-03 4.68139768e-01]
 [7.58797586e-01 2.95839645e-03 2.38244072e-01]
 [3.98613448e-10 4.55906093e-06 9.99995470e-01]
 [1.45275533e-01 8.10321271e-01 4.44031693e-02]
 [1.00000000e+00 5.37941859e-35 7.01908245e-20]
 [4.07750040e-01 4.36105102e-01 1.56144872e-01]
 [6.67143166e-02 6.86690072e-03 9.26418781e-01]
 [1.86478458e-02 6.34879281e-04 9.80717242e-01]
 [9.84397352e-01 2.73791375e-03 1.28647182e-02]
 [9.92811501e-01 6.84859278e-03 3.39908700e-04]
 [9.84397352e-01 2.73791375e-03 1.28647182e-02]
 [5.24770021e-01 2.40562007e-01 2.34668002e-01]
 [9.30731833e-01 5.14167324e-02 1.78513434e-02]
 [8.43800251e-07 9.97454584e-01 2.54460913e-03]
 [1.07853720e-02 9.38312888e-01 5.09018190e-02]
 [1.60762236e-01 7.66959310e-01 7.22785071e-02]
 [1.00000000e+00 2.30366575e-18 1.05609286e-24]
 [9.84397352e-01 2.73791375e-03 1.28647182e-02]
 [9.99793112e-01 1.48735053e-04 5.81840795e-05]
 [4.59884316e-01 2.37572357e-01 3.02543283e-01]
 [7.24956151e-24 5.29193347e-37 1.00000000e+00]
 [8.23578894e-01 6.25302026e-04 1.75795853e-01]
 [1.54013678e-01 7.98357427e-01 4.76289615e-02]
 [9.26508725e-01 3.95234600e-02 3.39678228e-02]
 [9.98567462e-01 5.80225969e-05 1.37458544e-03]
 [1.34647340e-01 4.41812165e-02 8.21171463e-01]
 [7.47288666e-20 1.00000000e+00 0.00000000e+00]
 [9.26508725e-01 3.95234600e-02 3.39678228e-02]
 [1.90189674e-01 5.18786609e-01 2.91023731e-01]
 [1.00000000e+00 3.98521391e-23 3.19261096e-15]
 [1.00000000e+00 3.98521391e-23 3.19261096e-15]
 [5.60778141e-01 1.98063865e-01 2.41158053e-01]
 [7.13710561e-02 3.35832080e-03 9.25270617e-01]
 [1.89215854e-01 7.01117635e-01 1.09666541e-01]
 [9.98567462e-01 5.80225969e-05 1.37458544e-03]
 [2.48258606e-01 8.58922601e-02 6.65849149e-01]
 [9.30731833e-01 5.14167324e-02 1.78513434e-02]
 [2.06421524e-01 5.71569145e-01 2.22009271e-01]
 [9.83948648e-01 6.98036747e-05 1.59815438e-02]
 [2.73392648e-01 2.66693801e-01 4.59913492e-01]
 [1.98956221e-01 1.33970588e-01 6.67073190e-01]
 [9.96098042e-01 3.75473779e-03 1.47217797e-04]
 [9.16314900e-01 1.25773717e-04 8.35593790e-02]
 [7.75262481e-03 1.31709348e-05 9.92234230e-01]
 [3.34371289e-04 9.88398850e-01 1.12667885e-02]
 [8.16274434e-02 7.95615137e-01 1.22757375e-01]
 [9.84397352e-01 2.73791375e-03 1.28647182e-02]
 [9.88729417e-01 3.03750811e-03 8.23300239e-03]
 [1.45808449e-02 9.73321676e-01 1.20974593e-02]
 [1.00000000e+00 7.39392662e-17 3.72976024e-25]
 [6.71521605e-07 9.95944321e-01 4.05490305e-03]
 [1.00000000e+00 2.30366575e-18 1.05609286e-24]
 [7.47288666e-20 1.00000000e+00 0.00000000e+00]
 [3.14771148e-12 9.99999046e-01 8.95890651e-07]
 [9.99793112e-01 1.48735053e-04 5.81840795e-05]
 [2.98101783e-01 5.37006855e-01 1.64891332e-01]
 [4.53138918e-01 2.86241859e-01 2.60619253e-01]
 [4.24911547e-03 1.43572199e-03 9.94315088e-01]
 [9.26508725e-01 3.95234600e-02 3.39678228e-02]
 [2.43288189e-01 5.34793258e-01 2.21918494e-01]
 [6.78819604e-04 1.35420784e-02 9.85779166e-01]
 [1.00000000e+00 2.66403900e-37 3.41695936e-17]
 [9.99989152e-01 2.04292974e-07 1.05615709e-05]
 [2.70748320e-11 3.33360561e-10 1.00000000e+00]
 [7.55052418e-02 5.70093930e-01 3.54400814e-01]
 [9.47085470e-02 2.36688163e-02 8.81622672e-01]
 [3.86195839e-03 7.48930156e-01 2.47207910e-01]
 [2.69281685e-01 7.28011966e-01 2.70634121e-03]
 [9.63154852e-01 1.87245645e-02 1.81205347e-02]
 [1.75663590e-01 2.13024989e-01 6.11311376e-01]
 [3.33660811e-01 4.15611237e-01 2.50727981e-01]
 [7.66934268e-03 9.90280416e-03 9.82427895e-01]
 [1.55834273e-01 2.68822610e-01 5.75343072e-01]
 [1.00000000e+00 2.30366575e-18 1.05609286e-24]
 [9.83206511e-01 3.67833884e-03 1.31152086e-02]
 [1.00000000e+00 7.39392662e-17 3.72976024e-25]
 [9.99976277e-01 2.37216354e-05 0.00000000e+00]
 [4.56678569e-01 3.49169374e-01 1.94152117e-01]
 [4.24911547e-03 1.43572199e-03 9.94315088e-01]
 [1.66425577e-27 0.00000000e+00 1.00000000e+00]
 [7.03144446e-02 1.84331328e-01 7.45354176e-01]
 [9.10443366e-02 3.21952403e-01 5.87003231e-01]
 [1.88085288e-01 5.21826982e-01 2.90087670e-01]
 [1.00000000e+00 5.37941859e-35 7.01908245e-20]
 [2.88567990e-01 6.09833121e-01 1.01598904e-01]
 [9.99990463e-01 9.53474682e-06 5.89667967e-11]
 [3.79684627e-01 3.63540500e-01 2.56774813e-01]
 [1.00000000e+00 3.42684012e-25 2.46228060e-09]
 [2.70718277e-01 4.06928748e-01 3.22352976e-01]
 [1.40029147e-01 6.25444591e-01 2.34526247e-01]
 [2.50009610e-03 9.90216613e-01 7.28323031e-03]
 [9.99990463e-01 9.53474682e-06 5.89667967e-11]
 [3.86195839e-03 7.48930156e-01 2.47207910e-01]
 [9.99992251e-01 7.41059193e-06 3.04963777e-07]
 [9.99793112e-01 1.48735053e-04 5.81840795e-05]
 [2.98648479e-06 9.96167958e-01 3.82902939e-03]
 [3.71395797e-01 4.25087065e-01 2.03517079e-01]
 [1.54013678e-01 7.98357427e-01 4.76289615e-02]
 [1.86478458e-02 6.34879281e-04 9.80717242e-01]
 [3.93011689e-01 2.07025483e-01 3.99962842e-01]
 [9.84397352e-01 2.73791375e-03 1.28647182e-02]
 [4.78110245e-08 1.25027393e-04 9.99874949e-01]
 [8.08349490e-01 1.56962126e-01 3.46883871e-02]
 [2.69316524e-01 4.92172986e-01 2.38510489e-01]
 [2.58878917e-01 5.63110888e-01 1.78010225e-01]
 [8.16274434e-02 7.95615137e-01 1.22757375e-01]
 [8.23578894e-01 6.25302026e-04 1.75795853e-01]
 [6.10044594e-07 9.96970654e-01 3.02870991e-03]
 [9.99999285e-01 6.65066466e-07 3.01804404e-09]
 [7.66934268e-03 9.90280416e-03 9.82427895e-01]
 [1.00000000e+00 3.53172214e-11 1.55851183e-11]
 [1.00000000e+00 3.98521391e-23 3.19261096e-15]
 [3.47916186e-02 7.79053604e-04 9.64429319e-01]
 [9.99976277e-01 2.37216354e-05 0.00000000e+00]
 [7.90571496e-02 1.97488666e-01 7.23454237e-01]
 [5.72577119e-03 2.44454190e-01 7.49820054e-01]
 [2.81523913e-01 4.89260852e-01 2.29215279e-01]
 [6.17045388e-02 1.88966049e-03 9.36405838e-01]
 [1.00000000e+00 1.76362464e-38 1.04995120e-16]
 [3.88091028e-01 3.46341729e-01 2.65567213e-01]
 [1.00000000e+00 1.28463815e-22 6.09604445e-15]
 [1.47330374e-01 3.26202735e-02 8.20049345e-01]
 [1.56053916e-01 7.97074318e-01 4.68717255e-02]
 [1.00000000e+00 0.00000000e+00 0.00000000e+00]
 [9.11203206e-01 1.60958059e-02 7.27010071e-02]
 [8.08349490e-01 1.56962126e-01 3.46883871e-02]
 [4.49938561e-05 9.98269558e-01 1.68538885e-03]
 [5.83862104e-02 1.51989356e-01 7.89624393e-01]
 [2.26743504e-01 3.31521302e-01 4.41735208e-01]
 [3.50996084e-03 8.19636116e-05 9.96408045e-01]
 [5.19434154e-01 2.64299273e-01 2.16266572e-01]
 [3.86195839e-03 7.48930156e-01 2.47207910e-01]
 [1.27027863e-06 9.94805157e-01 5.19348588e-03]
 [4.02822226e-01 3.28051746e-01 2.69125938e-01]
 [9.83182986e-07 7.26326823e-01 2.73672223e-01]
 [6.12356246e-01 2.96579003e-01 9.10648480e-02]
 [5.35833299e-01 2.69773424e-01 1.94393307e-01]
 [3.02752286e-01 3.64208847e-01 3.33038896e-01]
 [3.17398340e-01 5.05990922e-01 1.76610783e-01]
 [9.84397352e-01 2.73791375e-03 1.28647182e-02]
 [1.00000000e+00 3.98521391e-23 3.19261096e-15]
 [1.00000000e+00 4.38345003e-16 1.17367813e-12]
 [4.24911547e-03 1.43572199e-03 9.94315088e-01]
 [1.00000000e+00 1.71164316e-09 1.28987536e-18]
 [2.69281685e-01 7.28011966e-01 2.70634121e-03]
 [1.58689514e-01 2.94110954e-01 5.47199488e-01]
 [2.12137285e-03 2.87640467e-03 9.95002210e-01]
 [1.00000000e+00 7.39392662e-17 3.72976024e-25]
 [9.26508725e-01 3.95234600e-02 3.39678228e-02]
 [5.34627736e-02 1.62551552e-01 7.83985734e-01]
 [1.04412325e-01 2.75238365e-01 6.20349348e-01]
 [1.49205372e-01 7.50149608e-01 1.00644998e-01]
 [9.81799841e-01 1.74082611e-02 7.91846949e-04]
 [1.00000000e+00 5.37941859e-35 7.01908245e-20]
 [9.71998572e-01 4.29995962e-05 2.79584061e-02]
 [1.00226287e-04 9.99892473e-01 7.33028219e-06]
 [2.86152482e-01 6.89572334e-01 2.42752023e-02]
 [8.39678347e-02 7.82651186e-01 1.33380964e-01]
 [1.37160674e-01 3.46436113e-01 5.16403258e-01]
 [4.03795689e-01 4.76171404e-01 1.20032869e-01]]
[1 1 1 2 0 0 1 1 1 2 0 0 2 1 0 0 2 1 0 1 2 2 0 0 0 0 0 1 1 1 0 0 0 0 2 0 1
 0 0 2 1 0 1 0 0 0 2 1 0 2 0 1 0 2 2 0 0 2 1 1 0 0 1 0 1 0 1 1 0 1 0 2 0 1
 2 0 0 2 1 2 1 1 0 2 1 2 2 0 0 0 0 0 2 2 2 2 1 0 1 0 0 0 1 1 1 0 1 0 0 1 1
 1 2 2 0 2 0 1 1 1 0 1 0 2 0 0 2 0 2 2 1 2 0 0 0 2 1 0 0 0 1 2 2 2 0 1 1 0
 1 0 0 1 1 0 0 0 2 0 1 2 2 0 0 2 2 1 0 0 0 1 1 1 2 1]

 32/174 [====>.........................] - ETA: 2s
 64/174 [==========>...................] - ETA: 1s
 96/174 [===============>..............] - ETA: 1s
128/174 [=====================>........] - ETA: 0s
160/174 [==========================>...] - ETA: 0s
174/174 [==============================] - 3s 18ms/step
Test loss: 2.043039527432672
Test accuracy: 0.6781609181700081
[[46 10  2]
 [ 8 41  9]
 [22  5 31]]
