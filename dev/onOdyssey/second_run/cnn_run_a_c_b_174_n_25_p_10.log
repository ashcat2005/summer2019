Using TensorFlow backend.
WARNING:tensorflow:From /n/home00/nchou/.conda/envs/envi/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.
Instructions for updating:
Colocations handled automatically by placer.
cnn_aardvark_aug_concat.py:397: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor("in..., outputs=Tensor("de...)`
  model = Model(input=ins, output=dense2)
WARNING:tensorflow:From /n/home00/nchou/.conda/envs/envi/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.cast instead.
2019-11-07 09:05:02.518812: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
2019-11-07 09:05:02.543265: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2900000000 Hz
2019-11-07 09:05:02.543381: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x55b8b6dd8630 executing computations on platform Host. Devices:
2019-11-07 09:05:02.543406: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (0): <undefined>, <undefined>
None
Train on 348 samples, validate on 116 samples
Epoch 1/25

174/348 [==============>...............] - ETA: 10s - loss: 0.6945 - acc: 0.4770
348/348 [==============================] - 22s 63ms/step - loss: 0.6936 - acc: 0.4971 - val_loss: 0.6963 - val_acc: 0.4483
Epoch 2/25

174/348 [==============>...............] - ETA: 8s - loss: 0.6850 - acc: 0.5287
348/348 [==============================] - 20s 57ms/step - loss: 0.6868 - acc: 0.5431 - val_loss: 0.6970 - val_acc: 0.4741
Epoch 3/25

174/348 [==============>...............] - ETA: 8s - loss: 0.6832 - acc: 0.5747
348/348 [==============================] - 19s 56ms/step - loss: 0.6796 - acc: 0.5776 - val_loss: 0.6992 - val_acc: 0.4828
Epoch 4/25

174/348 [==============>...............] - ETA: 8s - loss: 0.6737 - acc: 0.5747
348/348 [==============================] - 19s 56ms/step - loss: 0.6740 - acc: 0.5690 - val_loss: 0.7040 - val_acc: 0.4483
Epoch 5/25

174/348 [==============>...............] - ETA: 8s - loss: 0.6710 - acc: 0.5575
348/348 [==============================] - 19s 56ms/step - loss: 0.6677 - acc: 0.5632 - val_loss: 0.7111 - val_acc: 0.4310
Epoch 6/25

174/348 [==============>...............] - ETA: 8s - loss: 0.6656 - acc: 0.5575
348/348 [==============================] - 19s 56ms/step - loss: 0.6621 - acc: 0.5661 - val_loss: 0.7200 - val_acc: 0.4483
Epoch 7/25

174/348 [==============>...............] - ETA: 8s - loss: 0.6525 - acc: 0.6034
348/348 [==============================] - 19s 56ms/step - loss: 0.6571 - acc: 0.5632 - val_loss: 0.7316 - val_acc: 0.4569
Epoch 8/25

174/348 [==============>...............] - ETA: 8s - loss: 0.6424 - acc: 0.5690
348/348 [==============================] - 19s 56ms/step - loss: 0.6524 - acc: 0.5776 - val_loss: 0.7455 - val_acc: 0.4828
Epoch 9/25

174/348 [==============>...............] - ETA: 8s - loss: 0.6414 - acc: 0.6034
348/348 [==============================] - 19s 56ms/step - loss: 0.6477 - acc: 0.5718 - val_loss: 0.7597 - val_acc: 0.5086
Epoch 10/25

174/348 [==============>...............] - ETA: 8s - loss: 0.6365 - acc: 0.5920
348/348 [==============================] - 19s 56ms/step - loss: 0.6428 - acc: 0.5891 - val_loss: 0.7745 - val_acc: 0.5172
Epoch 11/25

174/348 [==============>...............] - ETA: 8s - loss: 0.6493 - acc: 0.5460
348/348 [==============================] - 19s 56ms/step - loss: 0.6380 - acc: 0.5977 - val_loss: 0.7883 - val_acc: 0.5431
Epoch 12/25

174/348 [==============>...............] - ETA: 8s - loss: 0.6428 - acc: 0.6667
348/348 [==============================] - 19s 56ms/step - loss: 0.6335 - acc: 0.6236 - val_loss: 0.7996 - val_acc: 0.5431
Epoch 13/25

174/348 [==============>...............] - ETA: 8s - loss: 0.6281 - acc: 0.6437
348/348 [==============================] - 19s 56ms/step - loss: 0.6290 - acc: 0.6178 - val_loss: 0.8089 - val_acc: 0.5431
Epoch 14/25

174/348 [==============>...............] - ETA: 8s - loss: 0.6165 - acc: 0.6322
348/348 [==============================] - 19s 56ms/step - loss: 0.6248 - acc: 0.6293 - val_loss: 0.8226 - val_acc: 0.5690
Epoch 15/25

174/348 [==============>...............] - ETA: 8s - loss: 0.6192 - acc: 0.6092
348/348 [==============================] - 19s 56ms/step - loss: 0.6201 - acc: 0.6293 - val_loss: 0.8307 - val_acc: 0.6034
Epoch 16/25

174/348 [==============>...............] - ETA: 8s - loss: 0.6133 - acc: 0.6437
348/348 [==============================] - 19s 55ms/step - loss: 0.6152 - acc: 0.6523 - val_loss: 0.8424 - val_acc: 0.5948
Epoch 17/25

174/348 [==============>...............] - ETA: 8s - loss: 0.6106 - acc: 0.6724
348/348 [==============================] - 19s 56ms/step - loss: 0.6113 - acc: 0.6753 - val_loss: 0.8555 - val_acc: 0.5948
Epoch 18/25

174/348 [==============>...............] - ETA: 8s - loss: 0.5968 - acc: 0.6897
348/348 [==============================] - 19s 56ms/step - loss: 0.6072 - acc: 0.6810 - val_loss: 0.8650 - val_acc: 0.6034
Epoch 19/25

174/348 [==============>...............] - ETA: 8s - loss: 0.5877 - acc: 0.7299
348/348 [==============================] - 19s 55ms/step - loss: 0.6025 - acc: 0.6782 - val_loss: 0.8679 - val_acc: 0.6034
Epoch 20/25

174/348 [==============>...............] - ETA: 8s - loss: 0.5881 - acc: 0.7126
348/348 [==============================] - 19s 56ms/step - loss: 0.5970 - acc: 0.6782 - val_loss: 0.8761 - val_acc: 0.6121
Epoch 21/25

174/348 [==============>...............] - ETA: 8s - loss: 0.5812 - acc: 0.6839
348/348 [==============================] - 19s 55ms/step - loss: 0.5923 - acc: 0.6983 - val_loss: 0.8891 - val_acc: 0.6121
Epoch 22/25

174/348 [==============>...............] - ETA: 8s - loss: 0.6027 - acc: 0.6322
348/348 [==============================] - 19s 55ms/step - loss: 0.5864 - acc: 0.6897 - val_loss: 0.8965 - val_acc: 0.6121
Epoch 23/25

174/348 [==============>...............] - ETA: 8s - loss: 0.5878 - acc: 0.6782
348/348 [==============================] - 19s 55ms/step - loss: 0.5806 - acc: 0.6954 - val_loss: 0.9123 - val_acc: 0.6121
Epoch 24/25

174/348 [==============>...............] - ETA: 8s - loss: 0.5604 - acc: 0.7011
348/348 [==============================] - 19s 55ms/step - loss: 0.5746 - acc: 0.6954 - val_loss: 0.9231 - val_acc: 0.6121
Epoch 25/25

174/348 [==============>...............] - ETA: 8s - loss: 0.5541 - acc: 0.7126
348/348 [==============================] - 19s 55ms/step - loss: 0.5688 - acc: 0.6897 - val_loss: 0.9263 - val_acc: 0.6207
Saved trained model at /n/holylfs03/LABS/berger_lab/nchou/saved_models/aardvark_aug11.h5 
[[6.2821293e-01 3.7178710e-01]
 [4.8361924e-01 5.1638073e-01]
 [7.2752124e-01 2.7247873e-01]
 [7.8256190e-01 2.1743813e-01]
 [6.0905379e-01 3.9094621e-01]
 [4.5295435e-01 5.4704571e-01]
 [2.1973978e-01 7.8026021e-01]
 [8.7422228e-01 1.2577766e-01]
 [5.3646111e-01 4.6353883e-01]
 [7.3951232e-01 2.6048765e-01]
 [3.2100305e-01 6.7899692e-01]
 [5.0833237e-01 4.9166763e-01]
 [4.2720234e-01 5.7279766e-01]
 [4.6448451e-01 5.3551555e-01]
 [4.1373351e-01 5.8626646e-01]
 [9.8904347e-01 1.0956522e-02]
 [3.7267768e-01 6.2732232e-01]
 [4.6400136e-01 5.3599864e-01]
 [7.2963339e-01 2.7036667e-01]
 [4.5574337e-01 5.4425663e-01]
 [2.1973978e-01 7.8026021e-01]
 [3.7267768e-01 6.2732232e-01]
 [2.4957287e-01 7.5042719e-01]
 [6.0905379e-01 3.9094621e-01]
 [4.6448451e-01 5.3551555e-01]
 [4.6930259e-01 5.3069741e-01]
 [4.6178833e-01 5.3821176e-01]
 [3.4623179e-01 6.5376818e-01]
 [4.4468993e-01 5.5531013e-01]
 [4.1373351e-01 5.8626646e-01]
 [4.1943544e-01 5.8056450e-01]
 [4.5926744e-01 5.4073256e-01]
 [4.7685283e-01 5.2314723e-01]
 [4.5856896e-01 5.4143101e-01]
 [9.5318526e-01 4.6814710e-02]
 [5.9513766e-01 4.0486231e-01]
 [9.8982751e-01 1.0172442e-02]
 [5.0833237e-01 4.9166763e-01]
 [4.4494814e-01 5.5505180e-01]
 [4.1943544e-01 5.8056450e-01]
 [3.3528009e-01 6.6471988e-01]
 [4.5037925e-01 5.4962069e-01]
 [8.1925482e-01 1.8074523e-01]
 [7.2752124e-01 2.7247873e-01]
 [3.3917502e-01 6.6082501e-01]
 [3.6483827e-01 6.3516176e-01]
 [4.3178082e-01 5.6821918e-01]
 [4.4234183e-01 5.5765820e-01]
 [4.3769583e-01 5.6230414e-01]
 [9.8982751e-01 1.0172442e-02]
 [9.1098743e-03 9.9089009e-01]
 [9.8982751e-01 1.0172442e-02]
 [9.8904347e-01 1.0956522e-02]
 [3.9396378e-01 6.0603625e-01]
 [4.8956037e-01 5.1043963e-01]
 [4.0886346e-01 5.9113663e-01]
 [4.7885016e-01 5.2114981e-01]
 [4.1943544e-01 5.8056450e-01]
 [4.7810361e-01 5.2189642e-01]
 [6.0905379e-01 3.9094621e-01]
 [8.7422228e-01 1.2577766e-01]
 [4.6930259e-01 5.3069741e-01]
 [4.1943544e-01 5.8056450e-01]
 [4.6490788e-01 5.3509212e-01]
 [2.1973978e-01 7.8026021e-01]
 [6.7137951e-01 3.2862049e-01]
 [4.6490788e-01 5.3509212e-01]
 [4.3769583e-01 5.6230414e-01]
 [3.9875871e-01 6.0124129e-01]
 [2.9559723e-01 7.0440286e-01]
 [9.9984646e-01 1.5352374e-04]
 [4.4648528e-01 5.5351466e-01]
 [4.3769583e-01 5.6230414e-01]
 [9.8810786e-01 1.1892088e-02]
 [4.5037925e-01 5.4962069e-01]
 [4.6314186e-01 5.3685814e-01]
 [5.0840229e-01 4.9159768e-01]
 [8.7422228e-01 1.2577766e-01]
 [5.0833237e-01 4.9166763e-01]
 [5.0833237e-01 4.9166763e-01]
 [9.8904347e-01 1.0956522e-02]
 [4.4412035e-01 5.5587959e-01]
 [3.5527471e-01 6.4472526e-01]
 [4.4234183e-01 5.5765820e-01]
 [2.7980509e-01 7.2019488e-01]
 [7.3951232e-01 2.6048765e-01]
 [1.8505557e-04 9.9981493e-01]
 [4.5926744e-01 5.4073256e-01]
 [9.5955706e-01 4.0442958e-02]
 [3.4281754e-01 6.5718246e-01]
 [4.7685283e-01 5.2314723e-01]
 [4.3604115e-01 5.6395894e-01]
 [3.0756378e-01 6.9243622e-01]
 [7.8400916e-01 2.1599087e-01]
 [8.1826669e-01 1.8173338e-01]
 [7.8256190e-01 2.1743813e-01]
 [8.7422228e-01 1.2577766e-01]
 [4.6370691e-01 5.3629315e-01]
 [4.7685283e-01 5.2314723e-01]
 [4.5564023e-01 5.4435974e-01]
 [5.2438277e-01 4.7561726e-01]
 [8.1925482e-01 1.8074523e-01]
 [7.2752124e-01 2.7247873e-01]
 [4.4485867e-01 5.5514127e-01]
 [4.5765874e-01 5.4234123e-01]
 [7.3951232e-01 2.6048765e-01]
 [5.3764093e-01 4.6235904e-01]
 [4.6440947e-01 5.3559047e-01]
 [9.9737024e-01 2.6297446e-03]
 [4.8956037e-01 5.1043963e-01]
 [4.1943544e-01 5.8056450e-01]
 [4.6641076e-01 5.3358924e-01]
 [4.1943544e-01 5.8056450e-01]
 [9.9737024e-01 2.6297446e-03]
 [4.1256660e-01 5.8743340e-01]
 [3.4765908e-01 6.5234095e-01]]
[0 1 0 0 0 1 1 0 0 0 1 0 1 1 1 0 1 1 0 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 0 0 0
 0 1 1 1 1 0 0 1 1 1 1 1 0 1 0 0 1 1 1 1 1 1 0 0 1 1 1 1 0 1 1 1 1 0 1 1 0
 1 1 0 0 0 0 0 1 1 1 1 0 1 1 0 1 1 1 1 0 0 0 0 1 1 1 0 0 0 1 1 0 0 1 0 1 1
 1 1 0 1 1]

 32/116 [=======>......................] - ETA: 1s
 64/116 [===============>..............] - ETA: 0s
 96/116 [=======================>......] - ETA: 0s
116/116 [==============================] - 2s 15ms/step
Test loss: 0.7048657372080046
Test accuracy: 0.6810344786479555
[[32 26]
 [11 47]]
