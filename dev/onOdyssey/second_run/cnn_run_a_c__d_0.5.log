Using TensorFlow backend.
WARNING:tensorflow:From /n/home00/nchou/.conda/envs/envi/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.
Instructions for updating:
Colocations handled automatically by placer.
WARNING:tensorflow:From /n/home00/nchou/.conda/envs/envi/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.
Instructions for updating:
Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.
cnn_aardvark_aug_concat.py:397: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor("in..., outputs=Tensor("de...)`
  model = Model(input=ins, output=dense2)
WARNING:tensorflow:From /n/home00/nchou/.conda/envs/envi/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.cast instead.
2019-11-07 09:03:35.165949: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
2019-11-07 09:03:35.169949: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2900000000 Hz
2019-11-07 09:03:35.170072: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x55d8082cfe20 executing computations on platform Host. Devices:
2019-11-07 09:03:35.170092: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (0): <undefined>, <undefined>
[0.5]
Train on 348 samples, validate on 116 samples
Epoch 1/35

348/348 [==============================] - 24s 68ms/step - loss: 0.6933 - acc: 0.4971 - val_loss: 0.6832 - val_acc: 0.6207
Epoch 2/35

348/348 [==============================] - 21s 62ms/step - loss: 0.6757 - acc: 0.7931 - val_loss: 0.6729 - val_acc: 0.6121
Epoch 3/35

348/348 [==============================] - 21s 61ms/step - loss: 0.6542 - acc: 0.7356 - val_loss: 0.6623 - val_acc: 0.5862
Epoch 4/35

348/348 [==============================] - 21s 61ms/step - loss: 0.6279 - acc: 0.7328 - val_loss: 0.6622 - val_acc: 0.5345
Epoch 5/35

348/348 [==============================] - 21s 61ms/step - loss: 0.6023 - acc: 0.6580 - val_loss: 0.7089 - val_acc: 0.5862
Epoch 6/35

348/348 [==============================] - 21s 61ms/step - loss: 0.6406 - acc: 0.5718 - val_loss: 0.7418 - val_acc: 0.4914
Epoch 7/35

348/348 [==============================] - 21s 61ms/step - loss: 0.6242 - acc: 0.5661 - val_loss: 0.6863 - val_acc: 0.5172
Epoch 8/35

348/348 [==============================] - 21s 60ms/step - loss: 0.5618 - acc: 0.6638 - val_loss: 0.7308 - val_acc: 0.5948
Epoch 9/35

348/348 [==============================] - 21s 61ms/step - loss: 0.6143 - acc: 0.6121 - val_loss: 0.6816 - val_acc: 0.5862
Epoch 10/35

348/348 [==============================] - 21s 61ms/step - loss: 0.5314 - acc: 0.7241 - val_loss: 0.7869 - val_acc: 0.5000
Epoch 11/35

348/348 [==============================] - 21s 61ms/step - loss: 0.5943 - acc: 0.5977 - val_loss: 0.7049 - val_acc: 0.5776
Epoch 12/35

348/348 [==============================] - 21s 61ms/step - loss: 0.5109 - acc: 0.7443 - val_loss: 0.7665 - val_acc: 0.6034
Epoch 13/35

348/348 [==============================] - 21s 61ms/step - loss: 0.5708 - acc: 0.6466 - val_loss: 0.7233 - val_acc: 0.5862
Epoch 14/35

348/348 [==============================] - 21s 61ms/step - loss: 0.4941 - acc: 0.7586 - val_loss: 0.8179 - val_acc: 0.5086
Epoch 15/35

348/348 [==============================] - 21s 60ms/step - loss: 0.5476 - acc: 0.6609 - val_loss: 0.7539 - val_acc: 0.5603
Epoch 16/35

348/348 [==============================] - 21s 60ms/step - loss: 0.4785 - acc: 0.7557 - val_loss: 0.8043 - val_acc: 0.6034
Epoch 17/35

348/348 [==============================] - 21s 60ms/step - loss: 0.5226 - acc: 0.6724 - val_loss: 0.7756 - val_acc: 0.5862
Epoch 18/35

348/348 [==============================] - 21s 60ms/step - loss: 0.4655 - acc: 0.7615 - val_loss: 0.8517 - val_acc: 0.5259
Epoch 19/35

348/348 [==============================] - 21s 61ms/step - loss: 0.5001 - acc: 0.6839 - val_loss: 0.8127 - val_acc: 0.5517
Epoch 20/35

348/348 [==============================] - 21s 60ms/step - loss: 0.4518 - acc: 0.7644 - val_loss: 0.8506 - val_acc: 0.6121
Epoch 21/35

348/348 [==============================] - 21s 61ms/step - loss: 0.4792 - acc: 0.7328 - val_loss: 0.8355 - val_acc: 0.5862
Epoch 22/35

348/348 [==============================] - 21s 60ms/step - loss: 0.4393 - acc: 0.7787 - val_loss: 0.8952 - val_acc: 0.5690
Epoch 23/35

348/348 [==============================] - 21s 60ms/step - loss: 0.4603 - acc: 0.7213 - val_loss: 0.8731 - val_acc: 0.5776
Epoch 24/35

348/348 [==============================] - 21s 60ms/step - loss: 0.4257 - acc: 0.7557 - val_loss: 0.9075 - val_acc: 0.5948
Epoch 25/35

348/348 [==============================] - 21s 60ms/step - loss: 0.4443 - acc: 0.7529 - val_loss: 0.9010 - val_acc: 0.5690
Epoch 26/35

348/348 [==============================] - 21s 60ms/step - loss: 0.4127 - acc: 0.7902 - val_loss: 0.9551 - val_acc: 0.5603
Epoch 27/35

348/348 [==============================] - 21s 60ms/step - loss: 0.4304 - acc: 0.7414 - val_loss: 0.9390 - val_acc: 0.6121
Epoch 28/35

348/348 [==============================] - 21s 60ms/step - loss: 0.3991 - acc: 0.7960 - val_loss: 0.9777 - val_acc: 0.6121
Epoch 29/35

348/348 [==============================] - 21s 60ms/step - loss: 0.4166 - acc: 0.7874 - val_loss: 0.9759 - val_acc: 0.6207
Epoch 30/35

348/348 [==============================] - 21s 60ms/step - loss: 0.3869 - acc: 0.7989 - val_loss: 1.0273 - val_acc: 0.5776
Epoch 31/35

348/348 [==============================] - 21s 60ms/step - loss: 0.4028 - acc: 0.7644 - val_loss: 1.0174 - val_acc: 0.6293
Epoch 32/35

348/348 [==============================] - 21s 60ms/step - loss: 0.3763 - acc: 0.7989 - val_loss: 1.0512 - val_acc: 0.5603
Epoch 33/35

348/348 [==============================] - 21s 60ms/step - loss: 0.3862 - acc: 0.7989 - val_loss: 1.0636 - val_acc: 0.5948
Epoch 34/35

348/348 [==============================] - 21s 60ms/step - loss: 0.3682 - acc: 0.8190 - val_loss: 1.0868 - val_acc: 0.5862
Epoch 35/35

348/348 [==============================] - 21s 60ms/step - loss: 0.3676 - acc: 0.7874 - val_loss: 1.1019 - val_acc: 0.5776
Saved trained model at /n/holylfs03/LABS/berger_lab/nchou/saved_models/aardvark_aug11.h5 
[[8.6369699e-01 1.3630298e-01]
 [3.3050552e-01 6.6949451e-01]
 [9.9999058e-01 9.3826829e-06]
 [9.3063551e-01 6.9364503e-02]
 [8.4581876e-01 1.5418126e-01]
 [3.3748168e-01 6.6251832e-01]
 [1.0847315e-03 9.9891531e-01]
 [9.9999988e-01 7.1175947e-08]
 [6.6941416e-01 3.3058590e-01]
 [9.9999726e-01 2.7885910e-06]
 [4.4805834e-01 5.5194163e-01]
 [3.0138829e-01 6.9861168e-01]
 [3.0907357e-01 6.9092643e-01]
 [3.3442548e-01 6.6557449e-01]
 [2.3502354e-01 7.6497644e-01]
 [9.9983931e-01 1.6068212e-04]
 [2.8051957e-01 7.1948045e-01]
 [3.8191825e-01 6.1808175e-01]
 [9.3367106e-01 6.6328943e-02]
 [4.2848946e-03 9.9571508e-01]
 [1.0847315e-03 9.9891531e-01]
 [2.8051957e-01 7.1948045e-01]
 [6.7629060e-03 9.9323708e-01]
 [8.4581876e-01 1.5418126e-01]
 [3.3442548e-01 6.6557449e-01]
 [3.1069908e-01 6.8930089e-01]
 [2.9959518e-01 7.0040476e-01]
 [8.3241403e-01 1.6758598e-01]
 [3.8172770e-01 6.1827224e-01]
 [2.3502354e-01 7.6497644e-01]
 [2.6665738e-01 7.3334265e-01]
 [3.5276431e-01 6.4723569e-01]
 [3.3333793e-01 6.6666210e-01]
 [3.7856498e-01 6.2143499e-01]
 [9.9999940e-01 6.4705711e-07]
 [2.0373333e-02 9.7962672e-01]
 [9.7410405e-01 2.5895929e-02]
 [3.0138829e-01 6.9861168e-01]
 [3.7818182e-01 6.2181818e-01]
 [2.6665738e-01 7.3334265e-01]
 [3.9516363e-01 6.0483634e-01]
 [3.0002826e-01 6.9997180e-01]
 [7.8204278e-07 9.9999917e-01]
 [9.9999058e-01 9.3826829e-06]
 [1.3949910e-01 8.6050087e-01]
 [4.1231906e-01 5.8768094e-01]
 [2.3325920e-01 7.6674086e-01]
 [3.8496593e-01 6.1503404e-01]
 [2.2611964e-01 7.7388036e-01]
 [9.7410405e-01 2.5895929e-02]
 [1.7318461e-03 9.9826813e-01]
 [9.7410405e-01 2.5895929e-02]
 [9.9983931e-01 1.6068212e-04]
 [4.7266015e-01 5.2733976e-01]
 [5.0159371e-01 4.9840623e-01]
 [8.6212754e-01 1.3787249e-01]
 [6.3641280e-01 3.6358723e-01]
 [2.6665738e-01 7.3334265e-01]
 [3.3617049e-01 6.6382951e-01]
 [8.4581876e-01 1.5418126e-01]
 [9.9999988e-01 7.1175947e-08]
 [3.1069908e-01 6.8930089e-01]
 [2.6665738e-01 7.3334265e-01]
 [5.0879115e-01 4.9120882e-01]
 [1.0847315e-03 9.9891531e-01]
 [2.5819826e-01 7.4180168e-01]
 [5.0879115e-01 4.9120882e-01]
 [2.2611964e-01 7.7388036e-01]
 [8.7546244e-02 9.1245377e-01]
 [3.1764099e-01 6.8235904e-01]
 [3.2943650e-03 9.9670571e-01]
 [3.1982186e-01 6.8017817e-01]
 [2.2611964e-01 7.7388036e-01]
 [2.6104802e-03 9.9738950e-01]
 [3.0002826e-01 6.9997180e-01]
 [3.8903075e-01 6.1096925e-01]
 [7.0085770e-01 2.9914224e-01]
 [9.9999988e-01 7.1175947e-08]
 [3.0138829e-01 6.9861168e-01]
 [3.0138829e-01 6.9861168e-01]
 [9.9983931e-01 1.6068212e-04]
 [7.4054265e-01 2.5945735e-01]
 [2.6988530e-01 7.3011476e-01]
 [3.8496593e-01 6.1503404e-01]
 [1.8301259e-01 8.1698745e-01]
 [9.9999726e-01 2.7885910e-06]
 [8.0455524e-01 1.9544478e-01]
 [3.5276431e-01 6.4723569e-01]
 [8.3136672e-01 1.6863336e-01]
 [1.4272937e-01 8.5727060e-01]
 [3.3333793e-01 6.6666210e-01]
 [3.2038152e-01 6.7961848e-01]
 [6.9166422e-02 9.3083358e-01]
 [9.6949220e-01 3.0507794e-02]
 [9.7911662e-01 2.0883396e-02]
 [9.3063551e-01 6.9364503e-02]
 [9.9999988e-01 7.1175947e-08]
 [3.2296354e-01 6.7703640e-01]
 [3.3333793e-01 6.6666210e-01]
 [3.6796394e-01 6.3203603e-01]
 [7.6730520e-01 2.3269477e-01]
 [7.8204278e-07 9.9999917e-01]
 [9.9999058e-01 9.3826829e-06]
 [5.0971067e-01 4.9028933e-01]
 [3.2893759e-01 6.7106241e-01]
 [9.9999726e-01 2.7885910e-06]
 [1.7886534e-01 8.2113463e-01]
 [3.6603677e-01 6.3396317e-01]
 [1.0000000e+00 5.4435656e-09]
 [5.0159371e-01 4.9840623e-01]
 [2.6665738e-01 7.3334265e-01]
 [6.1835045e-01 3.8164952e-01]
 [2.6665738e-01 7.3334265e-01]
 [1.0000000e+00 5.4435656e-09]
 [1.0637517e-01 8.9362478e-01]
 [2.2234720e-01 7.7765286e-01]]
[0 1 0 0 0 1 1 0 0 0 1 1 1 1 1 0 1 1 0 1 1 1 1 0 1 1 1 0 1 1 1 1 1 1 0 1 0
 1 1 1 1 1 1 0 1 1 1 1 1 0 1 0 0 1 0 0 0 1 1 0 0 1 1 0 1 1 0 1 1 1 1 1 1 1
 1 1 0 0 1 1 0 0 1 1 1 0 0 1 0 1 1 1 1 0 0 0 0 1 1 1 0 1 0 0 1 0 1 1 0 0 1
 0 1 0 1 1]

 32/116 [=======>......................] - ETA: 1s
 64/116 [===============>..............] - ETA: 0s
 96/116 [=======================>......] - ETA: 0s
116/116 [==============================] - 2s 17ms/step
Test loss: 1.1781775416999027
Test accuracy: 0.6293103427722536
[[29 29]
 [14 44]]
