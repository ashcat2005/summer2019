Using TensorFlow backend.
WARNING:tensorflow:From /n/home00/nchou/.conda/envs/envi/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.
Instructions for updating:
Colocations handled automatically by placer.
cnn_aardvark_aug_concat.py:397: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor("in..., outputs=Tensor("de...)`
  model = Model(input=ins, output=dense2)
WARNING:tensorflow:From /n/home00/nchou/.conda/envs/envi/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.cast instead.
2019-11-07 11:45:22.437377: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
2019-11-07 11:45:22.567562: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2900000000 Hz
2019-11-07 11:45:22.567822: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x556ddba71570 executing computations on platform Host. Devices:
2019-11-07 11:45:22.567873: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (0): <undefined>, <undefined>
None
Train on 522 samples, validate on 174 samples
Epoch 1/40

522/522 [==============================] - 32s 61ms/step - loss: 1.0992 - acc: 0.2969 - val_loss: 1.0871 - val_acc: 0.3851
Epoch 2/40

522/522 [==============================] - 29s 55ms/step - loss: 1.0808 - acc: 0.5900 - val_loss: 1.0720 - val_acc: 0.3736
Epoch 3/40

522/522 [==============================] - 29s 55ms/step - loss: 1.0567 - acc: 0.5479 - val_loss: 1.0557 - val_acc: 0.4253
Epoch 4/40

522/522 [==============================] - 29s 55ms/step - loss: 1.0259 - acc: 0.5441 - val_loss: 1.0414 - val_acc: 0.3563
Epoch 5/40

522/522 [==============================] - 29s 55ms/step - loss: 0.9920 - acc: 0.5785 - val_loss: 1.0362 - val_acc: 0.3793
Epoch 6/40

522/522 [==============================] - 29s 55ms/step - loss: 0.9584 - acc: 0.5383 - val_loss: 1.0619 - val_acc: 0.4368
Epoch 7/40

522/522 [==============================] - 29s 55ms/step - loss: 0.9597 - acc: 0.4770 - val_loss: 1.1440 - val_acc: 0.4023
Epoch 8/40

522/522 [==============================] - 29s 55ms/step - loss: 0.9876 - acc: 0.4885 - val_loss: 1.0533 - val_acc: 0.3736
Epoch 9/40

522/522 [==============================] - 29s 55ms/step - loss: 0.8889 - acc: 0.5556 - val_loss: 1.1458 - val_acc: 0.4195
Epoch 10/40

522/522 [==============================] - 29s 55ms/step - loss: 0.9796 - acc: 0.4636 - val_loss: 1.1118 - val_acc: 0.4425
Epoch 11/40

522/522 [==============================] - 29s 55ms/step - loss: 0.8826 - acc: 0.5326 - val_loss: 1.2258 - val_acc: 0.3793
Epoch 12/40

522/522 [==============================] - 29s 55ms/step - loss: 0.9699 - acc: 0.4847 - val_loss: 1.0991 - val_acc: 0.4080
Epoch 13/40

522/522 [==============================] - 29s 55ms/step - loss: 0.8321 - acc: 0.6169 - val_loss: 1.1842 - val_acc: 0.4540
Epoch 14/40

522/522 [==============================] - 29s 55ms/step - loss: 0.9112 - acc: 0.5153 - val_loss: 1.1511 - val_acc: 0.4023
Epoch 15/40

522/522 [==============================] - 29s 55ms/step - loss: 0.8459 - acc: 0.5594 - val_loss: 1.1687 - val_acc: 0.3908
Epoch 16/40

522/522 [==============================] - 29s 55ms/step - loss: 0.8233 - acc: 0.5594 - val_loss: 1.2210 - val_acc: 0.3851
Epoch 17/40

522/522 [==============================] - 29s 55ms/step - loss: 0.8445 - acc: 0.5383 - val_loss: 1.1710 - val_acc: 0.4713
Epoch 18/40

522/522 [==============================] - 29s 55ms/step - loss: 0.7779 - acc: 0.6264 - val_loss: 1.2248 - val_acc: 0.4483
Epoch 19/40

522/522 [==============================] - 29s 55ms/step - loss: 0.8200 - acc: 0.5632 - val_loss: 1.2048 - val_acc: 0.4253
Epoch 20/40

522/522 [==============================] - 29s 55ms/step - loss: 0.7637 - acc: 0.6456 - val_loss: 1.2390 - val_acc: 0.4598
Epoch 21/40

522/522 [==============================] - 29s 55ms/step - loss: 0.7605 - acc: 0.6188 - val_loss: 1.2637 - val_acc: 0.4080
Epoch 22/40

522/522 [==============================] - 29s 55ms/step - loss: 0.7621 - acc: 0.5824 - val_loss: 1.2392 - val_acc: 0.4770
Epoch 23/40

522/522 [==============================] - 29s 55ms/step - loss: 0.7164 - acc: 0.6916 - val_loss: 1.2862 - val_acc: 0.4713
Epoch 24/40

522/522 [==============================] - 29s 55ms/step - loss: 0.7364 - acc: 0.6628 - val_loss: 1.2741 - val_acc: 0.4828
Epoch 25/40

522/522 [==============================] - 29s 55ms/step - loss: 0.7014 - acc: 0.6839 - val_loss: 1.2759 - val_acc: 0.4943
Epoch 26/40

522/522 [==============================] - 29s 55ms/step - loss: 0.6902 - acc: 0.6762 - val_loss: 1.2949 - val_acc: 0.4828
Epoch 27/40

522/522 [==============================] - 29s 55ms/step - loss: 0.6897 - acc: 0.6475 - val_loss: 1.2896 - val_acc: 0.5345
Epoch 28/40

522/522 [==============================] - 29s 56ms/step - loss: 0.6575 - acc: 0.7050 - val_loss: 1.3185 - val_acc: 0.5057
Epoch 29/40

522/522 [==============================] - 29s 55ms/step - loss: 0.6641 - acc: 0.6973 - val_loss: 1.3175 - val_acc: 0.5230
Epoch 30/40

522/522 [==============================] - 29s 56ms/step - loss: 0.6401 - acc: 0.7318 - val_loss: 1.3158 - val_acc: 0.5000
Epoch 31/40

522/522 [==============================] - 29s 55ms/step - loss: 0.6278 - acc: 0.7318 - val_loss: 1.3271 - val_acc: 0.5000
Epoch 32/40

522/522 [==============================] - 29s 55ms/step - loss: 0.6247 - acc: 0.7165 - val_loss: 1.3381 - val_acc: 0.5747
Epoch 33/40

522/522 [==============================] - 29s 55ms/step - loss: 0.6004 - acc: 0.7510 - val_loss: 1.3690 - val_acc: 0.5517
Epoch 34/40

522/522 [==============================] - 29s 55ms/step - loss: 0.5997 - acc: 0.7548 - val_loss: 1.3683 - val_acc: 0.5287
Epoch 35/40

522/522 [==============================] - 29s 56ms/step - loss: 0.5803 - acc: 0.7586 - val_loss: 1.3750 - val_acc: 0.5287
Epoch 36/40

522/522 [==============================] - 29s 55ms/step - loss: 0.5689 - acc: 0.7605 - val_loss: 1.3875 - val_acc: 0.5057
Epoch 37/40

522/522 [==============================] - 29s 55ms/step - loss: 0.5608 - acc: 0.7567 - val_loss: 1.4023 - val_acc: 0.5747
Epoch 38/40

522/522 [==============================] - 29s 56ms/step - loss: 0.5420 - acc: 0.7950 - val_loss: 1.4309 - val_acc: 0.5575
Epoch 39/40

522/522 [==============================] - 29s 56ms/step - loss: 0.5376 - acc: 0.7854 - val_loss: 1.4351 - val_acc: 0.5690
Epoch 40/40

522/522 [==============================] - 29s 55ms/step - loss: 0.5199 - acc: 0.7969 - val_loss: 1.4447 - val_acc: 0.5057
Saved trained model at /n/holylfs03/LABS/berger_lab/nchou/saved_models/aardvark_aug11.h5 
[[3.00071687e-01 3.80147457e-01 3.19780916e-01]
 [3.24193418e-01 3.63320440e-01 3.12486112e-01]
 [3.13361853e-01 3.62443745e-01 3.24194431e-01]
 [1.99610800e-01 1.86943054e-01 6.13446176e-01]
 [4.98403549e-01 2.12266162e-01 2.89330363e-01]
 [9.95325327e-01 4.67469497e-03 3.78081011e-10]
 [3.42426479e-01 3.51371765e-01 3.06201726e-01]
 [3.58299583e-01 3.39003414e-01 3.02697003e-01]
 [3.24497849e-01 3.55495602e-01 3.20006520e-01]
 [3.08929592e-01 3.56440246e-01 3.34630162e-01]
 [6.59075499e-01 2.04704404e-01 1.36220127e-01]
 [2.35906273e-01 4.54715490e-01 3.09378207e-01]
 [3.09458822e-01 2.97580689e-01 3.92960429e-01]
 [3.34435552e-01 5.53659797e-01 1.11904681e-01]
 [3.99089903e-01 1.63185120e-01 4.37725037e-01]
 [7.37135887e-01 1.15120739e-01 1.47743419e-01]
 [2.02146490e-04 7.21315714e-03 9.92584646e-01]
 [2.97860622e-01 4.32103127e-01 2.70036340e-01]
 [9.99999762e-01 2.85647569e-12 2.21954508e-07]
 [3.35452199e-01 4.00167078e-01 2.64380723e-01]
 [1.92579612e-01 3.15306634e-01 4.92113739e-01]
 [3.61567944e-01 1.31598949e-01 5.06833136e-01]
 [4.62244093e-01 2.43018657e-01 2.94737250e-01]
 [4.28347886e-01 3.82029384e-01 1.89622730e-01]
 [4.62244093e-01 2.43018657e-01 2.94737250e-01]
 [3.50798219e-01 3.09426844e-01 3.39774936e-01]
 [5.73102772e-01 2.07726255e-01 2.19171092e-01]
 [2.58765230e-03 8.59830678e-01 1.37581691e-01]
 [1.10530980e-01 7.34699845e-01 1.54769242e-01]
 [3.18717808e-01 4.11353886e-01 2.69928336e-01]
 [1.00000000e+00 4.04131589e-11 3.46138007e-10]
 [4.62244093e-01 2.43018657e-01 2.94737250e-01]
 [9.53129172e-01 1.61619727e-02 3.07088234e-02]
 [3.71225059e-01 2.59078532e-01 3.69696438e-01]
 [6.78115782e-07 5.59776947e-10 9.99999285e-01]
 [2.76813418e-01 2.67523944e-01 4.55662638e-01]
 [2.93106765e-01 4.38014716e-01 2.68878490e-01]
 [1.50015786e-01 4.14505213e-01 4.35478926e-01]
 [9.06412482e-01 1.33380704e-02 8.02495629e-02]
 [4.20409530e-01 2.96159983e-01 2.83430517e-01]
 [1.99372577e-03 9.98006284e-01 1.36466732e-11]
 [1.50015786e-01 4.14505213e-01 4.35478926e-01]
 [5.83080053e-01 3.11646938e-01 1.05273038e-01]
 [9.99988317e-01 5.52973086e-13 1.16994051e-05]
 [9.99988317e-01 5.52973086e-13 1.16994051e-05]
 [3.83185029e-01 3.30639184e-01 2.86175758e-01]
 [4.14327174e-01 1.95512176e-01 3.90160620e-01]
 [3.24971229e-01 3.98860782e-01 2.76167929e-01]
 [9.06412482e-01 1.33380704e-02 8.02495629e-02]
 [3.56045455e-01 2.68946022e-01 3.75008464e-01]
 [5.73102772e-01 2.07726255e-01 2.19171092e-01]
 [3.31974536e-01 4.09984559e-01 2.58040935e-01]
 [1.89284116e-01 4.63675022e-01 3.47040892e-01]
 [3.73609573e-01 2.81916708e-01 3.44473720e-01]
 [3.77536416e-01 2.83188224e-01 3.39275330e-01]
 [5.10492504e-01 3.98811221e-01 9.06963125e-02]
 [5.56840897e-01 1.03526250e-01 3.39632869e-01]
 [3.33179355e-01 9.49394777e-02 5.71881115e-01]
 [1.18342437e-01 5.19237757e-01 3.62419784e-01]
 [3.24497849e-01 3.55495602e-01 3.20006520e-01]
 [4.62244093e-01 2.43018657e-01 2.94737250e-01]
 [7.48339534e-01 1.53469712e-01 9.81907248e-02]
 [4.60298598e-01 2.99558878e-01 2.40142480e-01]
 [1.00000000e+00 9.53083612e-10 3.01612103e-11]
 [2.49095121e-03 8.50224793e-01 1.47284150e-01]
 [1.00000000e+00 4.04131589e-11 3.46138007e-10]
 [1.99372577e-03 9.98006284e-01 1.36466732e-11]
 [1.06231255e-06 9.99998689e-01 1.81531149e-07]
 [9.53129172e-01 1.61619727e-02 3.07088234e-02]
 [3.57897937e-01 3.74171108e-01 2.67930895e-01]
 [3.42789680e-01 3.76325309e-01 2.80885041e-01]
 [2.14520410e-01 1.26401827e-01 6.59077704e-01]
 [1.50015786e-01 4.14505213e-01 4.35478926e-01]
 [2.52065182e-01 4.30645615e-01 3.17289203e-01]
 [5.59619367e-01 3.96227315e-02 4.00757879e-01]
 [9.99975443e-01 2.17758065e-06 2.24120577e-05]
 [1.58382505e-02 8.58853519e-01 1.25308216e-01]
 [5.22179948e-03 4.03557867e-02 9.54422474e-01]
 [2.89881051e-01 4.14149910e-01 2.95968980e-01]
 [1.74614713e-01 1.86531991e-01 6.38853312e-01]
 [5.92247234e-04 9.18343127e-01 8.10645744e-02]
 [2.66864806e-01 4.60612059e-01 2.72523075e-01]
 [4.85979617e-01 3.61576051e-01 1.52444303e-01]
 [2.70818412e-01 3.34230214e-01 3.94951403e-01]
 [3.68321061e-01 3.48793387e-01 2.82885581e-01]
 [2.80075788e-01 3.54881465e-01 3.65042686e-01]
 [3.19256097e-01 3.42227280e-01 3.38516593e-01]
 [1.00000000e+00 4.04131589e-11 3.46138007e-10]
 [4.98403549e-01 2.12266162e-01 2.89330363e-01]
 [1.00000000e+00 9.53083612e-10 3.01612103e-11]
 [9.95325327e-01 4.67469497e-03 3.78081011e-10]
 [3.33836824e-01 3.79564762e-01 2.86598414e-01]
 [2.14520410e-01 1.26401827e-01 6.59077704e-01]
 [9.78043437e-01 2.61341215e-09 2.19566301e-02]
 [2.69221872e-01 3.32478613e-01 3.98299545e-01]
 [3.18999738e-01 3.16295087e-01 3.64705145e-01]
 [3.08542192e-01 3.34607750e-01 3.56849968e-01]
 [9.99999762e-01 2.85647569e-12 2.21954508e-07]
 [3.33609164e-01 3.81614804e-01 2.84775972e-01]
 [9.99980927e-01 1.89344955e-05 1.07922034e-07]
 [3.34157318e-01 3.48283023e-01 3.17559600e-01]
 [1.00000000e+00 4.35159159e-10 1.94056243e-10]
 [2.85553515e-01 3.48018557e-01 3.66427958e-01]
 [3.07047904e-01 4.10663038e-01 2.82289088e-01]
 [8.88577625e-02 8.17027271e-01 9.41149592e-02]
 [9.99980927e-01 1.89344955e-05 1.07922034e-07]
 [5.92247234e-04 9.18343127e-01 8.10645744e-02]
 [9.64147866e-01 6.89489720e-03 2.89572440e-02]
 [9.53129172e-01 1.61619727e-02 3.07088234e-02]
 [3.48964380e-03 8.29529762e-01 1.66980609e-01]
 [3.16005945e-01 3.49273860e-01 3.34720165e-01]
 [2.93106765e-01 4.38014716e-01 2.68878490e-01]
 [3.61567944e-01 1.31598949e-01 5.06833136e-01]
 [3.84494811e-01 2.86467969e-01 3.29037189e-01]
 [4.62244093e-01 2.43018657e-01 2.94737250e-01]
 [1.26839953e-03 4.20946211e-01 5.77785373e-01]
 [5.90854526e-01 2.60103524e-01 1.49041995e-01]
 [3.31675589e-01 3.36430997e-01 3.31893444e-01]
 [3.18827629e-01 3.80097121e-01 3.01075280e-01]
 [3.24497849e-01 3.55495602e-01 3.20006520e-01]
 [2.76813418e-01 2.67523944e-01 4.55662638e-01]
 [2.55249832e-02 6.91657186e-01 2.82817841e-01]
 [9.97711658e-01 2.17795884e-03 1.10321234e-04]
 [2.80075788e-01 3.54881465e-01 3.65042686e-01]
 [9.99801934e-01 5.15327702e-05 1.46580205e-04]
 [9.99988317e-01 5.52973086e-13 1.16994051e-05]
 [2.31532589e-01 1.35352746e-01 6.33114636e-01]
 [9.95325327e-01 4.67469497e-03 3.78081011e-10]
 [2.90077478e-01 3.18035483e-01 3.91887009e-01]
 [2.92152856e-02 4.65146393e-01 5.05638301e-01]
 [3.25734943e-01 3.57431263e-01 3.16833794e-01]
 [2.50444382e-01 9.22103748e-02 6.57345235e-01]
 [9.99957323e-01 1.90102844e-06 4.07620028e-05]
 [3.69449317e-01 3.32799017e-01 2.97751755e-01]
 [7.64320076e-01 4.37925064e-06 2.35675499e-01]
 [4.31724459e-01 1.62963450e-01 4.05312121e-01]
 [3.47949922e-01 4.01145130e-01 2.50905007e-01]
 [1.00000000e+00 2.28550665e-15 1.29666948e-13]
 [6.57610834e-01 1.34192079e-01 2.08197042e-01]
 [5.90854526e-01 2.60103524e-01 1.49041995e-01]
 [2.94431627e-01 8.77917837e-03 6.96789265e-01]
 [2.70868242e-01 3.19493473e-01 4.09638286e-01]
 [2.80697435e-01 3.64920855e-01 3.54381710e-01]
 [4.64523673e-01 1.88785598e-01 3.46690774e-01]
 [4.00776118e-01 3.20012361e-01 2.79211521e-01]
 [5.92247234e-04 9.18343127e-01 8.10645744e-02]
 [2.86416989e-03 8.40180576e-01 1.56955302e-01]
 [3.76209021e-01 3.28860700e-01 2.94930249e-01]
 [2.32463218e-02 5.53054333e-01 4.23699260e-01]
 [3.46387714e-01 4.04982924e-01 2.48629346e-01]
 [3.51716578e-01 3.13672513e-01 3.34610909e-01]
 [3.42426479e-01 3.51371765e-01 3.06201726e-01]
 [3.42093796e-01 3.60655874e-01 2.97250420e-01]
 [4.62244093e-01 2.43018657e-01 2.94737250e-01]
 [9.99988317e-01 5.52973086e-13 1.16994051e-05]
 [9.92768645e-01 5.45326970e-04 6.68601133e-03]
 [2.14520410e-01 1.26401827e-01 6.59077704e-01]
 [7.27786899e-01 2.72210598e-01 2.47323032e-06]
 [2.66864806e-01 4.60612059e-01 2.72523075e-01]
 [3.45568627e-01 3.04958403e-01 3.49472940e-01]
 [2.46745422e-01 2.71618038e-01 4.81636494e-01]
 [1.00000000e+00 9.53083612e-10 3.01612103e-11]
 [1.50015786e-01 4.14505213e-01 4.35478926e-01]
 [2.88826197e-01 3.96798253e-01 3.14375550e-01]
 [3.28017592e-01 2.80622661e-01 3.91359687e-01]
 [3.23657542e-01 4.28356230e-01 2.47986183e-01]
 [2.09690347e-01 3.46349537e-01 4.43960190e-01]
 [9.99999762e-01 2.85647569e-12 2.21954508e-07]
 [6.33983314e-01 6.35336637e-02 3.02482963e-01]
 [1.81476161e-01 6.97768271e-01 1.20755538e-01]
 [3.20957661e-01 4.42005068e-01 2.37037286e-01]
 [3.04670602e-01 4.31217909e-01 2.64111429e-01]
 [3.00052524e-01 3.50048721e-01 3.49898756e-01]
 [3.28070015e-01 3.96354795e-01 2.75575250e-01]]
[1 1 1 2 0 0 1 0 1 1 0 1 2 1 2 0 2 1 0 1 2 2 0 0 0 0 0 1 1 1 0 0 0 0 2 2 1
 2 0 0 1 2 0 0 0 0 0 1 0 2 0 1 1 0 0 0 0 2 1 1 0 0 0 0 1 0 1 1 0 1 1 2 2 1
 0 0 1 2 1 2 1 1 0 2 0 2 1 0 0 0 0 1 2 0 2 2 2 0 1 0 1 0 2 1 1 0 1 0 0 1 1
 1 2 0 0 2 0 1 1 1 2 1 0 2 0 0 2 0 2 2 1 2 0 0 0 0 1 0 0 0 2 2 1 0 0 1 1 0
 1 1 0 1 1 0 0 0 2 0 1 2 2 0 2 1 2 1 2 0 0 1 1 1 1 1]

 32/174 [====>.........................] - ETA: 2s
 64/174 [==========>...................] - ETA: 1s
 96/174 [===============>..............] - ETA: 1s
128/174 [=====================>........] - ETA: 0s
160/174 [==========================>...] - ETA: 0s
174/174 [==============================] - 3s 16ms/step
Test loss: 1.689366740741949
Test accuracy: 0.603448275862069
[[41 11  6]
 [11 39  8]
 [22 11 25]]
