Using TensorFlow backend.
WARNING:tensorflow:From /n/home00/nchou/.conda/envs/envi/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.
Instructions for updating:
Colocations handled automatically by placer.
WARNING:tensorflow:From /n/home00/nchou/.conda/envs/envi/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.
Instructions for updating:
Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.
cnn_aardvark_aug_concat.py:397: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor("in..., outputs=Tensor("de...)`
  model = Model(input=ins, output=dense2)
WARNING:tensorflow:From /n/home00/nchou/.conda/envs/envi/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.cast instead.
2019-11-07 09:05:02.686798: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
2019-11-07 09:05:02.734228: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2900000000 Hz
2019-11-07 09:05:02.734450: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x55f5baeb91b0 executing computations on platform Host. Devices:
2019-11-07 09:05:02.734497: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (0): <undefined>, <undefined>
[0.5]
Train on 348 samples, validate on 116 samples
Epoch 1/15

 58/348 [====>.........................] - ETA: 30s - loss: 0.6925 - acc: 0.4483
116/348 [=========>....................] - ETA: 19s - loss: 0.6920 - acc: 0.4828
174/348 [==============>...............] - ETA: 13s - loss: 0.6909 - acc: 0.4885
232/348 [===================>..........] - ETA: 8s - loss: 0.6910 - acc: 0.5000 
290/348 [========================>.....] - ETA: 4s - loss: 0.6903 - acc: 0.5034
348/348 [==============================] - 26s 75ms/step - loss: 0.6895 - acc: 0.5086 - val_loss: 0.7312 - val_acc: 0.5259
Epoch 2/15

 58/348 [====>.........................] - ETA: 17s - loss: 0.7033 - acc: 0.5172
116/348 [=========>....................] - ETA: 14s - loss: 0.6496 - acc: 0.6034
174/348 [==============>...............] - ETA: 10s - loss: 0.6426 - acc: 0.6322
232/348 [===================>..........] - ETA: 7s - loss: 0.6335 - acc: 0.6336 
290/348 [========================>.....] - ETA: 3s - loss: 0.6285 - acc: 0.6310
348/348 [==============================] - 23s 67ms/step - loss: 0.6216 - acc: 0.6437 - val_loss: 0.7073 - val_acc: 0.5086
Epoch 3/15

 58/348 [====>.........................] - ETA: 17s - loss: 0.5888 - acc: 0.5517
116/348 [=========>....................] - ETA: 14s - loss: 0.5996 - acc: 0.6379
174/348 [==============>...............] - ETA: 10s - loss: 0.5618 - acc: 0.6782
232/348 [===================>..........] - ETA: 7s - loss: 0.5769 - acc: 0.6379 
290/348 [========================>.....] - ETA: 3s - loss: 0.5686 - acc: 0.6448
348/348 [==============================] - 23s 67ms/step - loss: 0.5920 - acc: 0.6207 - val_loss: 0.7442 - val_acc: 0.5259
Epoch 4/15

 58/348 [====>.........................] - ETA: 17s - loss: 0.5255 - acc: 0.7241
116/348 [=========>....................] - ETA: 14s - loss: 0.5424 - acc: 0.7069
174/348 [==============>...............] - ETA: 10s - loss: 0.5674 - acc: 0.6839
232/348 [===================>..........] - ETA: 7s - loss: 0.5369 - acc: 0.7026 
290/348 [========================>.....] - ETA: 3s - loss: 0.5351 - acc: 0.6931
348/348 [==============================] - 23s 67ms/step - loss: 0.5177 - acc: 0.7098 - val_loss: 0.8966 - val_acc: 0.5086
Epoch 5/15

 58/348 [====>.........................] - ETA: 17s - loss: 0.5072 - acc: 0.7069
116/348 [=========>....................] - ETA: 14s - loss: 0.4951 - acc: 0.6897
174/348 [==============>...............] - ETA: 10s - loss: 0.4735 - acc: 0.7184
232/348 [===================>..........] - ETA: 7s - loss: 0.4659 - acc: 0.7241 
290/348 [========================>.....] - ETA: 3s - loss: 0.4623 - acc: 0.7345
348/348 [==============================] - 23s 66ms/step - loss: 0.4595 - acc: 0.7385 - val_loss: 0.8819 - val_acc: 0.5776
Epoch 6/15

 58/348 [====>.........................] - ETA: 17s - loss: 0.4395 - acc: 0.7586
116/348 [=========>....................] - ETA: 14s - loss: 0.4142 - acc: 0.7845
174/348 [==============>...............] - ETA: 10s - loss: 0.4111 - acc: 0.7644
232/348 [===================>..........] - ETA: 7s - loss: 0.4128 - acc: 0.7716 
290/348 [========================>.....] - ETA: 3s - loss: 0.4057 - acc: 0.7759
348/348 [==============================] - 23s 67ms/step - loss: 0.4200 - acc: 0.7644 - val_loss: 1.0183 - val_acc: 0.5517
Epoch 7/15

 58/348 [====>.........................] - ETA: 17s - loss: 0.3370 - acc: 0.7759
116/348 [=========>....................] - ETA: 13s - loss: 0.3844 - acc: 0.7672
174/348 [==============>...............] - ETA: 10s - loss: 0.4180 - acc: 0.7414
232/348 [===================>..........] - ETA: 6s - loss: 0.4051 - acc: 0.7586 
290/348 [========================>.....] - ETA: 3s - loss: 0.3980 - acc: 0.7724
348/348 [==============================] - 23s 66ms/step - loss: 0.3846 - acc: 0.7845 - val_loss: 1.0519 - val_acc: 0.6034
Epoch 8/15

 58/348 [====>.........................] - ETA: 17s - loss: 0.3534 - acc: 0.8276
116/348 [=========>....................] - ETA: 13s - loss: 0.3917 - acc: 0.8017
174/348 [==============>...............] - ETA: 10s - loss: 0.3532 - acc: 0.8333
232/348 [===================>..........] - ETA: 6s - loss: 0.3485 - acc: 0.8276 
290/348 [========================>.....] - ETA: 3s - loss: 0.3448 - acc: 0.8276
348/348 [==============================] - 23s 66ms/step - loss: 0.3467 - acc: 0.8247 - val_loss: 1.2075 - val_acc: 0.6293
Epoch 9/15

 58/348 [====>.........................] - ETA: 17s - loss: 0.2649 - acc: 0.8793
116/348 [=========>....................] - ETA: 13s - loss: 0.3257 - acc: 0.8362
174/348 [==============>...............] - ETA: 10s - loss: 0.3259 - acc: 0.8621
232/348 [===================>..........] - ETA: 6s - loss: 0.3228 - acc: 0.8578 
290/348 [========================>.....] - ETA: 3s - loss: 0.3196 - acc: 0.8621
348/348 [==============================] - 23s 65ms/step - loss: 0.3127 - acc: 0.8592 - val_loss: 1.3192 - val_acc: 0.6379
Epoch 10/15

 58/348 [====>.........................] - ETA: 17s - loss: 0.1809 - acc: 0.9483
116/348 [=========>....................] - ETA: 13s - loss: 0.2674 - acc: 0.8621
174/348 [==============>...............] - ETA: 10s - loss: 0.2919 - acc: 0.8621
232/348 [===================>..........] - ETA: 6s - loss: 0.2776 - acc: 0.8750 
290/348 [========================>.....] - ETA: 3s - loss: 0.2730 - acc: 0.8655
348/348 [==============================] - 23s 65ms/step - loss: 0.2810 - acc: 0.8678 - val_loss: 1.4019 - val_acc: 0.6552
Epoch 11/15

 58/348 [====>.........................] - ETA: 17s - loss: 0.2362 - acc: 0.8966
116/348 [=========>....................] - ETA: 13s - loss: 0.2469 - acc: 0.8793
174/348 [==============>...............] - ETA: 10s - loss: 0.2462 - acc: 0.8736
232/348 [===================>..........] - ETA: 6s - loss: 0.2528 - acc: 0.8707 
290/348 [========================>.....] - ETA: 3s - loss: 0.2544 - acc: 0.8759
348/348 [==============================] - 23s 66ms/step - loss: 0.2526 - acc: 0.8822 - val_loss: 1.3927 - val_acc: 0.6466
Epoch 12/15

 58/348 [====>.........................] - ETA: 17s - loss: 0.2108 - acc: 0.8966
116/348 [=========>....................] - ETA: 13s - loss: 0.2247 - acc: 0.9138
174/348 [==============>...............] - ETA: 10s - loss: 0.2267 - acc: 0.8966
232/348 [===================>..........] - ETA: 6s - loss: 0.2205 - acc: 0.9052 
290/348 [========================>.....] - ETA: 3s - loss: 0.2309 - acc: 0.9034
348/348 [==============================] - 23s 66ms/step - loss: 0.2210 - acc: 0.9109 - val_loss: 1.4103 - val_acc: 0.6897
Epoch 13/15

 58/348 [====>.........................] - ETA: 17s - loss: 0.1669 - acc: 0.9483
116/348 [=========>....................] - ETA: 13s - loss: 0.1932 - acc: 0.9310
174/348 [==============>...............] - ETA: 10s - loss: 0.1805 - acc: 0.9368
232/348 [===================>..........] - ETA: 6s - loss: 0.1993 - acc: 0.9310 
290/348 [========================>.....] - ETA: 3s - loss: 0.1950 - acc: 0.9310
348/348 [==============================] - 23s 66ms/step - loss: 0.1926 - acc: 0.9339 - val_loss: 1.4374 - val_acc: 0.6810
Epoch 14/15

 58/348 [====>.........................] - ETA: 17s - loss: 0.1235 - acc: 0.9655
116/348 [=========>....................] - ETA: 13s - loss: 0.1299 - acc: 0.9569
174/348 [==============>...............] - ETA: 10s - loss: 0.1406 - acc: 0.9483
232/348 [===================>..........] - ETA: 6s - loss: 0.1584 - acc: 0.9440 
290/348 [========================>.....] - ETA: 3s - loss: 0.1585 - acc: 0.9483
348/348 [==============================] - 23s 66ms/step - loss: 0.1765 - acc: 0.9368 - val_loss: 1.5977 - val_acc: 0.6638
Epoch 15/15

 58/348 [====>.........................] - ETA: 17s - loss: 0.1511 - acc: 0.9655
116/348 [=========>....................] - ETA: 14s - loss: 0.1721 - acc: 0.9655
174/348 [==============>...............] - ETA: 10s - loss: 0.1905 - acc: 0.9425
232/348 [===================>..........] - ETA: 6s - loss: 0.1790 - acc: 0.9483 
290/348 [========================>.....] - ETA: 3s - loss: 0.1698 - acc: 0.9448
348/348 [==============================] - 23s 66ms/step - loss: 0.1593 - acc: 0.9483 - val_loss: 1.5828 - val_acc: 0.7241
Saved trained model at /n/holylfs03/LABS/berger_lab/nchou/saved_models/aardvark_aug11.h5 
[[8.77420068e-01 1.22579932e-01]
 [2.69184023e-01 7.30815947e-01]
 [5.11037745e-03 9.94889617e-01]
 [8.54265094e-01 1.45734951e-01]
 [7.92334080e-01 2.07665950e-01]
 [1.55709937e-01 8.44290078e-01]
 [1.26304499e-07 9.99999881e-01]
 [1.00000000e+00 1.43796201e-17]
 [9.95309293e-01 4.69073281e-03]
 [1.00000000e+00 2.16813373e-11]
 [9.99594629e-01 4.05336090e-04]
 [6.55776441e-01 3.44223559e-01]
 [1.71486944e-01 8.28513086e-01]
 [2.40802899e-01 7.59197116e-01]
 [1.31195793e-02 9.86880422e-01]
 [2.80463837e-06 9.99997139e-01]
 [6.16771616e-02 9.38322842e-01]
 [3.90517861e-01 6.09482169e-01]
 [9.99785483e-01 2.14472413e-04]
 [2.48250376e-06 9.99997497e-01]
 [1.26304499e-07 9.99999881e-01]
 [6.16771616e-02 9.38322842e-01]
 [1.31322944e-08 1.00000000e+00]
 [7.92334080e-01 2.07665950e-01]
 [2.40802899e-01 7.59197116e-01]
 [4.40029979e-01 5.59970021e-01]
 [1.44933149e-01 8.55066895e-01]
 [9.99997377e-01 2.62183107e-06]
 [5.44936121e-01 4.55063909e-01]
 [1.31195793e-02 9.86880422e-01]
 [2.01351047e-01 7.98649013e-01]
 [2.04922870e-01 7.95077145e-01]
 [1.00938715e-01 8.99061322e-01]
 [2.62281626e-01 7.37718403e-01]
 [1.00000000e+00 6.29977466e-25]
 [6.60787919e-05 9.99933958e-01]
 [9.99999046e-01 9.53362360e-07]
 [6.55776441e-01 3.44223559e-01]
 [2.70017713e-01 7.29982316e-01]
 [2.01351047e-01 7.98649013e-01]
 [5.39081991e-01 4.60918009e-01]
 [3.00622471e-02 9.69937801e-01]
 [1.29835325e-05 9.99987006e-01]
 [5.11037745e-03 9.94889617e-01]
 [1.71803962e-02 9.82819617e-01]
 [5.75404521e-03 9.94245946e-01]
 [8.75913858e-01 1.24086089e-01]
 [5.37287652e-01 4.62712377e-01]
 [2.17346866e-02 9.78265285e-01]
 [9.99999046e-01 9.53362360e-07]
 [2.27843020e-06 9.99997735e-01]
 [9.99999046e-01 9.53362360e-07]
 [2.80463837e-06 9.99997139e-01]
 [9.97824311e-01 2.17566895e-03]
 [2.18855396e-01 7.81144619e-01]
 [9.99964237e-01 3.57633144e-05]
 [2.20566392e-01 7.79433668e-01]
 [2.01351047e-01 7.98649013e-01]
 [1.94169238e-01 8.05830777e-01]
 [7.92334080e-01 2.07665950e-01]
 [1.00000000e+00 1.43796201e-17]
 [4.40029979e-01 5.59970021e-01]
 [2.01351047e-01 7.98649013e-01]
 [6.53418720e-01 3.46581221e-01]
 [1.26304499e-07 9.99999881e-01]
 [5.48305921e-03 9.94516909e-01]
 [6.53418720e-01 3.46581221e-01]
 [2.17346866e-02 9.78265285e-01]
 [4.31583859e-02 9.56841588e-01]
 [9.99429747e-02 9.00057018e-01]
 [6.69290171e-21 1.00000000e+00]
 [1.91453576e-01 8.08546424e-01]
 [2.17346866e-02 9.78265285e-01]
 [1.38015311e-20 1.00000000e+00]
 [3.00622471e-02 9.69937801e-01]
 [4.18929607e-01 5.81070364e-01]
 [7.00782180e-01 2.99217850e-01]
 [1.00000000e+00 1.43796201e-17]
 [6.55776441e-01 3.44223559e-01]
 [6.55776441e-01 3.44223559e-01]
 [2.80463837e-06 9.99997139e-01]
 [7.94772685e-01 2.05227286e-01]
 [1.44996673e-01 8.55003357e-01]
 [5.37287652e-01 4.62712377e-01]
 [7.05827586e-03 9.92941737e-01]
 [1.00000000e+00 2.16813373e-11]
 [1.00000000e+00 1.61521083e-15]
 [2.04922870e-01 7.95077145e-01]
 [1.00000000e+00 2.63147101e-18]
 [1.98732354e-02 9.80126739e-01]
 [1.00938715e-01 8.99061322e-01]
 [2.10769713e-01 7.89230287e-01]
 [1.00000000e+00 6.80137847e-12]
 [1.00000000e+00 7.57172704e-16]
 [9.94755387e-01 5.24456240e-03]
 [8.54265094e-01 1.45734951e-01]
 [1.00000000e+00 1.43796201e-17]
 [1.85297087e-01 8.14702928e-01]
 [1.00938715e-01 8.99061322e-01]
 [3.27919841e-01 6.72080159e-01]
 [8.02559733e-01 1.97440282e-01]
 [1.29835325e-05 9.99987006e-01]
 [5.11037745e-03 9.94889617e-01]
 [4.45050210e-01 5.54949820e-01]
 [2.03604743e-01 7.96395242e-01]
 [1.00000000e+00 2.16813373e-11]
 [2.31474463e-04 9.99768555e-01]
 [4.32054311e-01 5.67945600e-01]
 [1.00000000e+00 5.51507628e-22]
 [2.18855396e-01 7.81144619e-01]
 [2.01351047e-01 7.98649013e-01]
 [8.83747399e-01 1.16252623e-01]
 [2.01351047e-01 7.98649013e-01]
 [1.00000000e+00 5.51507628e-22]
 [3.59002650e-02 9.64099765e-01]
 [5.27402908e-02 9.47259724e-01]]
[0 1 1 0 0 1 1 0 0 0 0 0 1 1 1 1 1 1 0 1 1 1 1 0 1 1 1 0 0 1 1 1 1 1 0 1 0
 0 1 1 0 1 1 1 1 1 0 0 1 0 1 0 1 0 1 0 1 1 1 0 0 1 1 0 1 1 0 1 1 1 1 1 1 1
 1 1 0 0 0 0 1 0 1 0 1 0 0 1 0 1 1 1 0 0 0 0 0 1 1 1 0 1 1 1 1 0 1 1 0 1 1
 0 1 0 1 1]

 32/116 [=======>......................] - ETA: 1s
 64/116 [===============>..............] - ETA: 0s
 96/116 [=======================>......] - ETA: 0s
116/116 [==============================] - 2s 17ms/step
Test loss: 2.9279475376523774
Test accuracy: 0.629310340716921
[[30 28]
 [15 43]]
