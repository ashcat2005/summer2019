Using TensorFlow backend.
WARNING:tensorflow:From /n/home00/nchou/.conda/envs/envi/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.
Instructions for updating:
Colocations handled automatically by placer.
WARNING:tensorflow:From /n/home00/nchou/.conda/envs/envi/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.
Instructions for updating:
Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.
cnn_aardvark_aug_concat.py:397: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor("in..., outputs=Tensor("de...)`
  model = Model(input=ins, output=dense2)
WARNING:tensorflow:From /n/home00/nchou/.conda/envs/envi/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.cast instead.
2019-11-07 09:05:02.514319: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
2019-11-07 09:05:02.543359: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2900000000 Hz
2019-11-07 09:05:02.543516: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x5650b6fe8b60 executing computations on platform Host. Devices:
2019-11-07 09:05:02.543553: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (0): <undefined>, <undefined>
[0.25]
Train on 348 samples, validate on 116 samples
Epoch 1/25

174/348 [==============>...............] - ETA: 10s - loss: 0.6920 - acc: 0.5345
348/348 [==============================] - 22s 62ms/step - loss: 0.6932 - acc: 0.4943 - val_loss: 0.6916 - val_acc: 0.4224
Epoch 2/25

174/348 [==============>...............] - ETA: 8s - loss: 0.6870 - acc: 0.5115
348/348 [==============================] - 19s 56ms/step - loss: 0.6867 - acc: 0.5575 - val_loss: 0.6912 - val_acc: 0.4483
Epoch 3/25

174/348 [==============>...............] - ETA: 8s - loss: 0.6796 - acc: 0.5747
348/348 [==============================] - 19s 55ms/step - loss: 0.6807 - acc: 0.5833 - val_loss: 0.6938 - val_acc: 0.4483
Epoch 4/25

174/348 [==============>...............] - ETA: 8s - loss: 0.6697 - acc: 0.6552
348/348 [==============================] - 19s 55ms/step - loss: 0.6749 - acc: 0.6178 - val_loss: 0.6976 - val_acc: 0.4569
Epoch 5/25

174/348 [==============>...............] - ETA: 8s - loss: 0.6657 - acc: 0.5977
348/348 [==============================] - 19s 55ms/step - loss: 0.6690 - acc: 0.5920 - val_loss: 0.7034 - val_acc: 0.4483
Epoch 6/25

174/348 [==============>...............] - ETA: 8s - loss: 0.6577 - acc: 0.6092
348/348 [==============================] - 19s 55ms/step - loss: 0.6635 - acc: 0.5891 - val_loss: 0.7116 - val_acc: 0.4483
Epoch 7/25

174/348 [==============>...............] - ETA: 8s - loss: 0.6541 - acc: 0.5862
348/348 [==============================] - 19s 55ms/step - loss: 0.6580 - acc: 0.6034 - val_loss: 0.7215 - val_acc: 0.4397
Epoch 8/25

174/348 [==============>...............] - ETA: 8s - loss: 0.6578 - acc: 0.6207
348/348 [==============================] - 19s 56ms/step - loss: 0.6529 - acc: 0.5948 - val_loss: 0.7332 - val_acc: 0.4655
Epoch 9/25

174/348 [==============>...............] - ETA: 8s - loss: 0.6419 - acc: 0.6092
348/348 [==============================] - 19s 55ms/step - loss: 0.6482 - acc: 0.5891 - val_loss: 0.7464 - val_acc: 0.5000
Epoch 10/25

174/348 [==============>...............] - ETA: 8s - loss: 0.6345 - acc: 0.5805
348/348 [==============================] - 19s 56ms/step - loss: 0.6429 - acc: 0.6034 - val_loss: 0.7599 - val_acc: 0.5086
Epoch 11/25

174/348 [==============>...............] - ETA: 8s - loss: 0.6370 - acc: 0.6149
348/348 [==============================] - 19s 55ms/step - loss: 0.6386 - acc: 0.6006 - val_loss: 0.7703 - val_acc: 0.5000
Epoch 12/25

174/348 [==============>...............] - ETA: 8s - loss: 0.6511 - acc: 0.5575
348/348 [==============================] - 19s 55ms/step - loss: 0.6334 - acc: 0.6034 - val_loss: 0.7817 - val_acc: 0.5603
Epoch 13/25

174/348 [==============>...............] - ETA: 8s - loss: 0.6265 - acc: 0.6379
348/348 [==============================] - 19s 55ms/step - loss: 0.6282 - acc: 0.6322 - val_loss: 0.7946 - val_acc: 0.5603
Epoch 14/25

174/348 [==============>...............] - ETA: 8s - loss: 0.6316 - acc: 0.6322
348/348 [==============================] - 19s 55ms/step - loss: 0.6239 - acc: 0.6408 - val_loss: 0.8083 - val_acc: 0.5603
Epoch 15/25

174/348 [==============>...............] - ETA: 8s - loss: 0.6181 - acc: 0.6552
348/348 [==============================] - 19s 55ms/step - loss: 0.6190 - acc: 0.6494 - val_loss: 0.8187 - val_acc: 0.5690
Epoch 16/25

174/348 [==============>...............] - ETA: 8s - loss: 0.6277 - acc: 0.6609
348/348 [==============================] - 19s 55ms/step - loss: 0.6138 - acc: 0.6552 - val_loss: 0.8298 - val_acc: 0.5776
Epoch 17/25

174/348 [==============>...............] - ETA: 8s - loss: 0.6350 - acc: 0.6034
348/348 [==============================] - 19s 55ms/step - loss: 0.6095 - acc: 0.6552 - val_loss: 0.8371 - val_acc: 0.5948
Epoch 18/25

174/348 [==============>...............] - ETA: 8s - loss: 0.6118 - acc: 0.6609
348/348 [==============================] - 19s 55ms/step - loss: 0.6044 - acc: 0.6724 - val_loss: 0.8542 - val_acc: 0.5948
Epoch 19/25

174/348 [==============>...............] - ETA: 8s - loss: 0.5929 - acc: 0.6954
348/348 [==============================] - 19s 55ms/step - loss: 0.6000 - acc: 0.6868 - val_loss: 0.8726 - val_acc: 0.6034
Epoch 20/25

174/348 [==============>...............] - ETA: 8s - loss: 0.6082 - acc: 0.6494
348/348 [==============================] - 19s 55ms/step - loss: 0.5945 - acc: 0.6897 - val_loss: 0.8870 - val_acc: 0.5948
Epoch 21/25

174/348 [==============>...............] - ETA: 8s - loss: 0.5946 - acc: 0.7241
348/348 [==============================] - 19s 55ms/step - loss: 0.5887 - acc: 0.7069 - val_loss: 0.8925 - val_acc: 0.6207
Epoch 22/25

174/348 [==============>...............] - ETA: 8s - loss: 0.5943 - acc: 0.6839
348/348 [==============================] - 19s 55ms/step - loss: 0.5833 - acc: 0.6925 - val_loss: 0.8978 - val_acc: 0.6121
Epoch 23/25

174/348 [==============>...............] - ETA: 8s - loss: 0.5959 - acc: 0.6609
348/348 [==============================] - 19s 55ms/step - loss: 0.5773 - acc: 0.6954 - val_loss: 0.9191 - val_acc: 0.6121
Epoch 24/25

174/348 [==============>...............] - ETA: 8s - loss: 0.5565 - acc: 0.6897
348/348 [==============================] - 19s 55ms/step - loss: 0.5708 - acc: 0.7011 - val_loss: 0.9436 - val_acc: 0.5948
Epoch 25/25

174/348 [==============>...............] - ETA: 8s - loss: 0.5622 - acc: 0.7241
348/348 [==============================] - 19s 55ms/step - loss: 0.5640 - acc: 0.7155 - val_loss: 0.9504 - val_acc: 0.6034
Saved trained model at /n/holylfs03/LABS/berger_lab/nchou/saved_models/aardvark_aug11.h5 
[[6.5304434e-01 3.4695569e-01]
 [4.8276359e-01 5.1723641e-01]
 [7.0489168e-01 2.9510832e-01]
 [7.9696757e-01 2.0303242e-01]
 [6.1285865e-01 3.8714129e-01]
 [4.6288037e-01 5.3711957e-01]
 [2.2811137e-01 7.7188867e-01]
 [8.9509219e-01 1.0490777e-01]
 [5.3996629e-01 4.6003374e-01]
 [7.3842233e-01 2.6157767e-01]
 [3.4351096e-01 6.5648907e-01]
 [5.2909458e-01 4.7090545e-01]
 [4.4098803e-01 5.5901200e-01]
 [4.7464910e-01 5.2535093e-01]
 [4.3431917e-01 5.6568086e-01]
 [9.9654049e-01 3.4594296e-03]
 [4.0013942e-01 5.9986055e-01]
 [4.7968993e-01 5.2031010e-01]
 [7.5252593e-01 2.4747404e-01]
 [4.7711831e-01 5.2288163e-01]
 [2.2811137e-01 7.7188867e-01]
 [4.0013942e-01 5.9986055e-01]
 [2.8697518e-01 7.1302480e-01]
 [6.1285865e-01 3.8714129e-01]
 [4.7464910e-01 5.2535093e-01]
 [4.8046455e-01 5.1953548e-01]
 [4.7643313e-01 5.2356690e-01]
 [4.0594018e-01 5.9405982e-01]
 [4.5879763e-01 5.4120231e-01]
 [4.3431917e-01 5.6568086e-01]
 [4.4589692e-01 5.5410314e-01]
 [4.6896729e-01 5.3103274e-01]
 [4.9373949e-01 5.0626051e-01]
 [4.6901050e-01 5.3098947e-01]
 [9.7350401e-01 2.6496040e-02]
 [5.8391875e-01 4.1608122e-01]
 [9.9661785e-01 3.3821403e-03]
 [5.2909458e-01 4.7090545e-01]
 [4.5725170e-01 5.4274827e-01]
 [4.4589692e-01 5.5410314e-01]
 [3.4120765e-01 6.5879244e-01]
 [4.6204770e-01 5.3795224e-01]
 [8.0517000e-01 1.9483002e-01]
 [7.0489168e-01 2.9510832e-01]
 [3.5092089e-01 6.4907908e-01]
 [4.0157372e-01 5.9842628e-01]
 [4.3031028e-01 5.6968969e-01]
 [4.5334780e-01 5.4665220e-01]
 [4.5116809e-01 5.4883200e-01]
 [9.9661785e-01 3.3821403e-03]
 [1.2197316e-02 9.8780268e-01]
 [9.9661785e-01 3.3821403e-03]
 [9.9654049e-01 3.4594296e-03]
 [3.8769069e-01 6.1230928e-01]
 [5.0252515e-01 4.9747482e-01]
 [4.6429172e-01 5.3570831e-01]
 [4.8962995e-01 5.1037008e-01]
 [4.4589692e-01 5.5410314e-01]
 [4.8817047e-01 5.1182956e-01]
 [6.1285865e-01 3.8714129e-01]
 [8.9509219e-01 1.0490777e-01]
 [4.8046455e-01 5.1953548e-01]
 [4.4589692e-01 5.5410314e-01]
 [4.8559988e-01 5.1440006e-01]
 [2.2811137e-01 7.7188867e-01]
 [6.7931902e-01 3.2068101e-01]
 [4.8559988e-01 5.1440006e-01]
 [4.5116809e-01 5.4883200e-01]
 [4.2010689e-01 5.7989317e-01]
 [3.5769770e-01 6.4230227e-01]
 [9.9995136e-01 4.8603863e-05]
 [4.5945168e-01 5.4054832e-01]
 [4.5116809e-01 5.4883200e-01]
 [9.9877614e-01 1.2239021e-03]
 [4.6204770e-01 5.3795224e-01]
 [4.7683913e-01 5.2316087e-01]
 [5.2371508e-01 4.7628489e-01]
 [8.9509219e-01 1.0490777e-01]
 [5.2909458e-01 4.7090545e-01]
 [5.2909458e-01 4.7090545e-01]
 [9.9654049e-01 3.4594296e-03]
 [4.6263352e-01 5.3736645e-01]
 [3.5374036e-01 6.4625967e-01]
 [4.5334780e-01 5.4665220e-01]
 [3.2751983e-01 6.7248017e-01]
 [7.3842233e-01 2.6157767e-01]
 [8.3440085e-05 9.9991655e-01]
 [4.6896729e-01 5.3103274e-01]
 [9.8907846e-01 1.0921560e-02]
 [3.5489386e-01 6.4510614e-01]
 [4.9373949e-01 5.0626051e-01]
 [4.4960743e-01 5.5039257e-01]
 [1.3498349e-01 8.6501646e-01]
 [8.7383115e-01 1.2616888e-01]
 [8.8810271e-01 1.1189729e-01]
 [7.9696757e-01 2.0303242e-01]
 [8.9509219e-01 1.0490777e-01]
 [4.7578132e-01 5.2421868e-01]
 [4.9373949e-01 5.0626051e-01]
 [4.7155496e-01 5.2844507e-01]
 [7.9306477e-01 2.0693520e-01]
 [8.0517000e-01 1.9483002e-01]
 [7.0489168e-01 2.9510832e-01]
 [4.5843288e-01 5.4156709e-01]
 [4.7030163e-01 5.2969831e-01]
 [7.3842233e-01 2.6157767e-01]
 [5.3972363e-01 4.6027642e-01]
 [4.7770751e-01 5.2229249e-01]
 [9.9847633e-01 1.5236237e-03]
 [5.0252515e-01 4.9747482e-01]
 [4.4589692e-01 5.5410314e-01]
 [4.9686575e-01 5.0313425e-01]
 [4.4589692e-01 5.5410314e-01]
 [9.9847633e-01 1.5236237e-03]
 [4.3993267e-01 5.6006736e-01]
 [3.6561912e-01 6.3438088e-01]]
[0 1 0 0 0 1 1 0 0 0 1 0 1 1 1 0 1 1 0 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 0 0 0
 0 1 1 1 1 0 0 1 1 1 1 1 0 1 0 0 1 0 1 1 1 1 0 0 1 1 1 1 0 1 1 1 1 0 1 1 0
 1 1 0 0 0 0 0 1 1 1 1 0 1 1 0 1 1 1 1 0 0 0 0 1 1 1 0 0 0 1 1 0 0 1 0 0 1
 1 1 0 1 1]

 32/116 [=======>......................] - ETA: 1s
 64/116 [===============>..............] - ETA: 0s
 96/116 [=======================>......] - ETA: 0s
116/116 [==============================] - 2s 15ms/step
Test loss: 0.7611870806792687
Test accuracy: 0.698275860013633
[[34 24]
 [11 47]]
