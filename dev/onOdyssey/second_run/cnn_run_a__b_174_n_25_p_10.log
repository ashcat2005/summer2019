Using TensorFlow backend.
WARNING:tensorflow:From /n/home00/nchou/.conda/envs/envi/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.
Instructions for updating:
Colocations handled automatically by placer.
cnn_aardvark_aug_concat.py:397: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor("in..., outputs=Tensor("de...)`
  model = Model(input=ins, output=dense2)
WARNING:tensorflow:From /n/home00/nchou/.conda/envs/envi/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.cast instead.
2019-11-07 09:04:55.289135: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
2019-11-07 09:04:55.325635: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2900000000 Hz
2019-11-07 09:04:55.325849: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x56523c43eba0 executing computations on platform Host. Devices:
2019-11-07 09:04:55.325896: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (0): <undefined>, <undefined>
None
Train on 348 samples, validate on 116 samples
Epoch 1/25

174/348 [==============>...............] - ETA: 7s - loss: 0.6963 - acc: 0.4253
348/348 [==============================] - 14s 41ms/step - loss: 0.6924 - acc: 0.4914 - val_loss: 0.6874 - val_acc: 0.5603
Epoch 2/25

174/348 [==============>...............] - ETA: 5s - loss: 0.6805 - acc: 0.6897
348/348 [==============================] - 12s 35ms/step - loss: 0.6807 - acc: 0.6868 - val_loss: 0.6849 - val_acc: 0.4569
Epoch 3/25

174/348 [==============>...............] - ETA: 5s - loss: 0.6767 - acc: 0.7011
348/348 [==============================] - 12s 36ms/step - loss: 0.6680 - acc: 0.7155 - val_loss: 0.6850 - val_acc: 0.4655
Epoch 4/25

174/348 [==============>...............] - ETA: 5s - loss: 0.6606 - acc: 0.6839
348/348 [==============================] - 12s 35ms/step - loss: 0.6587 - acc: 0.6954 - val_loss: 0.6875 - val_acc: 0.4483
Epoch 5/25

174/348 [==============>...............] - ETA: 5s - loss: 0.6473 - acc: 0.7069
348/348 [==============================] - 12s 36ms/step - loss: 0.6494 - acc: 0.7126 - val_loss: 0.6918 - val_acc: 0.5172
Epoch 6/25

174/348 [==============>...............] - ETA: 5s - loss: 0.6485 - acc: 0.7414
348/348 [==============================] - 12s 35ms/step - loss: 0.6398 - acc: 0.7213 - val_loss: 0.6972 - val_acc: 0.5690
Epoch 7/25

174/348 [==============>...............] - ETA: 5s - loss: 0.6304 - acc: 0.7356
348/348 [==============================] - 12s 36ms/step - loss: 0.6313 - acc: 0.7213 - val_loss: 0.7051 - val_acc: 0.5862
Epoch 8/25

174/348 [==============>...............] - ETA: 5s - loss: 0.6267 - acc: 0.6954
348/348 [==============================] - 12s 36ms/step - loss: 0.6224 - acc: 0.7155 - val_loss: 0.7145 - val_acc: 0.5517
Epoch 9/25

174/348 [==============>...............] - ETA: 5s - loss: 0.6181 - acc: 0.6724
348/348 [==============================] - 12s 36ms/step - loss: 0.6135 - acc: 0.6954 - val_loss: 0.7251 - val_acc: 0.5603
Epoch 10/25

174/348 [==============>...............] - ETA: 5s - loss: 0.6206 - acc: 0.6667
348/348 [==============================] - 12s 36ms/step - loss: 0.6049 - acc: 0.6983 - val_loss: 0.7391 - val_acc: 0.5603
Epoch 11/25

174/348 [==============>...............] - ETA: 5s - loss: 0.5990 - acc: 0.7184
348/348 [==============================] - 13s 36ms/step - loss: 0.5967 - acc: 0.7011 - val_loss: 0.7527 - val_acc: 0.5517
Epoch 12/25

174/348 [==============>...............] - ETA: 5s - loss: 0.5792 - acc: 0.7356
348/348 [==============================] - 12s 36ms/step - loss: 0.5879 - acc: 0.7011 - val_loss: 0.7701 - val_acc: 0.5776
Epoch 13/25

174/348 [==============>...............] - ETA: 5s - loss: 0.5910 - acc: 0.6897
348/348 [==============================] - 13s 36ms/step - loss: 0.5790 - acc: 0.7126 - val_loss: 0.7909 - val_acc: 0.5776
Epoch 14/25

174/348 [==============>...............] - ETA: 5s - loss: 0.5668 - acc: 0.7011
348/348 [==============================] - 13s 36ms/step - loss: 0.5712 - acc: 0.7213 - val_loss: 0.8107 - val_acc: 0.5690
Epoch 15/25

174/348 [==============>...............] - ETA: 5s - loss: 0.5451 - acc: 0.7299
348/348 [==============================] - 12s 36ms/step - loss: 0.5615 - acc: 0.7098 - val_loss: 0.8247 - val_acc: 0.5517
Epoch 16/25

174/348 [==============>...............] - ETA: 5s - loss: 0.5541 - acc: 0.7011
348/348 [==============================] - 13s 36ms/step - loss: 0.5526 - acc: 0.7098 - val_loss: 0.8415 - val_acc: 0.5603
Epoch 17/25

174/348 [==============>...............] - ETA: 5s - loss: 0.5395 - acc: 0.7414
348/348 [==============================] - 13s 36ms/step - loss: 0.5458 - acc: 0.7155 - val_loss: 0.8623 - val_acc: 0.5603
Epoch 18/25

174/348 [==============>...............] - ETA: 5s - loss: 0.5456 - acc: 0.6897
348/348 [==============================] - 13s 36ms/step - loss: 0.5364 - acc: 0.7011 - val_loss: 0.8906 - val_acc: 0.5862
Epoch 19/25

174/348 [==============>...............] - ETA: 5s - loss: 0.5045 - acc: 0.7931
348/348 [==============================] - 13s 36ms/step - loss: 0.5284 - acc: 0.7328 - val_loss: 0.9102 - val_acc: 0.5948
Epoch 20/25

174/348 [==============>...............] - ETA: 5s - loss: 0.5272 - acc: 0.7356
348/348 [==============================] - 13s 36ms/step - loss: 0.5202 - acc: 0.7299 - val_loss: 0.9245 - val_acc: 0.5776
Epoch 21/25

174/348 [==============>...............] - ETA: 5s - loss: 0.5250 - acc: 0.7011
348/348 [==============================] - 13s 36ms/step - loss: 0.5120 - acc: 0.7328 - val_loss: 0.9476 - val_acc: 0.5776
Epoch 22/25

174/348 [==============>...............] - ETA: 5s - loss: 0.4924 - acc: 0.7414
348/348 [==============================] - 13s 36ms/step - loss: 0.5049 - acc: 0.7443 - val_loss: 0.9739 - val_acc: 0.6121
Epoch 23/25

174/348 [==============>...............] - ETA: 5s - loss: 0.4836 - acc: 0.7471
348/348 [==============================] - 13s 36ms/step - loss: 0.4969 - acc: 0.7356 - val_loss: 1.0004 - val_acc: 0.6121
Epoch 24/25

174/348 [==============>...............] - ETA: 5s - loss: 0.4748 - acc: 0.7586
348/348 [==============================] - 12s 36ms/step - loss: 0.4893 - acc: 0.7471 - val_loss: 1.0224 - val_acc: 0.6293
Epoch 25/25

174/348 [==============>...............] - ETA: 5s - loss: 0.4863 - acc: 0.7414
348/348 [==============================] - 12s 36ms/step - loss: 0.4834 - acc: 0.7529 - val_loss: 1.0439 - val_acc: 0.5862
Saved trained model at /n/holylfs03/LABS/berger_lab/nchou/saved_models/aardvark_aug11.h5 
[[6.6643131e-01 3.3356869e-01]
 [5.0699532e-01 4.9300468e-01]
 [9.0315622e-01 9.6843801e-02]
 [7.9462349e-01 2.0537651e-01]
 [4.7787073e-01 5.2212924e-01]
 [4.9536151e-01 5.0463843e-01]
 [3.4633987e-02 9.6536601e-01]
 [9.3458951e-01 6.5410547e-02]
 [5.4669827e-01 4.5330176e-01]
 [9.7529864e-01 2.4701353e-02]
 [5.6633055e-01 4.3366948e-01]
 [4.7441244e-01 5.2558750e-01]
 [4.5892677e-01 5.4107314e-01]
 [4.2693475e-01 5.7306534e-01]
 [3.8738653e-01 6.1261344e-01]
 [9.8822939e-01 1.1770591e-02]
 [2.7446815e-01 7.2553188e-01]
 [5.3231400e-01 4.6768597e-01]
 [6.2597388e-01 3.7402609e-01]
 [2.6011410e-01 7.3988587e-01]
 [3.4633987e-02 9.6536601e-01]
 [2.7446815e-01 7.2553188e-01]
 [2.7253386e-01 7.2746617e-01]
 [4.7787073e-01 5.2212924e-01]
 [4.2693475e-01 5.7306534e-01]
 [3.5534805e-01 6.4465195e-01]
 [4.7080448e-01 5.2919549e-01]
 [3.7813619e-01 6.2186378e-01]
 [5.0272810e-01 4.9727181e-01]
 [3.8738653e-01 6.1261344e-01]
 [5.1457047e-01 4.8542956e-01]
 [5.0119311e-01 4.9880689e-01]
 [4.3083122e-01 5.6916881e-01]
 [5.4116577e-01 4.5883432e-01]
 [9.8038691e-01 1.9613096e-02]
 [4.2754656e-01 5.7245338e-01]
 [2.9235124e-03 9.9707651e-01]
 [4.7441244e-01 5.2558750e-01]
 [5.1122236e-01 4.8877767e-01]
 [5.1457047e-01 4.8542956e-01]
 [3.0316776e-01 6.9683218e-01]
 [4.5392331e-01 5.4607666e-01]
 [1.2642387e-08 1.0000000e+00]
 [9.0315622e-01 9.6843801e-02]
 [4.2111927e-01 5.7888073e-01]
 [7.6866865e-01 2.3133130e-01]
 [3.7860823e-01 6.2139183e-01]
 [4.3473133e-01 5.6526870e-01]
 [3.8462129e-01 6.1537868e-01]
 [2.9235124e-03 9.9707651e-01]
 [2.2129927e-02 9.7787011e-01]
 [2.9235124e-03 9.9707651e-01]
 [9.8822939e-01 1.1770591e-02]
 [6.4909261e-01 3.5090736e-01]
 [5.4803228e-01 4.5196772e-01]
 [2.0578650e-03 9.9794215e-01]
 [5.7459795e-01 4.2540210e-01]
 [5.1457047e-01 4.8542956e-01]
 [4.8638025e-01 5.1361972e-01]
 [4.7787073e-01 5.2212924e-01]
 [9.3458951e-01 6.5410547e-02]
 [3.5534805e-01 6.4465195e-01]
 [5.1457047e-01 4.8542956e-01]
 [6.4655483e-01 3.5344511e-01]
 [3.4633987e-02 9.6536601e-01]
 [7.0760906e-01 2.9239094e-01]
 [6.4655483e-01 3.5344511e-01]
 [3.8462129e-01 6.1537868e-01]
 [4.4855306e-01 5.5144691e-01]
 [5.5511630e-01 4.4488373e-01]
 [8.0888975e-01 1.9111030e-01]
 [4.5216164e-01 5.4783839e-01]
 [3.8462129e-01 6.1537868e-01]
 [1.0000000e+00 7.9302800e-11]
 [4.5392331e-01 5.4607666e-01]
 [4.9255574e-01 5.0744426e-01]
 [6.3649046e-01 3.6350954e-01]
 [9.3458951e-01 6.5410547e-02]
 [4.7441244e-01 5.2558750e-01]
 [4.7441244e-01 5.2558750e-01]
 [9.8822939e-01 1.1770591e-02]
 [5.7939821e-01 4.2060179e-01]
 [3.4356502e-01 6.5643495e-01]
 [4.3473133e-01 5.6526870e-01]
 [4.1508380e-01 5.8491617e-01]
 [9.7529864e-01 2.4701353e-02]
 [3.3131585e-06 9.9999666e-01]
 [5.0119311e-01 4.9880689e-01]
 [7.1166089e-04 9.9928838e-01]
 [4.2245564e-01 5.7754439e-01]
 [4.3083122e-01 5.6916881e-01]
 [4.6785265e-01 5.3214729e-01]
 [1.6116297e-02 9.8388368e-01]
 [9.7955769e-01 2.0442285e-02]
 [9.2353565e-01 7.6464355e-02]
 [7.9462349e-01 2.0537651e-01]
 [9.3458951e-01 6.5410547e-02]
 [4.5245838e-01 5.4754168e-01]
 [4.3083122e-01 5.6916881e-01]
 [4.8630929e-01 5.1369077e-01]
 [9.3040246e-01 6.9597512e-02]
 [1.2642387e-08 1.0000000e+00]
 [9.0315622e-01 9.6843801e-02]
 [5.6535882e-01 4.3464109e-01]
 [4.9430114e-01 5.0569880e-01]
 [9.7529864e-01 2.4701353e-02]
 [4.4847745e-01 5.5152261e-01]
 [4.9787071e-01 5.0212926e-01]
 [9.9998140e-01 1.8545166e-05]
 [5.4803228e-01 4.5196772e-01]
 [5.1457047e-01 4.8542956e-01]
 [5.6631362e-01 4.3368641e-01]
 [5.1457047e-01 4.8542956e-01]
 [9.9998140e-01 1.8545166e-05]
 [4.3315983e-01 5.6684017e-01]
 [4.4136804e-01 5.5863202e-01]]
[0 0 0 0 1 1 1 0 0 0 0 1 1 1 1 0 1 0 0 1 1 1 1 1 1 1 1 1 0 1 0 0 1 0 0 1 1
 1 0 0 1 1 1 0 1 0 1 1 1 1 1 1 0 0 0 1 0 0 1 1 0 1 0 0 1 0 0 1 1 0 0 1 1 0
 1 1 0 0 1 1 0 0 1 1 1 0 1 0 1 1 1 1 1 0 0 0 0 1 1 1 0 1 0 0 1 0 1 1 0 0 0
 0 0 0 1 1]

 32/116 [=======>......................] - ETA: 1s
 64/116 [===============>..............] - ETA: 0s
 96/116 [=======================>......] - ETA: 0s
116/116 [==============================] - 1s 12ms/step
Test loss: 0.9198315308011812
Test accuracy: 0.6810344848139532
[[37 21]
 [16 42]]
