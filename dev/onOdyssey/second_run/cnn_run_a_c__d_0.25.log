Using TensorFlow backend.
WARNING:tensorflow:From /n/home00/nchou/.conda/envs/envi/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.
Instructions for updating:
Colocations handled automatically by placer.
WARNING:tensorflow:From /n/home00/nchou/.conda/envs/envi/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.
Instructions for updating:
Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.
cnn_aardvark_aug_concat.py:397: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor("in..., outputs=Tensor("de...)`
  model = Model(input=ins, output=dense2)
WARNING:tensorflow:From /n/home00/nchou/.conda/envs/envi/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.cast instead.
2019-11-07 09:03:35.172095: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
2019-11-07 09:03:35.176013: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2900000000 Hz
2019-11-07 09:03:35.176125: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x55d2e87bfe60 executing computations on platform Host. Devices:
2019-11-07 09:03:35.176144: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (0): <undefined>, <undefined>
[0.25]
Train on 348 samples, validate on 116 samples
Epoch 1/35

348/348 [==============================] - 24s 69ms/step - loss: 0.6932 - acc: 0.4684 - val_loss: 0.6854 - val_acc: 0.5517
Epoch 2/35

348/348 [==============================] - 22s 62ms/step - loss: 0.6792 - acc: 0.6868 - val_loss: 0.6769 - val_acc: 0.5603
Epoch 3/35

348/348 [==============================] - 21s 62ms/step - loss: 0.6621 - acc: 0.6810 - val_loss: 0.6672 - val_acc: 0.6121
Epoch 4/35

348/348 [==============================] - 21s 61ms/step - loss: 0.6411 - acc: 0.6695 - val_loss: 0.6770 - val_acc: 0.5000
Epoch 5/35

348/348 [==============================] - 21s 62ms/step - loss: 0.6281 - acc: 0.5718 - val_loss: 0.7155 - val_acc: 0.5690
Epoch 6/35

348/348 [==============================] - 21s 61ms/step - loss: 0.6727 - acc: 0.5546 - val_loss: 0.6918 - val_acc: 0.5000
Epoch 7/35

348/348 [==============================] - 21s 62ms/step - loss: 0.6120 - acc: 0.5718 - val_loss: 0.7041 - val_acc: 0.5000
Epoch 8/35

348/348 [==============================] - 21s 61ms/step - loss: 0.6084 - acc: 0.5747 - val_loss: 0.6901 - val_acc: 0.5948
Epoch 9/35

348/348 [==============================] - 21s 61ms/step - loss: 0.6094 - acc: 0.6149 - val_loss: 0.6704 - val_acc: 0.6034
Epoch 10/35

348/348 [==============================] - 21s 61ms/step - loss: 0.5641 - acc: 0.6724 - val_loss: 0.7506 - val_acc: 0.5000
Epoch 11/35

348/348 [==============================] - 21s 61ms/step - loss: 0.6023 - acc: 0.5833 - val_loss: 0.6842 - val_acc: 0.5862
Epoch 12/35

348/348 [==============================] - 21s 61ms/step - loss: 0.5400 - acc: 0.7414 - val_loss: 0.7206 - val_acc: 0.5948
Epoch 13/35

348/348 [==============================] - 21s 61ms/step - loss: 0.5720 - acc: 0.6322 - val_loss: 0.7302 - val_acc: 0.5345
Epoch 14/35

348/348 [==============================] - 21s 61ms/step - loss: 0.5356 - acc: 0.6753 - val_loss: 0.7380 - val_acc: 0.5431
Epoch 15/35

348/348 [==============================] - 21s 61ms/step - loss: 0.5245 - acc: 0.6753 - val_loss: 0.7527 - val_acc: 0.5948
Epoch 16/35

348/348 [==============================] - 21s 61ms/step - loss: 0.5429 - acc: 0.6552 - val_loss: 0.7413 - val_acc: 0.5948
Epoch 17/35

348/348 [==============================] - 21s 61ms/step - loss: 0.4937 - acc: 0.7586 - val_loss: 0.7938 - val_acc: 0.5259
Epoch 18/35

348/348 [==============================] - 21s 61ms/step - loss: 0.5138 - acc: 0.6753 - val_loss: 0.7872 - val_acc: 0.6034
Epoch 19/35

348/348 [==============================] - 21s 61ms/step - loss: 0.5111 - acc: 0.7011 - val_loss: 0.7797 - val_acc: 0.6293
Epoch 20/35

348/348 [==============================] - 21s 61ms/step - loss: 0.4680 - acc: 0.7701 - val_loss: 0.8362 - val_acc: 0.5431
Epoch 21/35

348/348 [==============================] - 21s 61ms/step - loss: 0.4894 - acc: 0.6897 - val_loss: 0.8468 - val_acc: 0.6034
Epoch 22/35

348/348 [==============================] - 21s 61ms/step - loss: 0.5028 - acc: 0.7040 - val_loss: 0.8414 - val_acc: 0.5086
Epoch 23/35

348/348 [==============================] - 21s 61ms/step - loss: 0.4550 - acc: 0.7414 - val_loss: 0.8560 - val_acc: 0.5345
Epoch 24/35

348/348 [==============================] - 21s 61ms/step - loss: 0.4469 - acc: 0.7557 - val_loss: 0.9031 - val_acc: 0.5862
Epoch 25/35

348/348 [==============================] - 21s 61ms/step - loss: 0.4855 - acc: 0.7328 - val_loss: 0.9714 - val_acc: 0.5172
Epoch 26/35

348/348 [==============================] - 21s 61ms/step - loss: 0.4966 - acc: 0.6810 - val_loss: 0.9310 - val_acc: 0.5862
Epoch 27/35

348/348 [==============================] - 21s 61ms/step - loss: 0.4604 - acc: 0.7356 - val_loss: 0.9276 - val_acc: 0.5776
Epoch 28/35

348/348 [==============================] - 21s 61ms/step - loss: 0.4210 - acc: 0.7644 - val_loss: 0.9475 - val_acc: 0.5948
Epoch 29/35

348/348 [==============================] - 21s 61ms/step - loss: 0.4158 - acc: 0.7759 - val_loss: 1.0030 - val_acc: 0.5948
Epoch 30/35

348/348 [==============================] - 21s 61ms/step - loss: 0.4527 - acc: 0.7443 - val_loss: 1.2122 - val_acc: 0.5000
Epoch 31/35

348/348 [==============================] - 21s 61ms/step - loss: 0.5986 - acc: 0.6695 - val_loss: 1.3755 - val_acc: 0.6121
Epoch 32/35

348/348 [==============================] - 21s 61ms/step - loss: 0.7552 - acc: 0.6695 - val_loss: 1.0768 - val_acc: 0.5690
Epoch 33/35

348/348 [==============================] - 21s 61ms/step - loss: 0.4443 - acc: 0.7184 - val_loss: 1.0971 - val_acc: 0.5690
Epoch 34/35

348/348 [==============================] - 21s 61ms/step - loss: 0.4433 - acc: 0.7184 - val_loss: 1.4953 - val_acc: 0.6034
Epoch 35/35

348/348 [==============================] - 21s 60ms/step - loss: 0.7843 - acc: 0.6724 - val_loss: 1.3507 - val_acc: 0.5000
Saved trained model at /n/holylfs03/LABS/berger_lab/nchou/saved_models/aardvark_aug11.h5 
[[9.8101246e-01 1.8987512e-02]
 [9.0334040e-01 9.6659586e-02]
 [1.0000000e+00 2.0496278e-09]
 [9.9462718e-01 5.3728097e-03]
 [9.7510785e-01 2.4892170e-02]
 [8.1497234e-01 1.8502770e-01]
 [1.7036611e-02 9.8296344e-01]
 [1.0000000e+00 3.5045875e-10]
 [9.2482108e-01 7.5178929e-02]
 [1.0000000e+00 5.3231208e-08]
 [9.4626534e-01 5.3734716e-02]
 [8.0600089e-01 1.9399911e-01]
 [7.8379333e-01 2.1620665e-01]
 [8.1825006e-01 1.8174995e-01]
 [8.0070060e-01 1.9929942e-01]
 [1.0000000e+00 1.9541810e-08]
 [8.2202065e-01 1.7797935e-01]
 [8.5285383e-01 1.4714615e-01]
 [9.9725646e-01 2.7435382e-03]
 [6.2499408e-02 9.3750060e-01]
 [1.7036611e-02 9.8296344e-01]
 [8.2202065e-01 1.7797935e-01]
 [2.4091691e-01 7.5908315e-01]
 [9.7510785e-01 2.4892170e-02]
 [8.1825006e-01 1.8174995e-01]
 [7.9353213e-01 2.0646793e-01]
 [8.0499560e-01 1.9500439e-01]
 [9.9241865e-01 7.5814091e-03]
 [8.3808291e-01 1.6191708e-01]
 [8.0070060e-01 1.9929942e-01]
 [7.9059696e-01 2.0940301e-01]
 [8.2436538e-01 1.7563459e-01]
 [8.0955696e-01 1.9044308e-01]
 [8.3218336e-01 1.6781665e-01]
 [1.0000000e+00 1.3436873e-08]
 [2.6699460e-01 7.3300540e-01]
 [9.9777538e-01 2.2245888e-03]
 [8.0600089e-01 1.9399911e-01]
 [8.3561170e-01 1.6438828e-01]
 [7.9059696e-01 2.0940301e-01]
 [8.6773932e-01 1.3226070e-01]
 [7.9757488e-01 2.0242511e-01]
 [2.9980415e-06 9.9999702e-01]
 [1.0000000e+00 2.0496278e-09]
 [5.7888472e-01 4.2111531e-01]
 [8.6629230e-01 1.3370767e-01]
 [7.7875376e-01 2.2124620e-01]
 [8.3200723e-01 1.6799280e-01]
 [7.4884528e-01 2.5115472e-01]
 [9.9777538e-01 2.2245888e-03]
 [8.1775654e-03 9.9182242e-01]
 [9.9777538e-01 2.2245888e-03]
 [1.0000000e+00 1.9541810e-08]
 [8.4575403e-01 1.5424594e-01]
 [9.0778106e-01 9.2218906e-02]
 [9.7768605e-01 2.2313975e-02]
 [9.3945229e-01 6.0547668e-02]
 [7.9059696e-01 2.0940301e-01]
 [8.1678897e-01 1.8321104e-01]
 [9.7510785e-01 2.4892170e-02]
 [1.0000000e+00 3.5045875e-10]
 [7.9353213e-01 2.0646793e-01]
 [7.9059696e-01 2.0940301e-01]
 [9.0279049e-01 9.7209513e-02]
 [1.7036611e-02 9.8296344e-01]
 [8.4109902e-01 1.5890092e-01]
 [9.0279049e-01 9.7209513e-02]
 [7.4884528e-01 2.5115472e-01]
 [5.8116335e-01 4.1883662e-01]
 [8.0545008e-01 1.9454992e-01]
 [1.9199407e-01 8.0800587e-01]
 [7.9606968e-01 2.0393036e-01]
 [7.4884528e-01 2.5115472e-01]
 [2.8793084e-02 9.7120684e-01]
 [7.9757488e-01 2.0242511e-01]
 [8.4335637e-01 1.5664360e-01]
 [9.6921825e-01 3.0781737e-02]
 [1.0000000e+00 3.5045875e-10]
 [8.0600089e-01 1.9399911e-01]
 [8.0600089e-01 1.9399911e-01]
 [1.0000000e+00 1.9541810e-08]
 [9.6403372e-01 3.5966229e-02]
 [7.8722328e-01 2.1277669e-01]
 [8.3200723e-01 1.6799280e-01]
 [6.7795026e-01 3.2204977e-01]
 [1.0000000e+00 5.3231208e-08]
 [9.8794949e-01 1.2050464e-02]
 [8.2436538e-01 1.7563459e-01]
 [9.7907579e-01 2.0924231e-02]
 [5.8711231e-01 4.1288775e-01]
 [8.0955696e-01 1.9044308e-01]
 [7.9465240e-01 2.0534764e-01]
 [7.6827180e-01 2.3172817e-01]
 [9.9886346e-01 1.1365381e-03]
 [9.9755740e-01 2.4425455e-03]
 [9.9462718e-01 5.3728097e-03]
 [1.0000000e+00 3.5045875e-10]
 [8.0921006e-01 1.9079000e-01]
 [8.0955696e-01 1.9044308e-01]
 [8.3239400e-01 1.6760598e-01]
 [9.4602299e-01 5.3977020e-02]
 [2.9980415e-06 9.9999702e-01]
 [1.0000000e+00 2.0496278e-09]
 [8.9317787e-01 1.0682214e-01]
 [8.1876528e-01 1.8123476e-01]
 [1.0000000e+00 5.3231208e-08]
 [7.8586358e-01 2.1413647e-01]
 [8.2434565e-01 1.7565438e-01]
 [1.0000000e+00 1.8138177e-12]
 [9.0778106e-01 9.2218906e-02]
 [7.9059696e-01 2.0940301e-01]
 [9.3868202e-01 6.1317928e-02]
 [7.9059696e-01 2.0940301e-01]
 [1.0000000e+00 1.8138177e-12]
 [5.7445931e-01 4.2554060e-01]
 [7.2346383e-01 2.7653617e-01]]
[0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0
 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 1
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0
 0 0 0 0 0]

 32/116 [=======>......................] - ETA: 1s
 64/116 [===============>..............] - ETA: 0s
 96/116 [=======================>......] - ETA: 0s
116/116 [==============================] - 2s 17ms/step
Test loss: 1.5272364904140603
Test accuracy: 0.47413793103448276
[[51  7]
 [54  4]]
