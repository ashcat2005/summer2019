Using TensorFlow backend.
WARNING:tensorflow:From /n/home00/nchou/.conda/envs/envi/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.
Instructions for updating:
Colocations handled automatically by placer.
WARNING:tensorflow:From /n/home00/nchou/.conda/envs/envi/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.
Instructions for updating:
Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.
cnn_aardvark_aug_concat.py:397: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor("in..., outputs=Tensor("de...)`
  model = Model(input=ins, output=dense2)
WARNING:tensorflow:From /n/home00/nchou/.conda/envs/envi/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.cast instead.
2019-11-07 11:44:43.034321: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
2019-11-07 11:44:43.095102: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2900000000 Hz
2019-11-07 11:44:43.095335: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x55b0aeadf870 executing computations on platform Host. Devices:
2019-11-07 11:44:43.095388: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (0): <undefined>, <undefined>
[0.25]
Train on 522 samples, validate on 174 samples
Epoch 1/40

174/522 [=========>....................] - ETA: 12s - loss: 1.1055 - acc: 0.3161
348/522 [===================>..........] - ETA: 5s - loss: 1.1027 - acc: 0.3017 
522/522 [==============================] - 18s 35ms/step - loss: 1.1016 - acc: 0.2874 - val_loss: 1.0925 - val_acc: 0.2644
Epoch 2/40

174/522 [=========>....................] - ETA: 10s - loss: 1.0905 - acc: 0.3908
348/522 [===================>..........] - ETA: 4s - loss: 1.0871 - acc: 0.4138 
522/522 [==============================] - 17s 33ms/step - loss: 1.0873 - acc: 0.4157 - val_loss: 1.0822 - val_acc: 0.3218
Epoch 3/40

174/522 [=========>....................] - ETA: 9s - loss: 1.0777 - acc: 0.3908
348/522 [===================>..........] - ETA: 5s - loss: 1.0793 - acc: 0.4282
522/522 [==============================] - 17s 33ms/step - loss: 1.0728 - acc: 0.4464 - val_loss: 1.0746 - val_acc: 0.2816
Epoch 4/40

174/522 [=========>....................] - ETA: 10s - loss: 1.0746 - acc: 0.4425
348/522 [===================>..........] - ETA: 5s - loss: 1.0609 - acc: 0.4914 
522/522 [==============================] - 17s 33ms/step - loss: 1.0601 - acc: 0.4885 - val_loss: 1.0688 - val_acc: 0.2874
Epoch 5/40

174/522 [=========>....................] - ETA: 10s - loss: 1.0483 - acc: 0.5345
348/522 [===================>..........] - ETA: 5s - loss: 1.0430 - acc: 0.5259 
522/522 [==============================] - 17s 33ms/step - loss: 1.0479 - acc: 0.4981 - val_loss: 1.0639 - val_acc: 0.3448
Epoch 6/40

174/522 [=========>....................] - ETA: 10s - loss: 1.0329 - acc: 0.5402
348/522 [===================>..........] - ETA: 5s - loss: 1.0406 - acc: 0.5316 
522/522 [==============================] - 17s 33ms/step - loss: 1.0335 - acc: 0.5268 - val_loss: 1.0613 - val_acc: 0.4770
Epoch 7/40

174/522 [=========>....................] - ETA: 10s - loss: 1.0168 - acc: 0.6034
348/522 [===================>..........] - ETA: 5s - loss: 1.0180 - acc: 0.5546 
522/522 [==============================] - 17s 33ms/step - loss: 1.0199 - acc: 0.5364 - val_loss: 1.0599 - val_acc: 0.4655
Epoch 8/40

174/522 [=========>....................] - ETA: 10s - loss: 1.0236 - acc: 0.4885
348/522 [===================>..........] - ETA: 5s - loss: 1.0055 - acc: 0.5230 
522/522 [==============================] - 17s 33ms/step - loss: 1.0051 - acc: 0.5402 - val_loss: 1.0620 - val_acc: 0.4713
Epoch 9/40

174/522 [=========>....................] - ETA: 10s - loss: 1.0211 - acc: 0.5230
348/522 [===================>..........] - ETA: 5s - loss: 1.0128 - acc: 0.5316 
522/522 [==============================] - 17s 33ms/step - loss: 0.9899 - acc: 0.5402 - val_loss: 1.0656 - val_acc: 0.4770
Epoch 10/40

174/522 [=========>....................] - ETA: 10s - loss: 0.9712 - acc: 0.5287
348/522 [===================>..........] - ETA: 5s - loss: 0.9779 - acc: 0.4885 
522/522 [==============================] - 17s 33ms/step - loss: 0.9750 - acc: 0.5134 - val_loss: 1.0730 - val_acc: 0.4598
Epoch 11/40

174/522 [=========>....................] - ETA: 10s - loss: 0.9831 - acc: 0.4770
348/522 [===================>..........] - ETA: 5s - loss: 0.9665 - acc: 0.5172 
522/522 [==============================] - 17s 33ms/step - loss: 0.9596 - acc: 0.5230 - val_loss: 1.0834 - val_acc: 0.4713
Epoch 12/40

174/522 [=========>....................] - ETA: 10s - loss: 0.9362 - acc: 0.5517
348/522 [===================>..........] - ETA: 5s - loss: 0.9459 - acc: 0.5546 
522/522 [==============================] - 17s 33ms/step - loss: 0.9451 - acc: 0.5307 - val_loss: 1.0963 - val_acc: 0.4713
Epoch 13/40

174/522 [=========>....................] - ETA: 10s - loss: 0.9448 - acc: 0.4770
348/522 [===================>..........] - ETA: 5s - loss: 0.9436 - acc: 0.5029 
522/522 [==============================] - 17s 33ms/step - loss: 0.9291 - acc: 0.5268 - val_loss: 1.1099 - val_acc: 0.4540
Epoch 14/40

174/522 [=========>....................] - ETA: 10s - loss: 0.9405 - acc: 0.5690
348/522 [===================>..........] - ETA: 5s - loss: 0.9294 - acc: 0.5374 
522/522 [==============================] - 17s 33ms/step - loss: 0.9145 - acc: 0.5345 - val_loss: 1.1268 - val_acc: 0.4655
Epoch 15/40

174/522 [=========>....................] - ETA: 10s - loss: 0.8751 - acc: 0.5977
348/522 [===================>..........] - ETA: 5s - loss: 0.8800 - acc: 0.5603 
522/522 [==============================] - 17s 33ms/step - loss: 0.9007 - acc: 0.5517 - val_loss: 1.1460 - val_acc: 0.4713
Epoch 16/40

174/522 [=========>....................] - ETA: 10s - loss: 0.9189 - acc: 0.5057
348/522 [===================>..........] - ETA: 5s - loss: 0.9176 - acc: 0.5172 
522/522 [==============================] - 17s 33ms/step - loss: 0.8851 - acc: 0.5632 - val_loss: 1.1636 - val_acc: 0.4598
Epoch 17/40

174/522 [=========>....................] - ETA: 10s - loss: 0.8568 - acc: 0.6092
348/522 [===================>..........] - ETA: 5s - loss: 0.8627 - acc: 0.5862 
522/522 [==============================] - 17s 33ms/step - loss: 0.8728 - acc: 0.5709 - val_loss: 1.1838 - val_acc: 0.4598
Epoch 18/40

174/522 [=========>....................] - ETA: 10s - loss: 0.8594 - acc: 0.5575
348/522 [===================>..........] - ETA: 5s - loss: 0.8461 - acc: 0.5920 
522/522 [==============================] - 17s 33ms/step - loss: 0.8593 - acc: 0.5843 - val_loss: 1.2050 - val_acc: 0.4713
Epoch 19/40

174/522 [=========>....................] - ETA: 10s - loss: 0.8545 - acc: 0.6092
348/522 [===================>..........] - ETA: 5s - loss: 0.8443 - acc: 0.6121 
522/522 [==============================] - 17s 33ms/step - loss: 0.8460 - acc: 0.6130 - val_loss: 1.2263 - val_acc: 0.4540
Epoch 20/40

174/522 [=========>....................] - ETA: 10s - loss: 0.7995 - acc: 0.6207
348/522 [===================>..........] - ETA: 5s - loss: 0.8102 - acc: 0.6178 
522/522 [==============================] - 17s 33ms/step - loss: 0.8344 - acc: 0.6092 - val_loss: 1.2455 - val_acc: 0.4828
Epoch 21/40

174/522 [=========>....................] - ETA: 10s - loss: 0.8409 - acc: 0.5920
348/522 [===================>..........] - ETA: 5s - loss: 0.8118 - acc: 0.6149 
522/522 [==============================] - 17s 33ms/step - loss: 0.8227 - acc: 0.5939 - val_loss: 1.2550 - val_acc: 0.4540
Epoch 22/40

174/522 [=========>....................] - ETA: 10s - loss: 0.7914 - acc: 0.6379
348/522 [===================>..........] - ETA: 5s - loss: 0.7949 - acc: 0.6322 
522/522 [==============================] - 17s 33ms/step - loss: 0.8118 - acc: 0.6188 - val_loss: 1.2682 - val_acc: 0.5172
Epoch 23/40

174/522 [=========>....................] - ETA: 10s - loss: 0.7796 - acc: 0.6494
348/522 [===================>..........] - ETA: 5s - loss: 0.8010 - acc: 0.6121 
522/522 [==============================] - 17s 33ms/step - loss: 0.7994 - acc: 0.6169 - val_loss: 1.2770 - val_acc: 0.5000
Epoch 24/40

174/522 [=========>....................] - ETA: 10s - loss: 0.7698 - acc: 0.6437
348/522 [===================>..........] - ETA: 5s - loss: 0.7909 - acc: 0.6322 
522/522 [==============================] - 17s 33ms/step - loss: 0.7915 - acc: 0.6437 - val_loss: 1.2913 - val_acc: 0.4598
Epoch 25/40

174/522 [=========>....................] - ETA: 10s - loss: 0.7948 - acc: 0.6437
348/522 [===================>..........] - ETA: 5s - loss: 0.7878 - acc: 0.6379 
522/522 [==============================] - 17s 33ms/step - loss: 0.7813 - acc: 0.6494 - val_loss: 1.2903 - val_acc: 0.5287
Epoch 26/40

174/522 [=========>....................] - ETA: 10s - loss: 0.7891 - acc: 0.6092
348/522 [===================>..........] - ETA: 5s - loss: 0.7609 - acc: 0.6408 
522/522 [==============================] - 17s 33ms/step - loss: 0.7700 - acc: 0.6398 - val_loss: 1.2954 - val_acc: 0.4770
Epoch 27/40

174/522 [=========>....................] - ETA: 10s - loss: 0.7379 - acc: 0.7069
348/522 [===================>..........] - ETA: 5s - loss: 0.7336 - acc: 0.6810 
522/522 [==============================] - 17s 33ms/step - loss: 0.7602 - acc: 0.6533 - val_loss: 1.3045 - val_acc: 0.4483
Epoch 28/40

174/522 [=========>....................] - ETA: 10s - loss: 0.7226 - acc: 0.6897
348/522 [===================>..........] - ETA: 5s - loss: 0.7428 - acc: 0.6724 
522/522 [==============================] - 17s 33ms/step - loss: 0.7504 - acc: 0.6609 - val_loss: 1.3070 - val_acc: 0.5000
Epoch 29/40

174/522 [=========>....................] - ETA: 10s - loss: 0.7384 - acc: 0.6667
348/522 [===================>..........] - ETA: 5s - loss: 0.7377 - acc: 0.6523 
522/522 [==============================] - 17s 33ms/step - loss: 0.7446 - acc: 0.6552 - val_loss: 1.3110 - val_acc: 0.5230
Epoch 30/40

174/522 [=========>....................] - ETA: 10s - loss: 0.7427 - acc: 0.6667
348/522 [===================>..........] - ETA: 5s - loss: 0.7365 - acc: 0.6667 
522/522 [==============================] - 17s 33ms/step - loss: 0.7311 - acc: 0.6667 - val_loss: 1.3166 - val_acc: 0.4425
Epoch 31/40

174/522 [=========>....................] - ETA: 10s - loss: 0.7077 - acc: 0.6667
348/522 [===================>..........] - ETA: 5s - loss: 0.7407 - acc: 0.6667 
522/522 [==============================] - 17s 33ms/step - loss: 0.7253 - acc: 0.6743 - val_loss: 1.3127 - val_acc: 0.4828
Epoch 32/40

174/522 [=========>....................] - ETA: 10s - loss: 0.7188 - acc: 0.6724
348/522 [===================>..........] - ETA: 5s - loss: 0.7099 - acc: 0.6810 
522/522 [==============================] - 17s 33ms/step - loss: 0.7179 - acc: 0.6724 - val_loss: 1.3188 - val_acc: 0.5287
Epoch 33/40

174/522 [=========>....................] - ETA: 10s - loss: 0.7384 - acc: 0.6437
348/522 [===================>..........] - ETA: 5s - loss: 0.7036 - acc: 0.6839 
522/522 [==============================] - 17s 33ms/step - loss: 0.7081 - acc: 0.6686 - val_loss: 1.3225 - val_acc: 0.4483
Epoch 34/40

174/522 [=========>....................] - ETA: 10s - loss: 0.7205 - acc: 0.7069
348/522 [===================>..........] - ETA: 5s - loss: 0.7134 - acc: 0.6868 
522/522 [==============================] - 17s 33ms/step - loss: 0.6999 - acc: 0.6877 - val_loss: 1.3202 - val_acc: 0.4828
Epoch 35/40

174/522 [=========>....................] - ETA: 10s - loss: 0.7220 - acc: 0.6437
348/522 [===================>..........] - ETA: 5s - loss: 0.7309 - acc: 0.6695 
522/522 [==============================] - 17s 33ms/step - loss: 0.6949 - acc: 0.6801 - val_loss: 1.3292 - val_acc: 0.5287
Epoch 36/40

174/522 [=========>....................] - ETA: 10s - loss: 0.6991 - acc: 0.6724
348/522 [===================>..........] - ETA: 5s - loss: 0.7059 - acc: 0.6638 
522/522 [==============================] - 17s 33ms/step - loss: 0.6850 - acc: 0.6820 - val_loss: 1.3278 - val_acc: 0.4885
Epoch 37/40

174/522 [=========>....................] - ETA: 10s - loss: 0.6974 - acc: 0.6379
348/522 [===================>..........] - ETA: 5s - loss: 0.6625 - acc: 0.6782 
522/522 [==============================] - 17s 33ms/step - loss: 0.6759 - acc: 0.6916 - val_loss: 1.3308 - val_acc: 0.4885
Epoch 38/40

174/522 [=========>....................] - ETA: 10s - loss: 0.6958 - acc: 0.6667
348/522 [===================>..........] - ETA: 5s - loss: 0.6678 - acc: 0.6983 
522/522 [==============================] - 17s 33ms/step - loss: 0.6674 - acc: 0.6916 - val_loss: 1.3352 - val_acc: 0.5172
Epoch 39/40

174/522 [=========>....................] - ETA: 10s - loss: 0.7150 - acc: 0.7011
348/522 [===================>..........] - ETA: 5s - loss: 0.6626 - acc: 0.7184 
522/522 [==============================] - 17s 33ms/step - loss: 0.6642 - acc: 0.7088 - val_loss: 1.3338 - val_acc: 0.5172
Epoch 40/40

174/522 [=========>....................] - ETA: 10s - loss: 0.6289 - acc: 0.7126
348/522 [===================>..........] - ETA: 5s - loss: 0.6140 - acc: 0.7385 
522/522 [==============================] - 17s 33ms/step - loss: 0.6580 - acc: 0.6992 - val_loss: 1.3384 - val_acc: 0.5000
Saved trained model at /n/holylfs03/LABS/berger_lab/nchou/saved_models/aardvark_aug11.h5 
[[4.18869793e-01 2.51802832e-01 3.29327434e-01]
 [3.08509767e-01 3.24187815e-01 3.67302358e-01]
 [3.15357894e-01 3.15573305e-01 3.69068831e-01]
 [2.26886377e-01 3.57360095e-01 4.15753573e-01]
 [3.50850374e-01 1.15501493e-01 5.33648133e-01]
 [9.98711467e-01 1.27210980e-03 1.64066132e-05]
 [4.07342911e-01 2.55804986e-01 3.36852103e-01]
 [3.23151469e-01 2.96440184e-01 3.80408347e-01]
 [2.08613500e-01 3.74864489e-01 4.16522026e-01]
 [3.26291621e-01 2.81642646e-01 3.92065734e-01]
 [6.24823391e-01 2.84383059e-01 9.07935649e-02]
 [3.05440545e-01 2.19922423e-01 4.74637061e-01]
 [4.02681381e-01 1.91520274e-01 4.05798286e-01]
 [3.44823629e-01 5.23672938e-01 1.31503388e-01]
 [5.66257000e-01 4.10118438e-02 3.92731160e-01]
 [5.85368574e-01 2.54955322e-01 1.59676075e-01]
 [8.27869284e-04 5.19780396e-03 9.93974388e-01]
 [2.76699513e-01 2.72502869e-01 4.50797677e-01]
 [9.66485262e-01 1.62800532e-02 1.72345974e-02]
 [3.12867105e-01 2.98494875e-01 3.88637990e-01]
 [3.21517229e-01 1.00890175e-01 5.77592552e-01]
 [1.05180115e-01 5.05062699e-01 3.89757097e-01]
 [4.79411155e-01 1.77530125e-01 3.43058676e-01]
 [1.37937605e-01 4.31498110e-01 4.30564314e-01]
 [4.79411155e-01 1.77530125e-01 3.43058676e-01]
 [3.38959903e-01 2.51553506e-01 4.09486502e-01]
 [3.76417607e-01 3.63454819e-01 2.60127544e-01]
 [7.55301863e-02 6.78279400e-01 2.46190414e-01]
 [1.74683452e-01 5.77600479e-01 2.47716069e-01]
 [2.74511546e-01 3.08594316e-01 4.16894108e-01]
 [9.99959946e-01 4.46508559e-11 4.00820390e-05]
 [4.79411155e-01 1.77530125e-01 3.43058676e-01]
 [4.12051022e-01 2.15124428e-01 3.72824490e-01]
 [2.92660385e-01 2.43573397e-01 4.63766158e-01]
 [1.85847418e-13 4.72196149e-09 1.00000000e+00]
 [2.41359949e-01 5.23621380e-01 2.35018656e-01]
 [2.75136143e-01 2.74091840e-01 4.50771987e-01]
 [1.97586358e-01 2.49661341e-01 5.52752316e-01]
 [8.34812105e-01 4.68096137e-02 1.18378311e-01]
 [4.35237676e-01 2.35400125e-01 3.29362243e-01]
 [9.99998569e-01 9.54408907e-09 1.42957379e-06]
 [1.97586358e-01 2.49661341e-01 5.52752316e-01]
 [8.96061718e-01 1.08418404e-03 1.02854073e-01]
 [9.66207325e-01 3.80848223e-06 3.37888785e-02]
 [9.66207325e-01 3.80848223e-06 3.37888785e-02]
 [3.60007316e-01 2.54488796e-01 3.85503858e-01]
 [3.78223062e-01 3.33205521e-01 2.88571447e-01]
 [2.33778387e-01 3.18792105e-01 4.47429508e-01]
 [8.34812105e-01 4.68096137e-02 1.18378311e-01]
 [3.33068460e-01 2.31555521e-01 4.35375959e-01]
 [3.76417607e-01 3.63454819e-01 2.60127544e-01]
 [3.49648386e-01 2.69466937e-01 3.80884647e-01]
 [3.13658327e-01 6.02343261e-01 8.39983821e-02]
 [2.39819959e-01 2.99510807e-01 4.60669219e-01]
 [3.87425125e-01 1.68542713e-01 4.44032073e-01]
 [5.22014380e-01 4.47208613e-01 3.07770018e-02]
 [9.59165469e-02 6.35204434e-01 2.68878996e-01]
 [8.25447023e-01 1.44238383e-01 3.03145591e-02]
 [2.54713356e-01 3.15654904e-01 4.29631650e-01]
 [2.08613500e-01 3.74864489e-01 4.16522026e-01]
 [4.79411155e-01 1.77530125e-01 3.43058676e-01]
 [6.07310832e-01 1.72534630e-01 2.20154494e-01]
 [4.67883438e-01 2.64731228e-01 2.67385393e-01]
 [4.71385865e-05 9.99952197e-01 6.57834732e-07]
 [2.90040690e-02 6.86840832e-01 2.84155101e-01]
 [9.99959946e-01 4.46508559e-11 4.00820390e-05]
 [9.99998569e-01 9.54408907e-09 1.42957379e-06]
 [9.99349177e-01 3.48201836e-04 3.02595436e-04]
 [4.12051022e-01 2.15124428e-01 3.72824490e-01]
 [3.53343993e-01 2.86157906e-01 3.60498071e-01]
 [3.77333343e-01 2.82762676e-01 3.39903921e-01]
 [2.35406607e-01 1.54788792e-01 6.09804571e-01]
 [1.97586358e-01 2.49661341e-01 5.52752316e-01]
 [2.82068700e-01 2.95879483e-01 4.22051758e-01]
 [2.45813638e-01 1.35553209e-02 7.40631044e-01]
 [1.66190858e-07 9.75095809e-01 2.49040388e-02]
 [3.70134622e-01 4.55183923e-01 1.74681425e-01]
 [2.76452661e-01 2.68518329e-01 4.55029041e-01]
 [3.24882805e-01 3.36807758e-01 3.38309377e-01]
 [2.17311218e-01 3.56738418e-01 4.25950438e-01]
 [4.62035974e-03 1.64425582e-01 8.30954134e-01]
 [1.30801708e-01 4.95834291e-01 3.73364002e-01]
 [4.27144706e-01 3.19714904e-01 2.53140360e-01]
 [2.33240768e-01 3.60047907e-01 4.06711370e-01]
 [4.44827408e-01 2.23685086e-01 3.31487477e-01]
 [1.95245117e-01 4.21235442e-01 3.83519411e-01]
 [2.68401504e-01 3.38494569e-01 3.93103957e-01]
 [9.99959946e-01 4.46508559e-11 4.00820390e-05]
 [3.50850374e-01 1.15501493e-01 5.33648133e-01]
 [4.71385865e-05 9.99952197e-01 6.57834732e-07]
 [9.98711467e-01 1.27210980e-03 1.64066132e-05]
 [3.31128359e-01 3.02862763e-01 3.66008878e-01]
 [2.35406607e-01 1.54788792e-01 6.09804571e-01]
 [1.00000000e+00 0.00000000e+00 1.84365029e-23]
 [2.89513350e-01 2.95877099e-01 4.14609492e-01]
 [2.35752508e-01 4.00835872e-01 3.63411695e-01]
 [2.39341319e-01 3.09175581e-01 4.51483071e-01]
 [9.66485262e-01 1.62800532e-02 1.72345974e-02]
 [3.71533751e-01 3.34209204e-01 2.94257015e-01]
 [3.13914394e-10 7.47874374e-17 1.00000000e+00]
 [4.17821199e-01 2.51955241e-01 3.30223620e-01]
 [9.99811709e-01 1.88261227e-04 3.64517092e-13]
 [2.66239047e-01 3.19556475e-01 4.14204419e-01]
 [2.91146368e-01 2.88000852e-01 4.20852751e-01]
 [2.07981467e-01 5.70086956e-01 2.21931681e-01]
 [3.13914394e-10 7.47874374e-17 1.00000000e+00]
 [4.62035974e-03 1.64425582e-01 8.30954134e-01]
 [2.21810251e-01 3.28573287e-01 4.49616432e-01]
 [4.12051022e-01 2.15124428e-01 3.72824490e-01]
 [3.38539295e-02 7.02160954e-01 2.63985097e-01]
 [2.74630666e-01 2.92598516e-01 4.32770878e-01]
 [2.75136143e-01 2.74091840e-01 4.50771987e-01]
 [1.05180115e-01 5.05062699e-01 3.89757097e-01]
 [3.43592614e-01 2.93082923e-01 3.63324523e-01]
 [4.79411155e-01 1.77530125e-01 3.43058676e-01]
 [3.23676206e-02 6.35210335e-01 3.32421988e-01]
 [6.73925161e-01 1.85878918e-01 1.40195891e-01]
 [2.87819743e-01 2.45648697e-01 4.66531575e-01]
 [3.47378075e-01 2.82364130e-01 3.70257765e-01]
 [2.08613500e-01 3.74864489e-01 4.16522026e-01]
 [2.41359949e-01 5.23621380e-01 2.35018656e-01]
 [1.65664196e-01 4.84524012e-01 3.49811763e-01]
 [9.97713804e-01 1.90453400e-04 2.09582294e-03]
 [1.95245117e-01 4.21235442e-01 3.83519411e-01]
 [1.47489309e-01 1.76609887e-04 8.52334082e-01]
 [9.66207325e-01 3.80848223e-06 3.37888785e-02]
 [2.78349191e-01 1.00045480e-01 6.21605277e-01]
 [9.98711467e-01 1.27210980e-03 1.64066132e-05]
 [3.86391163e-01 2.92292714e-01 3.21316093e-01]
 [8.54474232e-02 3.89077783e-01 5.25474727e-01]
 [3.44877630e-01 3.06769252e-01 3.48353058e-01]
 [4.66141403e-01 1.82066217e-01 3.51792455e-01]
 [2.28547123e-07 9.67989445e-01 3.20103653e-02]
 [4.23267484e-01 2.49250710e-01 3.27481747e-01]
 [8.42427016e-06 9.99991536e-01 2.77227290e-08]
 [1.38289273e-01 5.84764302e-01 2.76946485e-01]
 [3.96850318e-01 2.55318046e-01 3.47831637e-01]
 [9.99998927e-01 4.58009225e-07 5.76064906e-07]
 [5.42743325e-01 1.38606682e-01 3.18650037e-01]
 [6.73925161e-01 1.85878918e-01 1.40195891e-01]
 [1.95830059e-03 4.77526783e-08 9.98041630e-01]
 [2.94801086e-01 2.79141486e-01 4.26057428e-01]
 [2.79609352e-01 3.14988673e-01 4.05402005e-01]
 [4.34110194e-01 3.94445211e-01 1.71444625e-01]
 [4.35837597e-01 2.41219923e-01 3.22942525e-01]
 [4.62035974e-03 1.64425582e-01 8.30954134e-01]
 [3.20947245e-02 6.88353181e-01 2.79552013e-01]
 [4.24819589e-01 2.49277517e-01 3.25902939e-01]
 [1.64209828e-01 5.31642318e-01 3.04147840e-01]
 [3.34558398e-01 3.28519225e-01 3.36922318e-01]
 [3.74341756e-01 2.65344769e-01 3.60313445e-01]
 [4.07342911e-01 2.55804986e-01 3.36852103e-01]
 [2.22579345e-01 3.53224337e-01 4.24196273e-01]
 [4.79411155e-01 1.77530125e-01 3.43058676e-01]
 [9.66207325e-01 3.80848223e-06 3.37888785e-02]
 [7.77455568e-01 1.05576083e-01 1.16968378e-01]
 [2.35406607e-01 1.54788792e-01 6.09804571e-01]
 [1.17456878e-03 9.98825371e-01 1.25462407e-09]
 [1.30801708e-01 4.95834291e-01 3.73364002e-01]
 [4.34765577e-01 2.17832133e-01 3.47402275e-01]
 [8.59743953e-02 3.17978144e-01 5.96047461e-01]
 [4.71385865e-05 9.99952197e-01 6.57834732e-07]
 [1.97586358e-01 2.49661341e-01 5.52752316e-01]
 [2.79632628e-01 3.66779059e-01 3.53588402e-01]
 [3.13914210e-01 2.29327500e-01 4.56758231e-01]
 [3.64744872e-01 3.10982764e-01 3.24272394e-01]
 [1.75376460e-01 3.64418566e-01 4.60204929e-01]
 [9.66485262e-01 1.62800532e-02 1.72345974e-02]
 [4.82628584e-01 2.11645320e-01 3.05726111e-01]
 [4.46459353e-01 2.75568634e-01 2.77972043e-01]
 [2.93833047e-01 3.02937835e-01 4.03229147e-01]
 [3.96088779e-01 2.91645378e-01 3.12265873e-01]
 [2.28560060e-01 3.64735603e-01 4.06704366e-01]
 [3.82509023e-01 2.83817142e-01 3.33673835e-01]]
[0 2 2 2 2 0 0 2 2 2 0 2 2 1 0 0 2 2 0 2 2 1 0 1 0 2 0 1 1 2 0 0 0 2 2 1 2
 2 0 0 0 2 0 0 0 2 0 2 0 2 0 2 1 2 2 0 1 0 2 2 0 0 0 1 1 0 0 0 0 2 0 2 2 2
 2 1 1 2 2 2 2 1 0 2 0 1 2 0 2 1 0 2 2 0 2 1 2 0 0 2 0 0 2 2 1 2 2 2 0 1 2
 2 1 2 0 1 0 2 2 2 1 1 0 1 2 0 2 0 0 2 2 0 1 0 1 1 0 0 0 0 2 2 2 0 0 2 1 0
 1 2 0 0 2 0 0 0 2 1 1 0 2 1 2 1 2 0 2 0 0 0 2 0 2 0]

 32/174 [====>.........................] - ETA: 1s
 64/174 [==========>...................] - ETA: 1s
 96/174 [===============>..............] - ETA: 0s
128/174 [=====================>........] - ETA: 0s
160/174 [==========================>...] - ETA: 0s
174/174 [==============================] - 2s 11ms/step
Test loss: 1.7461905452026718
Test accuracy: 0.40804597718277197
[[40  4 14]
 [14  8 36]
 [15 20 23]]
