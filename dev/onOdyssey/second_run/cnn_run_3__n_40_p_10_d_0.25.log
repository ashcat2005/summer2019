Using TensorFlow backend.
WARNING:tensorflow:From /n/home00/nchou/.conda/envs/envi/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.
Instructions for updating:
Colocations handled automatically by placer.
WARNING:tensorflow:From /n/home00/nchou/.conda/envs/envi/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.
Instructions for updating:
Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.
cnn_aardvark_aug_concat.py:397: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor("in..., outputs=Tensor("de...)`
  model = Model(input=ins, output=dense2)
WARNING:tensorflow:From /n/home00/nchou/.conda/envs/envi/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.cast instead.
2019-11-07 11:44:58.112287: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
2019-11-07 11:44:58.181011: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2900000000 Hz
2019-11-07 11:44:58.181281: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x55ae9e2f6dd0 executing computations on platform Host. Devices:
2019-11-07 11:44:58.181335: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (0): <undefined>, <undefined>
[0.25]
Train on 522 samples, validate on 174 samples
Epoch 1/40

522/522 [==============================] - 22s 42ms/step - loss: 1.0987 - acc: 0.3640 - val_loss: 1.0917 - val_acc: 0.3448
Epoch 2/40

522/522 [==============================] - 19s 36ms/step - loss: 1.0908 - acc: 0.4195 - val_loss: 1.0856 - val_acc: 0.3333
Epoch 3/40

522/522 [==============================] - 19s 36ms/step - loss: 1.0822 - acc: 0.4923 - val_loss: 1.0800 - val_acc: 0.3276
Epoch 4/40

522/522 [==============================] - 18s 35ms/step - loss: 1.0736 - acc: 0.5077 - val_loss: 1.0751 - val_acc: 0.3563
Epoch 5/40

522/522 [==============================] - 19s 36ms/step - loss: 1.0653 - acc: 0.5115 - val_loss: 1.0710 - val_acc: 0.4080
Epoch 6/40

522/522 [==============================] - 18s 35ms/step - loss: 1.0572 - acc: 0.5115 - val_loss: 1.0677 - val_acc: 0.4540
Epoch 7/40

522/522 [==============================] - 19s 36ms/step - loss: 1.0493 - acc: 0.5249 - val_loss: 1.0650 - val_acc: 0.4425
Epoch 8/40

522/522 [==============================] - 18s 35ms/step - loss: 1.0415 - acc: 0.5307 - val_loss: 1.0629 - val_acc: 0.4425
Epoch 9/40

522/522 [==============================] - 19s 36ms/step - loss: 1.0339 - acc: 0.5364 - val_loss: 1.0615 - val_acc: 0.4540
Epoch 10/40

522/522 [==============================] - 18s 35ms/step - loss: 1.0264 - acc: 0.5498 - val_loss: 1.0605 - val_acc: 0.4713
Epoch 11/40

522/522 [==============================] - 19s 35ms/step - loss: 1.0190 - acc: 0.5441 - val_loss: 1.0601 - val_acc: 0.4655
Epoch 12/40

522/522 [==============================] - 19s 36ms/step - loss: 1.0116 - acc: 0.5421 - val_loss: 1.0605 - val_acc: 0.4655
Epoch 13/40

522/522 [==============================] - 18s 35ms/step - loss: 1.0043 - acc: 0.5307 - val_loss: 1.0615 - val_acc: 0.4713
Epoch 14/40

522/522 [==============================] - 19s 36ms/step - loss: 0.9971 - acc: 0.5230 - val_loss: 1.0632 - val_acc: 0.4713
Epoch 15/40

522/522 [==============================] - 19s 36ms/step - loss: 0.9898 - acc: 0.5249 - val_loss: 1.0656 - val_acc: 0.4655
Epoch 16/40

522/522 [==============================] - 19s 36ms/step - loss: 0.9827 - acc: 0.5249 - val_loss: 1.0687 - val_acc: 0.4655
Epoch 17/40

522/522 [==============================] - 19s 36ms/step - loss: 0.9756 - acc: 0.5307 - val_loss: 1.0724 - val_acc: 0.4655
Epoch 18/40

522/522 [==============================] - 19s 36ms/step - loss: 0.9686 - acc: 0.5364 - val_loss: 1.0768 - val_acc: 0.4655
Epoch 19/40

522/522 [==============================] - 19s 36ms/step - loss: 0.9615 - acc: 0.5364 - val_loss: 1.0819 - val_acc: 0.4655
Epoch 20/40

522/522 [==============================] - 19s 36ms/step - loss: 0.9545 - acc: 0.5364 - val_loss: 1.0876 - val_acc: 0.4770
Epoch 21/40

522/522 [==============================] - 19s 36ms/step - loss: 0.9475 - acc: 0.5287 - val_loss: 1.0938 - val_acc: 0.4713
Epoch 22/40

522/522 [==============================] - 19s 36ms/step - loss: 0.9405 - acc: 0.5326 - val_loss: 1.1004 - val_acc: 0.4770
Epoch 23/40

522/522 [==============================] - 19s 36ms/step - loss: 0.9336 - acc: 0.5402 - val_loss: 1.1075 - val_acc: 0.4770
Epoch 24/40

522/522 [==============================] - 19s 36ms/step - loss: 0.9267 - acc: 0.5421 - val_loss: 1.1151 - val_acc: 0.4770
Epoch 25/40

522/522 [==============================] - 19s 36ms/step - loss: 0.9198 - acc: 0.5632 - val_loss: 1.1233 - val_acc: 0.4885
Epoch 26/40

522/522 [==============================] - 19s 36ms/step - loss: 0.9130 - acc: 0.5651 - val_loss: 1.1321 - val_acc: 0.4828
Epoch 27/40

522/522 [==============================] - 19s 36ms/step - loss: 0.9062 - acc: 0.5670 - val_loss: 1.1411 - val_acc: 0.4770
Epoch 28/40

522/522 [==============================] - 19s 36ms/step - loss: 0.8996 - acc: 0.5670 - val_loss: 1.1505 - val_acc: 0.4828
Epoch 29/40

522/522 [==============================] - 19s 36ms/step - loss: 0.8930 - acc: 0.5709 - val_loss: 1.1601 - val_acc: 0.4770
Epoch 30/40

522/522 [==============================] - 19s 36ms/step - loss: 0.8864 - acc: 0.5709 - val_loss: 1.1698 - val_acc: 0.4540
Epoch 31/40

522/522 [==============================] - 19s 36ms/step - loss: 0.8800 - acc: 0.5862 - val_loss: 1.1795 - val_acc: 0.4540
Epoch 32/40

522/522 [==============================] - 19s 36ms/step - loss: 0.8736 - acc: 0.5805 - val_loss: 1.1890 - val_acc: 0.4540
Epoch 33/40

522/522 [==============================] - 19s 36ms/step - loss: 0.8673 - acc: 0.5900 - val_loss: 1.1986 - val_acc: 0.4540
Epoch 34/40

522/522 [==============================] - 19s 36ms/step - loss: 0.8611 - acc: 0.5977 - val_loss: 1.2081 - val_acc: 0.4598
Epoch 35/40

522/522 [==============================] - 19s 36ms/step - loss: 0.8550 - acc: 0.6073 - val_loss: 1.2175 - val_acc: 0.4713
Epoch 36/40

522/522 [==============================] - 19s 36ms/step - loss: 0.8490 - acc: 0.6130 - val_loss: 1.2267 - val_acc: 0.4713
Epoch 37/40

522/522 [==============================] - 19s 36ms/step - loss: 0.8430 - acc: 0.6130 - val_loss: 1.2359 - val_acc: 0.4770
Epoch 38/40

522/522 [==============================] - 19s 36ms/step - loss: 0.8371 - acc: 0.6169 - val_loss: 1.2448 - val_acc: 0.4828
Epoch 39/40

522/522 [==============================] - 19s 36ms/step - loss: 0.8313 - acc: 0.6207 - val_loss: 1.2534 - val_acc: 0.4828
Epoch 40/40

522/522 [==============================] - 19s 36ms/step - loss: 0.8255 - acc: 0.6169 - val_loss: 1.2606 - val_acc: 0.4828
Saved trained model at /n/holylfs03/LABS/berger_lab/nchou/saved_models/aardvark_aug11.h5 
[[3.3211491e-01 3.3254951e-01 3.3533567e-01]
 [2.9411528e-01 3.4698948e-01 3.5889524e-01]
 [2.9752421e-01 3.4352788e-01 3.5894793e-01]
 [2.2472589e-01 3.9739192e-01 3.7788212e-01]
 [3.2230622e-01 2.4283145e-01 4.3486232e-01]
 [9.6962255e-01 2.1693198e-02 8.6842654e-03]
 [3.2565802e-01 3.3181983e-01 3.4252208e-01]
 [2.9599857e-01 3.3783713e-01 3.6616427e-01]
 [2.7177885e-01 3.6626422e-01 3.6195692e-01]
 [3.1892890e-01 3.3019891e-01 3.5087222e-01]
 [3.9187163e-01 3.9166862e-01 2.1645971e-01]
 [3.0416569e-01 4.3430901e-01 2.6152530e-01]
 [3.2469642e-01 3.0209547e-01 3.7320805e-01]
 [3.0210072e-01 4.7474912e-01 2.2315013e-01]
 [4.0746862e-01 3.0313814e-01 2.8939322e-01]
 [3.9586616e-01 3.8850221e-01 2.1563163e-01]
 [1.0178004e-02 1.1131695e-01 8.7850499e-01]
 [2.7974486e-01 3.3568472e-01 3.8457039e-01]
 [8.3438903e-01 9.0022020e-02 7.5588897e-02]
 [2.9222938e-01 3.3617395e-01 3.7159669e-01]
 [3.2596368e-01 3.8274828e-01 2.9128814e-01]
 [1.5113197e-01 4.0916616e-01 4.3970188e-01]
 [3.5386735e-01 4.1125533e-01 2.3487730e-01]
 [1.5474840e-01 4.0275535e-01 4.4249627e-01]
 [3.5386735e-01 4.1125533e-01 2.3487730e-01]
 [3.1350654e-01 3.1697679e-01 3.6951664e-01]
 [3.5188624e-01 3.8531387e-01 2.6279989e-01]
 [2.4193874e-01 5.2084786e-01 2.3721339e-01]
 [2.3453009e-01 4.3571159e-01 3.2975838e-01]
 [2.9515842e-01 3.3898494e-01 3.6585668e-01]
 [9.9280047e-01 4.0972314e-05 7.1586347e-03]
 [3.5386735e-01 4.1125533e-01 2.3487730e-01]
 [3.1976464e-01 3.2625708e-01 3.5397831e-01]
 [2.9369929e-01 3.3002195e-01 3.7627876e-01]
 [7.6056049e-06 1.4554738e-03 9.9853694e-01]
 [2.6222035e-01 4.8237315e-01 2.5540644e-01]
 [2.7865055e-01 3.3718657e-01 3.8416278e-01]
 [2.8004676e-01 3.4791833e-01 3.7203491e-01]
 [5.3828770e-01 2.3387933e-01 2.2783294e-01]
 [3.4045395e-01 3.2543853e-01 3.3410749e-01]
 [9.9854565e-01 3.1375999e-04 1.1405613e-03]
 [2.8004676e-01 3.4791833e-01 3.7203491e-01]
 [8.3535647e-01 8.1364103e-02 8.3279490e-02]
 [8.2496166e-01 4.1954718e-03 1.7084284e-01]
 [8.2496166e-01 4.1954718e-03 1.7084284e-01]
 [3.1475472e-01 3.4057704e-01 3.4466827e-01]
 [3.1570369e-01 3.9009205e-01 2.9420426e-01]
 [2.6807207e-01 3.4350207e-01 3.8842586e-01]
 [5.3828770e-01 2.3387933e-01 2.2783294e-01]
 [3.0707887e-01 3.1936511e-01 3.7355602e-01]
 [3.5188624e-01 3.8531387e-01 2.6279989e-01]
 [3.1314754e-01 3.3207288e-01 3.5477960e-01]
 [3.7084362e-01 4.7414663e-01 1.5500975e-01]
 [2.7417934e-01 3.1986567e-01 4.0595505e-01]
 [3.2306895e-01 3.0598018e-01 3.7095088e-01]
 [3.5192639e-01 4.7122988e-01 1.7684379e-01]
 [2.1395594e-01 4.7428855e-01 3.1175554e-01]
 [6.5925533e-01 2.4934670e-01 9.1397911e-02]
 [2.0191339e-01 3.4545889e-01 4.5262769e-01]
 [2.7177885e-01 3.6626422e-01 3.6195692e-01]
 [3.5386735e-01 4.1125533e-01 2.3487730e-01]
 [4.2641214e-01 3.2453752e-01 2.4905030e-01]
 [3.9829281e-01 3.3005837e-01 2.7164888e-01]
 [6.1734888e-04 9.9936646e-01 1.6154108e-05]
 [1.9221011e-01 5.3040010e-01 2.7738982e-01]
 [9.9280047e-01 4.0972314e-05 7.1586347e-03]
 [9.9854565e-01 3.1375999e-04 1.1405613e-03]
 [9.7906464e-01 1.9203823e-02 1.7315575e-03]
 [3.1976464e-01 3.2625708e-01 3.5397831e-01]
 [3.1209517e-01 3.3760363e-01 3.5030121e-01]
 [3.2612878e-01 3.3804050e-01 3.3583078e-01]
 [2.5292757e-01 2.6834708e-01 4.7872537e-01]
 [2.8004676e-01 3.4791833e-01 3.7203491e-01]
 [3.0155167e-01 3.4018517e-01 3.5826313e-01]
 [3.2803789e-01 1.7189883e-01 5.0006336e-01]
 [1.6238475e-04 6.8877620e-01 3.1106144e-01]
 [3.9233568e-01 4.7989824e-01 1.2776601e-01]
 [3.3656037e-01 3.9178425e-01 2.7165535e-01]
 [3.1181568e-01 3.4706923e-01 3.4111500e-01]
 [2.1774453e-01 3.9638624e-01 3.8586915e-01]
 [2.7482219e-02 3.1727201e-01 6.5524572e-01]
 [2.4315865e-01 3.8511541e-01 3.7172595e-01]
 [3.9137542e-01 3.6283946e-01 2.4578510e-01]
 [2.7960303e-01 3.6524215e-01 3.5515478e-01]
 [3.4471199e-01 3.1135404e-01 3.4393400e-01]
 [2.7955988e-01 3.8584262e-01 3.3459753e-01]
 [2.8492349e-01 3.6197978e-01 3.5309666e-01]
 [9.9280047e-01 4.0972314e-05 7.1586347e-03]
 [3.2230622e-01 2.4283145e-01 4.3486232e-01]
 [6.1734888e-04 9.9936646e-01 1.6154108e-05]
 [9.6962255e-01 2.1693198e-02 8.6842654e-03]
 [3.0147845e-01 3.5912392e-01 3.3939770e-01]
 [2.5292757e-01 2.6834708e-01 4.7872537e-01]
 [9.9999988e-01 3.8672156e-12 1.7671492e-07]
 [2.7564996e-01 3.4930691e-01 3.7504315e-01]
 [2.8085512e-01 3.6697716e-01 3.5216773e-01]
 [2.7727604e-01 3.4555149e-01 3.7717244e-01]
 [8.3438903e-01 9.0022020e-02 7.5588897e-02]
 [3.0896822e-01 3.5300800e-01 3.3802384e-01]
 [8.1136626e-08 4.6397983e-09 9.9999988e-01]
 [3.2573685e-01 3.2867366e-01 3.4558952e-01]
 [9.9498379e-01 4.9502589e-03 6.5905857e-05]
 [2.8365278e-01 3.4801167e-01 3.6833549e-01]
 [2.9380745e-01 3.4004942e-01 3.6614314e-01]
 [2.5403461e-01 4.3386805e-01 3.1209728e-01]
 [8.1136626e-08 4.6397983e-09 9.9999988e-01]
 [2.7482219e-02 3.1727201e-01 6.5524572e-01]
 [1.7993686e-01 3.8320893e-01 4.3685415e-01]
 [3.1976464e-01 3.2625708e-01 3.5397831e-01]
 [1.9917563e-01 5.3092235e-01 2.6990208e-01]
 [2.9054561e-01 3.3955684e-01 3.6989754e-01]
 [2.7865055e-01 3.3718657e-01 3.8416278e-01]
 [1.5113197e-01 4.0916616e-01 4.3970188e-01]
 [2.9546380e-01 3.3738759e-01 3.6714858e-01]
 [3.5386735e-01 4.1125533e-01 2.3487730e-01]
 [9.6560255e-02 4.4793597e-01 4.5550385e-01]
 [4.5217413e-01 3.2200143e-01 2.2582440e-01]
 [2.7964494e-01 3.0101037e-01 4.1934469e-01]
 [3.1003171e-01 3.3367327e-01 3.5629505e-01]
 [2.7177885e-01 3.6626422e-01 3.6195692e-01]
 [2.6222035e-01 4.8237315e-01 2.5540644e-01]
 [2.1872920e-01 4.1701671e-01 3.6425406e-01]
 [9.3893051e-01 5.3816333e-02 7.2531193e-03]
 [2.7955988e-01 3.8584262e-01 3.3459753e-01]
 [6.8759439e-03 7.4193085e-04 9.9238211e-01]
 [8.2496166e-01 4.1954718e-03 1.7084284e-01]
 [2.8111017e-01 3.8185456e-01 3.3703524e-01]
 [9.6962255e-01 2.1693198e-02 8.6842654e-03]
 [3.1329700e-01 3.5190520e-01 3.3479774e-01]
 [1.4560896e-01 3.9002049e-01 4.6437052e-01]
 [2.9199472e-01 3.4199005e-01 3.6601520e-01]
 [3.4417245e-01 2.9057181e-01 3.6525574e-01]
 [2.2075974e-04 6.9736224e-01 3.0241701e-01]
 [3.3653212e-01 3.2795680e-01 3.3551115e-01]
 [1.7332292e-01 8.2068396e-01 5.9931246e-03]
 [2.3259820e-01 4.5158622e-01 3.1581563e-01]
 [3.2031476e-01 3.2855457e-01 3.5113057e-01]
 [9.9739528e-01 1.4046887e-03 1.1999973e-03]
 [3.7300050e-01 2.6668262e-01 3.6031687e-01]
 [4.5217413e-01 3.2200143e-01 2.2582440e-01]
 [1.5631674e-01 1.1334931e-02 8.3234835e-01]
 [2.7880254e-01 3.4486744e-01 3.7633005e-01]
 [2.8879374e-01 3.5138911e-01 3.5981712e-01]
 [4.0052131e-01 4.0168279e-01 1.9779585e-01]
 [3.3421227e-01 3.1721461e-01 3.4857312e-01]
 [2.7482219e-02 3.1727201e-01 6.5524572e-01]
 [1.9718534e-01 5.2681452e-01 2.7600008e-01]
 [3.3708996e-01 3.2797319e-01 3.3493689e-01]
 [2.1476361e-01 4.5938259e-01 3.2585382e-01]
 [3.0730003e-01 3.4944761e-01 3.4325239e-01]
 [3.2291147e-01 3.3082953e-01 3.4625906e-01]
 [3.2565802e-01 3.3181983e-01 3.4252208e-01]
 [2.6499110e-01 3.4817287e-01 3.8683599e-01]
 [3.5386735e-01 4.1125533e-01 2.3487730e-01]
 [8.2496166e-01 4.1954718e-03 1.7084284e-01]
 [5.9083039e-01 3.5292062e-01 5.6248993e-02]
 [2.5292757e-01 2.6834708e-01 4.7872537e-01]
 [2.8754704e-02 9.7108746e-01 1.5781105e-04]
 [2.4315865e-01 3.8511541e-01 3.7172595e-01]
 [3.4644276e-01 3.1532308e-01 3.3823410e-01]
 [1.6369335e-01 4.1078436e-01 4.2552230e-01]
 [6.1734888e-04 9.9936646e-01 1.6154108e-05]
 [2.8004676e-01 3.4791833e-01 3.7203491e-01]
 [2.8249249e-01 3.7334570e-01 3.4416184e-01]
 [3.0198410e-01 3.0915830e-01 3.8885763e-01]
 [3.1599638e-01 3.4313595e-01 3.4086767e-01]
 [2.6797259e-01 3.6469489e-01 3.6733252e-01]
 [8.3438903e-01 9.0022020e-02 7.5588897e-02]
 [3.4855479e-01 3.5540915e-01 2.9603609e-01]
 [3.7275317e-01 3.3639461e-01 2.9085225e-01]
 [2.9670435e-01 3.3530128e-01 3.6799440e-01]
 [3.2221138e-01 3.4321064e-01 3.3457798e-01]
 [2.7125371e-01 3.7089926e-01 3.5784701e-01]
 [3.1579080e-01 3.3812091e-01 3.4608823e-01]]
[2 2 2 1 2 0 2 2 1 2 0 1 2 1 0 0 2 2 0 2 1 2 1 2 1 2 1 1 1 2 0 1 2 2 2 1 2
 2 0 0 0 2 0 0 0 2 1 2 0 2 1 2 1 2 2 1 1 0 2 1 1 0 0 1 1 0 0 0 2 2 1 2 2 2
 2 1 1 1 1 1 2 1 0 1 0 1 1 0 2 1 0 1 2 0 2 1 2 0 1 2 2 0 2 2 1 2 2 2 2 1 2
 2 2 2 1 2 0 2 2 1 1 1 0 1 2 0 1 0 1 2 2 2 1 0 1 1 2 0 0 0 2 2 2 1 2 2 1 0
 1 1 2 2 2 1 0 0 2 1 1 0 2 1 2 1 2 1 2 0 1 0 2 1 1 2]

 32/174 [====>.........................] - ETA: 1s
 64/174 [==========>...................] - ETA: 1s
 96/174 [===============>..............] - ETA: 0s
128/174 [=====================>........] - ETA: 0s
160/174 [==========================>...] - ETA: 0s
174/174 [==============================] - 2s 12ms/step
Test loss: 1.4752990391062595
Test accuracy: 0.36781609298168927
[[26 13 19]
 [ 5 18 35]
 [ 9 29 20]]
